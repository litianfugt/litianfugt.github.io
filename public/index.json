[{"content":"ä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\næŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\nå‘å¸ƒäº 2025å¹´9æœˆ24æ—¥ ä¸Šåˆ10:30\n","permalink":"http://localhost:1313/thoughts/2025-09-24-first-thought/","summary":"\u003cp\u003eä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\u003c/p\u003e\n\u003cp\u003eæŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\u003c/p\u003e","title":"åšå®¢éšæƒ³åŠŸèƒ½ä¸Šçº¿äº†"},{"content":"ç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\næœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\nå‘å¸ƒäº 2025å¹´9æœˆ23æ—¥ ä¸‹åˆ3:45\n","permalink":"http://localhost:1313/thoughts/2025-09-23-meditation/","summary":"\u003cp\u003eç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\u003c/p\u003e\n\u003cp\u003eæœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\u003c/p\u003e","title":"å…³äºå†¥æƒ³å’Œç”Ÿæ´»å¹³è¡¡çš„æ€è€ƒ"},{"content":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š Gitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\nGitåŸºç¡€æ¦‚å¿µ ä»€ä¹ˆæ˜¯Gitï¼Ÿ Gitæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œç”±Linus Torvaldsäº2005å¹´åˆ›å»ºã€‚ä¸é›†ä¸­å¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ˆå¦‚SVNï¼‰ä¸åŒï¼ŒGitçš„æ¯ä¸ªå¼€å‘è€…éƒ½æ‹¥æœ‰å®Œæ•´çš„ä»£ç ä»“åº“å‰¯æœ¬ï¼Œè¿™ä½¿å¾—Gitåœ¨é€Ÿåº¦ã€æ•°æ®å®Œæ•´æ€§å’Œæ”¯æŒåˆ†å¸ƒå¼å¼€å‘æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚\nGitçš„åŸºæœ¬å·¥ä½œåŒº Gitæœ‰ä¸‰ä¸ªä¸»è¦çš„å·¥ä½œåŒºï¼š\nå·¥ä½œåŒº(Working Directory)ï¼šä½ å½“å‰æ­£åœ¨å·¥ä½œçš„ç›®å½•ï¼ŒåŒ…å«é¡¹ç›®çš„æ‰€æœ‰æ–‡ä»¶ã€‚ æš‚å­˜åŒº(Staging Area)ï¼šä¹Ÿç§°ä¸º\u0026quot;ç´¢å¼•(Index)\u0026quot;ï¼Œæ˜¯ä¸€ä¸ªä¸´æ—¶ä¿å­˜ä¿®æ”¹çš„åœ°æ–¹ã€‚ æœ¬åœ°ä»“åº“(Local Repository)ï¼šGitä¿å­˜é¡¹ç›®å…ƒæ•°æ®å’Œå¯¹è±¡æ•°æ®åº“çš„åœ°æ–¹ã€‚ æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªè¿œç¨‹ä»“åº“(Remote Repository)ï¼Œé€šå¸¸æ˜¯æ‰˜ç®¡åœ¨GitHubã€GitLabç­‰å¹³å°ä¸Šçš„ä»“åº“ï¼Œç”¨äºå›¢é˜Ÿåä½œå’Œå¤‡ä»½ã€‚\nGitçš„åŸºæœ¬å·¥ä½œæµç¨‹ Gitçš„åŸºæœ¬å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\nåœ¨å·¥ä½œåŒºä¿®æ”¹æ–‡ä»¶ ä½¿ç”¨git addå°†ä¿®æ”¹æ·»åŠ åˆ°æš‚å­˜åŒº ä½¿ç”¨git commitå°†æš‚å­˜åŒºçš„å†…å®¹æäº¤åˆ°æœ¬åœ°ä»“åº“ ä½¿ç”¨git pushå°†æœ¬åœ°ä»“åº“çš„ä¿®æ”¹æ¨é€åˆ°è¿œç¨‹ä»“åº“ GitåŸºæœ¬å‘½ä»¤ åˆå§‹åŒ–é…ç½® é…ç½®ç”¨æˆ·ä¿¡æ¯ 1 2 3 4 5 6 7 8 # é…ç½®å…¨å±€ç”¨æˆ·å git config --global user.name \u0026#34;Your Name\u0026#34; # é…ç½®å…¨å±€é‚®ç®± git config --global user.email \u0026#34;your.email@example.com\u0026#34; # æŸ¥çœ‹é…ç½® git config --list åˆå§‹åŒ–ä»“åº“ 1 2 3 4 5 # åœ¨å½“å‰ç›®å½•åˆå§‹åŒ–Gitä»“åº“ git init # å…‹éš†è¿œç¨‹ä»“åº“ git clone https://github.com/username/repository.git åŸºæœ¬æ“ä½œ æŸ¥çœ‹çŠ¶æ€ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # æŸ¥çœ‹å·¥ä½œåŒºçŠ¶æ€ git status # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä¿®æ”¹æƒ…å†µ # æŸ¥çœ‹ç®€åŒ–çŠ¶æ€ git status -s # ç®€åŒ–è¾“å‡ºï¼Œé€‚åˆå¿«é€ŸæŸ¥çœ‹ # æŸ¥çœ‹æäº¤å†å² git log # æ˜¾ç¤ºè¯¦ç»†æäº¤è®°å½• # æŸ¥çœ‹ç®€æ´æäº¤å†å² git log --oneline # æ¯æ¡æäº¤ä¸€è¡Œï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ # æŸ¥çœ‹å›¾å½¢åŒ–æäº¤å†å² git log --graph --oneline --all æ·»åŠ å’Œæäº¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ·»åŠ æŒ‡å®šæ–‡ä»¶åˆ°æš‚å­˜åŒº git add filename # æ·»åŠ æ‰€æœ‰ä¿®æ”¹åˆ°æš‚å­˜åŒº git add . # æ·»åŠ æ‰€æœ‰ä¿®æ”¹ï¼ˆåŒ…æ‹¬æ–°æ–‡ä»¶ï¼‰åˆ°æš‚å­˜åŒº git add -A # æäº¤æš‚å­˜åŒºå†…å®¹ git commit -m \u0026#34;Commit message\u0026#34; # è·³è¿‡æš‚å­˜åŒºç›´æ¥æäº¤ git commit -a -m \u0026#34;Commit message\u0026#34; # ä¿®æ”¹æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯ git commit --amend æŸ¥çœ‹å’Œæ¯”è¾ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æŸ¥çœ‹å·¥ä½œåŒºä¸æš‚å­˜åŒºçš„å·®å¼‚ git diff # æŸ¥çœ‹æš‚å­˜åŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff --staged # æŸ¥çœ‹å·¥ä½œåŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff HEAD # æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶çš„å·®å¼‚ git diff filename # æŸ¥çœ‹æŒ‡å®šæäº¤çš„å·®å¼‚ git diff commit1 commit2 æ’¤é”€æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ’¤é”€å·¥ä½œåŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°æš‚å­˜åŒºçŠ¶æ€ï¼‰ git checkout -- filename # æ’¤é”€æš‚å­˜åŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°å·¥ä½œåŒºçŠ¶æ€ï¼‰ git reset HEAD filename # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~1 # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~1 # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~n # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~n è¿œç¨‹ä»“åº“æ“ä½œ æ·»åŠ å’Œç®¡ç†è¿œç¨‹ä»“åº“ 1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹è¿œç¨‹ä»“åº“ git remote -v # æ·»åŠ è¿œç¨‹ä»“åº“ git remote add origin https://github.com/username/repository.git # åˆ é™¤è¿œç¨‹ä»“åº“ git remote remove origin # ä¿®æ”¹è¿œç¨‹ä»“åº“URL git remote set-url origin https://github.com/username/new-repository.git æ¨é€å’Œæ‹‰å– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin main # æ¨é€å¹¶è®¾ç½®ä¸Šæ¸¸åˆ†æ”¯ git push -u origin main # æ‹‰å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ git pull origin main # è·å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ï¼ˆä¸åˆå¹¶ï¼‰ git fetch origin # åˆå¹¶è¿œç¨‹åˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge origin/main åˆ†æ”¯ç®¡ç† åˆ†æ”¯çš„åŸºæœ¬æ“ä½œ åˆ›å»ºå’Œåˆ‡æ¢åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # åˆ›å»ºæ–°åˆ†æ”¯ git branch feature-branch # åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯ git checkout feature-branch # åˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯ git checkout -b feature-branch # æŸ¥çœ‹æ‰€æœ‰åˆ†æ”¯ git branch -a # æŸ¥çœ‹æœ¬åœ°åˆ†æ”¯ git branch # æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯ git branch -r åˆå¹¶åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 # åˆ‡æ¢åˆ°ç›®æ ‡åˆ†æ”¯ git checkout main # åˆå¹¶æŒ‡å®šåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge feature-branch # åˆ é™¤å·²åˆå¹¶çš„åˆ†æ”¯ git branch -d feature-branch # å¼ºåˆ¶åˆ é™¤åˆ†æ”¯ï¼ˆå³ä½¿æœªåˆå¹¶ï¼‰ git branch -D feature-branch è§£å†³åˆå¹¶å†²çª å½“åˆå¹¶åˆ†æ”¯æ—¶ï¼Œå¦‚æœä¸¤ä¸ªåˆ†æ”¯å¯¹åŒä¸€æ–‡ä»¶çš„åŒä¸€éƒ¨åˆ†è¿›è¡Œäº†ä¸åŒçš„ä¿®æ”¹ï¼Œå°±ä¼šäº§ç”Ÿåˆå¹¶å†²çªã€‚è§£å†³åˆå¹¶å†²çªçš„æ­¥éª¤å¦‚ä¸‹ï¼š\næ‰§è¡Œgit mergeå‘½ä»¤ï¼ŒGitä¼šæ ‡è®°å†²çªæ–‡ä»¶ æ‰“å¼€å†²çªæ–‡ä»¶ï¼ŒæŸ¥çœ‹å†²çªæ ‡è®°ï¼ˆ\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;, =======, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;ï¼‰ æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶ï¼Œè§£å†³å†²çª ä½¿ç”¨git addæ ‡è®°å†²çªå·²è§£å†³ ä½¿ç”¨git commitå®Œæˆåˆå¹¶ 1 2 3 4 5 6 7 8 9 10 11 # åˆå¹¶åˆ†æ”¯ï¼ˆå‡è®¾äº§ç”Ÿå†²çªï¼‰ git merge feature-branch # æŸ¥çœ‹å†²çªçŠ¶æ€ git status # æ‰‹åŠ¨è§£å†³å†²çªåï¼Œæ ‡è®°å·²è§£å†³ git add conflicted-file # å®Œæˆåˆå¹¶ git commit å˜åŸº(Rebase) å˜åŸºæ˜¯å°†ä¸€ç³»åˆ—æäº¤åº”ç”¨åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šçš„æ“ä½œï¼Œå®ƒå¯ä»¥ä½¿æäº¤å†å²æ›´åŠ çº¿æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # å˜åŸºå½“å‰åˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main # å˜åŸºæŒ‡å®šåˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main feature-branch # äº¤äº’å¼å˜åŸºï¼ˆå¯ä»¥ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æäº¤ï¼‰ git rebase -i HEAD~3 # ç»§ç»­å˜åŸºï¼ˆè§£å†³å†²çªåï¼‰ git rebase --continue # å–æ¶ˆå˜åŸº git rebase --abort æ ‡ç­¾ç®¡ç† æ ‡ç­¾ç”¨äºæ ‡è®°é‡è¦çš„æäº¤ç‚¹ï¼Œé€šå¸¸ç”¨äºç‰ˆæœ¬å‘å¸ƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # åˆ›å»ºè½»é‡æ ‡ç­¾ git tag v1.0.0 # åˆ›å»ºå¸¦æ³¨é‡Šçš„æ ‡ç­¾ git tag -a v1.0.0 -m \u0026#34;Version 1.0.0 release\u0026#34; # æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾ git tag # æŸ¥çœ‹æ ‡ç­¾ä¿¡æ¯ git show v1.0.0 # æ¨é€æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin v1.0.0 # æ¨é€æ‰€æœ‰æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin --tags # åˆ é™¤æœ¬åœ°æ ‡ç­¾ git tag -d v1.0.0 # åˆ é™¤è¿œç¨‹æ ‡ç­¾ git push origin :refs/tags/v1.0.0 Gitå·¥ä½œæµæ¨¡å‹ é›†ä¸­å¼å·¥ä½œæµ é›†ä¸­å¼å·¥ä½œæµæ˜¯æœ€ç®€å•çš„å·¥ä½œæµï¼Œç±»ä¼¼äºSVNçš„å·¥ä½œæ–¹å¼ã€‚æ‰€æœ‰å¼€å‘è€…ç›´æ¥åœ¨ä¸»åˆ†æ”¯ä¸Šå·¥ä½œï¼Œé€‚åˆå°å‹é¡¹ç›®æˆ–ä¸ªäººé¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nå…‹éš†ä»“åº“ åœ¨ä¸»åˆ†æ”¯ä¸Šä¿®æ”¹ä»£ç  æäº¤ä¿®æ”¹ æ¨é€åˆ°è¿œç¨‹ä»“åº“ ä¼˜ç‚¹ï¼š\nç®€å•ç›´è§‚ æ— éœ€å­¦ä¹ åˆ†æ”¯ç®¡ç† ç¼ºç‚¹ï¼š\nå®¹æ˜“äº§ç”Ÿå†²çª ä¸é€‚åˆå›¢é˜Ÿåä½œ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµä¸ºæ¯ä¸ªæ–°åŠŸèƒ½åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„åˆ†æ”¯ï¼Œå¼€å‘å®Œæˆåå†åˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»ä¸»åˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›ä¸»åˆ†æ”¯ åˆ é™¤åŠŸèƒ½åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # åˆ‡æ¢åˆ°ä¸»åˆ†æ”¯ git checkout main # åˆå¹¶åŠŸèƒ½åˆ†æ”¯ git merge feature/new-feature # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature ä¼˜ç‚¹ï¼š\nåŠŸèƒ½éš”ç¦»ï¼Œå‡å°‘å†²çª ä¸»åˆ†æ”¯ä¿æŒç¨³å®š ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\néœ€è¦ç®¡ç†å¤šä¸ªåˆ†æ”¯ åˆå¹¶å¯èƒ½äº§ç”Ÿå†²çª Git Flowå·¥ä½œæµ Git Flowæ˜¯ä¸€ç§æ›´å¤æ‚çš„å·¥ä½œæµï¼Œå®šä¹‰äº†ä¸¥æ ¼çš„åˆ†æ”¯æ¨¡å‹ï¼Œé€‚ç”¨äºå¤§å‹é¡¹ç›®å’Œæ­£å¼å‘å¸ƒã€‚\nåˆ†æ”¯ç±»å‹ï¼š\nmainï¼šä¸»åˆ†æ”¯ï¼Œå§‹ç»ˆä¿æŒå¯å‘å¸ƒçŠ¶æ€ developï¼šå¼€å‘åˆ†æ”¯ï¼Œé›†æˆæ‰€æœ‰åŠŸèƒ½ featureï¼šåŠŸèƒ½åˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œå®Œæˆååˆå¹¶å›develop releaseï¼šå‘å¸ƒåˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œç”¨äºå‡†å¤‡å‘å¸ƒ hotfixï¼šä¿®å¤åˆ†æ”¯ï¼Œä»mainåˆ›å»ºï¼Œç”¨äºç´§æ€¥ä¿®å¤ å·¥ä½œæµç¨‹ï¼š\nä»developåˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›develop ä»developåˆ›å»ºå‘å¸ƒåˆ†æ”¯ æµ‹è¯•å’Œä¿®å¤ åˆå¹¶å‘å¸ƒåˆ†æ”¯åˆ°mainå’Œdevelop ä»mainåˆ›å»ºä¿®å¤åˆ†æ”¯ ä¿®å¤ååˆå¹¶åˆ°mainå’Œdevelop 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # åˆå§‹åŒ–Git Flow git flow init # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git flow feature start new-feature # å®ŒæˆåŠŸèƒ½åˆ†æ”¯ git flow feature finish new-feature # åˆ›å»ºå‘å¸ƒåˆ†æ”¯ git flow release start v1.0.0 # å®Œæˆå‘å¸ƒåˆ†æ”¯ git flow release finish v1.0.0 # åˆ›å»ºä¿®å¤åˆ†æ”¯ git flow hotfix start critical-fix # å®Œæˆä¿®å¤åˆ†æ”¯ git flow hotfix finish critical-fix ä¼˜ç‚¹ï¼š\nç»“æ„æ¸…æ™°ï¼ŒèŒè´£æ˜ç¡® é€‚åˆæ­£å¼å‘å¸ƒ æ”¯æŒç´§æ€¥ä¿®å¤ ç¼ºç‚¹ï¼š\næµç¨‹å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜ åˆ†æ”¯ç®¡ç†ç¹ç å¯¹äºå°å‹é¡¹ç›®è¿‡äºå¤æ‚ GitHub Flowå·¥ä½œæµ GitHub Flowæ˜¯GitHubä½¿ç”¨çš„ä¸€ç§ç®€åŒ–å·¥ä½œæµï¼Œé€‚åˆæŒç»­éƒ¨ç½²çš„é¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºPull Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ éƒ¨ç½² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitHubä¸Šåˆ›å»ºPull Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature git push origin --delete feature/new-feature ä¼˜ç‚¹ï¼š\nç®€å•æ˜äº† é€‚åˆæŒç»­éƒ¨ç½² ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\nä¸é€‚åˆéœ€è¦é•¿æœŸç»´æŠ¤å¤šä¸ªç‰ˆæœ¬çš„é¡¹ç›® ç¼ºå°‘æ˜ç¡®çš„å‘å¸ƒæµç¨‹ GitLab Flowå·¥ä½œæµ GitLab Flowæ˜¯GitLabæ¨èçš„å·¥ä½œæµï¼Œç»“åˆäº†GitHub Flowå’ŒGit Flowçš„ä¼˜ç‚¹ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºMerge Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ ä»mainåˆ›å»ºç¯å¢ƒåˆ†æ”¯ï¼ˆå¦‚stagingã€productionï¼‰ éƒ¨ç½²åˆ°ä¸åŒç¯å¢ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitLabä¸Šåˆ›å»ºMerge Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ›å»ºç¯å¢ƒåˆ†æ”¯ git checkout -b production main git push origin production # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ # ... ä¼˜ç‚¹ï¼š\nç®€å•ä¸”çµæ´» æ”¯æŒå¤šç¯å¢ƒéƒ¨ç½² é€‚åˆæŒç»­äº¤ä»˜ ç¼ºç‚¹ï¼š\nç¯å¢ƒåˆ†æ”¯ç®¡ç†éœ€è¦é¢å¤–å·¥ä½œ å¯¹äºå¤§å‹é¡¹ç›®å¯èƒ½ä¸å¤Ÿä¸¥æ ¼ Gité«˜çº§æŠ€å·§ é’©å­(Hooks) Gité’©å­æ˜¯åœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è‡ªåŠ¨æ‰§è¡Œçš„è„šæœ¬ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚\nå¸¸ç”¨é’©å­ç±»å‹ å®¢æˆ·ç«¯é’©å­ï¼š\npre-commitï¼šæäº¤å‰è¿è¡Œ commit-msgï¼šç¼–è¾‘æäº¤ä¿¡æ¯åè¿è¡Œ pre-pushï¼šæ¨é€å‰è¿è¡Œ æœåŠ¡å™¨ç«¯é’©å­ï¼š\npre-receiveï¼šæ¥æ”¶æ¨é€æ—¶è¿è¡Œ updateï¼šæ›´æ–°åˆ†æ”¯æ—¶è¿è¡Œ post-receiveï¼šæ¥æ”¶æ¨é€åè¿è¡Œ ç¤ºä¾‹ï¼špre-commité’©å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/sh # .git/hooks/pre-commit # æ£€æŸ¥ä»£ç é£æ ¼ npm run lint # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;ä»£ç é£æ ¼æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi # è¿è¡Œæµ‹è¯• npm test # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;æµ‹è¯•å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi å­æ¨¡å—(Submodules) Gitå­æ¨¡å—å…è®¸ä½ å°†ä¸€ä¸ªGitä»“åº“ä½œä¸ºå¦ä¸€ä¸ªGitä»“åº“çš„å­ç›®å½•ã€‚\næ·»åŠ å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 # æ·»åŠ å­æ¨¡å— git submodule add https://github.com/username/submodule-repository.git path/to/submodule # åˆå§‹åŒ–å­æ¨¡å— git submodule init # æ›´æ–°å­æ¨¡å— git submodule update # é€’å½’å…‹éš†åŒ…å«å­æ¨¡å—çš„ä»“åº“ git clone --recursive https://github.com/username/repository.git æ›´æ–°å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 12 # è¿›å…¥å­æ¨¡å—ç›®å½• cd path/to/submodule # æ‹‰å–æœ€æ–°ä»£ç  git pull origin main # è¿”å›ä¸»ä»“åº“ cd .. # æäº¤å­æ¨¡å—æ›´æ–° git add path/to/submodule git commit -m \u0026#34;Update submodule\u0026#34; å˜åŸº(Rebase)é«˜çº§ç”¨æ³• äº¤äº’å¼å˜åŸº äº¤äº’å¼å˜åŸºå…è®¸ä½ ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æˆ–é‡æ–°æ’åºæäº¤ã€‚\n1 2 # å¯¹æœ€è¿‘çš„3ä¸ªæäº¤è¿›è¡Œäº¤äº’å¼å˜åŸº git rebase -i HEAD~3 åœ¨æ‰“å¼€çš„ç¼–è¾‘å™¨ä¸­ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„å†…å®¹ï¼š\npick f7f3f6d Commit message 1 pick 310154e Commit message 2 pick a5f4a0d Commit message 3 # Rebase 1234567..a5f4a0d onto 1234567 (3 commands) # # Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to re-use the original merge # . commit\u0026#39;s author and message. # # These lines can be re-ordered; they are executed from top to bottom. ä½ å¯ä»¥é€šè¿‡ä¿®æ”¹å‘½ä»¤å‰çš„å…³é”®å­—æ¥æ”¹å˜æäº¤çš„å¤„ç†æ–¹å¼ã€‚\nå˜åŸº vs åˆå¹¶ å˜åŸºå’Œåˆå¹¶éƒ½æ˜¯æ•´åˆåˆ†æ”¯æ›´æ”¹çš„æ–¹æ³•ï¼Œä½†å®ƒä»¬æœ‰ä¸åŒçš„å·¥ä½œæ–¹å¼ï¼š\nåˆå¹¶(Merge)ï¼š\nåˆ›å»ºä¸€ä¸ªæ–°çš„\u0026quot;åˆå¹¶æäº¤\u0026quot; ä¿ç•™å®Œæ•´çš„åˆ†æ”¯å†å² é€‚åˆå…¬å…±åˆ†æ”¯ å˜åŸº(Rebase)ï¼š\nå°†æäº¤é‡æ–°åº”ç”¨åˆ°ç›®æ ‡åˆ†æ”¯ åˆ›å»ºçº¿æ€§çš„æäº¤å†å² é€‚åˆç§æœ‰åˆ†æ”¯ 1 2 3 4 5 6 7 # åˆå¹¶åˆ†æ”¯ git checkout main git merge feature-branch # å˜åŸºåˆ†æ”¯ git checkout feature-branch git rebase main å‚¨è—(Stash) å‚¨è—å…è®¸ä½ ä¸´æ—¶ä¿å­˜æœªæäº¤çš„ä¿®æ”¹ï¼Œä»¥ä¾¿åˆ‡æ¢åˆ†æ”¯æˆ–æ‰§è¡Œå…¶ä»–æ“ä½œã€‚\nåŸºæœ¬å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # å‚¨è—å½“å‰ä¿®æ”¹ git stash # å‚¨è—å¹¶æ·»åŠ è¯´æ˜ git stash save \u0026#34;Work in progress\u0026#34; # æŸ¥çœ‹å‚¨è—åˆ—è¡¨ git stash list # åº”ç”¨æœ€æ–°å‚¨è—ï¼ˆä¸åˆ é™¤ï¼‰ git stash apply # åº”ç”¨å¹¶åˆ é™¤æœ€æ–°å‚¨è— git stash pop # åº”ç”¨æŒ‡å®šå‚¨è— git stash apply stash@{1} # åˆ é™¤æŒ‡å®šå‚¨è— git stash drop stash@{1} # æ¸…é™¤æ‰€æœ‰å‚¨è— git stash clear é«˜çº§å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 # å‚¨è—æœªè·Ÿè¸ªçš„æ–‡ä»¶ git stash -u # å‚¨è—åŒ…æ‹¬å¿½ç•¥çš„æ–‡ä»¶ git stash -a # ä»å‚¨è—åˆ›å»ºåˆ†æ”¯ git stash branch new-branch stash@{1} ç­¾é€‰(Cherry-pick) ç­¾é€‰å…è®¸ä½ é€‰æ‹©ç‰¹å®šçš„æäº¤ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°å½“å‰åˆ†æ”¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ç­¾é€‰æŒ‡å®šæäº¤ git cherry-pick commit-hash # ç­¾é€‰ä½†ä¸æäº¤ git cherry-pick -n commit-hash # ç­¾é€‰å¹¶ç¼–è¾‘æäº¤ä¿¡æ¯ git cherry-pick -e commit-hash # ç­¾é€‰å¤šä¸ªæäº¤ git cherry-pick commit1 commit2 commit3 # ç­¾é€‰ä¸€ç³»åˆ—æäº¤ git cherry-pick commit1..commit3 # ä¸­æ­¢ç­¾é€‰ git cherry-pick --abort # ç»§ç»­ç­¾é€‰ï¼ˆè§£å†³å†²çªåï¼‰ git cherry-pick --continue å¼•ç”¨æ—¥å¿—(Reflog) å¼•ç”¨æ—¥å¿—è®°å½•äº†Gitä»“åº“ä¸­æ‰€æœ‰å¼•ç”¨çš„æ›´æ–°ï¼ŒåŒ…æ‹¬è¢«åˆ é™¤çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹å¼•ç”¨æ—¥å¿— git reflog # æŸ¥çœ‹æŒ‡å®šåˆ†æ”¯çš„å¼•ç”¨æ—¥å¿— git reflog show main # æŸ¥çœ‹å¼•ç”¨æ—¥å¿—å¹¶æ˜¾ç¤ºå·®å¼‚ git reflog show --stat # æ¢å¤è¢«åˆ é™¤çš„æäº¤ git reset --hard HEAD@{1} äºŒåˆ†æŸ¥æ‰¾(Bisect) äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºå¿«é€Ÿå®šä½å¼•å…¥é—®é¢˜çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # å¼€å§‹äºŒåˆ†æŸ¥æ‰¾ git bisect start # æ ‡è®°å½“å‰æäº¤ä¸ºæœ‰é—®é¢˜ git bisect bad # æ ‡è®°å·²çŸ¥æ­£å¸¸çš„æäº¤ git bisect good commit-hash # Gitä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸€ä¸ªä¸­é—´æäº¤ï¼Œæµ‹è¯•åæ ‡è®°ä¸ºgoodæˆ–bad git bisect good # æˆ– git bisect bad # é‡å¤æµ‹è¯•è¿‡ç¨‹ï¼Œç›´åˆ°æ‰¾åˆ°é—®é¢˜æäº¤ # ç»“æŸäºŒåˆ†æŸ¥æ‰¾ git bisect reset Gitæœ€ä½³å®è·µ æäº¤è§„èŒƒ æäº¤ä¿¡æ¯æ ¼å¼ è‰¯å¥½çš„æäº¤ä¿¡æ¯åº”è¯¥æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶éµå¾ªä¸€å®šçš„æ ¼å¼ï¼š\n\u0026lt;ç±»å‹\u0026gt;(\u0026lt;èŒƒå›´\u0026gt;): \u0026lt;ä¸»é¢˜\u0026gt; \u0026lt;è¯¦ç»†æè¿°\u0026gt; \u0026lt;é¡µè„š\u0026gt; ç±»å‹ï¼š\nfeatï¼šæ–°åŠŸèƒ½ fixï¼šä¿®å¤bug docsï¼šæ–‡æ¡£æ›´æ–° styleï¼šä»£ç æ ¼å¼ï¼ˆä¸å½±å“ä»£ç è¿è¡Œçš„å˜åŠ¨ï¼‰ refactorï¼šé‡æ„ï¼ˆæ—¢ä¸æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¹Ÿä¸æ˜¯ä¿®æ”¹bugçš„ä»£ç å˜åŠ¨ï¼‰ perfï¼šæ€§èƒ½ä¼˜åŒ– testï¼šå¢åŠ æµ‹è¯• choreï¼šæ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨ èŒƒå›´ï¼šå¯é€‰ï¼Œç”¨äºè¯´æ˜æäº¤å½±å“çš„èŒƒå›´ï¼Œå¦‚docs, api, coreç­‰ã€‚\nä¸»é¢˜ï¼šç®€æ´æè¿°æäº¤å†…å®¹ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦ã€‚\nè¯¦ç»†æè¿°ï¼šå¯é€‰ï¼Œè¯¦ç»†æè¿°æäº¤å†…å®¹ï¼Œæ¯è¡Œä¸è¶…è¿‡72ä¸ªå­—ç¬¦ã€‚\né¡µè„šï¼šå¯é€‰ï¼Œç”¨äºæ ‡è®°Breaking Changesæˆ–å…³é—­Issueã€‚\nç¤ºä¾‹æäº¤ä¿¡æ¯ feat(api): add user authentication endpoint Add a new endpoint for user authentication using JWT tokens. The endpoint supports both username/password and social login methods. Closes #123 åˆ†æ”¯å‘½åè§„èŒƒ è‰¯å¥½çš„åˆ†æ”¯å‘½åå¯ä»¥æé«˜å›¢é˜Ÿåä½œæ•ˆç‡ï¼š\n\u0026lt;ç±»å‹\u0026gt;/\u0026lt;æè¿°\u0026gt; ä¾‹å¦‚ï¼š feature/user-authentication fix/login-bug docs/api-documentation refactor/user-service ä»£ç å®¡æŸ¥ ä»£ç å®¡æŸ¥æ˜¯ä¿è¯ä»£ç è´¨é‡çš„é‡è¦ç¯èŠ‚ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å»ºè®®ï¼š\nä¿æŒå°çš„æäº¤ï¼šæ¯æ¬¡æäº¤åº”è¯¥åªå…³æ³¨ä¸€ä¸ªåŠŸèƒ½æˆ–ä¿®å¤ï¼Œä¾¿äºå®¡æŸ¥ã€‚ æä¾›æ¸…æ™°çš„æè¿°ï¼šåœ¨Pull Requestä¸­è¯¦ç»†è¯´æ˜ä¿®æ”¹å†…å®¹å’ŒåŸå› ã€‚ è‡ªåŠ¨åŒ–æ£€æŸ¥ï¼šä½¿ç”¨CI/CDå·¥å…·è‡ªåŠ¨è¿è¡Œæµ‹è¯•å’Œä»£ç é£æ ¼æ£€æŸ¥ã€‚ å…³æ³¨ä»£ç é€»è¾‘ï¼šä¸ä»…å…³æ³¨ä»£ç é£æ ¼ï¼Œè¿˜è¦å…³æ³¨é€»è¾‘æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚ æä¾›å»ºè®¾æ€§åé¦ˆï¼šå°Šé‡ä»–äººï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚ å¸¸è§é—®é¢˜è§£å†³ æ’¤é”€å·²æ¨é€çš„æäº¤ 1 2 3 4 5 6 7 # æ–¹æ³•1ï¼šåˆ›å»ºæ–°çš„æäº¤æ¥æ’¤é”€ git revert commit-hash git push origin main # æ–¹æ³•2ï¼šå¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git reset --hard HEAD~1 git push --force origin main åˆå¹¶é”™è¯¯çš„åˆ†æ”¯ 1 2 3 4 5 # æ’¤é”€åˆå¹¶ git reset --hard HEAD~1 # å¦‚æœå·²ç»æ¨é€ git revert -m 1 commit-hash æ¸…ç†å†å²è®°å½• 1 2 3 4 5 # äº¤äº’å¼å˜åŸºæ¸…ç†å†å² git rebase -i HEAD~n # å¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git push --force origin main å¤„ç†å¤§æ–‡ä»¶ 1 2 3 4 5 6 7 8 9 10 # æŸ¥æ‰¾å¤§æ–‡ä»¶ git rev-list --objects --all | git cat-file --batch-check=\u0026#39;%(objecttype) %(objectname) %(objectsize) %(rest)\u0026#39; | sed -n \u0026#39;s/^blob //p\u0026#39; | sort -nrk 2 | head -n 10 # ä½¿ç”¨BFG Repo-Cleaneræ¸…ç†å¤§æ–‡ä»¶ java -jar bfg.jar --strip-blobs-bigger-than 100M my-repo.git # æ¸…ç†å¹¶æ¨é€ git reflog expire --expire=now --all git gc --prune=now --aggressive git push --force origin main æ€»ç»“ Gitæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ŒæŒæ¡å…¶å·¥ä½œæµç¨‹å¯¹äºç°ä»£è½¯ä»¶å¼€å‘è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»Gitçš„åŸºæœ¬æ¦‚å¿µå’Œå‘½ä»¤å¼€å§‹ï¼Œé€æ­¥ä»‹ç»äº†åˆ†æ”¯ç®¡ç†ã€å„ç§å·¥ä½œæµæ¨¡å‹ä»¥åŠé«˜çº§æŠ€å·§ã€‚\né€šè¿‡å­¦ä¹ å’Œå®è·µè¿™äº›å†…å®¹ï¼Œä½ å¯ä»¥ï¼š\né«˜æ•ˆç®¡ç†ä¸ªäººé¡¹ç›®çš„ç‰ˆæœ¬ ä¸å›¢é˜Ÿæˆå‘˜åä½œå¼€å‘ å¤„ç†å¤æ‚çš„åˆå¹¶å’Œå†²çª ä½¿ç”¨é«˜çº§åŠŸèƒ½æé«˜å·¥ä½œæ•ˆç‡ è®°ä½ï¼ŒGitçš„å¼ºå¤§ä¹‹å¤„åœ¨äºå…¶çµæ´»æ€§ï¼Œä½ å¯ä»¥æ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥ä½œæµç¨‹å’Œå·¥å…·ã€‚åŒæ—¶ï¼Œè‰¯å¥½çš„å®è·µä¹ æƒ¯ï¼ˆå¦‚æ¸…æ™°çš„æäº¤ä¿¡æ¯ã€è§„èŒƒçš„åˆ†æ”¯å‘½åï¼‰å°†ä½¿ä½ çš„å¼€å‘è¿‡ç¨‹æ›´åŠ é¡ºç•…ã€‚\næœ€åï¼ŒGitæ˜¯ä¸€ä¸ªä¸æ–­å‘å±•çš„å·¥å…·ï¼ŒæŒç»­å­¦ä¹ å’Œæ¢ç´¢æ–°åŠŸèƒ½å°†å¸®åŠ©ä½ æ›´å¥½åœ°åˆ©ç”¨è¿™ä¸ªå¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ æŒæ¡Gitå·¥ä½œæµç¨‹ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚\n","permalink":"http://localhost:1313/posts/git-workflow/","summary":"\u003ch1 id=\"gitå·¥ä½œæµç¨‹ä»å…¥é—¨åˆ°ç²¾é€š\"\u003eGitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š\u003c/h1\u003e\n\u003cp\u003eGitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\u003c/p\u003e","title":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š"},{"content":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\nå›¾åƒåŸºç¡€ å›¾åƒè¡¨ç¤º æ•°å­—å›¾åƒçš„æ¦‚å¿µ æ•°å­—å›¾åƒæ˜¯ç”±æœ‰é™æ•°é‡çš„åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆçš„äºŒç»´çŸ©é˜µã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import numpy as np import matplotlib.pyplot as plt # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç°åº¦å›¾åƒ # 5x5çš„ç°åº¦å›¾åƒï¼Œå€¼èŒƒå›´0-255 gray_image = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ], dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert gray_image is not None, \u0026#34;ç°åº¦å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # æ˜¾ç¤ºå›¾åƒ plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Grayscale Image\u0026#39;) plt.colorbar() plt.show() å½©è‰²å›¾åƒè¡¨ç¤º å½©è‰²å›¾åƒé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“æ¥è¡¨ç¤ºã€‚æ¯ä¸ªåƒç´ ç”±ä¸‰ä¸ªå€¼ç»„æˆï¼Œåˆ†åˆ«ä»£è¡¨çº¢ã€ç»¿ã€è“ä¸‰ä¸ªé¢œè‰²é€šé“çš„å¼ºåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰²å›¾åƒ # 5x5x3çš„RGBå›¾åƒï¼Œå€¼èŒƒå›´0-255 color_image = np.zeros((5, 5, 3), dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert color_image is not None, \u0026#34;å½©è‰²å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # è®¾ç½®çº¢è‰²é€šé“ color_image[:, :, 0] = np.array([ [255, 200, 150, 100, 50], [230, 180, 130, 80, 30], [210, 160, 110, 60, 10], [190, 140, 90, 40, 0], [170, 120, 70, 20, 0] ]) # è®¾ç½®ç»¿è‰²é€šé“ color_image[:, :, 1] = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ]) # è®¾ç½®è“è‰²é€šé“ color_image[:, :, 2] = np.array([ [0, 30, 60, 90, 120], [50, 80, 110, 140, 170], [100, 130, 160, 190, 200], [150, 180, 210, 220, 230], [200, 230, 240, 250, 255] ]) # æ˜¾ç¤ºå›¾åƒ plt.imshow(color_image) plt.title(\u0026#39;Color Image\u0026#39;) plt.show() å…¶ä»–é¢œè‰²ç©ºé—´ é™¤äº†RGBï¼Œè¿˜æœ‰å…¶ä»–å¸¸ç”¨çš„é¢œè‰²ç©ºé—´ï¼Œå¦‚HSVï¼ˆè‰²ç›¸ã€é¥±å’Œåº¦ã€æ˜åº¦ï¼‰å’ŒLabï¼ˆäº®åº¦ã€aé€šé“ã€bé€šé“ï¼‰ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import cv2 # å°†RGBå›¾åƒè½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´ hsv_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2HSV) # å°†RGBå›¾åƒè½¬æ¢ä¸ºLabé¢œè‰²ç©ºé—´ lab_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2Lab) # æ˜¾ç¤ºä¸åŒé¢œè‰²ç©ºé—´çš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(color_image) plt.title(\u0026#39;RGB Image\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(hsv_image) plt.title(\u0026#39;HSV Image\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(lab_image) plt.title(\u0026#39;Lab Image\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå±æ€§ åˆ†è¾¨ç‡ å›¾åƒåˆ†è¾¨ç‡æ˜¯æŒ‡å›¾åƒä¸­åƒç´ çš„æ•°é‡ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºå®½åº¦Ã—é«˜åº¦ï¼ˆå¦‚1920Ã—1080ï¼‰ã€‚é«˜åˆ†è¾¨ç‡å›¾åƒåŒ…å«æ›´å¤šç»†èŠ‚ï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šçš„å­˜å‚¨ç©ºé—´å’Œå¤„ç†æ—¶é—´ã€‚\n1 2 3 4 5 6 # è·å–å›¾åƒåˆ†è¾¨ç‡ height, width = gray_image.shape print(f\u0026#34;ç°åº¦å›¾åƒåˆ†è¾¨ç‡: {width}x{height}\u0026#34;) height, width, channels = color_image.shape print(f\u0026#34;å½©è‰²å›¾åƒåˆ†è¾¨ç‡: {width}x{height}, é€šé“æ•°: {channels}\u0026#34;) ä½æ·±åº¦ ä½æ·±åº¦æ˜¯æŒ‡æ¯ä¸ªåƒç´ ä½¿ç”¨çš„ä½æ•°ï¼Œå†³å®šäº†å›¾åƒå¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ã€‚å¸¸è§çš„ä½æ·±åº¦æœ‰8ä½ï¼ˆ256ä¸ªç°åº¦çº§ï¼‰ã€24ä½ï¼ˆRGBå„8ä½ï¼Œçº¦1670ä¸‡ç§é¢œè‰²ï¼‰ç­‰ã€‚\n1 2 3 4 5 6 7 8 9 10 # æ£€æŸ¥å›¾åƒçš„ä½æ·±åº¦ print(f\u0026#34;ç°åº¦å›¾åƒæ•°æ®ç±»å‹: {gray_image.dtype}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ•°æ®ç±»å‹: {color_image.dtype}\u0026#34;) # è®¡ç®—å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ gray_levels = 2 ** (gray_image.itemsize * 8) color_levels = 2 ** (color_image.itemsize * 8) print(f\u0026#34;ç°åº¦å›¾åƒå¯ä»¥è¡¨ç¤ºçš„ç°åº¦çº§æ•°: {gray_levels}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ¯ä¸ªé€šé“å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²çº§æ•°: {color_levels}\u0026#34;) å›¾åƒåŸºæœ¬å¤„ç† å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨OpenCVè¯»å–å›¾åƒ OpenCVæ˜¯ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„è®¡ç®—æœºè§†è§‰åº“ï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import cv2 # è¯»å–å›¾åƒ # æ³¨æ„ï¼šOpenCVé»˜è®¤ä»¥BGRæ ¼å¼è¯»å–å½©è‰²å›¾åƒ image_bgr = cv2.imread(\u0026#39;example.jpg\u0026#39;) # æ£€æŸ¥å›¾åƒæ˜¯å¦æˆåŠŸè¯»å– if image_bgr is None: print(\u0026#34;æ— æ³•è¯»å–å›¾åƒ\u0026#34;) else: # è½¬æ¢ä¸ºRGBæ ¼å¼ä»¥ä¾¿æ­£ç¡®æ˜¾ç¤º image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.title(\u0026#39;Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() ä½¿ç”¨PIL/Pillowè¯»å–å›¾åƒ Pillowæ˜¯Pythonå›¾åƒå¤„ç†åº“ï¼Œæä¾›äº†ç®€å•æ˜“ç”¨çš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from PIL import Image # è¯»å–å›¾åƒ image = Image.open(\u0026#39;example.jpg\u0026#39;) # æ˜¾ç¤ºå›¾åƒ image.show() # è½¬æ¢ä¸ºnumpyæ•°ç»„ image_array = np.array(image) # æ˜¾ç¤ºå›¾åƒä¿¡æ¯ print(f\u0026#34;å›¾åƒå¤§å°: {image.size}\u0026#34;) print(f\u0026#34;å›¾åƒæ¨¡å¼: {image.mode}\u0026#34;) print(f\u0026#34;å›¾åƒæ•°ç»„å½¢çŠ¶: {image_array.shape}\u0026#34;) å›¾åƒåŸºæœ¬æ“ä½œ è£å‰ªå›¾åƒ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image_rgb[50:200, 100:300] # æ˜¾ç¤ºè£å‰ªåçš„å›¾åƒ plt.imshow(cropped_image) plt.title(\u0026#39;Cropped Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() è°ƒæ•´å›¾åƒå¤§å° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # ä½¿ç”¨OpenCVè°ƒæ•´å›¾åƒå¤§å° resized_cv2 = cv2.resize(image_rgb, (300, 200)) # ä½¿ç”¨PILè°ƒæ•´å›¾åƒå¤§å° resized_pil = Image.fromarray(image_rgb).resize((300, 200)) # æ˜¾ç¤ºè°ƒæ•´å¤§å°åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(resized_cv2) plt.title(\u0026#39;Resized with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(resized_pil) plt.title(\u0026#39;Resized with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() æ—‹è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ä½¿ç”¨OpenCVæ—‹è½¬å›¾åƒ (h, w) = image_rgb.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) rotated_cv2 = cv2.warpAffine(image_rgb, M, (w, h)) # ä½¿ç”¨PILæ—‹è½¬å›¾åƒ rotated_pil = Image.fromarray(image_rgb).rotate(45) # æ˜¾ç¤ºæ—‹è½¬åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(rotated_cv2) plt.title(\u0026#39;Rotated with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(rotated_pil) plt.title(\u0026#39;Rotated with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç¿»è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # æ°´å¹³ç¿»è½¬ flipped_h = cv2.flip(image_rgb, 1) # å‚ç›´ç¿»è½¬ flipped_v = cv2.flip(image_rgb, 0) # æ°´å¹³å’Œå‚ç›´ç¿»è½¬ flipped_hv = cv2.flip(image_rgb, -1) # æ˜¾ç¤ºç¿»è½¬åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(flipped_h) plt.title(\u0026#39;Horizontal Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(flipped_v) plt.title(\u0026#39;Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(flipped_hv) plt.title(\u0026#39;Horizontal and Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå¢å¼º äº®åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ äº®åº¦ brightness_increase = cv2.convertScaleAbs(image_rgb, alpha=1.2, beta=50) # å‡å°‘äº®åº¦ brightness_decrease = cv2.convertScaleAbs(image_rgb, alpha=1.0, beta=-50) # æ˜¾ç¤ºäº®åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(brightness_increase) plt.title(\u0026#39;Increased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(brightness_decrease) plt.title(\u0026#39;Decreased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ å¯¹æ¯”åº¦ contrast_increase = cv2.convertScaleAbs(image_rgb, alpha=1.5, beta=0) # å‡å°‘å¯¹æ¯”åº¦ contrast_decrease = cv2.convertScaleAbs(image_rgb, alpha=0.5, beta=0) # æ˜¾ç¤ºå¯¹æ¯”åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(contrast_increase) plt.title(\u0026#39;Increased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(contrast_decrease) plt.title(\u0026#39;Decreased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›´æ–¹å›¾å‡è¡¡åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # ç›´æ–¹å›¾å‡è¡¡åŒ– equalized_image = cv2.equalizeHist(gray_image) # æ˜¾ç¤ºç›´æ–¹å›¾å‡è¡¡åŒ–å‰åçš„å›¾åƒå’Œç›´æ–¹å›¾ plt.figure(figsize=(15, 10)) # åŸå§‹å›¾åƒ plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Grayscale Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # å‡è¡¡åŒ–åçš„å›¾åƒ plt.subplot(2, 2, 2) plt.imshow(equalized_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Equalized Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # åŸå§‹ç›´æ–¹å›¾ plt.subplot(2, 2, 3) plt.hist(gray_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Original Histogram\u0026#39;) # å‡è¡¡åŒ–åçš„ç›´æ–¹å›¾ plt.subplot(2, 2, 4) plt.hist(equalized_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Equalized Histogram\u0026#39;) plt.tight_layout() plt.show() ä¼½é©¬æ ¡æ­£ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def adjust_gamma(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) # åº”ç”¨ä¸åŒçš„ä¼½é©¬å€¼ gamma_1_5 = adjust_gamma(image_rgb, 1.5) gamma_0_5 = adjust_gamma(image_rgb, 0.5) # æ˜¾ç¤ºä¼½é©¬æ ¡æ­£åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image (Î³=1.0)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(gamma_1_5) plt.title(\u0026#39;Gamma=1.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(gamma_0_5) plt.title(\u0026#39;Gamma=0.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒæ»¤æ³¢ å‡å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # åº”ç”¨ä¸åŒå¤§å°çš„å‡å€¼æ»¤æ³¢ blur_3x3 = cv2.blur(gray_image, (3, 3)) blur_5x5 = cv2.blur(gray_image, (5, 5)) blur_7x7 = cv2.blur(gray_image, (7, 7)) # æ˜¾ç¤ºå‡å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(blur_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(blur_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(blur_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() é«˜æ–¯æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°å’Œæ ‡å‡†å·®çš„é«˜æ–¯æ»¤æ³¢ gaussian_3x3 = cv2.GaussianBlur(gray_image, (3, 3), 0) gaussian_5x5 = cv2.GaussianBlur(gray_image, (5, 5), 0) gaussian_7x7 = cv2.GaussianBlur(gray_image, (7, 7), 0) # æ˜¾ç¤ºé«˜æ–¯æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(gaussian_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(gaussian_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(gaussian_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ä¸­å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°çš„ä¸­å€¼æ»¤æ³¢ median_3 = cv2.medianBlur(gray_image, 3) median_5 = cv2.medianBlur(gray_image, 5) median_7 = cv2.medianBlur(gray_image, 7) # æ˜¾ç¤ºä¸­å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(median_3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(median_5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(median_7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åŒè¾¹æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨åŒè¾¹æ»¤æ³¢ bilateral = cv2.bilateralFilter(gray_image, 9, 75, 75) # æ˜¾ç¤ºåŒè¾¹æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(bilateral, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Bilateral Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è¾¹ç¼˜æ£€æµ‹ Sobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # åº”ç”¨Sobelç®—å­ sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3) sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3) sobel_xy = cv2.Sobel(gray_image, cv2.CV_64F, 1, 1, ksize=3) # è½¬æ¢å›uint8 sobel_x = cv2.convertScaleAbs(sobel_x) sobel_y = cv2.convertScaleAbs(sobel_y) sobel_xy = cv2.convertScaleAbs(sobel_xy) # æ˜¾ç¤ºSobelè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(sobel_x, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel X\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(sobel_y, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel Y\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(sobel_xy, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel XY\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Laplacianç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # åº”ç”¨Laplacianç®—å­ laplacian = cv2.Laplacian(gray_image, cv2.CV_64F) laplacian = cv2.convertScaleAbs(laplacian) # æ˜¾ç¤ºLaplacianè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(laplacian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Laplacian Edge Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Cannyè¾¹ç¼˜æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨Cannyè¾¹ç¼˜æ£€æµ‹ canny_low = cv2.Canny(gray_image, 50, 150) canny_high = cv2.Canny(gray_image, 100, 200) # æ˜¾ç¤ºCannyè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(canny_low, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (50, 150)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(canny_high, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (100, 200)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒåˆ†å‰² é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # åº”ç”¨ä¸åŒç±»å‹çš„é˜ˆå€¼åˆ†å‰² ret, thresh_binary = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY) ret, thresh_binary_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV) ret, thresh_trunc = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TRUNC) ret, thresh_tozero = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO) ret, thresh_tozero_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO_INV) # æ˜¾ç¤ºé˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 2) plt.imshow(thresh_binary, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 3) plt.imshow(thresh_binary_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 4) plt.imshow(thresh_trunc, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Truncated Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 5) plt.imshow(thresh_tozero, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 6) plt.imshow(thresh_tozero_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_mean = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2) adaptive_gaussian = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) # æ˜¾ç¤ºè‡ªé€‚åº”é˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(adaptive_mean, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Mean Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(adaptive_gaussian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Gaussian Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Otsué˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨Otsué˜ˆå€¼åˆ†å‰² ret, otsu = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # æ˜¾ç¤ºOtsué˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(otsu, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;Otsu Threshold (Threshold={ret})\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åˆ†æ°´å²­ç®—æ³• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # åˆ›å»ºä¸€ä¸ªç®€å•çš„äºŒå€¼å›¾åƒ binary_image = np.zeros((300, 300), dtype=np.uint8) cv2.circle(binary_image, (100, 100), 50, 255, -1) cv2.circle(binary_image, (200, 200), 50, 255, -1) # åº”ç”¨è·ç¦»å˜æ¢ dist_transform = cv2.distanceTransform(binary_image, cv2.DIST_L2, 5) ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0) sure_fg = np.uint8(sure_fg) # æœªçŸ¥åŒºåŸŸ unknown = cv2.subtract(binary_image, sure_fg) # æ ‡è®°æ ‡ç­¾ ret, markers = cv2.connectedComponents(sure_fg) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR), markers) # æ˜¾ç¤ºåˆ†æ°´å²­ç®—æ³•ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(binary_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(dist_transform, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Distance Transform\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(markers, cmap=\u0026#39;jet\u0026#39;) plt.title(\u0026#39;Watershed Segmentation\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç‰¹å¾æå– Harrisè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # åº”ç”¨Harrisè§’ç‚¹æ£€æµ‹ gray_float = np.float32(gray_image) harris_corners = cv2.cornerHarris(gray_float, 2, 3, 0.04) # æ‰©å¤§è§’ç‚¹æ ‡è®° harris_corners = cv2.dilate(harris_corners, None) # è®¾ç½®é˜ˆå€¼ threshold = 0.01 * harris_corners.max() corner_image = image_rgb.copy() corner_image[harris_corners \u0026gt; threshold] = [255, 0, 0] # æ˜¾ç¤ºHarrisè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(corner_image) plt.title(\u0026#39;Harris Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Shi-Tomasiè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åº”ç”¨Shi-Tomasiè§’ç‚¹æ£€æµ‹ corners = cv2.goodFeaturesToTrack(gray_image, 100, 0.01, 10) corners = np.int0(corners) # ç»˜åˆ¶è§’ç‚¹ shi_tomasi_image = image_rgb.copy() for corner in corners: x, y = corner.ravel() cv2.circle(shi_tomasi_image, (x, y), 3, 255, -1) # æ˜¾ç¤ºShi-Tomasiè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(shi_tomasi_image) plt.title(\u0026#39;Shi-Tomasi Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() SIFTç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºSIFTç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(sift_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;SIFT Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ORBç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºORBç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(orb_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;ORB Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›®æ ‡æ£€æµ‹ Haarçº§è”åˆ†ç±»å™¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # åŠ è½½Haarçº§è”åˆ†ç±»å™¨ face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_frontalface_default.xml\u0026#39;) eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_eye.xml\u0026#39;) # æ£€æµ‹äººè„¸å’Œçœ¼ç› faces = face_cascade.detectMultiScale(gray_image, 1.3, 5) face_eye_image = image_rgb.copy() for (x, y, w, h) in faces: cv2.rectangle(face_eye_image, (x, y), (x+w, y+h), (255, 0, 0), 2) roi_gray = gray_image[y:y+h, x:x+w] roi_color = face_eye_image[y:y+h, x:x+w] eyes = eye_cascade.detectMultiScale(roi_gray) for (ex, ey, ew, eh) in eyes: cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2) # æ˜¾ç¤ºHaarçº§è”åˆ†ç±»å™¨æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(face_eye_image) plt.title(\u0026#39;Haar Cascade Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() HOGç‰¹å¾ä¸SVM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from skimage.feature import hog from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score # æå–HOGç‰¹å¾ def extract_hog_features(images): features = [] for image in images: # è®¡ç®—HOGç‰¹å¾ fd = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False) features.append(fd) return np.array(features) # å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›æ ‡è®°çš„å›¾åƒæ•°æ® # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦çœŸå®æ•°æ® # X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2) # æå–è®­ç»ƒå’Œæµ‹è¯•é›†çš„HOGç‰¹å¾ # X_train_hog = extract_hog_features(X_train) # X_test_hog = extract_hog_features(X_test) # è®­ç»ƒSVMåˆ†ç±»å™¨ # svm = SVC(kernel=\u0026#39;linear\u0026#39;) # svm.fit(X_train_hog, y_train) # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° # y_pred = svm.predict(X_test_hog) # accuracy = accuracy_score(y_test, y_pred) # print(f\u0026#34;Accuracy: {accuracy}\u0026#34;) æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ä»£ç ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®‰è£…ç›¸åº”çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ # å¦‚TensorFlowæˆ–PyTorchï¼Œä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ # ä½¿ç”¨TensorFlowå’Œé¢„è®­ç»ƒçš„SSDæ¨¡å‹ \u0026#34;\u0026#34;\u0026#34; import tensorflow as tf # åŠ è½½é¢„è®­ç»ƒçš„SSDæ¨¡å‹ model = tf.saved_model.load(\u0026#39;ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\u0026#39;) # é¢„å¤„ç†å›¾åƒ input_tensor = tf.convert_to_tensor(image_rgb) input_tensor = input_tensor[tf.newaxis, ...] # è¿è¡Œæ¨¡å‹ detections = model(input_tensor) # è§£ææ£€æµ‹ç»“æœ num_detections = int(detections.pop(\u0026#39;num_detections\u0026#39;)) detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()} detections[\u0026#39;num_detections\u0026#39;] = num_detections # è¿‡æ»¤æ£€æµ‹ç»“æœ min_score_thresh = 0.5 detections[\u0026#39;detection_classes\u0026#39;] = detections[\u0026#39;detection_classes\u0026#39;].astype(np.int64) indexes = np.where(detections[\u0026#39;detection_scores\u0026#39;] \u0026gt; min_score_thresh)[0] # ç»˜åˆ¶æ£€æµ‹ç»“æœ result_image = image_rgb.copy() for i in indexes: class_id = detections[\u0026#39;detection_classes\u0026#39;][i] score = detections[\u0026#39;detection_scores\u0026#39;][i] bbox = detections[\u0026#39;detection_boxes\u0026#39;][i] # å°†å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†è½¬æ¢ä¸ºåƒç´ åæ ‡ h, w, _ = image_rgb.shape y1, x1, y2, x2 = bbox y1, x1, y2, x2 = int(y1 * h), int(x1 * w), int(y2 * h), int(x2 * w) # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾ cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2) label = f\u0026#34;{class_id}: {score:.2f}\u0026#34; cv2.putText(result_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # æ˜¾ç¤ºæ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(result_image) plt.title(\u0026#39;Deep Learning Object Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() \u0026#34;\u0026#34;\u0026#34; æ€»ç»“ è®¡ç®—æœºè§†è§‰æ˜¯ä¸€ä¸ªå¹¿æ³›è€Œæ·±å…¥çš„é¢†åŸŸï¼Œæœ¬æ–‡ä»‹ç»äº†ä»åŸºç¡€çš„å›¾åƒè¡¨ç¤ºå’Œå¤„ç†åˆ°é«˜çº§çš„ç‰¹å¾æå–å’Œç›®æ ‡æ£€æµ‹çš„åŸºæœ¬æ¦‚å¿µå’Œæ–¹æ³•ã€‚é€šè¿‡å­¦ä¹ è¿™äº›åŸºç¡€çŸ¥è¯†ï¼Œè¯»è€…å¯ä»¥ä¸ºè¿›ä¸€æ­¥æ¢ç´¢è®¡ç®—æœºè§†è§‰çš„æ›´é«˜çº§ä¸»é¢˜æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸæ­£åœ¨ç»å†å¿«é€Ÿå˜é©ã€‚ä¼ ç»Ÿçš„è®¡ç®—æœºè§†è§‰æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ ç›¸ç»“åˆï¼Œæ­£åœ¨æ¨åŠ¨è®¡ç®—æœºè§†è§‰åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ä¸æ–­æ‹“å±•ã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºè§†è§‰çš„åŸºæœ¬åŸç†ï¼Œå¹¶æ¿€å‘è¿›ä¸€æ­¥å­¦ä¹ å’Œæ¢ç´¢çš„å…´è¶£ã€‚\nåœ¨æœªæ¥ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å°†ç»§ç»­å‘å±•ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€å¢å¼ºç°å®ã€æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸå‘æŒ¥è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚æŒæ¡è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå°†ä¸ºè¯»è€…åœ¨è¿™ä¸€å……æ»¡æœºé‡çš„é¢†åŸŸä¸­å‘å±•æä¾›æœ‰åŠ›æ”¯æŒã€‚\n","permalink":"http://localhost:1313/posts/computer-vision-basics/","summary":"\u003ch1 id=\"è®¡ç®—æœºè§†è§‰åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eè®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eè®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\u003c/p\u003e","title":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£"},{"content":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\næ·±åº¦å­¦ä¹ ä¸å›¾åƒå¤„ç† ä¼ ç»Ÿå›¾åƒå¤„ç†çš„å±€é™æ€§ ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ä¸»è¦ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ç‰¹å¾æå–å™¨å’Œç®—æ³•ï¼Œè¿™äº›æ–¹æ³•è™½ç„¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š\nç‰¹å¾è®¾è®¡å›°éš¾ï¼šéœ€è¦é¢†åŸŸä¸“å®¶è®¾è®¡ç‰¹å¾ï¼Œè€—æ—¶ä¸”éš¾ä»¥æ³›åŒ–ã€‚ é€‚åº”æ€§å·®ï¼šå¯¹å…‰ç…§ã€è§’åº¦ã€å°ºåº¦ç­‰å˜åŒ–æ•æ„Ÿã€‚ å¤æ‚åœºæ™¯å¤„ç†èƒ½åŠ›æœ‰é™ï¼šéš¾ä»¥å¤„ç†å¤æ‚èƒŒæ™¯å’Œå¤šå˜çš„ç¯å¢ƒã€‚ ç«¯åˆ°ç«¯å­¦ä¹ å›°éš¾ï¼šé€šå¸¸éœ€è¦å¤šä¸ªæ­¥éª¤ç»„åˆï¼Œéš¾ä»¥å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚ æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿ æ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œé€šè¿‡è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„è®¸å¤šå±€é™ï¼š\nè‡ªåŠ¨ç‰¹å¾æå–ï¼šæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾ï¼Œç½‘ç»œè‡ªåŠ¨å­¦ä¹ æœ€ä¼˜è¡¨ç¤ºã€‚ å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ï¼šå¤šå±‚ç½‘ç»œç»“æ„å¯ä»¥å­¦ä¹ å¤æ‚çš„ç‰¹å¾å±‚æ¬¡ã€‚ ç«¯åˆ°ç«¯å­¦ä¹ ï¼šä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºï¼Œæ•´ä¸ªè¿‡ç¨‹å¯ä¼˜åŒ–ã€‚ é€‚åº”æ€§å¼ºï¼šå¯¹å„ç§å˜åŒ–å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ã€‚ å¤§æ•°æ®é©±åŠ¨ï¼šèƒ½å¤Ÿåˆ©ç”¨å¤§é‡æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚ å·ç§¯ç¥ç»ç½‘ç»œ(CNN) å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†é¢†åŸŸæœ€æˆåŠŸçš„åº”ç”¨ä¹‹ä¸€ï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäºç”Ÿç‰©è§†è§‰ç³»ç»Ÿã€‚\nCNNçš„åŸºæœ¬ç»“æ„ å…¸å‹çš„CNNç”±ä»¥ä¸‹å‡ ç§å±‚ç»„æˆï¼š\nå·ç§¯å±‚(Convolutional Layer)ï¼šä½¿ç”¨å·ç§¯æ ¸æå–å±€éƒ¨ç‰¹å¾ã€‚ æ± åŒ–å±‚(Pooling Layer)ï¼šé™ä½ç©ºé—´ç»´åº¦ï¼Œå‡å°‘è®¡ç®—é‡ã€‚ æ¿€æ´»å‡½æ•°å±‚(Activation Layer)ï¼šå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚ å…¨è¿æ¥å±‚(Fully Connected Layer)ï¼šæ•´åˆç‰¹å¾ï¼Œè¿›è¡Œæœ€ç»ˆåˆ†ç±»æˆ–å›å½’ã€‚ å½’ä¸€åŒ–å±‚(Normalization Layer)ï¼šå¦‚æ‰¹å½’ä¸€åŒ–(Batch Normalization)ï¼ŒåŠ é€Ÿè®­ç»ƒã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # ä½¿ç”¨PyTorchæ„å»ºç®€å•çš„CNN import torch import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self, num_classes=10): super(SimpleCNN, self).__init__() self.features = nn.Sequential( # å·ç§¯å±‚1 nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚2 nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚3 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2) ) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(128 * 28 * 28, 512), # è¾“å…¥å°ºå¯¸éœ€ä¸ç‰¹å¾å›¾å°ºå¯¸ä¸€è‡´ nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(512, num_classes) ) def forward(self, x): # x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, 3, 224, 224) æˆ–æ ¹æ®å®é™…è¾“å…¥è°ƒæ•´ # è¿”å›åˆ†ç±»ç»“æœ x = self.features(x) x = x.view(x.size(0), -1) x = self.classifier(x) return x ç»å…¸CNNæ¶æ„ LeNet-5 LeNet-5æ˜¯æœ€æ—©çš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œç”±Yann LeCunåœ¨1998å¹´æå‡ºï¼Œä¸»è¦ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class LeNet5(nn.Module): def __init__(self): super(LeNet5, self).__init__() self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1) self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = torch.relu(self.conv1(x)) x = self.pool1(x) x = torch.relu(self.conv2(x)) x = self.pool2(x) x = x.view(-1, 16 * 5 * 5) x = torch.relu(self.fc1(x)) x = torch.relu(self.fc2(x)) x = self.fc3(x) return x AlexNet AlexNetåœ¨2012å¹´ImageNetç«èµ›ä¸­å–å¾—äº†çªç ´æ€§æˆç»©ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å´›èµ·ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class AlexNet(nn.Module): def __init__(self, num_classes=1000): super(AlexNet, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x VGGNet VGGNetä»¥å…¶ç®€æ´çš„ç»“æ„å’Œå‡ºè‰²çš„æ€§èƒ½è‘—ç§°ï¼Œä¸»è¦ç‰¹ç‚¹æ˜¯ä½¿ç”¨å°å°ºå¯¸å·ç§¯æ ¸å’Œæ·±å±‚ç½‘ç»œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class VGG16(nn.Module): def __init__(self, num_classes=1000): super(VGG16, self).__init__() self.features = nn.Sequential( # Block 1 nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 2 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 3 nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 4 nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 5 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) self.classifier = nn.Sequential( nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x ResNet ResNeté€šè¿‡å¼•å…¥æ®‹å·®è¿æ¥è§£å†³äº†æ·±å±‚ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—æ„å»ºæ•°ç™¾ç”šè‡³ä¸Šåƒå±‚çš„ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample self.stride = stride def forward(self, x): identity = x out = self.conv1(x) out = self.bn1(out) out = nn.ReLU(inplace=True)(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = nn.ReLU(inplace=True)(out) return out class ResNet(nn.Module): def __init__(self, block, layers, num_classes=1000): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2) self.layer3 = self._make_layer(block, 256, layers[2], stride=2) self.layer4 = self._make_layer(block, 512, layers[3], stride=2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def _make_layer(self, block, channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != channels * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channels, channels * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channels * block.expansion), ) layers = [] layers.append(block(self.in_channels, channels, stride, downsample)) self.in_channels = channels * block.expansion for _ in range(1, blocks): layers.append(block(self.in_channels, channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = nn.ReLU(inplace=True)(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x def resnet18(): return ResNet(BasicBlock, [2, 2, 2, 2]) CNNåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒåˆ†ç±» å›¾åƒåˆ†ç±»æ˜¯CNNæœ€åŸºæœ¬çš„åº”ç”¨ï¼Œé€šè¿‡è®­ç»ƒç½‘ç»œè¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNetè¿›è¡Œå›¾åƒåˆ†ç±» import torchvision.models as models import torchvision.transforms as transforms from PIL import Image # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = models.resnet18(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image) input_batch = input_tensor.unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_batch) # è·å–é¢„æµ‹ç»“æœ _, predicted_idx = torch.max(output, 1) ç›®æ ‡æ£€æµ‹ ç›®æ ‡æ£€æµ‹ä¸ä»…è¯†åˆ«å›¾åƒä¸­çš„å¯¹è±¡ï¼Œè¿˜ç¡®å®šå®ƒä»¬çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # ä½¿ç”¨Faster R-CNNè¿›è¡Œç›®æ ‡æ£€æµ‹ import torchvision from torchvision.models.detection import fasterrcnn_resnet50_fpn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fasterrcnn_resnet50_fpn(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† transform = transforms.Compose([transforms.ToTensor()]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) image_tensor = transform(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): predictions = model(image_tensor) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡ï¼ŒåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ä½¿ç”¨FCNè¿›è¡Œè¯­ä¹‰åˆ†å‰² from torchvision.models.segmentation import fcn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fcn.fcn_resnet50(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_tensor)[\u0026#39;out\u0026#39;] ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN) ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ˜¯ç”±Ian Goodfellowåœ¨2014å¹´æå‡ºçš„ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚\nGANçš„åŸºæœ¬åŸç† GANç”±ä¸¤ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼š\nç”Ÿæˆå™¨(Generator)ï¼šè¯•å›¾ç”Ÿæˆé€¼çœŸçš„æ•°æ®ï¼Œä»¥æ¬ºéª—åˆ¤åˆ«å™¨ã€‚ åˆ¤åˆ«å™¨(Discriminator)ï¼šè¯•å›¾åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆå™¨ç”Ÿæˆçš„å‡æ•°æ®ã€‚ è¿™ä¸¤ä¸ªç½‘ç»œé€šè¿‡å¯¹æŠ—è®­ç»ƒä¸æ–­æ”¹è¿›ï¼Œæœ€ç»ˆç”Ÿæˆå™¨èƒ½å¤Ÿç”Ÿæˆä¸çœŸå®æ•°æ®åˆ†å¸ƒç›¸ä¼¼çš„æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€å•çš„GANå®ç° import torch import torch.nn as nn class Generator(nn.Module): def __init__(self, latent_dim, img_shape): super(Generator, self).__init__() self.img_shape = img_shape def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *self.img_shape) return img class Discriminator(nn.Module): def __init__(self, img_shape): super(Discriminator, self).__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, img): img_flat = img.view(img.size(0), -1) validity = self.model(img_flat) return validity GANçš„è®­ç»ƒè¿‡ç¨‹ GANçš„è®­ç»ƒè¿‡ç¨‹æ˜¯ä¸€ä¸ªæå°æå¤§åšå¼ˆé—®é¢˜ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # GANè®­ç»ƒå¾ªç¯ import torch.optim as optim # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨ latent_dim = 100 img_shape = (1, 28, 28) # MNISTå›¾åƒå¤§å° generator = Generator(latent_dim, img_shape) discriminator = Discriminator(img_shape) # ä¼˜åŒ–å™¨ optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # æŸå¤±å‡½æ•° adversarial_loss = torch.nn.BCELoss() # è®­ç»ƒå‚æ•° n_epochs = 200 batch_size = 64 for epoch in range(n_epochs): for i, (imgs, _) in enumerate(dataloader): # çœŸå®å’Œå‡çš„æ ‡ç­¾ real = torch.ones(imgs.size(0), 1) fake = torch.zeros(imgs.size(0), 1) # è®­ç»ƒç”Ÿæˆå™¨ optimizer_G.zero_grad() z = torch.randn(imgs.size(0), latent_dim) gen_imgs = generator(z) g_loss = adversarial_loss(discriminator(gen_imgs), real) g_loss.backward() optimizer_G.step() # è®­ç»ƒåˆ¤åˆ«å™¨ optimizer_D.zero_grad() real_loss = adversarial_loss(discriminator(imgs), real) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2 d_loss.backward() optimizer_D.step() å¸¸è§çš„GANå˜ä½“ DCGAN (Deep Convolutional GAN) DCGANå°†CNNç»“æ„å¼•å…¥GANï¼Œæé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class DCGAN_Generator(nn.Module): def __init__(self, latent_dim, channels=1): super(DCGAN_Generator, self).__init__() self.init_size = 7 # åˆå§‹å¤§å° self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2)) self.conv_blocks = nn.Sequential( nn.BatchNorm2d(128), nn.Upsample(scale_factor=2), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.BatchNorm2d(128, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Upsample(scale_factor=2), nn.Conv2d(128, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Conv2d(64, channels, 3, stride=1, padding=1), nn.Tanh(), ) def forward(self, z): out = self.l1(z) out = out.view(out.shape[0], 128, self.init_size, self.init_size) img = self.conv_blocks(out) return img CycleGAN CycleGANç”¨äºåœ¨æ²¡æœ‰æˆå¯¹è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ResidualBlock(nn.Module): def __init__(self, in_features): super(ResidualBlock, self).__init__() self.block = nn.Sequential( nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features), nn.ReLU(inplace=True), nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features) ) def forward(self, x): return x + self.block(x) class GeneratorResNet(nn.Module): def __init__(self, input_shape, num_residual_blocks): super(GeneratorResNet, self).__init__() channels = input_shape[0] # åˆå§‹å·ç§¯å— out_features = 64 model = [ nn.ReflectionPad2d(3), nn.Conv2d(channels, out_features, 7), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # ä¸‹é‡‡æ · for _ in range(2): out_features *= 2 model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # æ®‹å·®å— for _ in range(num_residual_blocks): model += [ResidualBlock(out_features)] # ä¸Šé‡‡æ · for _ in range(2): out_features //= 2 model += [ nn.Upsample(scale_factor=2), nn.Conv2d(in_features, out_features, 3, stride=1, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # è¾“å‡ºå±‚ model += [nn.ReflectionPad2d(3), nn.Conv2d(out_features, channels, 7), nn.Tanh()] self.model = nn.Sequential(*model) def forward(self, x): return self.model(x) StyleGAN StyleGANé€šè¿‡é£æ ¼æ§åˆ¶ç”Ÿæˆé«˜è´¨é‡çš„äººè„¸å›¾åƒï¼Œå…·æœ‰å‡ºè‰²çš„å¯æ§æ€§å’Œå¤šæ ·æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class StyleGAN_Generator(nn.Module): def __init__(self, latent_dim, n_mlp=8): super(StyleGAN_Generator, self).__init__() # æ˜ å°„ç½‘ç»œ layers = [] for i in range(n_mlp): layers.append(nn.Linear(latent_dim, latent_dim)) layers.append(nn.LeakyReLU(0.2)) self.mapping = nn.Sequential(*layers) # åˆæˆç½‘ç»œ self.synthesis = self._build_synthesis_network(latent_dim) def _build_synthesis_network(self, latent_dim): # è¿™é‡Œç®€åŒ–äº†StyleGANçš„åˆæˆç½‘ç»œç»“æ„ # å®é™…çš„StyleGANç»“æ„æ›´ä¸ºå¤æ‚ï¼ŒåŒ…æ‹¬AdaINã€å™ªå£°æ³¨å…¥ç­‰ layers = nn.ModuleList() # åˆå§‹å¸¸æ•° self.constant_input = nn.Parameter(torch.randn(1, 512, 4, 4)) # ç”Ÿæˆå— in_channels = 512 for i in range(8): # 8ä¸ªä¸Šé‡‡æ ·å— out_channels = min(512, 512 // (2 ** (i // 2))) layers.append(StyleGAN_Block(in_channels, out_channels, upsample=(i \u0026gt; 0))) in_channels = out_channels # è¾“å‡ºå±‚ layers.append(nn.Conv2d(in_channels, 3, 1)) layers.append(nn.Tanh()) return nn.Sequential(*layers) def forward(self, z): # é€šè¿‡æ˜ å°„ç½‘ç»œ w = self.mapping(z) # é€šè¿‡åˆæˆç½‘ç»œ x = self.synthesis(w) return x class StyleGAN_Block(nn.Module): def __init__(self, in_channels, out_channels, upsample=False): super(StyleGAN_Block, self).__init__() self.upsample = upsample if upsample: self.up = nn.Upsample(scale_factor=2, mode=\u0026#39;bilinear\u0026#39;, align_corners=False) self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1) self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1) self.activate = nn.LeakyReLU(0.2) def forward(self, x): if self.upsample: x = self.up(x) x = self.conv1(x) x = self.activate(x) x = self.conv2(x) x = self.activate(x) return x GANåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒç”Ÿæˆ GANå¯ä»¥ç”Ÿæˆå„ç§ç±»å‹çš„å›¾åƒï¼Œä»ç®€å•çš„äººè„¸åˆ°å¤æ‚çš„åœºæ™¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨é¢„è®­ç»ƒçš„StyleGANç”Ÿæˆäººè„¸ import torch from stylegan2_pytorch import Generator # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = Generator(256, 512, 8).cuda() # å‡è®¾æœ‰é¢„è®­ç»ƒæƒé‡ model.load_state_dict(torch.load(\u0026#39;stylegan2-ffhq-config-f.pt\u0026#39;)) model.eval() # ç”Ÿæˆéšæœºæ½œåœ¨å‘é‡ z = torch.randn(1, 512).cuda() # ç”Ÿæˆå›¾åƒ with torch.no_grad(): img = model(z) å›¾åƒä¿®å¤ GANå¯ä»¥ç”¨äºä¿®å¤å›¾åƒä¸­çš„ç¼ºå¤±éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # ç®€åŒ–çš„å›¾åƒä¿®å¤æ¨¡å‹ class ImageInpainting(nn.Module): def __init__(self): super(ImageInpainting, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(4, 64, 7, stride=1, padding=3), # 4é€šé“ï¼šRGB + mask nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 512, 3, stride=2, padding=1), nn.ReLU(inplace=True), ) # ä¸­é—´å±‚ self.middle = nn.Sequential( nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 7, stride=1, padding=3), nn.Tanh(), ) def forward(self, x, mask): # è¿æ¥å›¾åƒå’Œæ©ç  x_masked = x * (1 - mask) input = torch.cat([x_masked, mask], dim=1) # ç¼–ç  x = self.encoder(input) # ä¸­é—´å¤„ç† x = self.middle(x) # è§£ç  x = self.decoder(x) # ç»„åˆåŸå§‹å›¾åƒå’Œç”Ÿæˆéƒ¨åˆ† output = x * mask + x_masked return output å›¾åƒè¶…åˆ†è¾¨ç‡ GANå¯ä»¥ç”¨äºå°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 # SRGANç”Ÿæˆå™¨ class SRGAN_Generator(nn.Module): def __init__(self, scale_factor=4): super(SRGAN_Generator, self).__init__() # åˆå§‹å·ç§¯ self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4) self.relu = nn.ReLU(inplace=True) # æ®‹å·®å— residual_blocks = [] for _ in range(16): residual_blocks.append(ResidualBlock(64)) self.residual_blocks = nn.Sequential(*residual_blocks) # ä¸Šé‡‡æ · upsampling = [] for _ in range(int(math.log(scale_factor, 2))): upsampling.append(nn.Conv2d(64, 256, 3, stride=1, padding=1)) upsampling.append(nn.PixelShuffle(2)) upsampling.append(nn.ReLU(inplace=True)) self.upsampling = nn.Sequential(*upsampling) # è¾“å‡ºå±‚ self.conv2 = nn.Conv2d(64, 3, 9, stride=1, padding=4) self.tanh = nn.Tanh() def forward(self, x): # åˆå§‹å·ç§¯ x = self.conv1(x) residual = x x = self.relu(x) # æ®‹å·®å— x = self.residual_blocks(x) # æ®‹å·®è¿æ¥ x = x + residual # ä¸Šé‡‡æ · x = self.upsampling(x) # è¾“å‡º x = self.conv2(x) x = self.tanh(x) return x class ResidualBlock(nn.Module): def __init__(self, channels): super(ResidualBlock, self).__init__() self.conv1 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(channels) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = out + residual return out é£æ ¼è¿ç§» GANå¯ä»¥å®ç°ä»ä¸€ç§è‰ºæœ¯é£æ ¼åˆ°å¦ä¸€ç§é£æ ¼çš„å›¾åƒè½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€åŒ–çš„é£æ ¼è¿ç§»ç½‘ç»œ class StyleTransfer(nn.Module): def __init__(self): super(StyleTransfer, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 9, stride=1, padding=4), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(inplace=True), ) # æ®‹å·®å— residual_blocks = [] for _ in range(5): residual_blocks.append(ResidualBlock(128)) self.residual_blocks = nn.Sequential(*residual_blocks) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 3, 9, stride=1, padding=4), nn.Tanh(), ) def forward(self, x): # ç¼–ç  x = self.encoder(x) # æ®‹å·®å¤„ç† x = self.residual_blocks(x) # è§£ç  x = self.decoder(x) return x å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ è‡ªç¼–ç å™¨(Autoencoder) è‡ªç¼–ç å™¨æ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç¼–ç å™¨å°†è¾“å…¥å‹ç¼©ä¸ºä½ç»´è¡¨ç¤ºï¼Œå†é€šè¿‡è§£ç å™¨é‡æ„åŸå§‹è¾“å…¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Autoencoder(nn.Module): def __init__(self, latent_dim): super(Autoencoder, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), nn.Linear(128 * 4 * 4, latent_dim), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def forward(self, x): z = self.encoder(x) x_reconstructed = self.decoder(z) return x_reconstructed, z å˜åˆ†è‡ªç¼–ç å™¨(VAE) å˜åˆ†è‡ªç¼–ç å™¨æ˜¯è‡ªç¼–ç å™¨çš„æ¦‚ç‡ç‰ˆæœ¬ï¼Œå¯ä»¥ç”Ÿæˆæ–°çš„æ•°æ®æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class VAE(nn.Module): def __init__(self, latent_dim): super(VAE, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), ) # å‡å€¼å’Œæ–¹å·® self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim) self.fc_var = nn.Linear(128 * 4 * 4, latent_dim) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def encode(self, x): h = self.encoder(x) mu = self.fc_mu(h) log_var = self.fc_var(h) return mu, log_var def reparameterize(self, mu, log_var): std = torch.exp(0.5 * log_var) eps = torch.randn_like(std) z = mu + eps * std return z def decode(self, z): return self.decoder(z) def forward(self, x): mu, log_var = self.encode(x) z = self.reparameterize(mu, log_var) x_reconstructed = self.decode(z) return x_reconstructed, mu, log_var æ‰©æ•£æ¨¡å‹(Diffusion Model) æ‰©æ•£æ¨¡å‹æ˜¯è¿‘å¹´æ¥å…´èµ·çš„ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡é€æ­¥æ·»åŠ å’Œå»é™¤å™ªå£°æ¥ç”Ÿæˆå›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class DiffusionModel(nn.Module): def __init__(self, timesteps=1000): super(DiffusionModel, self).__init__() self.timesteps = timesteps # å™ªå£°è°ƒåº¦å™¨ self.beta = torch.linspace(0.0001, 0.02, timesteps) self.alpha = 1. - self.beta self.alpha_hat = torch.cumprod(self.alpha, dim=0) # U-Netç»“æ„ self.unet = self._build_unet() def _build_unet(self): # ç®€åŒ–çš„U-Netç»“æ„ return nn.Sequential( # ä¸‹é‡‡æ · nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), # ä¸­é—´å±‚ nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), # ä¸Šé‡‡æ · nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 3, padding=1), ) def forward(self, x, t): # æ·»åŠ æ—¶é—´åµŒå…¥ t_emb = self._get_time_embedding(t, x.shape[0]) t_emb = t_emb.view(-1, 1, 1, 1).expand(-1, 3, x.shape[2], x.shape[3]) x = torch.cat([x, t_emb], dim=1) # é€šè¿‡U-Neté¢„æµ‹å™ªå£° noise_pred = self.unet(x) return noise_pred def _get_time_embedding(self, t, batch_size): # ç®€åŒ–çš„æ—¶é—´åµŒå…¥ t = t.view(-1, 1) t = t.float() / self.timesteps t = t * 2 * math.pi sin_t = torch.sin(t) cos_t = torch.cos(t) t_emb = torch.cat([sin_t, cos_t], dim=1) t_emb = t_emb.repeat(1, 3) # æ‰©å±•åˆ°3é€šé“ return t_emb def sample(self, x_shape): # ä»çº¯å™ªå£°å¼€å§‹ x = torch.randn(x_shape) # é€æ­¥å»å™ª for t in reversed(range(self.timesteps)): t_batch = torch.full((x_shape[0],), t, dtype=torch.long) noise_pred = self.forward(x, t_batch) # è®¡ç®—å»å™ªåçš„å›¾åƒ alpha_t = self.alpha[t] alpha_hat_t = self.alpha_hat[t] beta_t = self.beta[t] if t \u0026gt; 0: noise = torch.randn_like(x) else: noise = torch.zeros_like(x) x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * noise_pred) + torch.sqrt(beta_t) * noise return x è§†è§‰Transformer(ViT) è§†è§‰Transformerå°†Transformeræ¶æ„åº”ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸Šå–å¾—äº†ä¸CNNç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 class PatchEmbed(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768): super(PatchEmbed, self).__init__() self.img_size = img_size self.patch_size = patch_size self.n_patches = (img_size // patch_size) ** 2 self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size) def forward(self, x): x = self.proj(x) # (B, embed_dim, n_patches ** 0.5, n_patches ** 0.5) x = x.flatten(2) # (B, embed_dim, n_patches) x = x.transpose(1, 2) # (B, n_patches, embed_dim) return x class Attention(nn.Module): def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.): super(Attention, self).__init__() self.n_heads = n_heads self.dim = dim self.head_dim = dim // n_heads self.scale = self.head_dim ** -0.5 self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias) self.attn_drop = nn.Dropout(attn_p) self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_p) def forward(self, x): n_samples, n_tokens, dim = x.shape qkv = self.qkv(x) # (n_samples, n_tokens, 3 * dim) qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim) qkv = qkv.permute(2, 0, 3, 1, 4) # (3, n_samples, n_heads, n_tokens, head_dim) q, k, v = qkv[0], qkv[1], qkv[2] k_t = k.transpose(-2, -1) # (n_samples, n_heads, head_dim, n_tokens) dp = (q @ k_t) * self.scale # (n_samples, n_heads, n_tokens, n_tokens) attn = dp.softmax(dim=-1) # (n_samples, n_heads, n_tokens, n_tokens) attn = self.attn_drop(attn) weighted_avg = attn @ v # (n_samples, n_heads, n_tokens, head_dim) weighted_avg = weighted_avg.transpose(1, 2) # (n_samples, n_tokens, n_heads, head_dim) weighted_avg = weighted_avg.flatten(2) # (n_samples, n_tokens, dim) x = self.proj(weighted_avg) x = self.proj_drop(x) return x class MLP(nn.Module): def __init__(self, in_features, hidden_features, out_features, p=0.): super(MLP, self).__init__() self.fc1 = nn.Linear(in_features, hidden_features) self.act = nn.GELU() self.fc2 = nn.Linear(hidden_features, out_features) self.drop = nn.Dropout(p) def forward(self, x): x = self.fc1(x) x = self.act(x) x = self.drop(x) x = self.fc2(x) x = self.drop(x) return x class Block(nn.Module): def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(Block, self).__init__() self.norm1 = nn.LayerNorm(dim, eps=1e-6) self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p) self.norm2 = nn.LayerNorm(dim, eps=1e-6) hidden_features = int(dim * mlp_ratio) self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim, p=p) def forward(self, x): x = x + self.attn(self.norm1(x)) x = x + self.mlp(self.norm2(x)) return x class VisionTransformer(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, n_classes=1000, embed_dim=768, depth=12, n_heads=12, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(VisionTransformer, self).__init__() self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_channels=in_channels, embed_dim=embed_dim) self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) self.pos_embed = nn.Parameter(torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)) self.pos_drop = nn.Dropout(p=p) self.blocks = nn.ModuleList([ Block(dim=embed_dim, n_heads=n_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, p=p, attn_p=attn_p) for _ in range(depth) ]) self.norm = nn.LayerNorm(embed_dim, eps=1e-6) self.head = nn.Linear(embed_dim, n_classes) def forward(self, x): n_samples = x.shape[0] x = self.patch_embed(x) cls_token = self.cls_token.expand(n_samples, -1, -1) x = torch.cat((cls_token, x), dim=1) x = x + self.pos_embed x = self.pos_drop(x) for block in self.blocks: x = block(x) x = self.norm(x) cls_token_final = x[:, 0] x = self.head(cls_token_final) return x æ·±åº¦å­¦ä¹ å›¾åƒå¤„ç†çš„æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘ å½“å‰æŒ‘æˆ˜ æ•°æ®éœ€æ±‚ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜ã€‚ è®¡ç®—èµ„æºï¼šè®­ç»ƒå¤§å‹æ¨¡å‹éœ€è¦å¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚ å¯è§£é‡Šæ€§ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸è¢«è§†ä¸º\u0026quot;é»‘ç›’\u0026quot;ï¼Œéš¾ä»¥è§£é‡Šå…¶å†³ç­–è¿‡ç¨‹ã€‚ æ³›åŒ–èƒ½åŠ›ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®åˆ†å¸ƒå¤–è¡¨ç°ä¸ä½³ï¼Œé²æ£’æ€§æœ‰å¾…æé«˜ã€‚ é¢†åŸŸé€‚åº”ï¼šå°†æ¨¡å‹ä»ä¸€ä¸ªé¢†åŸŸè¿ç§»åˆ°å¦ä¸€ä¸ªé¢†åŸŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ æœªæ¥æ–¹å‘ è‡ªç›‘ç£å­¦ä¹ ï¼šå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä»æœªæ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ ã€‚ å°æ ·æœ¬å­¦ä¹ ï¼šä½¿æ¨¡å‹èƒ½å¤Ÿä»å°‘é‡æ ·æœ¬ä¸­å­¦ä¹ ã€‚ å¤šæ¨¡æ€å­¦ä¹ ï¼šç»“åˆå›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€çš„ä¿¡æ¯ã€‚ ç¥ç»æ¶æ„æœç´¢ï¼šè‡ªåŠ¨è®¾è®¡æœ€ä¼˜çš„ç½‘ç»œç»“æ„ã€‚ æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿï¼šä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œã€‚ å¯è§£é‡ŠAIï¼šæé«˜æ¨¡å‹çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚ é²æ£’æ€§å¢å¼ºï¼šæé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ ·æœ¬å’Œåˆ†å¸ƒå¤–æ•°æ®çš„é²æ£’æ€§ã€‚ æ€»ç»“ æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯CNNå’ŒGANï¼Œå·²ç»å½»åº•æ”¹å˜äº†å›¾åƒå¤„ç†é¢†åŸŸã€‚ä»å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆå’Œé£æ ¼è¿ç§»ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­éƒ½å–å¾—äº†ä»¤äººç©ç›®çš„æˆæœã€‚\nCNNé€šè¿‡å…¶å±€éƒ¨è¿æ¥å’Œæƒå€¼å…±äº«çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆåœ°æå–å›¾åƒçš„å±‚æ¬¡ç‰¹å¾ï¼Œæˆä¸ºå›¾åƒå¤„ç†çš„åŸºç¡€æ¶æ„ã€‚GANé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä¸ºå›¾åƒç”Ÿæˆå’Œè½¬æ¢ä»»åŠ¡æä¾›äº†å¼ºå¤§çš„å·¥å…·ã€‚\né™¤äº†CNNå’ŒGANï¼Œè‡ªç¼–ç å™¨ã€å˜åˆ†è‡ªç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹å’Œè§†è§‰Transformerç­‰æ¨¡å‹ä¹Ÿåœ¨å›¾åƒå¤„ç†ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œä¸æ–­æ¨åŠ¨ç€è¯¥é¢†åŸŸçš„å‘å±•ã€‚\nå°½ç®¡æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†ä»é¢ä¸´æ•°æ®éœ€æ±‚ã€è®¡ç®—èµ„æºã€å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚æœªæ¥ï¼Œè‡ªç›‘ç£å­¦ä¹ ã€å°æ ·æœ¬å­¦ä¹ ã€å¤šæ¨¡æ€å­¦ä¹ ç­‰æ–¹å‘å°†å¼•é¢†å›¾åƒå¤„ç†é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚\nä½œä¸ºå›¾åƒç®—æ³•å·¥ç¨‹å¸ˆï¼Œäº†è§£å’ŒæŒæ¡è¿™äº›æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹äºè§£å†³å®é™…é—®é¢˜è‡³å…³é‡è¦ã€‚é€šè¿‡ä¸æ–­å­¦ä¹ å’Œå®è·µï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°åº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œæ¨åŠ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åˆ›æ–°å’Œå‘å±•ã€‚\n","permalink":"http://localhost:1313/posts/deep-learning-image-processing/","summary":"\u003ch1 id=\"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ä»cnnåˆ°gan\"\u003eæ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN\u003c/h1\u003e\n\u003cp\u003eæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\u003c/p\u003e","title":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨"},{"content":"ç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ åœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\nç®—æ³•å¤æ‚åº¦åˆ†æ æ—¶é—´å¤æ‚åº¦ æ—¶é—´å¤æ‚åº¦æ˜¯è¡¡é‡ç®—æ³•æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡å¢é•¿è€Œå¢é•¿çš„é€Ÿç‡ã€‚å¸¸è§çš„æ—¶é—´å¤æ‚åº¦ä»ä½åˆ°é«˜ä¾æ¬¡ä¸ºï¼š\nO(1) - å¸¸æ•°æ—¶é—´ å¸¸æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ï¼Œæ˜¯æœ€ç†æƒ³çš„å¤æ‚åº¦ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šè·å–æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´  def get_first_element(arr): return arr[0] # æ— è®ºæ•°ç»„å¤šå¤§ï¼Œæ‰§è¡Œæ—¶é—´ç›¸åŒ O(log n) - å¯¹æ•°æ—¶é—´ å¯¹æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„å¯¹æ•°å¢é•¿ï¼Œå¸¸è§äºåˆ†æ²»ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šäºŒåˆ†æŸ¥æ‰¾ å‚æ•°ï¼šarr (List[int])ï¼Œtarget (int) è¿”å›ï¼šç›®æ ‡ç´¢å¼•æˆ–-1 \u0026#34;\u0026#34;\u0026#34; def binary_search(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: mid = (left + right) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 O(n) - çº¿æ€§æ—¶é—´ çº¿æ€§æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 4 5 6 7 # ç¤ºä¾‹ï¼šæŸ¥æ‰¾æ•°ç»„ä¸­çš„æœ€å¤§å€¼ def find_max(arr): max_val = arr[0] for val in arr: if val \u0026gt; max_val: max_val = val return max_val O(n log n) - çº¿æ€§å¯¹æ•°æ—¶é—´ çº¿æ€§å¯¹æ•°æ—¶é—´ç®—æ³•å¸¸è§äºé«˜æ•ˆçš„æ’åºç®—æ³•ï¼Œå¦‚å¿«é€Ÿæ’åºã€å½’å¹¶æ’åºã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # ç¤ºä¾‹ï¼šå½’å¹¶æ’åº def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) right = merge_sort(arr[mid:]) return merge(left, right) def merge(left, right): result = [] i = j = 0 while i \u0026lt; len(left) and j \u0026lt; len(right): if left[i] \u0026lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result.extend(left[i:]) result.extend(right[j:]) return result O(nÂ²) - å¹³æ–¹æ—¶é—´ å¹³æ–¹æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ï¼Œå¸¸è§äºç®€å•çš„æ’åºç®—æ³•å’ŒåµŒå¥—å¾ªç¯ã€‚\n1 2 3 4 5 6 7 8 # ç¤ºä¾‹ï¼šå†’æ³¡æ’åº def bubble_sort(arr): n = len(arr) for i in range(n): for j in range(0, n - i - 1): if arr[j] \u0026gt; arr[j + 1]: arr[j], arr[j + 1] = arr[j + 1], arr[j] return arr O(2â¿) - æŒ‡æ•°æ—¶é—´ æŒ‡æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡æŒ‡æ•°å¢é•¿ï¼Œé€šå¸¸ç”¨äºè§£å†³NPéš¾é—®é¢˜ã€‚\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šé€’å½’è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼ˆä½æ•ˆç‰ˆæœ¬ï¼‰ å‚æ•°ï¼šn (int) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n \u0026lt;= 1: return n return fibonacci(n - 1) + fibonacci(n - 2) O(n!) - é˜¶ä¹˜æ—¶é—´ é˜¶ä¹˜æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„é˜¶ä¹˜å¢é•¿ï¼Œæ˜¯æœ€å·®çš„å¤æ‚åº¦ï¼Œå¸¸è§äºæš´åŠ›æœç´¢æ‰€æœ‰æ’åˆ—ç»„åˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ç¤ºä¾‹ï¼šç”Ÿæˆæ‰€æœ‰æ’åˆ— def permutations(arr): if len(arr) \u0026lt;= 1: return [arr] result = [] for i in range(len(arr)): rest = arr[:i] + arr[i+1:] for p in permutations(rest): result.append([arr[i]] + p) return result ç©ºé—´å¤æ‚åº¦ ç©ºé—´å¤æ‚åº¦è¡¡é‡ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­æ‰€éœ€é¢å¤–ç©ºé—´éšè¾“å…¥è§„æ¨¡å¢é•¿çš„é€Ÿç‡ã€‚\nO(1) - å¸¸æ•°ç©ºé—´ å¸¸æ•°ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåŸåœ°äº¤æ¢æ•°ç»„å…ƒç´  def swap_elements(arr, i, j): arr[i], arr[j] = arr[j], arr[i] # ä¸éœ€è¦é¢å¤–ç©ºé—´ O(n) - çº¿æ€§ç©ºé—´ çº¿æ€§ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šå¤åˆ¶æ•°ç»„ def copy_array(arr): return arr.copy() # éœ€è¦ä¸åŸæ•°ç»„å¤§å°ç›¸åŒçš„é¢å¤–ç©ºé—´ O(nÂ²) - å¹³æ–¹ç©ºé—´ å¹³æ–¹ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåˆ›å»ºäºŒç»´æ•°ç»„ def create_2d_array(n): return [[0 for _ in range(n)] for _ in range(n)] # éœ€è¦nÂ²çš„é¢å¤–ç©ºé—´ å¤æ‚åº¦åˆ†ææŠ€å·§ å¾ªç¯åˆ†æ å¯¹äºå¾ªç¯ç»“æ„ï¼Œå¤æ‚åº¦é€šå¸¸ç”±å¾ªç¯æ¬¡æ•°å’Œå¾ªç¯ä½“å†…çš„æ“ä½œå†³å®šã€‚\n1 2 3 4 5 6 7 8 9 10 # O(n) - å•å±‚å¾ªç¯ def example1(n): for i in range(n): # å¾ªç¯næ¬¡ print(i) # O(1)æ“ä½œ # O(nÂ²) - åµŒå¥—å¾ªç¯ def example2(n): for i in range(n): # å¤–å±‚å¾ªç¯næ¬¡ for j in range(n): # å†…å±‚å¾ªç¯næ¬¡ print(i, j) # O(1)æ“ä½œ é€’å½’åˆ†æ å¯¹äºé€’å½’ç®—æ³•ï¼Œå¯ä»¥ä½¿ç”¨é€’å½’æ ‘æˆ–ä¸»å®šç†(Master Theorem)æ¥åˆ†æå¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 # é€’å½’æ ‘åˆ†æï¼šå½’å¹¶æ’åº # T(n) = 2T(n/2) + O(n) # æ¯å±‚æ€»å¤æ‚åº¦ä¸ºO(n)ï¼Œå…±æœ‰log nå±‚ï¼Œå› æ­¤æ€»å¤æ‚åº¦ä¸ºO(n log n) def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) # T(n/2) right = merge_sort(arr[mid:]) # T(n/2) return merge(left, right) # O(n) å‡æ‘Šåˆ†æ å‡æ‘Šåˆ†æç”¨äºè®¡ç®—ä¸€ç³»åˆ—æ“ä½œçš„å¹³å‡å¤æ‚åº¦ï¼Œå³ä½¿æŸäº›æ“ä½œå¯èƒ½å¾ˆè€—æ—¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åŠ¨æ€æ•°ç»„çš„å‡æ‘Šåˆ†æ # è™½ç„¶å¶å°”éœ€è¦O(n)æ—¶é—´æ‰©å®¹ï¼Œä½†næ¬¡appendæ“ä½œçš„æ€»æ—¶é—´ä¸ºO(n) # å› æ­¤æ¯æ¬¡appendçš„å‡æ‘Šæ—¶é—´ä¸ºO(1) class DynamicArray: def __init__(self): self.capacity = 1 self.size = 0 self.array = [None] * self.capacity def append(self, item): if self.size == self.capacity: self._resize(2 * self.capacity) # O(n)æ“ä½œï¼Œä½†ä¸é¢‘ç¹ self.array[self.size] = item self.size += 1 def _resize(self, new_capacity): new_array = [None] * new_capacity for i in range(self.size): new_array[i] = self.array[i] self.array = new_array self.capacity = new_capacity ç®—æ³•ä¼˜åŒ–ç­–ç•¥ æ—¶é—´ä¼˜åŒ–ç­–ç•¥ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„æ˜¯ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºé¢‘ç¹æŸ¥æ‰¾æ“ä½œï¼Œå“ˆå¸Œè¡¨(O(1))æ¯”æ•°ç»„(O(n))æ›´é«˜æ•ˆã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨å“ˆå¸Œè¡¨ä¼˜åŒ–æŸ¥æ‰¾ def find_duplicates(arr): seen = set() duplicates = [] for item in arr: if item in seen: # O(1)æŸ¥æ‰¾ duplicates.append(item) else: seen.add(item) return duplicates é¢„è®¡ç®—å’Œç¼“å­˜ å¯¹äºé‡å¤è®¡ç®—ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®¡ç®—æˆ–ç¼“å­˜æŠ€æœ¯é¿å…é‡å¤å·¥ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— \u0026#34;\u0026#34;\u0026#34; ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— å‚æ•°ï¼šn (int), cache (dict) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n, cache={}): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n in cache: return cache[n] if n \u0026lt;= 1: return n result = fibonacci(n - 1, cache) + fibonacci(n - 2, cache) cache[n] = result return result ä½è¿ç®—ä¼˜åŒ– ä½è¿ç®—é€šå¸¸æ¯”ç®—æœ¯è¿ç®—æ›´å¿«ï¼Œå¯ä»¥ç”¨äºæŸäº›ç‰¹å®šåœºæ™¯çš„ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨ä½è¿ç®—åˆ¤æ–­å¥‡å¶ def is_even(n): return (n \u0026amp; 1) == 0 # æ¯”n % 2 == 0æ›´å¿« # ä½¿ç”¨ä½è¿ç®—äº¤æ¢å˜é‡ def swap(a, b): a = a ^ b b = a ^ b a = a ^ b return a, b å¹¶è¡Œè®¡ç®— å¯¹äºå¯ä»¥å¹¶è¡Œå¤„ç†çš„é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å¤šçº¿ç¨‹æˆ–å¤šè¿›ç¨‹åŠ é€Ÿã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† import concurrent.futures def process_data(data): # å¤„ç†æ•°æ®çš„å‡½æ•°ï¼Œè¿”å›å¤„ç†ç»“æœ result = ... # æ ¹æ®å®é™…éœ€æ±‚å¤„ç† return result def parallel_process(data_list, num_workers=4): with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor: results = list(executor.map(process_data, data_list)) return results ç©ºé—´ä¼˜åŒ–ç­–ç•¥ åŸåœ°ç®—æ³• åŸåœ°ç®—æ³•ä¸éœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´æˆ–åªéœ€è¦å¸¸æ•°çº§åˆ«çš„é¢å¤–ç©ºé—´ã€‚\n1 2 3 4 5 6 7 8 # åŸåœ°åè½¬æ•°ç»„ def reverse_array(arr): left, right = 0, len(arr) - 1 while left \u0026lt; right: arr[left], arr[right] = arr[right], arr[left] left += 1 right -= 1 return arr æ•°æ®å‹ç¼© å¯¹äºå¤§è§„æ¨¡æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å‹ç¼©æŠ€æœ¯å‡å°‘å­˜å‚¨éœ€æ±‚ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨ç¨€ç–çŸ©é˜µè¡¨ç¤ºä¼˜åŒ–å­˜å‚¨ class SparseMatrix: def __init__(self, rows, cols): self.rows = rows self.cols = cols self.data = {} # åªå­˜å‚¨éé›¶å…ƒç´  def set(self, i, j, value): if value != 0: self.data[(i, j)] = value elif (i, j) in self.data: del self.data[(i, j)] def get(self, i, j): return self.data.get((i, j), 0) æƒ°æ€§è®¡ç®— æƒ°æ€§è®¡ç®—åªåœ¨éœ€è¦æ—¶æ‰è®¡ç®—ç»“æœï¼Œå¯ä»¥èŠ‚çœä¸å¿…è¦çš„è®¡ç®—å’Œå­˜å‚¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æƒ°æ€§è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ— def lazy_fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b # ä½¿ç”¨ç”Ÿæˆå™¨ fib = lazy_fibonacci() for _ in range(10): print(next(fib)) æ—¶ç©ºæƒè¡¡ æœ‰æ—¶å¯ä»¥é€šè¿‡å¢åŠ ç©ºé—´ä½¿ç”¨æ¥å‡å°‘æ—¶é—´å¤æ‚åº¦ï¼Œæˆ–è€…é€šè¿‡å¢åŠ æ—¶é—´å¤æ‚åº¦æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\nç©ºé—´æ¢æ—¶é—´ ä½¿ç”¨é¢å¤–çš„ç©ºé—´æ¥å­˜å‚¨ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–æœ€é•¿å…¬å…±å­åºåˆ— def longest_common_subsequence(text1, text2): m, n = len(text1), len(text2) # åˆ›å»ºäºŒç»´æ•°ç»„å­˜å‚¨ä¸­é—´ç»“æœ dp = [[0] * (n + 1) for _ in range(m + 1)] for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: dp[i][j] = dp[i - 1][j - 1] + 1 else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[m][n] æ—¶é—´æ¢ç©ºé—´ é€šè¿‡å¢åŠ è®¡ç®—æ—¶é—´æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ def fibonacci_with_rolling_array(n): if n \u0026lt;= 1: return n # åªä¿å­˜æœ€è¿‘çš„ä¸¤ä¸ªå€¼ a, b = 0, 1 for _ in range(2, n + 1): a, b = b, a + b return b å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ æ’åºç®—æ³•ä¼˜åŒ– å¿«é€Ÿæ’åºä¼˜åŒ– å¿«é€Ÿæ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)ï¼Œä½†åœ¨æœ€åæƒ…å†µä¸‹ä¼šé€€åŒ–åˆ°O(nÂ²)ã€‚ä»¥ä¸‹æ˜¯å‡ ç§ä¼˜åŒ–æ–¹æ³•ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def optimized_quick_sort(arr): # ä½¿ç”¨ä¸‰æ•°å–ä¸­æ³•é€‰æ‹©åŸºå‡†ï¼Œé¿å…æœ€åæƒ…å†µ def median_of_three(left, right): mid = (left + right) // 2 if arr[left] \u0026gt; arr[mid]: arr[left], arr[mid] = arr[mid], arr[left] if arr[left] \u0026gt; arr[right]: arr[left], arr[right] = arr[right], arr[left] if arr[mid] \u0026gt; arr[right]: arr[mid], arr[right] = arr[right], arr[mid] return mid def partition(left, right): # é€‰æ‹©åŸºå‡† pivot_idx = median_of_three(left, right) pivot = arr[pivot_idx] # å°†åŸºå‡†ç§»åˆ°æœ€å³è¾¹ arr[pivot_idx], arr[right] = arr[right], arr[pivot_idx] i = left for j in range(left, right): if arr[j] \u0026lt;= pivot: arr[i], arr[j] = arr[j], arr[i] i += 1 # å°†åŸºå‡†ç§»åˆ°æ­£ç¡®ä½ç½® arr[i], arr[right] = arr[right], arr[i] return i def sort(left, right): # å°æ•°ç»„ä½¿ç”¨æ’å…¥æ’åº if right - left + 1 \u0026lt;= 20: insertion_sort(arr, left, right) return if left \u0026lt; right: pivot_idx = partition(left, right) sort(left, pivot_idx - 1) sort(pivot_idx + 1, right) def insertion_sort(arr, left, right): for i in range(left + 1, right + 1): key = arr[i] j = i - 1 while j \u0026gt;= left and arr[j] \u0026gt; key: arr[j + 1] = arr[j] j -= 1 arr[j + 1] = key sort(0, len(arr) - 1) return arr è®¡æ•°æ’åºä¼˜åŒ– è®¡æ•°æ’åºæ˜¯ä¸€ç§éæ¯”è¾ƒæ’åºç®—æ³•ï¼Œé€‚ç”¨äºæ•´æ•°ä¸”èŒƒå›´ä¸å¤§çš„æƒ…å†µã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def counting_sort(arr, max_val=None): if not arr: return arr if max_val is None: max_val = max(arr) # åˆ›å»ºè®¡æ•°æ•°ç»„ count = [0] * (max_val + 1) # ç»Ÿè®¡æ¯ä¸ªå…ƒç´ çš„å‡ºç°æ¬¡æ•° for num in arr: count[num] += 1 # è®¡ç®—ç´¯ç§¯è®¡æ•° for i in range(1, len(count)): count[i] += count[i - 1] # æ„å»ºæ’åºç»“æœ result = [0] * len(arr) for num in reversed(arr): result[count[num] - 1] = num count[num] -= 1 return result æœç´¢ç®—æ³•ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ç§é«˜æ•ˆçš„æœç´¢ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(log n)ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def binary_search_optimized(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: # é˜²æ­¢æ•´æ•°æº¢å‡º mid = left + (right - left) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 è·³è¡¨æœç´¢ä¼˜åŒ– è·³è¡¨æ˜¯ä¸€ç§æ¦‚ç‡æ•°æ®ç»“æ„ï¼Œå…è®¸å¿«é€Ÿæœç´¢ï¼Œç±»ä¼¼äºå¹³è¡¡æ ‘ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import random class SkipNode: def __init__(self, val=None, level=0): self.val = val self.next = [None] * level class SkipList: def __init__(self, max_level=16, p=0.5): self.max_level = max_level self.p = p self.level = 1 self.head = SkipNode(None, max_level) def random_level(self): level = 1 while random.random() \u0026lt; self.p and level \u0026lt; self.max_level: level += 1 return level def insert(self, val): update = [None] * self.max_level current = self.head # æ‰¾åˆ°æ’å…¥ä½ç½® for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] update[i] = current # åˆ›å»ºæ–°èŠ‚ç‚¹ node_level = self.random_level() if node_level \u0026gt; self.level: for i in range(self.level, node_level): update[i] = self.head self.level = node_level # æ’å…¥æ–°èŠ‚ç‚¹ new_node = SkipNode(val, node_level) for i in range(node_level): new_node.next[i] = update[i].next[i] update[i].next[i] = new_node def search(self, val): current = self.head for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] current = current.next[0] if current and current.val == val: return True return False å›¾ç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ç”¨äºå¯»æ‰¾å•æºæœ€çŸ­è·¯å¾„ï¼Œå¯ä»¥ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import heapq def dijkstra_optimized(graph, start): n = len(graph) dist = [float(\u0026#39;inf\u0026#39;)] * n dist[start] = 0 # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ— pq = [(0, start)] while pq: current_dist, u = heapq.heappop(pq) # å¦‚æœå·²ç»æ‰¾åˆ°æ›´çŸ­è·¯å¾„ï¼Œè·³è¿‡ if current_dist \u0026gt; dist[u]: continue for v, weight in graph[u]: distance = current_dist + weight if distance \u0026lt; dist[v]: dist[v] = distance heapq.heappush(pq, (distance, v)) return dist A*ç®—æ³•ä¼˜åŒ– A*ç®—æ³•æ˜¯ä¸€ç§å¯å‘å¼æœç´¢ç®—æ³•ï¼Œå¸¸ç”¨äºè·¯å¾„è§„åˆ’ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import heapq def a_star_search(graph, start, goal, heuristic): # ä¼˜å…ˆé˜Ÿåˆ—ï¼š(f_score, node) open_set = [(0, start)] # ä»èµ·ç‚¹åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„å®é™…ä»£ä»· g_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} g_score[start] = 0 # ä»èµ·ç‚¹ç»è¿‡æ¯ä¸ªèŠ‚ç‚¹åˆ°ç»ˆç‚¹çš„ä¼°è®¡ä»£ä»· f_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} f_score[start] = heuristic(start, goal) # è®°å½•è·¯å¾„ came_from = {} while open_set: current_f, current = heapq.heappop(open_set) if current == goal: # é‡å»ºè·¯å¾„ path = [current] while current in came_from: current = came_from[current] path.append(current) return path[::-1] for neighbor in graph[current]: # è®¡ç®—ä»èµ·ç‚¹åˆ°é‚»å±…çš„ä¸´æ—¶g_score tentative_g_score = g_score[current] + graph[current][neighbor] if tentative_g_score \u0026lt; g_score[neighbor]: # æ‰¾åˆ°æ›´å¥½çš„è·¯å¾„ came_from[neighbor] = current g_score[neighbor] = tentative_g_score f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, goal) heapq.heappush(open_set, (f_score[neighbor], neighbor)) return None # æ²¡æœ‰æ‰¾åˆ°è·¯å¾„ åŠ¨æ€è§„åˆ’ä¼˜åŒ– çŠ¶æ€å‹ç¼© å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ä½è¿ç®—è¿›è¡ŒçŠ¶æ€å‹ç¼©ï¼Œå‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # æ—…è¡Œå•†é—®é¢˜(TSP)çš„çŠ¶æ€å‹ç¼©ä¼˜åŒ– def tsp_dp(distances): n = len(distances) # dp[mask][i]è¡¨ç¤ºè®¿é—®è¿‡maskä¸­çš„åŸå¸‚ï¼Œæœ€ååœç•™åœ¨åŸå¸‚içš„æœ€çŸ­è·ç¦» dp = [[float(\u0026#39;inf\u0026#39;)] * n for _ in range(1 \u0026lt;\u0026lt; n)] dp[1][0] = 0 # ä»åŸå¸‚0å¼€å§‹ for mask in range(1 \u0026lt;\u0026lt; n): for i in range(n): if mask \u0026amp; (1 \u0026lt;\u0026lt; i): # å¦‚æœåŸå¸‚iåœ¨maskä¸­ for j in range(n): if not mask \u0026amp; (1 \u0026lt;\u0026lt; j): # å¦‚æœåŸå¸‚jä¸åœ¨maskä¸­ new_mask = mask | (1 \u0026lt;\u0026lt; j) dp[new_mask][j] = min(dp[new_mask][j], dp[mask][i] + distances[i][j]) # è®¡ç®—å›åˆ°èµ·ç‚¹çš„æœ€çŸ­è·ç¦» final_mask = (1 \u0026lt;\u0026lt; n) - 1 min_distance = float(\u0026#39;inf\u0026#39;) for i in range(1, n): min_distance = min(min_distance, dp[final_mask][i] + distances[i][0]) return min_distance æ»šåŠ¨æ•°ç»„ä¼˜åŒ– å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # æœ€é•¿å…¬å…±å­åºåˆ—çš„æ»šåŠ¨æ•°ç»„ä¼˜åŒ– def lcs_rolling_array(text1, text2): m, n = len(text1), len(text2) # ä½¿ç”¨ä¸¤è¡Œæ•°ç»„ä»£æ›¿å®Œæ•´çš„äºŒç»´æ•°ç»„ prev = [0] * (n + 1) curr = [0] * (n + 1) for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: curr[j] = prev[j - 1] + 1 else: curr[j] = max(prev[j], curr[j - 1]) # æ»šåŠ¨æ•°ç»„ prev, curr = curr, prev curr = [0] * (n + 1) return prev[n] å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æ å›¾åƒå¤„ç†ä¸­çš„ä¼˜åŒ– å·ç§¯è¿ç®—ä¼˜åŒ– å·ç§¯è¿ç®—æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import numpy as np def naive_convolution(image, kernel): # åŸå§‹å·ç§¯å®ç° height, width = image.shape k_height, k_width = kernel.shape output = np.zeros((height - k_height + 1, width - k_width + 1)) for i in range(output.shape[0]): for j in range(output.shape[1]): output[i, j] = np.sum(image[i:i+k_height, j:j+k_width] * kernel) return output def optimized_convolution(image, kernel): # ä½¿ç”¨FFTåŠ é€Ÿå·ç§¯ from scipy.signal import fftconvolve return fftconvolve(image, kernel, mode=\u0026#39;valid\u0026#39;) def separable_convolution(image, kernel): # å¯åˆ†ç¦»å·ç§¯ä¼˜åŒ– # å¦‚æœkernelå¯ä»¥åˆ†ç¦»ä¸ºæ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªä¸€ç»´æ ¸ # ä¾‹å¦‚ï¼škernel = h_kernel * v_kernel^T # å‡è®¾kernelæ˜¯å¯åˆ†ç¦»çš„ u, s, vh = np.linalg.svd(kernel) h_kernel = u[:, 0] * np.sqrt(s[0]) v_kernel = vh[0, :] * np.sqrt(s[0]) # å…ˆè¿›è¡Œæ°´å¹³å·ç§¯ temp = np.zeros_like(image) for i in range(image.shape[0]): temp[i, :] = np.convolve(image[i, :], h_kernel, mode=\u0026#39;valid\u0026#39;) # å†è¿›è¡Œå‚ç›´å·ç§¯ output = np.zeros((temp.shape[0] - len(v_kernel) + 1, temp.shape[1])) for j in range(temp.shape[1]): output[:, j] = np.convolve(temp[:, j], v_kernel, mode=\u0026#39;valid\u0026#39;) return output å›¾åƒé‡‘å­—å¡”ä¼˜åŒ– å›¾åƒé‡‘å­—å¡”æ˜¯ä¸€ç§å¤šå°ºåº¦è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥ç”¨äºåŠ é€Ÿå›¾åƒå¤„ç†ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def build_gaussian_pyramid(image, levels): pyramid = [image] for _ in range(levels - 1): # ä¸‹é‡‡æ · image = cv2.pyrDown(image) pyramid.append(image) return pyramid def process_with_pyramid(image, process_func, levels=4): # æ„å»ºé‡‘å­—å¡” pyramid = build_gaussian_pyramid(image, levels) # ä»æœ€ç²—çº§åˆ«å¼€å§‹å¤„ç† result = process_func(pyramid[-1]) # é€çº§ä¸Šé‡‡æ ·å¹¶ç»†åŒ– for i in range(levels - 2, -1, -1): # ä¸Šé‡‡æ ·ç»“æœ result = cv2.pyrUp(result) # è°ƒæ•´å¤§å°ä»¥åŒ¹é…å½“å‰çº§åˆ« result = cv2.resize(result, (pyramid[i].shape[1], pyramid[i].shape[0])) # ä¸å½“å‰çº§åˆ«ç»“åˆ result = process_func(pyramid[i], result) return result æœºå™¨å­¦ä¹ ä¸­çš„ä¼˜åŒ– æ¢¯åº¦ä¸‹é™ä¼˜åŒ– æ¢¯åº¦ä¸‹é™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ï¼Œæœ‰å¤šç§å˜ä½“ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import numpy as np def gradient_descent(X, y, learning_rate=0.01, epochs=1000): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def stochastic_gradient_descent(X, y, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): for i in range(m): # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ xi = X[i:i+1] yi = y[i:i+1] # è®¡ç®—é¢„æµ‹å€¼ prediction = xi.dot(theta) # è®¡ç®—è¯¯å·® error = prediction - yi # è®¡ç®—æ¢¯åº¦ gradient = xi.T.dot(error) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def mini_batch_gradient_descent(X, y, batch_size=32, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # éšæœºæ‰“ä¹±æ•°æ® indices = np.random.permutation(m) X_shuffled = X[indices] y_shuffled = y[indices] # åˆ†æ‰¹å¤„ç† for i in range(0, m, batch_size): X_batch = X_shuffled[i:i+batch_size] y_batch = y_shuffled[i:i+batch_size] # è®¡ç®—é¢„æµ‹å€¼ predictions = X_batch.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y_batch # è®¡ç®—æ¢¯åº¦ gradient = X_batch.T.dot(error) / len(X_batch) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def momentum_gradient_descent(X, y, learning_rate=0.01, momentum=0.9, epochs=1000): m, n = X.shape theta = np.zeros(n) velocity = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°é€Ÿåº¦ velocity = momentum * velocity - learning_rate * gradient # æ›´æ–°å‚æ•° theta += velocity return theta çŸ©é˜µè¿ç®—ä¼˜åŒ– åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼ŒçŸ©é˜µè¿ç®—æ˜¯æ ¸å¿ƒæ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import numpy as np def naive_matrix_multiply(A, B): # åŸå§‹çŸ©é˜µä¹˜æ³•å®ç° m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(m): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] return C def blocked_matrix_multiply(A, B, block_size=32): # åˆ†å—çŸ©é˜µä¹˜æ³•ä¼˜åŒ– m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(0, m, block_size): for j in range(0, p, block_size): for k in range(0, n, block_size): # å¤„ç†å½“å‰å— for ii in range(i, min(i + block_size, m)): for jj in range(j, min(j + block_size, p)): for kk in range(k, min(k + block_size, n)): C[ii, jj] += A[ii, kk] * B[kk, jj] return C def vectorized_matrix_multiply(A, B): # å‘é‡åŒ–çŸ©é˜µä¹˜æ³•ï¼ˆä½¿ç”¨NumPyå†…ç½®å‡½æ•°ï¼‰ return np.dot(A, B) def parallel_matrix_multiply(A, B): # å¹¶è¡ŒçŸ©é˜µä¹˜æ³• from concurrent.futures import ThreadPoolExecutor m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) def compute_row(i): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] with ThreadPoolExecutor() as executor: executor.map(compute_row, range(m)) return C æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ– ç´¢å¼•ä¼˜åŒ– ç´¢å¼•æ˜¯æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–çš„å…³é”®ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æŸ¥è¯¢é€Ÿåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # ç®€å•çš„Bæ ‘ç´¢å¼•å®ç° class BTreeNode: def __init__(self, leaf=False): self.keys = [] self.children = [] self.leaf = leaf class BTree: def __init__(self, t): self.root = BTreeNode(leaf=True) self.t = t # æœ€å°åº¦æ•° def search(self, key, node=None): if node is None: node = self.root i = 0 while i \u0026lt; len(node.keys) and key \u0026gt; node.keys[i]: i += 1 if i \u0026lt; len(node.keys) and key == node.keys[i]: return True # æ‰¾åˆ°é”® if node.leaf: return False # æœªæ‰¾åˆ°é”® return self.search(key, node.children[i]) def insert(self, key): root = self.root if len(root.keys) == (2 * self.t) - 1: # æ ¹èŠ‚ç‚¹å·²æ»¡ï¼Œåˆ›å»ºæ–°æ ¹èŠ‚ç‚¹ new_root = BTreeNode() new_root.children.append(self.root) self.root = new_root self._split_child(new_root, 0) self._insert_nonfull(new_root, key) else: self._insert_nonfull(root, key) def _split_child(self, parent, index): t = self.t y = parent.children[index] z = BTreeNode(leaf=y.leaf) # å°†yçš„ä¸­é—´é”®æå‡åˆ°çˆ¶èŠ‚ç‚¹ parent.keys.insert(index, y.keys[t-1]) # å°†yçš„ååŠéƒ¨åˆ†é”®å¤åˆ¶åˆ°z z.keys = y.keys[t:(2*t-1)] # å¦‚æœyä¸æ˜¯å¶å­èŠ‚ç‚¹ï¼Œå¤åˆ¶å­èŠ‚ç‚¹ if not y.leaf: z.children = y.children[t:(2*t)] # æ›´æ–°yçš„é”®å’Œå­èŠ‚ç‚¹ y.keys = y.keys[0:(t-1)] y.children = y.children[0:t] # å°†zæ’å…¥çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹åˆ—è¡¨ parent.children.insert(index + 1, z) def _insert_nonfull(self, node, key): i = len(node.keys) - 1 if node.leaf: # åœ¨å¶å­èŠ‚ç‚¹ä¸­æ’å…¥é”® node.keys.append(0) while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: node.keys[i+1] = node.keys[i] i -= 1 node.keys[i+1] = key else: # æ‰¾åˆ°åˆé€‚çš„å­èŠ‚ç‚¹ while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: i -= 1 i += 1 # å¦‚æœå­èŠ‚ç‚¹å·²æ»¡ï¼Œå…ˆåˆ†è£‚ if len(node.children[i].keys) == (2 * self.t) - 1: self._split_child(node, i) if key \u0026gt; node.keys[i]: i += 1 self._insert_nonfull(node.children[i], key) æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ– æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–æ˜¯æ•°æ®åº“ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¯ä»¥é€šè¿‡å¤šç§ç­–ç•¥ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class QueryOptimizer: def __init__(self, database): self.database = database def optimize_query(self, query): # è§£ææŸ¥è¯¢ parsed_query = self._parse_query(query) # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = self._generate_execution_plans(parsed_query) # è¯„ä¼°æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬ plan_costs = [self._estimate_cost(plan) for plan in plans] # é€‰æ‹©æˆæœ¬æœ€ä½çš„è®¡åˆ’ best_plan = plans[plan_costs.index(min(plan_costs))] return best_plan def _parse_query(self, query): # ç®€åŒ–çš„æŸ¥è¯¢è§£æ # å®é™…å®ç°ä¼šæ›´å¤æ‚ return { \u0026#39;tables\u0026#39;: query.get(\u0026#39;tables\u0026#39;, []), \u0026#39;conditions\u0026#39;: query.get(\u0026#39;conditions\u0026#39;, []), \u0026#39;projections\u0026#39;: query.get(\u0026#39;projections\u0026#39;, []), \u0026#39;order_by\u0026#39;: query.get(\u0026#39;order_by\u0026#39;, []), \u0026#39;limit\u0026#39;: query.get(\u0026#39;limit\u0026#39;, None) } def _generate_execution_plans(self, parsed_query): # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = [] # ç®€å•å®ç°ï¼šåªè€ƒè™‘è¡¨è¿æ¥é¡ºåº tables = parsed_query[\u0026#39;tables\u0026#39;] # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è¡¨è¿æ¥é¡ºåº from itertools import permutations for table_order in permutations(tables): plan = { \u0026#39;table_order\u0026#39;: table_order, \u0026#39;join_method\u0026#39;: \u0026#39;nested_loop\u0026#39;, # å¯ä»¥æ˜¯nested_loop, hash_join, merge_join \u0026#39;access_method\u0026#39;: {table: \u0026#39;index_scan\u0026#39; for table in tables}, # å¯ä»¥æ˜¯full_scan, index_scan \u0026#39;conditions\u0026#39;: parsed_query[\u0026#39;conditions\u0026#39;], \u0026#39;projections\u0026#39;: parsed_query[\u0026#39;projections\u0026#39;], \u0026#39;order_by\u0026#39;: parsed_query[\u0026#39;order_by\u0026#39;], \u0026#39;limit\u0026#39;: parsed_query[\u0026#39;limit\u0026#39;] } plans.append(plan) return plans def _estimate_cost(self, plan): # ä¼°è®¡æ‰§è¡Œè®¡åˆ’çš„æˆæœ¬ cost = 0 # ä¼°è®¡è¡¨è®¿é—®æˆæœ¬ for table in plan[\u0026#39;table_order\u0026#39;]: access_method = plan[\u0026#39;access_method\u0026#39;][table] table_stats = self.database.get_table_stats(table) if access_method == \u0026#39;full_scan\u0026#39;: cost += table_stats[\u0026#39;row_count\u0026#39;] elif access_method == \u0026#39;index_scan\u0026#39;: # å‡è®¾ç´¢å¼•å¯ä»¥è¿‡æ»¤æ‰90%çš„æ•°æ® cost += table_stats[\u0026#39;row_count\u0026#39;] * 0.1 # ä¼°è®¡è¿æ¥æˆæœ¬ for i in range(len(plan[\u0026#39;table_order\u0026#39;]) - 1): join_method = plan[\u0026#39;join_method\u0026#39;] if join_method == \u0026#39;nested_loop\u0026#39;: # åµŒå¥—å¾ªç¯è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] * right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;hash_join\u0026#39;: # å“ˆå¸Œè¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;merge_join\u0026#39;: # åˆå¹¶è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] # ä¼°è®¡æ’åºæˆæœ¬ if plan[\u0026#39;order_by\u0026#39;]: # å‡è®¾æ’åºæˆæœ¬ä¸ºn log n result_size = cost # ç®€åŒ–å‡è®¾ cost += result_size * np.log2(result_size) return cost æ€§èƒ½åˆ†æå·¥å…· æ—¶é—´åˆ†æå·¥å…· Pythonä¸­çš„æ—¶é—´åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import time import timeit import cProfile import pstats def time_function(func, *args, **kwargs): # ç®€å•çš„æ—¶é—´æµ‹é‡ start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f\u0026#34;å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: {end_time - start_time:.6f} ç§’\u0026#34;) return result def benchmark_function(func, *args, **kwargs): # ä½¿ç”¨timeitè¿›è¡Œæ›´ç²¾ç¡®çš„åŸºå‡†æµ‹è¯• import functools wrapped = functools.partial(func, *args, **kwargs) time_taken = timeit.timeit(wrapped, number=1000) print(f\u0026#34;å‡½æ•° {func.__name__} å¹³å‡æ‰§è¡Œæ—¶é—´: {time_taken/1000:.6f} ç§’\u0026#34;) return func(*args, **kwargs) def profile_function(func, *args, **kwargs): # ä½¿ç”¨cProfileè¿›è¡Œè¯¦ç»†æ€§èƒ½åˆ†æ profiler = cProfile.Profile() profiler.enable() result = func(*args, **kwargs) profiler.disable() stats = pstats.Stats(profiler).sort_stats(\u0026#39;cumulative\u0026#39;) stats.print_stats() return result å†…å­˜åˆ†æå·¥å…· Pythonä¸­çš„å†…å­˜åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import sys import tracemalloc import objgraph def get_object_size(obj): # è·å–å¯¹è±¡çš„å†…å­˜å¤§å° return sys.getsizeof(obj) def trace_memory(func, *args, **kwargs): # è·Ÿè¸ªå†…å­˜ä½¿ç”¨æƒ…å†µ tracemalloc.start() result = func(*args, **kwargs) snapshot = tracemalloc.take_snapshot() top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) print(\u0026#34;[ å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œ ]\u0026#34;) for stat in top_stats[:10]: print(stat) tracemalloc.stop() return result def analyze_object_growth(func, *args, **kwargs): # åˆ†æå¯¹è±¡å¢é•¿æƒ…å†µ objgraph.show_growth() result = func(*args, **kwargs) objgraph.show_growth() return result å¯è§†åŒ–åˆ†æå·¥å…· ä½¿ç”¨matplotlibå¯è§†åŒ–æ€§èƒ½æ•°æ® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import matplotlib.pyplot as plt import numpy as np def plot_time_complexity(algorithms, input_sizes, title=\u0026#34;æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒ\u0026#34;): # ç»˜åˆ¶ç®—æ³•æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒå›¾ plt.figure(figsize=(10, 6)) for name, func in algorithms.items(): times = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡æ‰§è¡Œæ—¶é—´ start_time = time.time() func(test_data) end_time = time.time() times.append(end_time - start_time) plt.plot(input_sizes, times, label=name, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;æ‰§è¡Œæ—¶é—´ (ç§’)\u0026#39;) plt.title(title) plt.legend() plt.grid(True) plt.show() def generate_test_data(size): # ç”Ÿæˆæµ‹è¯•æ•°æ® return np.random.rand(size) def plot_memory_usage(func, input_sizes, title=\u0026#34;å†…å­˜ä½¿ç”¨æƒ…å†µ\u0026#34;): # ç»˜åˆ¶å‡½æ•°å†…å­˜ä½¿ç”¨æƒ…å†µå›¾ memory_usage = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡å†…å­˜ä½¿ç”¨ tracemalloc.start() func(test_data) snapshot = tracemalloc.take_snapshot() current, peak = tracemalloc.get_traced_memory() tracemalloc.stop() memory_usage.append(peak / (1024 * 1024)) # è½¬æ¢ä¸ºMB plt.figure(figsize=(10, 6)) plt.plot(input_sizes, memory_usage, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;å†…å­˜ä½¿ç”¨ (MB)\u0026#39;) plt.title(title) plt.grid(True) plt.show() æ€»ç»“ ç®—æ³•ä¼˜åŒ–æ˜¯æå‡è½¯ä»¶æ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚æœ¬æ–‡ä»ç®—æ³•å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä»‹ç»äº†æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦çš„æ¦‚å¿µåŠåˆ†ææ–¹æ³•ï¼Œç„¶åè¯¦ç»†æ¢è®¨äº†å„ç§ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬æ—¶é—´ä¼˜åŒ–ã€ç©ºé—´ä¼˜åŒ–å’Œæ—¶ç©ºæƒè¡¡ã€‚\né€šè¿‡å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ï¼Œå¦‚æ’åºç®—æ³•ã€æœç´¢ç®—æ³•ã€å›¾ç®—æ³•å’ŒåŠ¨æ€è§„åˆ’çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬äº†è§£äº†å¦‚ä½•å°†ç†è®ºåº”ç”¨åˆ°å®è·µä¸­ã€‚å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æå±•ç¤ºäº†ç®—æ³•ä¼˜åŒ–åœ¨å›¾åƒå¤„ç†ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®åº“æŸ¥è¯¢ç­‰é¢†åŸŸçš„å…·ä½“åº”ç”¨ã€‚\næœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†å„ç§æ€§èƒ½åˆ†æå·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\nç®—æ³•ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­å­¦ä¹ å’Œå®è·µçš„è¿‡ç¨‹ã€‚éšç€æŠ€æœ¯çš„å‘å±•ï¼Œæ–°çš„ä¼˜åŒ–æ–¹æ³•å’Œå·¥å…·ä¸æ–­æ¶Œç°ã€‚æŒæ¡è¿™äº›ä¼˜åŒ–æŠ€å·§ï¼Œä¸ä»…èƒ½å¤Ÿæé«˜ä»£ç æ€§èƒ½ï¼Œè¿˜èƒ½åŸ¹å…»ç³»ç»Ÿæ€ç»´å’Œé—®é¢˜è§£å†³èƒ½åŠ›ï¼Œä¸ºæˆä¸ºä¸€åä¼˜ç§€çš„è½¯ä»¶å·¥ç¨‹å¸ˆå¥ å®šåŸºç¡€ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…æ·±å…¥ç†è§£ç®—æ³•ä¼˜åŒ–çš„åŸç†å’Œæ–¹æ³•ï¼Œå¹¶åœ¨å®é™…å¼€å‘ä¸­çµæ´»åº”ç”¨ï¼Œåˆ›é€ å‡ºæ›´é«˜æ•ˆã€æ›´ä¼˜é›…çš„ä»£ç ã€‚\n","permalink":"http://localhost:1313/posts/algorithm-optimization/","summary":"\u003ch1 id=\"ç®—æ³•ä¼˜åŒ–ä»ç†è®ºåˆ°å®è·µ\"\u003eç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ\u003c/h1\u003e\n\u003cp\u003eåœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\u003c/p\u003e","title":"ç®—æ³•ä¼˜åŒ–ï¼šæå‡ä»£ç æ€§èƒ½çš„å®ç”¨æŠ€å·§"},{"content":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\nå›¾åƒçš„åŸºæœ¬è¡¨ç¤º åƒç´ ä¸å›¾åƒçŸ©é˜µ åœ¨æ•°å­—ä¸–ç•Œä¸­ï¼Œå›¾åƒç”±åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚å¯¹äºç°åº¦å›¾åƒï¼Œæ¯ä¸ªåƒç´ çš„å€¼è¡¨ç¤ºäº®åº¦ï¼Œé€šå¸¸èŒƒå›´æ˜¯0ï¼ˆé»‘è‰²ï¼‰åˆ°255ï¼ˆç™½è‰²ï¼‰ã€‚å¯¹äºå½©è‰²å›¾åƒï¼Œé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“è¡¨ç¤ºï¼Œæ¯ä¸ªé€šé“çš„å€¼èŒƒå›´ä¹Ÿæ˜¯0åˆ°255ã€‚\nåœ¨è®¡ç®—æœºä¸­ï¼Œå›¾åƒé€šå¸¸è¡¨ç¤ºä¸ºçŸ©é˜µã€‚ç°åº¦å›¾åƒæ˜¯äºŒç»´çŸ©é˜µï¼Œè€Œå½©è‰²å›¾åƒæ˜¯ä¸‰ç»´çŸ©é˜µï¼ˆé«˜åº¦Ã—å®½åº¦Ã—é€šé“æ•°ï¼‰ã€‚\n1 2 3 4 5 6 7 8 # Pythonä¸­ä½¿ç”¨NumPyè¡¨ç¤ºå›¾åƒ import numpy as np # åˆ›å»ºä¸€ä¸ª100x100çš„ç°åº¦å›¾åƒï¼ˆå…¨é»‘ï¼‰ gray_image = np.zeros((100, 100), dtype=np.uint8) # åˆ›å»ºä¸€ä¸ª100x100x3çš„å½©è‰²å›¾åƒï¼ˆå…¨é»‘ï¼‰ color_image = np.zeros((100, 100, 3), dtype=np.uint8) å›¾åƒç±»å‹ äºŒå€¼å›¾åƒï¼šæ¯ä¸ªåƒç´ åªæœ‰ä¸¤ä¸ªå¯èƒ½çš„å€¼ï¼ˆé€šå¸¸æ˜¯0å’Œ1ï¼‰ï¼Œè¡¨ç¤ºé»‘ç™½ä¸¤è‰²ã€‚ ç°åº¦å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰ä¸€ä¸ªå€¼ï¼Œè¡¨ç¤ºä»é»‘åˆ°ç™½çš„ç°åº¦çº§åˆ«ã€‚ å½©è‰²å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰å¤šä¸ªå€¼ï¼Œé€šå¸¸ä½¿ç”¨RGBã€HSVæˆ–CMYKç­‰é¢œè‰²æ¨¡å‹è¡¨ç¤ºã€‚ å¤šå…‰è°±å›¾åƒï¼šåŒ…å«å¤šä¸ªå…‰è°±é€šé“çš„å›¾åƒï¼Œå¦‚å«æ˜Ÿå›¾åƒã€‚ 3Då›¾åƒï¼šè¡¨ç¤ºä¸‰ç»´ç©ºé—´æ•°æ®çš„å›¾åƒï¼Œå¦‚åŒ»å­¦CTæ‰«æã€‚ åŸºæœ¬å›¾åƒæ“ä½œ å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨Pythonçš„OpenCVåº“å¯ä»¥è½»æ¾è¯»å–å’Œæ˜¾ç¤ºå›¾åƒï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 import cv2 import matplotlib.pyplot as plt # è¯»å–å›¾åƒ image = cv2.imread(\u0026#39;image.jpg\u0026#39;) # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆOpenCVé»˜è®¤ä½¿ç”¨BGRï¼Œè€Œmatplotlibä½¿ç”¨RGBï¼‰ image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() å›¾åƒç¼©æ”¾ä¸æ—‹è½¬ 1 2 3 4 5 6 7 8 # ç¼©æ”¾å›¾åƒ resized_image = cv2.resize(image, (width, height)) # æ—‹è½¬å›¾åƒ (h, w) = image.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) # æ—‹è½¬45åº¦ï¼Œç¼©æ”¾å› å­ä¸º1.0 rotated_image = cv2.warpAffine(image, M, (w, h)) å›¾åƒè£å‰ªä¸æ‹¼æ¥ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image[100:400, 200:500] # æ‹¼æ¥å›¾åƒ (æ°´å¹³æ‹¼æ¥) horizontal_concat = np.hstack((image1, image2)) # å‚ç›´æ‹¼æ¥ vertical_concat = np.vstack((image1, image2)) å›¾åƒå¢å¼ºæŠ€æœ¯ äº®åº¦ä¸å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 # äº®åº¦è°ƒæ•´ (å¢åŠ 50ä¸ªå•ä½) brightness_image = cv2.add(image, np.ones(image.shape, dtype=np.uint8) * 50) # å¯¹æ¯”åº¦è°ƒæ•´ (1.5å€) contrast_image = cv2.multiply(image, 1.5) ç›´æ–¹å›¾å‡è¡¡åŒ– ç›´æ–¹å›¾å‡è¡¡åŒ–æ˜¯ä¸€ç§å¢å¼ºå›¾åƒå¯¹æ¯”åº¦çš„æ–¹æ³•ï¼Œé€šè¿‡é‡æ–°åˆ†å¸ƒå›¾åƒçš„åƒç´ å¼ºåº¦ï¼Œä½¿å…¶ç›´æ–¹å›¾å¹³å¦åŒ–ã€‚\n1 2 3 # ç°åº¦å›¾åƒç›´æ–¹å›¾å‡è¡¡åŒ– gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) equalized_image = cv2.equalizeHist(gray_image) ä¼½é©¬æ ¡æ­£ ä¼½é©¬æ ¡æ­£ç”¨äºè°ƒæ•´å›¾åƒçš„äº®åº¦ï¼Œç‰¹åˆ«é€‚ç”¨äºæ˜¾ç¤ºè®¾å¤‡çš„éçº¿æ€§å“åº”ã€‚\ngamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼\n1 2 3 4 5 6 7 8 9 # ä¼½é©¬æ ¡æ­£å‡½æ•° def gamma_correction(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) gamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼ å›¾åƒæ»¤æ³¢ å›¾åƒæ»¤æ³¢æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œç”¨äºå»å™ªã€è¾¹ç¼˜æ£€æµ‹å’Œç‰¹å¾æå–ç­‰ä»»åŠ¡ã€‚\nå‡å€¼æ»¤æ³¢ å‡å€¼æ»¤æ³¢æ˜¯æœ€ç®€å•çš„æ»¤æ³¢æ–¹æ³•ä¹‹ä¸€ï¼Œå®ƒç”¨é‚»åŸŸåƒç´ çš„å¹³å‡å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ã€‚\n1 2 # 5x5å‡å€¼æ»¤æ³¢ blurred_image = cv2.blur(image, (5, 5)) é«˜æ–¯æ»¤æ³¢ é«˜æ–¯æ»¤æ³¢ä½¿ç”¨é«˜æ–¯å‡½æ•°ä½œä¸ºæƒé‡ï¼Œå¯¹é‚»åŸŸåƒç´ è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å™ªå£°åŒæ—¶ä¿ç•™è¾¹ç¼˜ä¿¡æ¯ã€‚\n1 2 # 5x5é«˜æ–¯æ»¤æ³¢ gaussian_blurred = cv2.GaussianBlur(image, (5, 5), 0) ä¸­å€¼æ»¤æ³¢ ä¸­å€¼æ»¤æ³¢ç”¨é‚»åŸŸåƒç´ çš„ä¸­å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ï¼Œå¯¹äºå»é™¤æ¤’ç›å™ªå£°ç‰¹åˆ«æœ‰æ•ˆã€‚\n1 2 # 5x5ä¸­å€¼æ»¤æ³¢ median_blurred = cv2.medianBlur(image, 5) åŒè¾¹æ»¤æ³¢ åŒè¾¹æ»¤æ³¢åœ¨è€ƒè™‘ç©ºé—´é‚»è¿‘åº¦çš„åŒæ—¶ï¼Œä¹Ÿè€ƒè™‘åƒç´ å€¼çš„ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿåœ¨å¹³æ»‘å›¾åƒçš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ã€‚\n1 2 # åŒè¾¹æ»¤æ³¢ bilateral_filtered = cv2.bilateralFilter(image, 9, 75, 75) è¾¹ç¼˜æ£€æµ‹ è¾¹ç¼˜æ£€æµ‹æ˜¯å›¾åƒå¤„ç†ä¸­çš„é‡è¦ä»»åŠ¡ï¼Œç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“è¾¹ç•Œã€‚\nSobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Sobelè¾¹ç¼˜æ£€æµ‹ sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3) # æ°´å¹³æ–¹å‘ sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3) # å‚ç›´æ–¹å‘ # è®¡ç®—æ¢¯åº¦å¹…å€¼ gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2) # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´ gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255) Cannyè¾¹ç¼˜æ£€æµ‹ Cannyè¾¹ç¼˜æ£€æµ‹æ˜¯ä¸€ç§å¤šé˜¶æ®µçš„è¾¹ç¼˜æ£€æµ‹ç®—æ³•ï¼Œè¢«è®¤ä¸ºæ˜¯ç›®å‰æœ€ä¼˜çš„è¾¹ç¼˜æ£€æµ‹æ–¹æ³•ä¹‹ä¸€ã€‚\n1 2 # Cannyè¾¹ç¼˜æ£€æµ‹ edges = cv2.Canny(gray, 100, 200) # é˜ˆå€¼1å’Œé˜ˆå€¼2 Laplacianç®—å­ 1 2 3 # Laplacianè¾¹ç¼˜æ£€æµ‹ laplacian = cv2.Laplacian(gray, cv2.CV_64F) laplacian = np.uint8(np.absolute(laplacian)) å½¢æ€å­¦æ“ä½œ å½¢æ€å­¦æ“ä½œåŸºäºå›¾åƒçš„å½¢çŠ¶ï¼Œå¸¸ç”¨äºäºŒå€¼å›¾åƒçš„å¤„ç†ã€‚\nè…èš€ä¸è†¨èƒ€ 1 2 3 4 5 6 7 8 # åˆ›å»ºä¸€ä¸ª5x5çš„æ ¸ kernel = np.ones((5, 5), np.uint8) # è…èš€æ“ä½œ eroded_image = cv2.erode(binary_image, kernel, iterations=1) # è†¨èƒ€æ“ä½œ dilated_image = cv2.dilate(binary_image, kernel, iterations=1) å¼€è¿ç®—ä¸é—­è¿ç®— 1 2 3 4 5 # å¼€è¿ç®—ï¼ˆå…ˆè…èš€åè†¨èƒ€ï¼‰ opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel) # é—­è¿ç®—ï¼ˆå…ˆè†¨èƒ€åè…èš€ï¼‰ closing = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel) å½¢æ€å­¦æ¢¯åº¦ 1 2 # å½¢æ€å­¦æ¢¯åº¦ï¼ˆè†¨èƒ€å‡è…èš€ï¼‰ gradient = cv2.morphologyEx(binary_image, cv2.MORPH_GRADIENT, kernel) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²æ˜¯å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡çš„è¿‡ç¨‹ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦ä»»åŠ¡ã€‚\né˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 # å…¨å±€é˜ˆå€¼åˆ†å‰² _, thresholded = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_threshold = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) åˆ†æ°´å²­ç®—æ³• åˆ†æ°´å²­ç®—æ³•æ˜¯ä¸€ç§åŸºäºæ‹“æ‰‘ç†è®ºçš„å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºå¯¹æ¥è§¦ç‰©ä½“çš„åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 # æ ‡è®°èƒŒæ™¯å’Œå‰æ™¯ ret, markers = cv2.connectedComponents(sure_foreground) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(image, markers) image[markers == -1] = [255, 0, 0] # æ ‡è®°åˆ†æ°´å²­è¾¹ç•Œ K-meansèšç±» 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # å°†å›¾åƒé‡å¡‘ä¸º2Dæ•°ç»„ pixel_values = image.reshape((-1, 3)) pixel_values = np.float32(pixel_values) # å®šä¹‰åœæ­¢æ ‡å‡†å’ŒKå€¼ criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2) k = 3 # åº”ç”¨K-meansèšç±» _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) # è½¬æ¢å›åŸå§‹å›¾åƒå½¢çŠ¶å¹¶åº”ç”¨èšç±»ç»“æœ centers = np.uint8(centers) segmented_image = centers[labels.flatten()] segmented_image = segmented_image.reshape(image.shape) å›¾åƒç‰¹å¾æå– ç‰¹å¾æå–æ˜¯ä»å›¾åƒä¸­æå–æœ‰æ„ä¹‰ä¿¡æ¯çš„è¿‡ç¨‹ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥ç”¨äºå›¾åƒè¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢ç­‰ä»»åŠ¡ã€‚\nè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 # Harrisè§’ç‚¹æ£€æµ‹ gray = np.float32(gray) harris_corners = cv2.cornerHarris(gray, 2, 3, 0.04) harris_corners = cv2.dilate(harris_corners, None) # æ ‡è®°è§’ç‚¹ image[harris_corners \u0026gt; 0.01 * harris_corners.max()] = [0, 0, 255] SIFTç‰¹å¾ SIFTï¼ˆScale-Invariant Feature Transformï¼‰æ˜¯ä¸€ç§ç”¨äºæ£€æµ‹å’Œæè¿°å›¾åƒå±€éƒ¨ç‰¹å¾çš„ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray, keypoints, None) ORBç‰¹å¾ ORBæ˜¯ä¸€ç§å¿«é€Ÿçš„ç‰¹å¾æ£€æµ‹å™¨å’Œæè¿°ç¬¦ï¼Œç»“åˆäº†FASTå…³é”®ç‚¹æ£€æµ‹å™¨å’ŒBRIEFæè¿°ç¬¦ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray, keypoints, None) åº”ç”¨åœºæ™¯ å›¾åƒå¤„ç†æŠ€æœ¯å¹¿æ³›åº”ç”¨äºå„ä¸ªé¢†åŸŸï¼š\nåŒ»å­¦å½±åƒï¼šCTã€MRIå›¾åƒçš„åˆ†æå’Œè¯Šæ–­ï¼Œç»†èƒè®¡æ•°ï¼Œç—…å˜æ£€æµ‹ç­‰ã€‚ è‡ªåŠ¨é©¾é©¶ï¼šè½¦é“çº¿æ£€æµ‹ï¼Œéšœç¢ç‰©è¯†åˆ«ï¼Œäº¤é€šæ ‡å¿—è¯†åˆ«ç­‰ã€‚ å®‰é˜²ç›‘æ§ï¼šäººè„¸è¯†åˆ«ï¼Œè¡Œä¸ºåˆ†æï¼Œå¼‚å¸¸æ£€æµ‹ç­‰ã€‚ å·¥ä¸šæ£€æµ‹ï¼šäº§å“ç¼ºé™·æ£€æµ‹ï¼Œå°ºå¯¸æµ‹é‡ï¼Œè´¨é‡æ§åˆ¶ç­‰ã€‚ é¥æ„Ÿå›¾åƒï¼šåœŸåœ°åˆ©ç”¨åˆ†ç±»ï¼Œç¯å¢ƒç›‘æµ‹ï¼Œç¾å®³è¯„ä¼°ç­‰ã€‚ å¢å¼ºç°å®ï¼šå›¾åƒé…å‡†ï¼Œç›®æ ‡è·Ÿè¸ªï¼Œåœºæ™¯ç†è§£ç­‰ã€‚ æ•°å­—å¨±ä¹ï¼šå›¾åƒç¾åŒ–ï¼Œç‰¹æ•ˆå¤„ç†ï¼Œè™šæ‹Ÿç°å®ç­‰ã€‚ æ€»ç»“ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰çš„åŸºç¡€ï¼Œæ¶µç›–äº†ä»åŸºæœ¬çš„åƒç´ æ“ä½œåˆ°å¤æ‚çš„ç‰¹å¾æå–å’Œåˆ†æã€‚æœ¬æ–‡ä»‹ç»äº†å›¾åƒçš„åŸºæœ¬è¡¨ç¤ºã€åŸºæœ¬æ“ä½œã€å›¾åƒå¢å¼ºæŠ€æœ¯ã€æ»¤æ³¢æ–¹æ³•ã€è¾¹ç¼˜æ£€æµ‹ã€å½¢æ€å­¦æ“ä½œã€å›¾åƒåˆ†å‰²å’Œç‰¹å¾æå–ç­‰å†…å®¹ã€‚\næŒæ¡è¿™äº›åŸºç¡€çŸ¥è¯†å¯¹äºè¿›ä¸€æ­¥å­¦ä¹ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ è‡³å…³é‡è¦ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸éœ€è¦æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©åˆé€‚çš„å›¾åƒå¤„ç†æ–¹æ³•ï¼Œå¹¶å¯èƒ½éœ€è¦ç»„åˆå¤šç§æŠ€æœ¯æ¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¸å¤šä¼ ç»Ÿçš„å›¾åƒå¤„ç†ä»»åŠ¡ç°åœ¨ä¹Ÿå¯ä»¥é€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•å®ç°ï¼Œä½†ç†è§£ä¼ ç»Ÿå›¾åƒå¤„ç†çš„åŸºæœ¬åŸç†ä»ç„¶éå¸¸é‡è¦ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ å…¥é—¨å›¾åƒå¤„ç†é¢†åŸŸï¼Œä¸ºåç»­çš„å­¦ä¹ å’Œç ”ç©¶æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\n","permalink":"http://localhost:1313/posts/image-processing-basics/","summary":"\u003ch1 id=\"å›¾åƒå¤„ç†åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eå›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eå›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\u003c/p\u003e","title":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°æ»¤æ³¢"},{"content":"404 - é¡µé¢ä¸å­˜åœ¨ æŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\næ‚¨å¯ä»¥å°è¯•ï¼š è¿”å›é¦–é¡µ æŸ¥çœ‹æ–‡ç« åˆ—è¡¨ ä½¿ç”¨æœç´¢åŠŸèƒ½ æŸ¥çœ‹ç½‘ç«™åœ°å›¾ å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡å…³äºé¡µé¢ä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\n","permalink":"http://localhost:1313/404/","summary":"\u003ch1 id=\"404---é¡µé¢ä¸å­˜åœ¨\"\u003e404 - é¡µé¢ä¸å­˜åœ¨\u003c/h1\u003e\n\u003cp\u003eæŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\u003c/p\u003e\n\u003ch2 id=\"æ‚¨å¯ä»¥å°è¯•\"\u003eæ‚¨å¯ä»¥å°è¯•ï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/\"\u003eè¿”å›é¦–é¡µ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/\"\u003eæŸ¥çœ‹æ–‡ç« åˆ—è¡¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/search/\"\u003eä½¿ç”¨æœç´¢åŠŸèƒ½\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sitemap.xml\"\u003eæŸ¥çœ‹ç½‘ç«™åœ°å›¾\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eå¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡\u003ca href=\"/about/\"\u003eå…³äºé¡µé¢\u003c/a\u003eä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\u003c/p\u003e","title":"404 é¡µé¢ä¸å­˜åœ¨"},{"content":"ä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\næŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\nå‘å¸ƒäº 2025å¹´9æœˆ24æ—¥ ä¸Šåˆ10:30\n","permalink":"http://localhost:1313/thoughts/2025-09-24-first-thought/","summary":"\u003cp\u003eä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\u003c/p\u003e\n\u003cp\u003eæŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\u003c/p\u003e","title":"åšå®¢éšæƒ³åŠŸèƒ½ä¸Šçº¿äº†"},{"content":"ç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\næœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\nå‘å¸ƒäº 2025å¹´9æœˆ23æ—¥ ä¸‹åˆ3:45\n","permalink":"http://localhost:1313/thoughts/2025-09-23-meditation/","summary":"\u003cp\u003eç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\u003c/p\u003e\n\u003cp\u003eæœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\u003c/p\u003e","title":"å…³äºå†¥æƒ³å’Œç”Ÿæ´»å¹³è¡¡çš„æ€è€ƒ"},{"content":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š Gitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\nGitåŸºç¡€æ¦‚å¿µ ä»€ä¹ˆæ˜¯Gitï¼Ÿ Gitæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œç”±Linus Torvaldsäº2005å¹´åˆ›å»ºã€‚ä¸é›†ä¸­å¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ˆå¦‚SVNï¼‰ä¸åŒï¼ŒGitçš„æ¯ä¸ªå¼€å‘è€…éƒ½æ‹¥æœ‰å®Œæ•´çš„ä»£ç ä»“åº“å‰¯æœ¬ï¼Œè¿™ä½¿å¾—Gitåœ¨é€Ÿåº¦ã€æ•°æ®å®Œæ•´æ€§å’Œæ”¯æŒåˆ†å¸ƒå¼å¼€å‘æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚\nGitçš„åŸºæœ¬å·¥ä½œåŒº Gitæœ‰ä¸‰ä¸ªä¸»è¦çš„å·¥ä½œåŒºï¼š\nå·¥ä½œåŒº(Working Directory)ï¼šä½ å½“å‰æ­£åœ¨å·¥ä½œçš„ç›®å½•ï¼ŒåŒ…å«é¡¹ç›®çš„æ‰€æœ‰æ–‡ä»¶ã€‚ æš‚å­˜åŒº(Staging Area)ï¼šä¹Ÿç§°ä¸º\u0026quot;ç´¢å¼•(Index)\u0026quot;ï¼Œæ˜¯ä¸€ä¸ªä¸´æ—¶ä¿å­˜ä¿®æ”¹çš„åœ°æ–¹ã€‚ æœ¬åœ°ä»“åº“(Local Repository)ï¼šGitä¿å­˜é¡¹ç›®å…ƒæ•°æ®å’Œå¯¹è±¡æ•°æ®åº“çš„åœ°æ–¹ã€‚ æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªè¿œç¨‹ä»“åº“(Remote Repository)ï¼Œé€šå¸¸æ˜¯æ‰˜ç®¡åœ¨GitHubã€GitLabç­‰å¹³å°ä¸Šçš„ä»“åº“ï¼Œç”¨äºå›¢é˜Ÿåä½œå’Œå¤‡ä»½ã€‚\nGitçš„åŸºæœ¬å·¥ä½œæµç¨‹ Gitçš„åŸºæœ¬å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\nåœ¨å·¥ä½œåŒºä¿®æ”¹æ–‡ä»¶ ä½¿ç”¨git addå°†ä¿®æ”¹æ·»åŠ åˆ°æš‚å­˜åŒº ä½¿ç”¨git commitå°†æš‚å­˜åŒºçš„å†…å®¹æäº¤åˆ°æœ¬åœ°ä»“åº“ ä½¿ç”¨git pushå°†æœ¬åœ°ä»“åº“çš„ä¿®æ”¹æ¨é€åˆ°è¿œç¨‹ä»“åº“ GitåŸºæœ¬å‘½ä»¤ åˆå§‹åŒ–é…ç½® é…ç½®ç”¨æˆ·ä¿¡æ¯ 1 2 3 4 5 6 7 8 # é…ç½®å…¨å±€ç”¨æˆ·å git config --global user.name \u0026#34;Your Name\u0026#34; # é…ç½®å…¨å±€é‚®ç®± git config --global user.email \u0026#34;your.email@example.com\u0026#34; # æŸ¥çœ‹é…ç½® git config --list åˆå§‹åŒ–ä»“åº“ 1 2 3 4 5 # åœ¨å½“å‰ç›®å½•åˆå§‹åŒ–Gitä»“åº“ git init # å…‹éš†è¿œç¨‹ä»“åº“ git clone https://github.com/username/repository.git åŸºæœ¬æ“ä½œ æŸ¥çœ‹çŠ¶æ€ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # æŸ¥çœ‹å·¥ä½œåŒºçŠ¶æ€ git status # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä¿®æ”¹æƒ…å†µ # æŸ¥çœ‹ç®€åŒ–çŠ¶æ€ git status -s # ç®€åŒ–è¾“å‡ºï¼Œé€‚åˆå¿«é€ŸæŸ¥çœ‹ # æŸ¥çœ‹æäº¤å†å² git log # æ˜¾ç¤ºè¯¦ç»†æäº¤è®°å½• # æŸ¥çœ‹ç®€æ´æäº¤å†å² git log --oneline # æ¯æ¡æäº¤ä¸€è¡Œï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ # æŸ¥çœ‹å›¾å½¢åŒ–æäº¤å†å² git log --graph --oneline --all æ·»åŠ å’Œæäº¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ·»åŠ æŒ‡å®šæ–‡ä»¶åˆ°æš‚å­˜åŒº git add filename # æ·»åŠ æ‰€æœ‰ä¿®æ”¹åˆ°æš‚å­˜åŒº git add . # æ·»åŠ æ‰€æœ‰ä¿®æ”¹ï¼ˆåŒ…æ‹¬æ–°æ–‡ä»¶ï¼‰åˆ°æš‚å­˜åŒº git add -A # æäº¤æš‚å­˜åŒºå†…å®¹ git commit -m \u0026#34;Commit message\u0026#34; # è·³è¿‡æš‚å­˜åŒºç›´æ¥æäº¤ git commit -a -m \u0026#34;Commit message\u0026#34; # ä¿®æ”¹æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯ git commit --amend æŸ¥çœ‹å’Œæ¯”è¾ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æŸ¥çœ‹å·¥ä½œåŒºä¸æš‚å­˜åŒºçš„å·®å¼‚ git diff # æŸ¥çœ‹æš‚å­˜åŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff --staged # æŸ¥çœ‹å·¥ä½œåŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff HEAD # æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶çš„å·®å¼‚ git diff filename # æŸ¥çœ‹æŒ‡å®šæäº¤çš„å·®å¼‚ git diff commit1 commit2 æ’¤é”€æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ’¤é”€å·¥ä½œåŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°æš‚å­˜åŒºçŠ¶æ€ï¼‰ git checkout -- filename # æ’¤é”€æš‚å­˜åŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°å·¥ä½œåŒºçŠ¶æ€ï¼‰ git reset HEAD filename # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~1 # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~1 # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~n # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~n è¿œç¨‹ä»“åº“æ“ä½œ æ·»åŠ å’Œç®¡ç†è¿œç¨‹ä»“åº“ 1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹è¿œç¨‹ä»“åº“ git remote -v # æ·»åŠ è¿œç¨‹ä»“åº“ git remote add origin https://github.com/username/repository.git # åˆ é™¤è¿œç¨‹ä»“åº“ git remote remove origin # ä¿®æ”¹è¿œç¨‹ä»“åº“URL git remote set-url origin https://github.com/username/new-repository.git æ¨é€å’Œæ‹‰å– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin main # æ¨é€å¹¶è®¾ç½®ä¸Šæ¸¸åˆ†æ”¯ git push -u origin main # æ‹‰å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ git pull origin main # è·å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ï¼ˆä¸åˆå¹¶ï¼‰ git fetch origin # åˆå¹¶è¿œç¨‹åˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge origin/main åˆ†æ”¯ç®¡ç† åˆ†æ”¯çš„åŸºæœ¬æ“ä½œ åˆ›å»ºå’Œåˆ‡æ¢åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # åˆ›å»ºæ–°åˆ†æ”¯ git branch feature-branch # åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯ git checkout feature-branch # åˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯ git checkout -b feature-branch # æŸ¥çœ‹æ‰€æœ‰åˆ†æ”¯ git branch -a # æŸ¥çœ‹æœ¬åœ°åˆ†æ”¯ git branch # æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯ git branch -r åˆå¹¶åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 # åˆ‡æ¢åˆ°ç›®æ ‡åˆ†æ”¯ git checkout main # åˆå¹¶æŒ‡å®šåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge feature-branch # åˆ é™¤å·²åˆå¹¶çš„åˆ†æ”¯ git branch -d feature-branch # å¼ºåˆ¶åˆ é™¤åˆ†æ”¯ï¼ˆå³ä½¿æœªåˆå¹¶ï¼‰ git branch -D feature-branch è§£å†³åˆå¹¶å†²çª å½“åˆå¹¶åˆ†æ”¯æ—¶ï¼Œå¦‚æœä¸¤ä¸ªåˆ†æ”¯å¯¹åŒä¸€æ–‡ä»¶çš„åŒä¸€éƒ¨åˆ†è¿›è¡Œäº†ä¸åŒçš„ä¿®æ”¹ï¼Œå°±ä¼šäº§ç”Ÿåˆå¹¶å†²çªã€‚è§£å†³åˆå¹¶å†²çªçš„æ­¥éª¤å¦‚ä¸‹ï¼š\næ‰§è¡Œgit mergeå‘½ä»¤ï¼ŒGitä¼šæ ‡è®°å†²çªæ–‡ä»¶ æ‰“å¼€å†²çªæ–‡ä»¶ï¼ŒæŸ¥çœ‹å†²çªæ ‡è®°ï¼ˆ\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;, =======, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;ï¼‰ æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶ï¼Œè§£å†³å†²çª ä½¿ç”¨git addæ ‡è®°å†²çªå·²è§£å†³ ä½¿ç”¨git commitå®Œæˆåˆå¹¶ 1 2 3 4 5 6 7 8 9 10 11 # åˆå¹¶åˆ†æ”¯ï¼ˆå‡è®¾äº§ç”Ÿå†²çªï¼‰ git merge feature-branch # æŸ¥çœ‹å†²çªçŠ¶æ€ git status # æ‰‹åŠ¨è§£å†³å†²çªåï¼Œæ ‡è®°å·²è§£å†³ git add conflicted-file # å®Œæˆåˆå¹¶ git commit å˜åŸº(Rebase) å˜åŸºæ˜¯å°†ä¸€ç³»åˆ—æäº¤åº”ç”¨åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šçš„æ“ä½œï¼Œå®ƒå¯ä»¥ä½¿æäº¤å†å²æ›´åŠ çº¿æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # å˜åŸºå½“å‰åˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main # å˜åŸºæŒ‡å®šåˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main feature-branch # äº¤äº’å¼å˜åŸºï¼ˆå¯ä»¥ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æäº¤ï¼‰ git rebase -i HEAD~3 # ç»§ç»­å˜åŸºï¼ˆè§£å†³å†²çªåï¼‰ git rebase --continue # å–æ¶ˆå˜åŸº git rebase --abort æ ‡ç­¾ç®¡ç† æ ‡ç­¾ç”¨äºæ ‡è®°é‡è¦çš„æäº¤ç‚¹ï¼Œé€šå¸¸ç”¨äºç‰ˆæœ¬å‘å¸ƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # åˆ›å»ºè½»é‡æ ‡ç­¾ git tag v1.0.0 # åˆ›å»ºå¸¦æ³¨é‡Šçš„æ ‡ç­¾ git tag -a v1.0.0 -m \u0026#34;Version 1.0.0 release\u0026#34; # æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾ git tag # æŸ¥çœ‹æ ‡ç­¾ä¿¡æ¯ git show v1.0.0 # æ¨é€æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin v1.0.0 # æ¨é€æ‰€æœ‰æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin --tags # åˆ é™¤æœ¬åœ°æ ‡ç­¾ git tag -d v1.0.0 # åˆ é™¤è¿œç¨‹æ ‡ç­¾ git push origin :refs/tags/v1.0.0 Gitå·¥ä½œæµæ¨¡å‹ é›†ä¸­å¼å·¥ä½œæµ é›†ä¸­å¼å·¥ä½œæµæ˜¯æœ€ç®€å•çš„å·¥ä½œæµï¼Œç±»ä¼¼äºSVNçš„å·¥ä½œæ–¹å¼ã€‚æ‰€æœ‰å¼€å‘è€…ç›´æ¥åœ¨ä¸»åˆ†æ”¯ä¸Šå·¥ä½œï¼Œé€‚åˆå°å‹é¡¹ç›®æˆ–ä¸ªäººé¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nå…‹éš†ä»“åº“ åœ¨ä¸»åˆ†æ”¯ä¸Šä¿®æ”¹ä»£ç  æäº¤ä¿®æ”¹ æ¨é€åˆ°è¿œç¨‹ä»“åº“ ä¼˜ç‚¹ï¼š\nç®€å•ç›´è§‚ æ— éœ€å­¦ä¹ åˆ†æ”¯ç®¡ç† ç¼ºç‚¹ï¼š\nå®¹æ˜“äº§ç”Ÿå†²çª ä¸é€‚åˆå›¢é˜Ÿåä½œ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµä¸ºæ¯ä¸ªæ–°åŠŸèƒ½åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„åˆ†æ”¯ï¼Œå¼€å‘å®Œæˆåå†åˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»ä¸»åˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›ä¸»åˆ†æ”¯ åˆ é™¤åŠŸèƒ½åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # åˆ‡æ¢åˆ°ä¸»åˆ†æ”¯ git checkout main # åˆå¹¶åŠŸèƒ½åˆ†æ”¯ git merge feature/new-feature # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature ä¼˜ç‚¹ï¼š\nåŠŸèƒ½éš”ç¦»ï¼Œå‡å°‘å†²çª ä¸»åˆ†æ”¯ä¿æŒç¨³å®š ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\néœ€è¦ç®¡ç†å¤šä¸ªåˆ†æ”¯ åˆå¹¶å¯èƒ½äº§ç”Ÿå†²çª Git Flowå·¥ä½œæµ Git Flowæ˜¯ä¸€ç§æ›´å¤æ‚çš„å·¥ä½œæµï¼Œå®šä¹‰äº†ä¸¥æ ¼çš„åˆ†æ”¯æ¨¡å‹ï¼Œé€‚ç”¨äºå¤§å‹é¡¹ç›®å’Œæ­£å¼å‘å¸ƒã€‚\nåˆ†æ”¯ç±»å‹ï¼š\nmainï¼šä¸»åˆ†æ”¯ï¼Œå§‹ç»ˆä¿æŒå¯å‘å¸ƒçŠ¶æ€ developï¼šå¼€å‘åˆ†æ”¯ï¼Œé›†æˆæ‰€æœ‰åŠŸèƒ½ featureï¼šåŠŸèƒ½åˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œå®Œæˆååˆå¹¶å›develop releaseï¼šå‘å¸ƒåˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œç”¨äºå‡†å¤‡å‘å¸ƒ hotfixï¼šä¿®å¤åˆ†æ”¯ï¼Œä»mainåˆ›å»ºï¼Œç”¨äºç´§æ€¥ä¿®å¤ å·¥ä½œæµç¨‹ï¼š\nä»developåˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›develop ä»developåˆ›å»ºå‘å¸ƒåˆ†æ”¯ æµ‹è¯•å’Œä¿®å¤ åˆå¹¶å‘å¸ƒåˆ†æ”¯åˆ°mainå’Œdevelop ä»mainåˆ›å»ºä¿®å¤åˆ†æ”¯ ä¿®å¤ååˆå¹¶åˆ°mainå’Œdevelop 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # åˆå§‹åŒ–Git Flow git flow init # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git flow feature start new-feature # å®ŒæˆåŠŸèƒ½åˆ†æ”¯ git flow feature finish new-feature # åˆ›å»ºå‘å¸ƒåˆ†æ”¯ git flow release start v1.0.0 # å®Œæˆå‘å¸ƒåˆ†æ”¯ git flow release finish v1.0.0 # åˆ›å»ºä¿®å¤åˆ†æ”¯ git flow hotfix start critical-fix # å®Œæˆä¿®å¤åˆ†æ”¯ git flow hotfix finish critical-fix ä¼˜ç‚¹ï¼š\nç»“æ„æ¸…æ™°ï¼ŒèŒè´£æ˜ç¡® é€‚åˆæ­£å¼å‘å¸ƒ æ”¯æŒç´§æ€¥ä¿®å¤ ç¼ºç‚¹ï¼š\næµç¨‹å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜ åˆ†æ”¯ç®¡ç†ç¹ç å¯¹äºå°å‹é¡¹ç›®è¿‡äºå¤æ‚ GitHub Flowå·¥ä½œæµ GitHub Flowæ˜¯GitHubä½¿ç”¨çš„ä¸€ç§ç®€åŒ–å·¥ä½œæµï¼Œé€‚åˆæŒç»­éƒ¨ç½²çš„é¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºPull Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ éƒ¨ç½² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitHubä¸Šåˆ›å»ºPull Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature git push origin --delete feature/new-feature ä¼˜ç‚¹ï¼š\nç®€å•æ˜äº† é€‚åˆæŒç»­éƒ¨ç½² ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\nä¸é€‚åˆéœ€è¦é•¿æœŸç»´æŠ¤å¤šä¸ªç‰ˆæœ¬çš„é¡¹ç›® ç¼ºå°‘æ˜ç¡®çš„å‘å¸ƒæµç¨‹ GitLab Flowå·¥ä½œæµ GitLab Flowæ˜¯GitLabæ¨èçš„å·¥ä½œæµï¼Œç»“åˆäº†GitHub Flowå’ŒGit Flowçš„ä¼˜ç‚¹ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºMerge Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ ä»mainåˆ›å»ºç¯å¢ƒåˆ†æ”¯ï¼ˆå¦‚stagingã€productionï¼‰ éƒ¨ç½²åˆ°ä¸åŒç¯å¢ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitLabä¸Šåˆ›å»ºMerge Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ›å»ºç¯å¢ƒåˆ†æ”¯ git checkout -b production main git push origin production # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ # ... ä¼˜ç‚¹ï¼š\nç®€å•ä¸”çµæ´» æ”¯æŒå¤šç¯å¢ƒéƒ¨ç½² é€‚åˆæŒç»­äº¤ä»˜ ç¼ºç‚¹ï¼š\nç¯å¢ƒåˆ†æ”¯ç®¡ç†éœ€è¦é¢å¤–å·¥ä½œ å¯¹äºå¤§å‹é¡¹ç›®å¯èƒ½ä¸å¤Ÿä¸¥æ ¼ Gité«˜çº§æŠ€å·§ é’©å­(Hooks) Gité’©å­æ˜¯åœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è‡ªåŠ¨æ‰§è¡Œçš„è„šæœ¬ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚\nå¸¸ç”¨é’©å­ç±»å‹ å®¢æˆ·ç«¯é’©å­ï¼š\npre-commitï¼šæäº¤å‰è¿è¡Œ commit-msgï¼šç¼–è¾‘æäº¤ä¿¡æ¯åè¿è¡Œ pre-pushï¼šæ¨é€å‰è¿è¡Œ æœåŠ¡å™¨ç«¯é’©å­ï¼š\npre-receiveï¼šæ¥æ”¶æ¨é€æ—¶è¿è¡Œ updateï¼šæ›´æ–°åˆ†æ”¯æ—¶è¿è¡Œ post-receiveï¼šæ¥æ”¶æ¨é€åè¿è¡Œ ç¤ºä¾‹ï¼špre-commité’©å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/sh # .git/hooks/pre-commit # æ£€æŸ¥ä»£ç é£æ ¼ npm run lint # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;ä»£ç é£æ ¼æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi # è¿è¡Œæµ‹è¯• npm test # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;æµ‹è¯•å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi å­æ¨¡å—(Submodules) Gitå­æ¨¡å—å…è®¸ä½ å°†ä¸€ä¸ªGitä»“åº“ä½œä¸ºå¦ä¸€ä¸ªGitä»“åº“çš„å­ç›®å½•ã€‚\næ·»åŠ å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 # æ·»åŠ å­æ¨¡å— git submodule add https://github.com/username/submodule-repository.git path/to/submodule # åˆå§‹åŒ–å­æ¨¡å— git submodule init # æ›´æ–°å­æ¨¡å— git submodule update # é€’å½’å…‹éš†åŒ…å«å­æ¨¡å—çš„ä»“åº“ git clone --recursive https://github.com/username/repository.git æ›´æ–°å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 12 # è¿›å…¥å­æ¨¡å—ç›®å½• cd path/to/submodule # æ‹‰å–æœ€æ–°ä»£ç  git pull origin main # è¿”å›ä¸»ä»“åº“ cd .. # æäº¤å­æ¨¡å—æ›´æ–° git add path/to/submodule git commit -m \u0026#34;Update submodule\u0026#34; å˜åŸº(Rebase)é«˜çº§ç”¨æ³• äº¤äº’å¼å˜åŸº äº¤äº’å¼å˜åŸºå…è®¸ä½ ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æˆ–é‡æ–°æ’åºæäº¤ã€‚\n1 2 # å¯¹æœ€è¿‘çš„3ä¸ªæäº¤è¿›è¡Œäº¤äº’å¼å˜åŸº git rebase -i HEAD~3 åœ¨æ‰“å¼€çš„ç¼–è¾‘å™¨ä¸­ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„å†…å®¹ï¼š\npick f7f3f6d Commit message 1 pick 310154e Commit message 2 pick a5f4a0d Commit message 3 # Rebase 1234567..a5f4a0d onto 1234567 (3 commands) # # Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to re-use the original merge # . commit\u0026#39;s author and message. # # These lines can be re-ordered; they are executed from top to bottom. ä½ å¯ä»¥é€šè¿‡ä¿®æ”¹å‘½ä»¤å‰çš„å…³é”®å­—æ¥æ”¹å˜æäº¤çš„å¤„ç†æ–¹å¼ã€‚\nå˜åŸº vs åˆå¹¶ å˜åŸºå’Œåˆå¹¶éƒ½æ˜¯æ•´åˆåˆ†æ”¯æ›´æ”¹çš„æ–¹æ³•ï¼Œä½†å®ƒä»¬æœ‰ä¸åŒçš„å·¥ä½œæ–¹å¼ï¼š\nåˆå¹¶(Merge)ï¼š\nåˆ›å»ºä¸€ä¸ªæ–°çš„\u0026quot;åˆå¹¶æäº¤\u0026quot; ä¿ç•™å®Œæ•´çš„åˆ†æ”¯å†å² é€‚åˆå…¬å…±åˆ†æ”¯ å˜åŸº(Rebase)ï¼š\nå°†æäº¤é‡æ–°åº”ç”¨åˆ°ç›®æ ‡åˆ†æ”¯ åˆ›å»ºçº¿æ€§çš„æäº¤å†å² é€‚åˆç§æœ‰åˆ†æ”¯ 1 2 3 4 5 6 7 # åˆå¹¶åˆ†æ”¯ git checkout main git merge feature-branch # å˜åŸºåˆ†æ”¯ git checkout feature-branch git rebase main å‚¨è—(Stash) å‚¨è—å…è®¸ä½ ä¸´æ—¶ä¿å­˜æœªæäº¤çš„ä¿®æ”¹ï¼Œä»¥ä¾¿åˆ‡æ¢åˆ†æ”¯æˆ–æ‰§è¡Œå…¶ä»–æ“ä½œã€‚\nåŸºæœ¬å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # å‚¨è—å½“å‰ä¿®æ”¹ git stash # å‚¨è—å¹¶æ·»åŠ è¯´æ˜ git stash save \u0026#34;Work in progress\u0026#34; # æŸ¥çœ‹å‚¨è—åˆ—è¡¨ git stash list # åº”ç”¨æœ€æ–°å‚¨è—ï¼ˆä¸åˆ é™¤ï¼‰ git stash apply # åº”ç”¨å¹¶åˆ é™¤æœ€æ–°å‚¨è— git stash pop # åº”ç”¨æŒ‡å®šå‚¨è— git stash apply stash@{1} # åˆ é™¤æŒ‡å®šå‚¨è— git stash drop stash@{1} # æ¸…é™¤æ‰€æœ‰å‚¨è— git stash clear é«˜çº§å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 # å‚¨è—æœªè·Ÿè¸ªçš„æ–‡ä»¶ git stash -u # å‚¨è—åŒ…æ‹¬å¿½ç•¥çš„æ–‡ä»¶ git stash -a # ä»å‚¨è—åˆ›å»ºåˆ†æ”¯ git stash branch new-branch stash@{1} ç­¾é€‰(Cherry-pick) ç­¾é€‰å…è®¸ä½ é€‰æ‹©ç‰¹å®šçš„æäº¤ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°å½“å‰åˆ†æ”¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ç­¾é€‰æŒ‡å®šæäº¤ git cherry-pick commit-hash # ç­¾é€‰ä½†ä¸æäº¤ git cherry-pick -n commit-hash # ç­¾é€‰å¹¶ç¼–è¾‘æäº¤ä¿¡æ¯ git cherry-pick -e commit-hash # ç­¾é€‰å¤šä¸ªæäº¤ git cherry-pick commit1 commit2 commit3 # ç­¾é€‰ä¸€ç³»åˆ—æäº¤ git cherry-pick commit1..commit3 # ä¸­æ­¢ç­¾é€‰ git cherry-pick --abort # ç»§ç»­ç­¾é€‰ï¼ˆè§£å†³å†²çªåï¼‰ git cherry-pick --continue å¼•ç”¨æ—¥å¿—(Reflog) å¼•ç”¨æ—¥å¿—è®°å½•äº†Gitä»“åº“ä¸­æ‰€æœ‰å¼•ç”¨çš„æ›´æ–°ï¼ŒåŒ…æ‹¬è¢«åˆ é™¤çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹å¼•ç”¨æ—¥å¿— git reflog # æŸ¥çœ‹æŒ‡å®šåˆ†æ”¯çš„å¼•ç”¨æ—¥å¿— git reflog show main # æŸ¥çœ‹å¼•ç”¨æ—¥å¿—å¹¶æ˜¾ç¤ºå·®å¼‚ git reflog show --stat # æ¢å¤è¢«åˆ é™¤çš„æäº¤ git reset --hard HEAD@{1} äºŒåˆ†æŸ¥æ‰¾(Bisect) äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºå¿«é€Ÿå®šä½å¼•å…¥é—®é¢˜çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # å¼€å§‹äºŒåˆ†æŸ¥æ‰¾ git bisect start # æ ‡è®°å½“å‰æäº¤ä¸ºæœ‰é—®é¢˜ git bisect bad # æ ‡è®°å·²çŸ¥æ­£å¸¸çš„æäº¤ git bisect good commit-hash # Gitä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸€ä¸ªä¸­é—´æäº¤ï¼Œæµ‹è¯•åæ ‡è®°ä¸ºgoodæˆ–bad git bisect good # æˆ– git bisect bad # é‡å¤æµ‹è¯•è¿‡ç¨‹ï¼Œç›´åˆ°æ‰¾åˆ°é—®é¢˜æäº¤ # ç»“æŸäºŒåˆ†æŸ¥æ‰¾ git bisect reset Gitæœ€ä½³å®è·µ æäº¤è§„èŒƒ æäº¤ä¿¡æ¯æ ¼å¼ è‰¯å¥½çš„æäº¤ä¿¡æ¯åº”è¯¥æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶éµå¾ªä¸€å®šçš„æ ¼å¼ï¼š\n\u0026lt;ç±»å‹\u0026gt;(\u0026lt;èŒƒå›´\u0026gt;): \u0026lt;ä¸»é¢˜\u0026gt; \u0026lt;è¯¦ç»†æè¿°\u0026gt; \u0026lt;é¡µè„š\u0026gt; ç±»å‹ï¼š\nfeatï¼šæ–°åŠŸèƒ½ fixï¼šä¿®å¤bug docsï¼šæ–‡æ¡£æ›´æ–° styleï¼šä»£ç æ ¼å¼ï¼ˆä¸å½±å“ä»£ç è¿è¡Œçš„å˜åŠ¨ï¼‰ refactorï¼šé‡æ„ï¼ˆæ—¢ä¸æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¹Ÿä¸æ˜¯ä¿®æ”¹bugçš„ä»£ç å˜åŠ¨ï¼‰ perfï¼šæ€§èƒ½ä¼˜åŒ– testï¼šå¢åŠ æµ‹è¯• choreï¼šæ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨ èŒƒå›´ï¼šå¯é€‰ï¼Œç”¨äºè¯´æ˜æäº¤å½±å“çš„èŒƒå›´ï¼Œå¦‚docs, api, coreç­‰ã€‚\nä¸»é¢˜ï¼šç®€æ´æè¿°æäº¤å†…å®¹ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦ã€‚\nè¯¦ç»†æè¿°ï¼šå¯é€‰ï¼Œè¯¦ç»†æè¿°æäº¤å†…å®¹ï¼Œæ¯è¡Œä¸è¶…è¿‡72ä¸ªå­—ç¬¦ã€‚\né¡µè„šï¼šå¯é€‰ï¼Œç”¨äºæ ‡è®°Breaking Changesæˆ–å…³é—­Issueã€‚\nç¤ºä¾‹æäº¤ä¿¡æ¯ feat(api): add user authentication endpoint Add a new endpoint for user authentication using JWT tokens. The endpoint supports both username/password and social login methods. Closes #123 åˆ†æ”¯å‘½åè§„èŒƒ è‰¯å¥½çš„åˆ†æ”¯å‘½åå¯ä»¥æé«˜å›¢é˜Ÿåä½œæ•ˆç‡ï¼š\n\u0026lt;ç±»å‹\u0026gt;/\u0026lt;æè¿°\u0026gt; ä¾‹å¦‚ï¼š feature/user-authentication fix/login-bug docs/api-documentation refactor/user-service ä»£ç å®¡æŸ¥ ä»£ç å®¡æŸ¥æ˜¯ä¿è¯ä»£ç è´¨é‡çš„é‡è¦ç¯èŠ‚ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å»ºè®®ï¼š\nä¿æŒå°çš„æäº¤ï¼šæ¯æ¬¡æäº¤åº”è¯¥åªå…³æ³¨ä¸€ä¸ªåŠŸèƒ½æˆ–ä¿®å¤ï¼Œä¾¿äºå®¡æŸ¥ã€‚ æä¾›æ¸…æ™°çš„æè¿°ï¼šåœ¨Pull Requestä¸­è¯¦ç»†è¯´æ˜ä¿®æ”¹å†…å®¹å’ŒåŸå› ã€‚ è‡ªåŠ¨åŒ–æ£€æŸ¥ï¼šä½¿ç”¨CI/CDå·¥å…·è‡ªåŠ¨è¿è¡Œæµ‹è¯•å’Œä»£ç é£æ ¼æ£€æŸ¥ã€‚ å…³æ³¨ä»£ç é€»è¾‘ï¼šä¸ä»…å…³æ³¨ä»£ç é£æ ¼ï¼Œè¿˜è¦å…³æ³¨é€»è¾‘æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚ æä¾›å»ºè®¾æ€§åé¦ˆï¼šå°Šé‡ä»–äººï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚ å¸¸è§é—®é¢˜è§£å†³ æ’¤é”€å·²æ¨é€çš„æäº¤ 1 2 3 4 5 6 7 # æ–¹æ³•1ï¼šåˆ›å»ºæ–°çš„æäº¤æ¥æ’¤é”€ git revert commit-hash git push origin main # æ–¹æ³•2ï¼šå¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git reset --hard HEAD~1 git push --force origin main åˆå¹¶é”™è¯¯çš„åˆ†æ”¯ 1 2 3 4 5 # æ’¤é”€åˆå¹¶ git reset --hard HEAD~1 # å¦‚æœå·²ç»æ¨é€ git revert -m 1 commit-hash æ¸…ç†å†å²è®°å½• 1 2 3 4 5 # äº¤äº’å¼å˜åŸºæ¸…ç†å†å² git rebase -i HEAD~n # å¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git push --force origin main å¤„ç†å¤§æ–‡ä»¶ 1 2 3 4 5 6 7 8 9 10 # æŸ¥æ‰¾å¤§æ–‡ä»¶ git rev-list --objects --all | git cat-file --batch-check=\u0026#39;%(objecttype) %(objectname) %(objectsize) %(rest)\u0026#39; | sed -n \u0026#39;s/^blob //p\u0026#39; | sort -nrk 2 | head -n 10 # ä½¿ç”¨BFG Repo-Cleaneræ¸…ç†å¤§æ–‡ä»¶ java -jar bfg.jar --strip-blobs-bigger-than 100M my-repo.git # æ¸…ç†å¹¶æ¨é€ git reflog expire --expire=now --all git gc --prune=now --aggressive git push --force origin main æ€»ç»“ Gitæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ŒæŒæ¡å…¶å·¥ä½œæµç¨‹å¯¹äºç°ä»£è½¯ä»¶å¼€å‘è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»Gitçš„åŸºæœ¬æ¦‚å¿µå’Œå‘½ä»¤å¼€å§‹ï¼Œé€æ­¥ä»‹ç»äº†åˆ†æ”¯ç®¡ç†ã€å„ç§å·¥ä½œæµæ¨¡å‹ä»¥åŠé«˜çº§æŠ€å·§ã€‚\né€šè¿‡å­¦ä¹ å’Œå®è·µè¿™äº›å†…å®¹ï¼Œä½ å¯ä»¥ï¼š\né«˜æ•ˆç®¡ç†ä¸ªäººé¡¹ç›®çš„ç‰ˆæœ¬ ä¸å›¢é˜Ÿæˆå‘˜åä½œå¼€å‘ å¤„ç†å¤æ‚çš„åˆå¹¶å’Œå†²çª ä½¿ç”¨é«˜çº§åŠŸèƒ½æé«˜å·¥ä½œæ•ˆç‡ è®°ä½ï¼ŒGitçš„å¼ºå¤§ä¹‹å¤„åœ¨äºå…¶çµæ´»æ€§ï¼Œä½ å¯ä»¥æ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥ä½œæµç¨‹å’Œå·¥å…·ã€‚åŒæ—¶ï¼Œè‰¯å¥½çš„å®è·µä¹ æƒ¯ï¼ˆå¦‚æ¸…æ™°çš„æäº¤ä¿¡æ¯ã€è§„èŒƒçš„åˆ†æ”¯å‘½åï¼‰å°†ä½¿ä½ çš„å¼€å‘è¿‡ç¨‹æ›´åŠ é¡ºç•…ã€‚\næœ€åï¼ŒGitæ˜¯ä¸€ä¸ªä¸æ–­å‘å±•çš„å·¥å…·ï¼ŒæŒç»­å­¦ä¹ å’Œæ¢ç´¢æ–°åŠŸèƒ½å°†å¸®åŠ©ä½ æ›´å¥½åœ°åˆ©ç”¨è¿™ä¸ªå¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ æŒæ¡Gitå·¥ä½œæµç¨‹ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚\n","permalink":"http://localhost:1313/posts/git-workflow/","summary":"\u003ch1 id=\"gitå·¥ä½œæµç¨‹ä»å…¥é—¨åˆ°ç²¾é€š\"\u003eGitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š\u003c/h1\u003e\n\u003cp\u003eGitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\u003c/p\u003e","title":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š"},{"content":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\nå›¾åƒåŸºç¡€ å›¾åƒè¡¨ç¤º æ•°å­—å›¾åƒçš„æ¦‚å¿µ æ•°å­—å›¾åƒæ˜¯ç”±æœ‰é™æ•°é‡çš„åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆçš„äºŒç»´çŸ©é˜µã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import numpy as np import matplotlib.pyplot as plt # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç°åº¦å›¾åƒ # 5x5çš„ç°åº¦å›¾åƒï¼Œå€¼èŒƒå›´0-255 gray_image = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ], dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert gray_image is not None, \u0026#34;ç°åº¦å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # æ˜¾ç¤ºå›¾åƒ plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Grayscale Image\u0026#39;) plt.colorbar() plt.show() å½©è‰²å›¾åƒè¡¨ç¤º å½©è‰²å›¾åƒé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“æ¥è¡¨ç¤ºã€‚æ¯ä¸ªåƒç´ ç”±ä¸‰ä¸ªå€¼ç»„æˆï¼Œåˆ†åˆ«ä»£è¡¨çº¢ã€ç»¿ã€è“ä¸‰ä¸ªé¢œè‰²é€šé“çš„å¼ºåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰²å›¾åƒ # 5x5x3çš„RGBå›¾åƒï¼Œå€¼èŒƒå›´0-255 color_image = np.zeros((5, 5, 3), dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert color_image is not None, \u0026#34;å½©è‰²å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # è®¾ç½®çº¢è‰²é€šé“ color_image[:, :, 0] = np.array([ [255, 200, 150, 100, 50], [230, 180, 130, 80, 30], [210, 160, 110, 60, 10], [190, 140, 90, 40, 0], [170, 120, 70, 20, 0] ]) # è®¾ç½®ç»¿è‰²é€šé“ color_image[:, :, 1] = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ]) # è®¾ç½®è“è‰²é€šé“ color_image[:, :, 2] = np.array([ [0, 30, 60, 90, 120], [50, 80, 110, 140, 170], [100, 130, 160, 190, 200], [150, 180, 210, 220, 230], [200, 230, 240, 250, 255] ]) # æ˜¾ç¤ºå›¾åƒ plt.imshow(color_image) plt.title(\u0026#39;Color Image\u0026#39;) plt.show() å…¶ä»–é¢œè‰²ç©ºé—´ é™¤äº†RGBï¼Œè¿˜æœ‰å…¶ä»–å¸¸ç”¨çš„é¢œè‰²ç©ºé—´ï¼Œå¦‚HSVï¼ˆè‰²ç›¸ã€é¥±å’Œåº¦ã€æ˜åº¦ï¼‰å’ŒLabï¼ˆäº®åº¦ã€aé€šé“ã€bé€šé“ï¼‰ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import cv2 # å°†RGBå›¾åƒè½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´ hsv_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2HSV) # å°†RGBå›¾åƒè½¬æ¢ä¸ºLabé¢œè‰²ç©ºé—´ lab_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2Lab) # æ˜¾ç¤ºä¸åŒé¢œè‰²ç©ºé—´çš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(color_image) plt.title(\u0026#39;RGB Image\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(hsv_image) plt.title(\u0026#39;HSV Image\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(lab_image) plt.title(\u0026#39;Lab Image\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå±æ€§ åˆ†è¾¨ç‡ å›¾åƒåˆ†è¾¨ç‡æ˜¯æŒ‡å›¾åƒä¸­åƒç´ çš„æ•°é‡ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºå®½åº¦Ã—é«˜åº¦ï¼ˆå¦‚1920Ã—1080ï¼‰ã€‚é«˜åˆ†è¾¨ç‡å›¾åƒåŒ…å«æ›´å¤šç»†èŠ‚ï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šçš„å­˜å‚¨ç©ºé—´å’Œå¤„ç†æ—¶é—´ã€‚\n1 2 3 4 5 6 # è·å–å›¾åƒåˆ†è¾¨ç‡ height, width = gray_image.shape print(f\u0026#34;ç°åº¦å›¾åƒåˆ†è¾¨ç‡: {width}x{height}\u0026#34;) height, width, channels = color_image.shape print(f\u0026#34;å½©è‰²å›¾åƒåˆ†è¾¨ç‡: {width}x{height}, é€šé“æ•°: {channels}\u0026#34;) ä½æ·±åº¦ ä½æ·±åº¦æ˜¯æŒ‡æ¯ä¸ªåƒç´ ä½¿ç”¨çš„ä½æ•°ï¼Œå†³å®šäº†å›¾åƒå¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ã€‚å¸¸è§çš„ä½æ·±åº¦æœ‰8ä½ï¼ˆ256ä¸ªç°åº¦çº§ï¼‰ã€24ä½ï¼ˆRGBå„8ä½ï¼Œçº¦1670ä¸‡ç§é¢œè‰²ï¼‰ç­‰ã€‚\n1 2 3 4 5 6 7 8 9 10 # æ£€æŸ¥å›¾åƒçš„ä½æ·±åº¦ print(f\u0026#34;ç°åº¦å›¾åƒæ•°æ®ç±»å‹: {gray_image.dtype}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ•°æ®ç±»å‹: {color_image.dtype}\u0026#34;) # è®¡ç®—å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ gray_levels = 2 ** (gray_image.itemsize * 8) color_levels = 2 ** (color_image.itemsize * 8) print(f\u0026#34;ç°åº¦å›¾åƒå¯ä»¥è¡¨ç¤ºçš„ç°åº¦çº§æ•°: {gray_levels}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ¯ä¸ªé€šé“å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²çº§æ•°: {color_levels}\u0026#34;) å›¾åƒåŸºæœ¬å¤„ç† å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨OpenCVè¯»å–å›¾åƒ OpenCVæ˜¯ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„è®¡ç®—æœºè§†è§‰åº“ï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import cv2 # è¯»å–å›¾åƒ # æ³¨æ„ï¼šOpenCVé»˜è®¤ä»¥BGRæ ¼å¼è¯»å–å½©è‰²å›¾åƒ image_bgr = cv2.imread(\u0026#39;example.jpg\u0026#39;) # æ£€æŸ¥å›¾åƒæ˜¯å¦æˆåŠŸè¯»å– if image_bgr is None: print(\u0026#34;æ— æ³•è¯»å–å›¾åƒ\u0026#34;) else: # è½¬æ¢ä¸ºRGBæ ¼å¼ä»¥ä¾¿æ­£ç¡®æ˜¾ç¤º image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.title(\u0026#39;Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() ä½¿ç”¨PIL/Pillowè¯»å–å›¾åƒ Pillowæ˜¯Pythonå›¾åƒå¤„ç†åº“ï¼Œæä¾›äº†ç®€å•æ˜“ç”¨çš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from PIL import Image # è¯»å–å›¾åƒ image = Image.open(\u0026#39;example.jpg\u0026#39;) # æ˜¾ç¤ºå›¾åƒ image.show() # è½¬æ¢ä¸ºnumpyæ•°ç»„ image_array = np.array(image) # æ˜¾ç¤ºå›¾åƒä¿¡æ¯ print(f\u0026#34;å›¾åƒå¤§å°: {image.size}\u0026#34;) print(f\u0026#34;å›¾åƒæ¨¡å¼: {image.mode}\u0026#34;) print(f\u0026#34;å›¾åƒæ•°ç»„å½¢çŠ¶: {image_array.shape}\u0026#34;) å›¾åƒåŸºæœ¬æ“ä½œ è£å‰ªå›¾åƒ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image_rgb[50:200, 100:300] # æ˜¾ç¤ºè£å‰ªåçš„å›¾åƒ plt.imshow(cropped_image) plt.title(\u0026#39;Cropped Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() è°ƒæ•´å›¾åƒå¤§å° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # ä½¿ç”¨OpenCVè°ƒæ•´å›¾åƒå¤§å° resized_cv2 = cv2.resize(image_rgb, (300, 200)) # ä½¿ç”¨PILè°ƒæ•´å›¾åƒå¤§å° resized_pil = Image.fromarray(image_rgb).resize((300, 200)) # æ˜¾ç¤ºè°ƒæ•´å¤§å°åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(resized_cv2) plt.title(\u0026#39;Resized with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(resized_pil) plt.title(\u0026#39;Resized with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() æ—‹è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ä½¿ç”¨OpenCVæ—‹è½¬å›¾åƒ (h, w) = image_rgb.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) rotated_cv2 = cv2.warpAffine(image_rgb, M, (w, h)) # ä½¿ç”¨PILæ—‹è½¬å›¾åƒ rotated_pil = Image.fromarray(image_rgb).rotate(45) # æ˜¾ç¤ºæ—‹è½¬åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(rotated_cv2) plt.title(\u0026#39;Rotated with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(rotated_pil) plt.title(\u0026#39;Rotated with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç¿»è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # æ°´å¹³ç¿»è½¬ flipped_h = cv2.flip(image_rgb, 1) # å‚ç›´ç¿»è½¬ flipped_v = cv2.flip(image_rgb, 0) # æ°´å¹³å’Œå‚ç›´ç¿»è½¬ flipped_hv = cv2.flip(image_rgb, -1) # æ˜¾ç¤ºç¿»è½¬åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(flipped_h) plt.title(\u0026#39;Horizontal Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(flipped_v) plt.title(\u0026#39;Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(flipped_hv) plt.title(\u0026#39;Horizontal and Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå¢å¼º äº®åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ äº®åº¦ brightness_increase = cv2.convertScaleAbs(image_rgb, alpha=1.2, beta=50) # å‡å°‘äº®åº¦ brightness_decrease = cv2.convertScaleAbs(image_rgb, alpha=1.0, beta=-50) # æ˜¾ç¤ºäº®åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(brightness_increase) plt.title(\u0026#39;Increased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(brightness_decrease) plt.title(\u0026#39;Decreased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ å¯¹æ¯”åº¦ contrast_increase = cv2.convertScaleAbs(image_rgb, alpha=1.5, beta=0) # å‡å°‘å¯¹æ¯”åº¦ contrast_decrease = cv2.convertScaleAbs(image_rgb, alpha=0.5, beta=0) # æ˜¾ç¤ºå¯¹æ¯”åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(contrast_increase) plt.title(\u0026#39;Increased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(contrast_decrease) plt.title(\u0026#39;Decreased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›´æ–¹å›¾å‡è¡¡åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # ç›´æ–¹å›¾å‡è¡¡åŒ– equalized_image = cv2.equalizeHist(gray_image) # æ˜¾ç¤ºç›´æ–¹å›¾å‡è¡¡åŒ–å‰åçš„å›¾åƒå’Œç›´æ–¹å›¾ plt.figure(figsize=(15, 10)) # åŸå§‹å›¾åƒ plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Grayscale Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # å‡è¡¡åŒ–åçš„å›¾åƒ plt.subplot(2, 2, 2) plt.imshow(equalized_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Equalized Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # åŸå§‹ç›´æ–¹å›¾ plt.subplot(2, 2, 3) plt.hist(gray_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Original Histogram\u0026#39;) # å‡è¡¡åŒ–åçš„ç›´æ–¹å›¾ plt.subplot(2, 2, 4) plt.hist(equalized_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Equalized Histogram\u0026#39;) plt.tight_layout() plt.show() ä¼½é©¬æ ¡æ­£ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def adjust_gamma(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) # åº”ç”¨ä¸åŒçš„ä¼½é©¬å€¼ gamma_1_5 = adjust_gamma(image_rgb, 1.5) gamma_0_5 = adjust_gamma(image_rgb, 0.5) # æ˜¾ç¤ºä¼½é©¬æ ¡æ­£åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image (Î³=1.0)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(gamma_1_5) plt.title(\u0026#39;Gamma=1.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(gamma_0_5) plt.title(\u0026#39;Gamma=0.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒæ»¤æ³¢ å‡å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # åº”ç”¨ä¸åŒå¤§å°çš„å‡å€¼æ»¤æ³¢ blur_3x3 = cv2.blur(gray_image, (3, 3)) blur_5x5 = cv2.blur(gray_image, (5, 5)) blur_7x7 = cv2.blur(gray_image, (7, 7)) # æ˜¾ç¤ºå‡å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(blur_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(blur_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(blur_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() é«˜æ–¯æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°å’Œæ ‡å‡†å·®çš„é«˜æ–¯æ»¤æ³¢ gaussian_3x3 = cv2.GaussianBlur(gray_image, (3, 3), 0) gaussian_5x5 = cv2.GaussianBlur(gray_image, (5, 5), 0) gaussian_7x7 = cv2.GaussianBlur(gray_image, (7, 7), 0) # æ˜¾ç¤ºé«˜æ–¯æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(gaussian_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(gaussian_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(gaussian_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ä¸­å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°çš„ä¸­å€¼æ»¤æ³¢ median_3 = cv2.medianBlur(gray_image, 3) median_5 = cv2.medianBlur(gray_image, 5) median_7 = cv2.medianBlur(gray_image, 7) # æ˜¾ç¤ºä¸­å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(median_3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(median_5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(median_7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åŒè¾¹æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨åŒè¾¹æ»¤æ³¢ bilateral = cv2.bilateralFilter(gray_image, 9, 75, 75) # æ˜¾ç¤ºåŒè¾¹æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(bilateral, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Bilateral Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è¾¹ç¼˜æ£€æµ‹ Sobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # åº”ç”¨Sobelç®—å­ sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3) sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3) sobel_xy = cv2.Sobel(gray_image, cv2.CV_64F, 1, 1, ksize=3) # è½¬æ¢å›uint8 sobel_x = cv2.convertScaleAbs(sobel_x) sobel_y = cv2.convertScaleAbs(sobel_y) sobel_xy = cv2.convertScaleAbs(sobel_xy) # æ˜¾ç¤ºSobelè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(sobel_x, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel X\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(sobel_y, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel Y\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(sobel_xy, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel XY\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Laplacianç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # åº”ç”¨Laplacianç®—å­ laplacian = cv2.Laplacian(gray_image, cv2.CV_64F) laplacian = cv2.convertScaleAbs(laplacian) # æ˜¾ç¤ºLaplacianè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(laplacian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Laplacian Edge Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Cannyè¾¹ç¼˜æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨Cannyè¾¹ç¼˜æ£€æµ‹ canny_low = cv2.Canny(gray_image, 50, 150) canny_high = cv2.Canny(gray_image, 100, 200) # æ˜¾ç¤ºCannyè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(canny_low, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (50, 150)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(canny_high, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (100, 200)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒåˆ†å‰² é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # åº”ç”¨ä¸åŒç±»å‹çš„é˜ˆå€¼åˆ†å‰² ret, thresh_binary = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY) ret, thresh_binary_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV) ret, thresh_trunc = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TRUNC) ret, thresh_tozero = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO) ret, thresh_tozero_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO_INV) # æ˜¾ç¤ºé˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 2) plt.imshow(thresh_binary, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 3) plt.imshow(thresh_binary_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 4) plt.imshow(thresh_trunc, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Truncated Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 5) plt.imshow(thresh_tozero, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 6) plt.imshow(thresh_tozero_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_mean = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2) adaptive_gaussian = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) # æ˜¾ç¤ºè‡ªé€‚åº”é˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(adaptive_mean, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Mean Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(adaptive_gaussian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Gaussian Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Otsué˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨Otsué˜ˆå€¼åˆ†å‰² ret, otsu = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # æ˜¾ç¤ºOtsué˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(otsu, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;Otsu Threshold (Threshold={ret})\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åˆ†æ°´å²­ç®—æ³• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # åˆ›å»ºä¸€ä¸ªç®€å•çš„äºŒå€¼å›¾åƒ binary_image = np.zeros((300, 300), dtype=np.uint8) cv2.circle(binary_image, (100, 100), 50, 255, -1) cv2.circle(binary_image, (200, 200), 50, 255, -1) # åº”ç”¨è·ç¦»å˜æ¢ dist_transform = cv2.distanceTransform(binary_image, cv2.DIST_L2, 5) ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0) sure_fg = np.uint8(sure_fg) # æœªçŸ¥åŒºåŸŸ unknown = cv2.subtract(binary_image, sure_fg) # æ ‡è®°æ ‡ç­¾ ret, markers = cv2.connectedComponents(sure_fg) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR), markers) # æ˜¾ç¤ºåˆ†æ°´å²­ç®—æ³•ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(binary_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(dist_transform, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Distance Transform\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(markers, cmap=\u0026#39;jet\u0026#39;) plt.title(\u0026#39;Watershed Segmentation\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç‰¹å¾æå– Harrisè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # åº”ç”¨Harrisè§’ç‚¹æ£€æµ‹ gray_float = np.float32(gray_image) harris_corners = cv2.cornerHarris(gray_float, 2, 3, 0.04) # æ‰©å¤§è§’ç‚¹æ ‡è®° harris_corners = cv2.dilate(harris_corners, None) # è®¾ç½®é˜ˆå€¼ threshold = 0.01 * harris_corners.max() corner_image = image_rgb.copy() corner_image[harris_corners \u0026gt; threshold] = [255, 0, 0] # æ˜¾ç¤ºHarrisè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(corner_image) plt.title(\u0026#39;Harris Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Shi-Tomasiè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åº”ç”¨Shi-Tomasiè§’ç‚¹æ£€æµ‹ corners = cv2.goodFeaturesToTrack(gray_image, 100, 0.01, 10) corners = np.int0(corners) # ç»˜åˆ¶è§’ç‚¹ shi_tomasi_image = image_rgb.copy() for corner in corners: x, y = corner.ravel() cv2.circle(shi_tomasi_image, (x, y), 3, 255, -1) # æ˜¾ç¤ºShi-Tomasiè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(shi_tomasi_image) plt.title(\u0026#39;Shi-Tomasi Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() SIFTç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºSIFTç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(sift_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;SIFT Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ORBç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºORBç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(orb_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;ORB Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›®æ ‡æ£€æµ‹ Haarçº§è”åˆ†ç±»å™¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # åŠ è½½Haarçº§è”åˆ†ç±»å™¨ face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_frontalface_default.xml\u0026#39;) eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_eye.xml\u0026#39;) # æ£€æµ‹äººè„¸å’Œçœ¼ç› faces = face_cascade.detectMultiScale(gray_image, 1.3, 5) face_eye_image = image_rgb.copy() for (x, y, w, h) in faces: cv2.rectangle(face_eye_image, (x, y), (x+w, y+h), (255, 0, 0), 2) roi_gray = gray_image[y:y+h, x:x+w] roi_color = face_eye_image[y:y+h, x:x+w] eyes = eye_cascade.detectMultiScale(roi_gray) for (ex, ey, ew, eh) in eyes: cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2) # æ˜¾ç¤ºHaarçº§è”åˆ†ç±»å™¨æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(face_eye_image) plt.title(\u0026#39;Haar Cascade Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() HOGç‰¹å¾ä¸SVM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from skimage.feature import hog from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score # æå–HOGç‰¹å¾ def extract_hog_features(images): features = [] for image in images: # è®¡ç®—HOGç‰¹å¾ fd = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False) features.append(fd) return np.array(features) # å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›æ ‡è®°çš„å›¾åƒæ•°æ® # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦çœŸå®æ•°æ® # X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2) # æå–è®­ç»ƒå’Œæµ‹è¯•é›†çš„HOGç‰¹å¾ # X_train_hog = extract_hog_features(X_train) # X_test_hog = extract_hog_features(X_test) # è®­ç»ƒSVMåˆ†ç±»å™¨ # svm = SVC(kernel=\u0026#39;linear\u0026#39;) # svm.fit(X_train_hog, y_train) # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° # y_pred = svm.predict(X_test_hog) # accuracy = accuracy_score(y_test, y_pred) # print(f\u0026#34;Accuracy: {accuracy}\u0026#34;) æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ä»£ç ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®‰è£…ç›¸åº”çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ # å¦‚TensorFlowæˆ–PyTorchï¼Œä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ # ä½¿ç”¨TensorFlowå’Œé¢„è®­ç»ƒçš„SSDæ¨¡å‹ \u0026#34;\u0026#34;\u0026#34; import tensorflow as tf # åŠ è½½é¢„è®­ç»ƒçš„SSDæ¨¡å‹ model = tf.saved_model.load(\u0026#39;ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\u0026#39;) # é¢„å¤„ç†å›¾åƒ input_tensor = tf.convert_to_tensor(image_rgb) input_tensor = input_tensor[tf.newaxis, ...] # è¿è¡Œæ¨¡å‹ detections = model(input_tensor) # è§£ææ£€æµ‹ç»“æœ num_detections = int(detections.pop(\u0026#39;num_detections\u0026#39;)) detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()} detections[\u0026#39;num_detections\u0026#39;] = num_detections # è¿‡æ»¤æ£€æµ‹ç»“æœ min_score_thresh = 0.5 detections[\u0026#39;detection_classes\u0026#39;] = detections[\u0026#39;detection_classes\u0026#39;].astype(np.int64) indexes = np.where(detections[\u0026#39;detection_scores\u0026#39;] \u0026gt; min_score_thresh)[0] # ç»˜åˆ¶æ£€æµ‹ç»“æœ result_image = image_rgb.copy() for i in indexes: class_id = detections[\u0026#39;detection_classes\u0026#39;][i] score = detections[\u0026#39;detection_scores\u0026#39;][i] bbox = detections[\u0026#39;detection_boxes\u0026#39;][i] # å°†å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†è½¬æ¢ä¸ºåƒç´ åæ ‡ h, w, _ = image_rgb.shape y1, x1, y2, x2 = bbox y1, x1, y2, x2 = int(y1 * h), int(x1 * w), int(y2 * h), int(x2 * w) # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾ cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2) label = f\u0026#34;{class_id}: {score:.2f}\u0026#34; cv2.putText(result_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # æ˜¾ç¤ºæ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(result_image) plt.title(\u0026#39;Deep Learning Object Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() \u0026#34;\u0026#34;\u0026#34; æ€»ç»“ è®¡ç®—æœºè§†è§‰æ˜¯ä¸€ä¸ªå¹¿æ³›è€Œæ·±å…¥çš„é¢†åŸŸï¼Œæœ¬æ–‡ä»‹ç»äº†ä»åŸºç¡€çš„å›¾åƒè¡¨ç¤ºå’Œå¤„ç†åˆ°é«˜çº§çš„ç‰¹å¾æå–å’Œç›®æ ‡æ£€æµ‹çš„åŸºæœ¬æ¦‚å¿µå’Œæ–¹æ³•ã€‚é€šè¿‡å­¦ä¹ è¿™äº›åŸºç¡€çŸ¥è¯†ï¼Œè¯»è€…å¯ä»¥ä¸ºè¿›ä¸€æ­¥æ¢ç´¢è®¡ç®—æœºè§†è§‰çš„æ›´é«˜çº§ä¸»é¢˜æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸæ­£åœ¨ç»å†å¿«é€Ÿå˜é©ã€‚ä¼ ç»Ÿçš„è®¡ç®—æœºè§†è§‰æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ ç›¸ç»“åˆï¼Œæ­£åœ¨æ¨åŠ¨è®¡ç®—æœºè§†è§‰åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ä¸æ–­æ‹“å±•ã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºè§†è§‰çš„åŸºæœ¬åŸç†ï¼Œå¹¶æ¿€å‘è¿›ä¸€æ­¥å­¦ä¹ å’Œæ¢ç´¢çš„å…´è¶£ã€‚\nåœ¨æœªæ¥ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å°†ç»§ç»­å‘å±•ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€å¢å¼ºç°å®ã€æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸå‘æŒ¥è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚æŒæ¡è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå°†ä¸ºè¯»è€…åœ¨è¿™ä¸€å……æ»¡æœºé‡çš„é¢†åŸŸä¸­å‘å±•æä¾›æœ‰åŠ›æ”¯æŒã€‚\n","permalink":"http://localhost:1313/posts/computer-vision-basics/","summary":"\u003ch1 id=\"è®¡ç®—æœºè§†è§‰åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eè®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eè®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\u003c/p\u003e","title":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£"},{"content":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\næ·±åº¦å­¦ä¹ ä¸å›¾åƒå¤„ç† ä¼ ç»Ÿå›¾åƒå¤„ç†çš„å±€é™æ€§ ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ä¸»è¦ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ç‰¹å¾æå–å™¨å’Œç®—æ³•ï¼Œè¿™äº›æ–¹æ³•è™½ç„¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š\nç‰¹å¾è®¾è®¡å›°éš¾ï¼šéœ€è¦é¢†åŸŸä¸“å®¶è®¾è®¡ç‰¹å¾ï¼Œè€—æ—¶ä¸”éš¾ä»¥æ³›åŒ–ã€‚ é€‚åº”æ€§å·®ï¼šå¯¹å…‰ç…§ã€è§’åº¦ã€å°ºåº¦ç­‰å˜åŒ–æ•æ„Ÿã€‚ å¤æ‚åœºæ™¯å¤„ç†èƒ½åŠ›æœ‰é™ï¼šéš¾ä»¥å¤„ç†å¤æ‚èƒŒæ™¯å’Œå¤šå˜çš„ç¯å¢ƒã€‚ ç«¯åˆ°ç«¯å­¦ä¹ å›°éš¾ï¼šé€šå¸¸éœ€è¦å¤šä¸ªæ­¥éª¤ç»„åˆï¼Œéš¾ä»¥å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚ æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿ æ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œé€šè¿‡è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„è®¸å¤šå±€é™ï¼š\nè‡ªåŠ¨ç‰¹å¾æå–ï¼šæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾ï¼Œç½‘ç»œè‡ªåŠ¨å­¦ä¹ æœ€ä¼˜è¡¨ç¤ºã€‚ å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ï¼šå¤šå±‚ç½‘ç»œç»“æ„å¯ä»¥å­¦ä¹ å¤æ‚çš„ç‰¹å¾å±‚æ¬¡ã€‚ ç«¯åˆ°ç«¯å­¦ä¹ ï¼šä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºï¼Œæ•´ä¸ªè¿‡ç¨‹å¯ä¼˜åŒ–ã€‚ é€‚åº”æ€§å¼ºï¼šå¯¹å„ç§å˜åŒ–å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ã€‚ å¤§æ•°æ®é©±åŠ¨ï¼šèƒ½å¤Ÿåˆ©ç”¨å¤§é‡æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚ å·ç§¯ç¥ç»ç½‘ç»œ(CNN) å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†é¢†åŸŸæœ€æˆåŠŸçš„åº”ç”¨ä¹‹ä¸€ï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäºç”Ÿç‰©è§†è§‰ç³»ç»Ÿã€‚\nCNNçš„åŸºæœ¬ç»“æ„ å…¸å‹çš„CNNç”±ä»¥ä¸‹å‡ ç§å±‚ç»„æˆï¼š\nå·ç§¯å±‚(Convolutional Layer)ï¼šä½¿ç”¨å·ç§¯æ ¸æå–å±€éƒ¨ç‰¹å¾ã€‚ æ± åŒ–å±‚(Pooling Layer)ï¼šé™ä½ç©ºé—´ç»´åº¦ï¼Œå‡å°‘è®¡ç®—é‡ã€‚ æ¿€æ´»å‡½æ•°å±‚(Activation Layer)ï¼šå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚ å…¨è¿æ¥å±‚(Fully Connected Layer)ï¼šæ•´åˆç‰¹å¾ï¼Œè¿›è¡Œæœ€ç»ˆåˆ†ç±»æˆ–å›å½’ã€‚ å½’ä¸€åŒ–å±‚(Normalization Layer)ï¼šå¦‚æ‰¹å½’ä¸€åŒ–(Batch Normalization)ï¼ŒåŠ é€Ÿè®­ç»ƒã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # ä½¿ç”¨PyTorchæ„å»ºç®€å•çš„CNN import torch import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self, num_classes=10): super(SimpleCNN, self).__init__() self.features = nn.Sequential( # å·ç§¯å±‚1 nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚2 nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚3 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2) ) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(128 * 28 * 28, 512), # è¾“å…¥å°ºå¯¸éœ€ä¸ç‰¹å¾å›¾å°ºå¯¸ä¸€è‡´ nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(512, num_classes) ) def forward(self, x): # x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, 3, 224, 224) æˆ–æ ¹æ®å®é™…è¾“å…¥è°ƒæ•´ # è¿”å›åˆ†ç±»ç»“æœ x = self.features(x) x = x.view(x.size(0), -1) x = self.classifier(x) return x ç»å…¸CNNæ¶æ„ LeNet-5 LeNet-5æ˜¯æœ€æ—©çš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œç”±Yann LeCunåœ¨1998å¹´æå‡ºï¼Œä¸»è¦ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class LeNet5(nn.Module): def __init__(self): super(LeNet5, self).__init__() self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1) self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = torch.relu(self.conv1(x)) x = self.pool1(x) x = torch.relu(self.conv2(x)) x = self.pool2(x) x = x.view(-1, 16 * 5 * 5) x = torch.relu(self.fc1(x)) x = torch.relu(self.fc2(x)) x = self.fc3(x) return x AlexNet AlexNetåœ¨2012å¹´ImageNetç«èµ›ä¸­å–å¾—äº†çªç ´æ€§æˆç»©ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å´›èµ·ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class AlexNet(nn.Module): def __init__(self, num_classes=1000): super(AlexNet, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x VGGNet VGGNetä»¥å…¶ç®€æ´çš„ç»“æ„å’Œå‡ºè‰²çš„æ€§èƒ½è‘—ç§°ï¼Œä¸»è¦ç‰¹ç‚¹æ˜¯ä½¿ç”¨å°å°ºå¯¸å·ç§¯æ ¸å’Œæ·±å±‚ç½‘ç»œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class VGG16(nn.Module): def __init__(self, num_classes=1000): super(VGG16, self).__init__() self.features = nn.Sequential( # Block 1 nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 2 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 3 nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 4 nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 5 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) self.classifier = nn.Sequential( nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x ResNet ResNeté€šè¿‡å¼•å…¥æ®‹å·®è¿æ¥è§£å†³äº†æ·±å±‚ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—æ„å»ºæ•°ç™¾ç”šè‡³ä¸Šåƒå±‚çš„ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample self.stride = stride def forward(self, x): identity = x out = self.conv1(x) out = self.bn1(out) out = nn.ReLU(inplace=True)(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = nn.ReLU(inplace=True)(out) return out class ResNet(nn.Module): def __init__(self, block, layers, num_classes=1000): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2) self.layer3 = self._make_layer(block, 256, layers[2], stride=2) self.layer4 = self._make_layer(block, 512, layers[3], stride=2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def _make_layer(self, block, channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != channels * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channels, channels * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channels * block.expansion), ) layers = [] layers.append(block(self.in_channels, channels, stride, downsample)) self.in_channels = channels * block.expansion for _ in range(1, blocks): layers.append(block(self.in_channels, channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = nn.ReLU(inplace=True)(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x def resnet18(): return ResNet(BasicBlock, [2, 2, 2, 2]) CNNåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒåˆ†ç±» å›¾åƒåˆ†ç±»æ˜¯CNNæœ€åŸºæœ¬çš„åº”ç”¨ï¼Œé€šè¿‡è®­ç»ƒç½‘ç»œè¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNetè¿›è¡Œå›¾åƒåˆ†ç±» import torchvision.models as models import torchvision.transforms as transforms from PIL import Image # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = models.resnet18(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image) input_batch = input_tensor.unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_batch) # è·å–é¢„æµ‹ç»“æœ _, predicted_idx = torch.max(output, 1) ç›®æ ‡æ£€æµ‹ ç›®æ ‡æ£€æµ‹ä¸ä»…è¯†åˆ«å›¾åƒä¸­çš„å¯¹è±¡ï¼Œè¿˜ç¡®å®šå®ƒä»¬çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # ä½¿ç”¨Faster R-CNNè¿›è¡Œç›®æ ‡æ£€æµ‹ import torchvision from torchvision.models.detection import fasterrcnn_resnet50_fpn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fasterrcnn_resnet50_fpn(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† transform = transforms.Compose([transforms.ToTensor()]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) image_tensor = transform(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): predictions = model(image_tensor) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡ï¼ŒåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ä½¿ç”¨FCNè¿›è¡Œè¯­ä¹‰åˆ†å‰² from torchvision.models.segmentation import fcn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fcn.fcn_resnet50(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_tensor)[\u0026#39;out\u0026#39;] ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN) ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ˜¯ç”±Ian Goodfellowåœ¨2014å¹´æå‡ºçš„ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚\nGANçš„åŸºæœ¬åŸç† GANç”±ä¸¤ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼š\nç”Ÿæˆå™¨(Generator)ï¼šè¯•å›¾ç”Ÿæˆé€¼çœŸçš„æ•°æ®ï¼Œä»¥æ¬ºéª—åˆ¤åˆ«å™¨ã€‚ åˆ¤åˆ«å™¨(Discriminator)ï¼šè¯•å›¾åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆå™¨ç”Ÿæˆçš„å‡æ•°æ®ã€‚ è¿™ä¸¤ä¸ªç½‘ç»œé€šè¿‡å¯¹æŠ—è®­ç»ƒä¸æ–­æ”¹è¿›ï¼Œæœ€ç»ˆç”Ÿæˆå™¨èƒ½å¤Ÿç”Ÿæˆä¸çœŸå®æ•°æ®åˆ†å¸ƒç›¸ä¼¼çš„æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€å•çš„GANå®ç° import torch import torch.nn as nn class Generator(nn.Module): def __init__(self, latent_dim, img_shape): super(Generator, self).__init__() self.img_shape = img_shape def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *self.img_shape) return img class Discriminator(nn.Module): def __init__(self, img_shape): super(Discriminator, self).__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, img): img_flat = img.view(img.size(0), -1) validity = self.model(img_flat) return validity GANçš„è®­ç»ƒè¿‡ç¨‹ GANçš„è®­ç»ƒè¿‡ç¨‹æ˜¯ä¸€ä¸ªæå°æå¤§åšå¼ˆé—®é¢˜ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # GANè®­ç»ƒå¾ªç¯ import torch.optim as optim # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨ latent_dim = 100 img_shape = (1, 28, 28) # MNISTå›¾åƒå¤§å° generator = Generator(latent_dim, img_shape) discriminator = Discriminator(img_shape) # ä¼˜åŒ–å™¨ optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # æŸå¤±å‡½æ•° adversarial_loss = torch.nn.BCELoss() # è®­ç»ƒå‚æ•° n_epochs = 200 batch_size = 64 for epoch in range(n_epochs): for i, (imgs, _) in enumerate(dataloader): # çœŸå®å’Œå‡çš„æ ‡ç­¾ real = torch.ones(imgs.size(0), 1) fake = torch.zeros(imgs.size(0), 1) # è®­ç»ƒç”Ÿæˆå™¨ optimizer_G.zero_grad() z = torch.randn(imgs.size(0), latent_dim) gen_imgs = generator(z) g_loss = adversarial_loss(discriminator(gen_imgs), real) g_loss.backward() optimizer_G.step() # è®­ç»ƒåˆ¤åˆ«å™¨ optimizer_D.zero_grad() real_loss = adversarial_loss(discriminator(imgs), real) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2 d_loss.backward() optimizer_D.step() å¸¸è§çš„GANå˜ä½“ DCGAN (Deep Convolutional GAN) DCGANå°†CNNç»“æ„å¼•å…¥GANï¼Œæé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class DCGAN_Generator(nn.Module): def __init__(self, latent_dim, channels=1): super(DCGAN_Generator, self).__init__() self.init_size = 7 # åˆå§‹å¤§å° self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2)) self.conv_blocks = nn.Sequential( nn.BatchNorm2d(128), nn.Upsample(scale_factor=2), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.BatchNorm2d(128, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Upsample(scale_factor=2), nn.Conv2d(128, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Conv2d(64, channels, 3, stride=1, padding=1), nn.Tanh(), ) def forward(self, z): out = self.l1(z) out = out.view(out.shape[0], 128, self.init_size, self.init_size) img = self.conv_blocks(out) return img CycleGAN CycleGANç”¨äºåœ¨æ²¡æœ‰æˆå¯¹è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ResidualBlock(nn.Module): def __init__(self, in_features): super(ResidualBlock, self).__init__() self.block = nn.Sequential( nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features), nn.ReLU(inplace=True), nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features) ) def forward(self, x): return x + self.block(x) class GeneratorResNet(nn.Module): def __init__(self, input_shape, num_residual_blocks): super(GeneratorResNet, self).__init__() channels = input_shape[0] # åˆå§‹å·ç§¯å— out_features = 64 model = [ nn.ReflectionPad2d(3), nn.Conv2d(channels, out_features, 7), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # ä¸‹é‡‡æ · for _ in range(2): out_features *= 2 model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # æ®‹å·®å— for _ in range(num_residual_blocks): model += [ResidualBlock(out_features)] # ä¸Šé‡‡æ · for _ in range(2): out_features //= 2 model += [ nn.Upsample(scale_factor=2), nn.Conv2d(in_features, out_features, 3, stride=1, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # è¾“å‡ºå±‚ model += [nn.ReflectionPad2d(3), nn.Conv2d(out_features, channels, 7), nn.Tanh()] self.model = nn.Sequential(*model) def forward(self, x): return self.model(x) StyleGAN StyleGANé€šè¿‡é£æ ¼æ§åˆ¶ç”Ÿæˆé«˜è´¨é‡çš„äººè„¸å›¾åƒï¼Œå…·æœ‰å‡ºè‰²çš„å¯æ§æ€§å’Œå¤šæ ·æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class StyleGAN_Generator(nn.Module): def __init__(self, latent_dim, n_mlp=8): super(StyleGAN_Generator, self).__init__() # æ˜ å°„ç½‘ç»œ layers = [] for i in range(n_mlp): layers.append(nn.Linear(latent_dim, latent_dim)) layers.append(nn.LeakyReLU(0.2)) self.mapping = nn.Sequential(*layers) # åˆæˆç½‘ç»œ self.synthesis = self._build_synthesis_network(latent_dim) def _build_synthesis_network(self, latent_dim): # è¿™é‡Œç®€åŒ–äº†StyleGANçš„åˆæˆç½‘ç»œç»“æ„ # å®é™…çš„StyleGANç»“æ„æ›´ä¸ºå¤æ‚ï¼ŒåŒ…æ‹¬AdaINã€å™ªå£°æ³¨å…¥ç­‰ layers = nn.ModuleList() # åˆå§‹å¸¸æ•° self.constant_input = nn.Parameter(torch.randn(1, 512, 4, 4)) # ç”Ÿæˆå— in_channels = 512 for i in range(8): # 8ä¸ªä¸Šé‡‡æ ·å— out_channels = min(512, 512 // (2 ** (i // 2))) layers.append(StyleGAN_Block(in_channels, out_channels, upsample=(i \u0026gt; 0))) in_channels = out_channels # è¾“å‡ºå±‚ layers.append(nn.Conv2d(in_channels, 3, 1)) layers.append(nn.Tanh()) return nn.Sequential(*layers) def forward(self, z): # é€šè¿‡æ˜ å°„ç½‘ç»œ w = self.mapping(z) # é€šè¿‡åˆæˆç½‘ç»œ x = self.synthesis(w) return x class StyleGAN_Block(nn.Module): def __init__(self, in_channels, out_channels, upsample=False): super(StyleGAN_Block, self).__init__() self.upsample = upsample if upsample: self.up = nn.Upsample(scale_factor=2, mode=\u0026#39;bilinear\u0026#39;, align_corners=False) self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1) self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1) self.activate = nn.LeakyReLU(0.2) def forward(self, x): if self.upsample: x = self.up(x) x = self.conv1(x) x = self.activate(x) x = self.conv2(x) x = self.activate(x) return x GANåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒç”Ÿæˆ GANå¯ä»¥ç”Ÿæˆå„ç§ç±»å‹çš„å›¾åƒï¼Œä»ç®€å•çš„äººè„¸åˆ°å¤æ‚çš„åœºæ™¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨é¢„è®­ç»ƒçš„StyleGANç”Ÿæˆäººè„¸ import torch from stylegan2_pytorch import Generator # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = Generator(256, 512, 8).cuda() # å‡è®¾æœ‰é¢„è®­ç»ƒæƒé‡ model.load_state_dict(torch.load(\u0026#39;stylegan2-ffhq-config-f.pt\u0026#39;)) model.eval() # ç”Ÿæˆéšæœºæ½œåœ¨å‘é‡ z = torch.randn(1, 512).cuda() # ç”Ÿæˆå›¾åƒ with torch.no_grad(): img = model(z) å›¾åƒä¿®å¤ GANå¯ä»¥ç”¨äºä¿®å¤å›¾åƒä¸­çš„ç¼ºå¤±éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # ç®€åŒ–çš„å›¾åƒä¿®å¤æ¨¡å‹ class ImageInpainting(nn.Module): def __init__(self): super(ImageInpainting, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(4, 64, 7, stride=1, padding=3), # 4é€šé“ï¼šRGB + mask nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 512, 3, stride=2, padding=1), nn.ReLU(inplace=True), ) # ä¸­é—´å±‚ self.middle = nn.Sequential( nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 7, stride=1, padding=3), nn.Tanh(), ) def forward(self, x, mask): # è¿æ¥å›¾åƒå’Œæ©ç  x_masked = x * (1 - mask) input = torch.cat([x_masked, mask], dim=1) # ç¼–ç  x = self.encoder(input) # ä¸­é—´å¤„ç† x = self.middle(x) # è§£ç  x = self.decoder(x) # ç»„åˆåŸå§‹å›¾åƒå’Œç”Ÿæˆéƒ¨åˆ† output = x * mask + x_masked return output å›¾åƒè¶…åˆ†è¾¨ç‡ GANå¯ä»¥ç”¨äºå°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 # SRGANç”Ÿæˆå™¨ class SRGAN_Generator(nn.Module): def __init__(self, scale_factor=4): super(SRGAN_Generator, self).__init__() # åˆå§‹å·ç§¯ self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4) self.relu = nn.ReLU(inplace=True) # æ®‹å·®å— residual_blocks = [] for _ in range(16): residual_blocks.append(ResidualBlock(64)) self.residual_blocks = nn.Sequential(*residual_blocks) # ä¸Šé‡‡æ · upsampling = [] for _ in range(int(math.log(scale_factor, 2))): upsampling.append(nn.Conv2d(64, 256, 3, stride=1, padding=1)) upsampling.append(nn.PixelShuffle(2)) upsampling.append(nn.ReLU(inplace=True)) self.upsampling = nn.Sequential(*upsampling) # è¾“å‡ºå±‚ self.conv2 = nn.Conv2d(64, 3, 9, stride=1, padding=4) self.tanh = nn.Tanh() def forward(self, x): # åˆå§‹å·ç§¯ x = self.conv1(x) residual = x x = self.relu(x) # æ®‹å·®å— x = self.residual_blocks(x) # æ®‹å·®è¿æ¥ x = x + residual # ä¸Šé‡‡æ · x = self.upsampling(x) # è¾“å‡º x = self.conv2(x) x = self.tanh(x) return x class ResidualBlock(nn.Module): def __init__(self, channels): super(ResidualBlock, self).__init__() self.conv1 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(channels) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = out + residual return out é£æ ¼è¿ç§» GANå¯ä»¥å®ç°ä»ä¸€ç§è‰ºæœ¯é£æ ¼åˆ°å¦ä¸€ç§é£æ ¼çš„å›¾åƒè½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€åŒ–çš„é£æ ¼è¿ç§»ç½‘ç»œ class StyleTransfer(nn.Module): def __init__(self): super(StyleTransfer, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 9, stride=1, padding=4), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(inplace=True), ) # æ®‹å·®å— residual_blocks = [] for _ in range(5): residual_blocks.append(ResidualBlock(128)) self.residual_blocks = nn.Sequential(*residual_blocks) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 3, 9, stride=1, padding=4), nn.Tanh(), ) def forward(self, x): # ç¼–ç  x = self.encoder(x) # æ®‹å·®å¤„ç† x = self.residual_blocks(x) # è§£ç  x = self.decoder(x) return x å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ è‡ªç¼–ç å™¨(Autoencoder) è‡ªç¼–ç å™¨æ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç¼–ç å™¨å°†è¾“å…¥å‹ç¼©ä¸ºä½ç»´è¡¨ç¤ºï¼Œå†é€šè¿‡è§£ç å™¨é‡æ„åŸå§‹è¾“å…¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Autoencoder(nn.Module): def __init__(self, latent_dim): super(Autoencoder, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), nn.Linear(128 * 4 * 4, latent_dim), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def forward(self, x): z = self.encoder(x) x_reconstructed = self.decoder(z) return x_reconstructed, z å˜åˆ†è‡ªç¼–ç å™¨(VAE) å˜åˆ†è‡ªç¼–ç å™¨æ˜¯è‡ªç¼–ç å™¨çš„æ¦‚ç‡ç‰ˆæœ¬ï¼Œå¯ä»¥ç”Ÿæˆæ–°çš„æ•°æ®æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class VAE(nn.Module): def __init__(self, latent_dim): super(VAE, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), ) # å‡å€¼å’Œæ–¹å·® self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim) self.fc_var = nn.Linear(128 * 4 * 4, latent_dim) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def encode(self, x): h = self.encoder(x) mu = self.fc_mu(h) log_var = self.fc_var(h) return mu, log_var def reparameterize(self, mu, log_var): std = torch.exp(0.5 * log_var) eps = torch.randn_like(std) z = mu + eps * std return z def decode(self, z): return self.decoder(z) def forward(self, x): mu, log_var = self.encode(x) z = self.reparameterize(mu, log_var) x_reconstructed = self.decode(z) return x_reconstructed, mu, log_var æ‰©æ•£æ¨¡å‹(Diffusion Model) æ‰©æ•£æ¨¡å‹æ˜¯è¿‘å¹´æ¥å…´èµ·çš„ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡é€æ­¥æ·»åŠ å’Œå»é™¤å™ªå£°æ¥ç”Ÿæˆå›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class DiffusionModel(nn.Module): def __init__(self, timesteps=1000): super(DiffusionModel, self).__init__() self.timesteps = timesteps # å™ªå£°è°ƒåº¦å™¨ self.beta = torch.linspace(0.0001, 0.02, timesteps) self.alpha = 1. - self.beta self.alpha_hat = torch.cumprod(self.alpha, dim=0) # U-Netç»“æ„ self.unet = self._build_unet() def _build_unet(self): # ç®€åŒ–çš„U-Netç»“æ„ return nn.Sequential( # ä¸‹é‡‡æ · nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), # ä¸­é—´å±‚ nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), # ä¸Šé‡‡æ · nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 3, padding=1), ) def forward(self, x, t): # æ·»åŠ æ—¶é—´åµŒå…¥ t_emb = self._get_time_embedding(t, x.shape[0]) t_emb = t_emb.view(-1, 1, 1, 1).expand(-1, 3, x.shape[2], x.shape[3]) x = torch.cat([x, t_emb], dim=1) # é€šè¿‡U-Neté¢„æµ‹å™ªå£° noise_pred = self.unet(x) return noise_pred def _get_time_embedding(self, t, batch_size): # ç®€åŒ–çš„æ—¶é—´åµŒå…¥ t = t.view(-1, 1) t = t.float() / self.timesteps t = t * 2 * math.pi sin_t = torch.sin(t) cos_t = torch.cos(t) t_emb = torch.cat([sin_t, cos_t], dim=1) t_emb = t_emb.repeat(1, 3) # æ‰©å±•åˆ°3é€šé“ return t_emb def sample(self, x_shape): # ä»çº¯å™ªå£°å¼€å§‹ x = torch.randn(x_shape) # é€æ­¥å»å™ª for t in reversed(range(self.timesteps)): t_batch = torch.full((x_shape[0],), t, dtype=torch.long) noise_pred = self.forward(x, t_batch) # è®¡ç®—å»å™ªåçš„å›¾åƒ alpha_t = self.alpha[t] alpha_hat_t = self.alpha_hat[t] beta_t = self.beta[t] if t \u0026gt; 0: noise = torch.randn_like(x) else: noise = torch.zeros_like(x) x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * noise_pred) + torch.sqrt(beta_t) * noise return x è§†è§‰Transformer(ViT) è§†è§‰Transformerå°†Transformeræ¶æ„åº”ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸Šå–å¾—äº†ä¸CNNç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 class PatchEmbed(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768): super(PatchEmbed, self).__init__() self.img_size = img_size self.patch_size = patch_size self.n_patches = (img_size // patch_size) ** 2 self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size) def forward(self, x): x = self.proj(x) # (B, embed_dim, n_patches ** 0.5, n_patches ** 0.5) x = x.flatten(2) # (B, embed_dim, n_patches) x = x.transpose(1, 2) # (B, n_patches, embed_dim) return x class Attention(nn.Module): def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.): super(Attention, self).__init__() self.n_heads = n_heads self.dim = dim self.head_dim = dim // n_heads self.scale = self.head_dim ** -0.5 self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias) self.attn_drop = nn.Dropout(attn_p) self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_p) def forward(self, x): n_samples, n_tokens, dim = x.shape qkv = self.qkv(x) # (n_samples, n_tokens, 3 * dim) qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim) qkv = qkv.permute(2, 0, 3, 1, 4) # (3, n_samples, n_heads, n_tokens, head_dim) q, k, v = qkv[0], qkv[1], qkv[2] k_t = k.transpose(-2, -1) # (n_samples, n_heads, head_dim, n_tokens) dp = (q @ k_t) * self.scale # (n_samples, n_heads, n_tokens, n_tokens) attn = dp.softmax(dim=-1) # (n_samples, n_heads, n_tokens, n_tokens) attn = self.attn_drop(attn) weighted_avg = attn @ v # (n_samples, n_heads, n_tokens, head_dim) weighted_avg = weighted_avg.transpose(1, 2) # (n_samples, n_tokens, n_heads, head_dim) weighted_avg = weighted_avg.flatten(2) # (n_samples, n_tokens, dim) x = self.proj(weighted_avg) x = self.proj_drop(x) return x class MLP(nn.Module): def __init__(self, in_features, hidden_features, out_features, p=0.): super(MLP, self).__init__() self.fc1 = nn.Linear(in_features, hidden_features) self.act = nn.GELU() self.fc2 = nn.Linear(hidden_features, out_features) self.drop = nn.Dropout(p) def forward(self, x): x = self.fc1(x) x = self.act(x) x = self.drop(x) x = self.fc2(x) x = self.drop(x) return x class Block(nn.Module): def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(Block, self).__init__() self.norm1 = nn.LayerNorm(dim, eps=1e-6) self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p) self.norm2 = nn.LayerNorm(dim, eps=1e-6) hidden_features = int(dim * mlp_ratio) self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim, p=p) def forward(self, x): x = x + self.attn(self.norm1(x)) x = x + self.mlp(self.norm2(x)) return x class VisionTransformer(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, n_classes=1000, embed_dim=768, depth=12, n_heads=12, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(VisionTransformer, self).__init__() self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_channels=in_channels, embed_dim=embed_dim) self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) self.pos_embed = nn.Parameter(torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)) self.pos_drop = nn.Dropout(p=p) self.blocks = nn.ModuleList([ Block(dim=embed_dim, n_heads=n_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, p=p, attn_p=attn_p) for _ in range(depth) ]) self.norm = nn.LayerNorm(embed_dim, eps=1e-6) self.head = nn.Linear(embed_dim, n_classes) def forward(self, x): n_samples = x.shape[0] x = self.patch_embed(x) cls_token = self.cls_token.expand(n_samples, -1, -1) x = torch.cat((cls_token, x), dim=1) x = x + self.pos_embed x = self.pos_drop(x) for block in self.blocks: x = block(x) x = self.norm(x) cls_token_final = x[:, 0] x = self.head(cls_token_final) return x æ·±åº¦å­¦ä¹ å›¾åƒå¤„ç†çš„æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘ å½“å‰æŒ‘æˆ˜ æ•°æ®éœ€æ±‚ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜ã€‚ è®¡ç®—èµ„æºï¼šè®­ç»ƒå¤§å‹æ¨¡å‹éœ€è¦å¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚ å¯è§£é‡Šæ€§ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸è¢«è§†ä¸º\u0026quot;é»‘ç›’\u0026quot;ï¼Œéš¾ä»¥è§£é‡Šå…¶å†³ç­–è¿‡ç¨‹ã€‚ æ³›åŒ–èƒ½åŠ›ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®åˆ†å¸ƒå¤–è¡¨ç°ä¸ä½³ï¼Œé²æ£’æ€§æœ‰å¾…æé«˜ã€‚ é¢†åŸŸé€‚åº”ï¼šå°†æ¨¡å‹ä»ä¸€ä¸ªé¢†åŸŸè¿ç§»åˆ°å¦ä¸€ä¸ªé¢†åŸŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ æœªæ¥æ–¹å‘ è‡ªç›‘ç£å­¦ä¹ ï¼šå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä»æœªæ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ ã€‚ å°æ ·æœ¬å­¦ä¹ ï¼šä½¿æ¨¡å‹èƒ½å¤Ÿä»å°‘é‡æ ·æœ¬ä¸­å­¦ä¹ ã€‚ å¤šæ¨¡æ€å­¦ä¹ ï¼šç»“åˆå›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€çš„ä¿¡æ¯ã€‚ ç¥ç»æ¶æ„æœç´¢ï¼šè‡ªåŠ¨è®¾è®¡æœ€ä¼˜çš„ç½‘ç»œç»“æ„ã€‚ æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿï¼šä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œã€‚ å¯è§£é‡ŠAIï¼šæé«˜æ¨¡å‹çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚ é²æ£’æ€§å¢å¼ºï¼šæé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ ·æœ¬å’Œåˆ†å¸ƒå¤–æ•°æ®çš„é²æ£’æ€§ã€‚ æ€»ç»“ æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯CNNå’ŒGANï¼Œå·²ç»å½»åº•æ”¹å˜äº†å›¾åƒå¤„ç†é¢†åŸŸã€‚ä»å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆå’Œé£æ ¼è¿ç§»ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­éƒ½å–å¾—äº†ä»¤äººç©ç›®çš„æˆæœã€‚\nCNNé€šè¿‡å…¶å±€éƒ¨è¿æ¥å’Œæƒå€¼å…±äº«çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆåœ°æå–å›¾åƒçš„å±‚æ¬¡ç‰¹å¾ï¼Œæˆä¸ºå›¾åƒå¤„ç†çš„åŸºç¡€æ¶æ„ã€‚GANé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä¸ºå›¾åƒç”Ÿæˆå’Œè½¬æ¢ä»»åŠ¡æä¾›äº†å¼ºå¤§çš„å·¥å…·ã€‚\né™¤äº†CNNå’ŒGANï¼Œè‡ªç¼–ç å™¨ã€å˜åˆ†è‡ªç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹å’Œè§†è§‰Transformerç­‰æ¨¡å‹ä¹Ÿåœ¨å›¾åƒå¤„ç†ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œä¸æ–­æ¨åŠ¨ç€è¯¥é¢†åŸŸçš„å‘å±•ã€‚\nå°½ç®¡æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†ä»é¢ä¸´æ•°æ®éœ€æ±‚ã€è®¡ç®—èµ„æºã€å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚æœªæ¥ï¼Œè‡ªç›‘ç£å­¦ä¹ ã€å°æ ·æœ¬å­¦ä¹ ã€å¤šæ¨¡æ€å­¦ä¹ ç­‰æ–¹å‘å°†å¼•é¢†å›¾åƒå¤„ç†é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚\nä½œä¸ºå›¾åƒç®—æ³•å·¥ç¨‹å¸ˆï¼Œäº†è§£å’ŒæŒæ¡è¿™äº›æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹äºè§£å†³å®é™…é—®é¢˜è‡³å…³é‡è¦ã€‚é€šè¿‡ä¸æ–­å­¦ä¹ å’Œå®è·µï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°åº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œæ¨åŠ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åˆ›æ–°å’Œå‘å±•ã€‚\n","permalink":"http://localhost:1313/posts/deep-learning-image-processing/","summary":"\u003ch1 id=\"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ä»cnnåˆ°gan\"\u003eæ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN\u003c/h1\u003e\n\u003cp\u003eæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\u003c/p\u003e","title":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨"},{"content":"ç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ åœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\nç®—æ³•å¤æ‚åº¦åˆ†æ æ—¶é—´å¤æ‚åº¦ æ—¶é—´å¤æ‚åº¦æ˜¯è¡¡é‡ç®—æ³•æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡å¢é•¿è€Œå¢é•¿çš„é€Ÿç‡ã€‚å¸¸è§çš„æ—¶é—´å¤æ‚åº¦ä»ä½åˆ°é«˜ä¾æ¬¡ä¸ºï¼š\nO(1) - å¸¸æ•°æ—¶é—´ å¸¸æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ï¼Œæ˜¯æœ€ç†æƒ³çš„å¤æ‚åº¦ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šè·å–æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´  def get_first_element(arr): return arr[0] # æ— è®ºæ•°ç»„å¤šå¤§ï¼Œæ‰§è¡Œæ—¶é—´ç›¸åŒ O(log n) - å¯¹æ•°æ—¶é—´ å¯¹æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„å¯¹æ•°å¢é•¿ï¼Œå¸¸è§äºåˆ†æ²»ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šäºŒåˆ†æŸ¥æ‰¾ å‚æ•°ï¼šarr (List[int])ï¼Œtarget (int) è¿”å›ï¼šç›®æ ‡ç´¢å¼•æˆ–-1 \u0026#34;\u0026#34;\u0026#34; def binary_search(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: mid = (left + right) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 O(n) - çº¿æ€§æ—¶é—´ çº¿æ€§æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 4 5 6 7 # ç¤ºä¾‹ï¼šæŸ¥æ‰¾æ•°ç»„ä¸­çš„æœ€å¤§å€¼ def find_max(arr): max_val = arr[0] for val in arr: if val \u0026gt; max_val: max_val = val return max_val O(n log n) - çº¿æ€§å¯¹æ•°æ—¶é—´ çº¿æ€§å¯¹æ•°æ—¶é—´ç®—æ³•å¸¸è§äºé«˜æ•ˆçš„æ’åºç®—æ³•ï¼Œå¦‚å¿«é€Ÿæ’åºã€å½’å¹¶æ’åºã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # ç¤ºä¾‹ï¼šå½’å¹¶æ’åº def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) right = merge_sort(arr[mid:]) return merge(left, right) def merge(left, right): result = [] i = j = 0 while i \u0026lt; len(left) and j \u0026lt; len(right): if left[i] \u0026lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result.extend(left[i:]) result.extend(right[j:]) return result O(nÂ²) - å¹³æ–¹æ—¶é—´ å¹³æ–¹æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ï¼Œå¸¸è§äºç®€å•çš„æ’åºç®—æ³•å’ŒåµŒå¥—å¾ªç¯ã€‚\n1 2 3 4 5 6 7 8 # ç¤ºä¾‹ï¼šå†’æ³¡æ’åº def bubble_sort(arr): n = len(arr) for i in range(n): for j in range(0, n - i - 1): if arr[j] \u0026gt; arr[j + 1]: arr[j], arr[j + 1] = arr[j + 1], arr[j] return arr O(2â¿) - æŒ‡æ•°æ—¶é—´ æŒ‡æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡æŒ‡æ•°å¢é•¿ï¼Œé€šå¸¸ç”¨äºè§£å†³NPéš¾é—®é¢˜ã€‚\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šé€’å½’è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼ˆä½æ•ˆç‰ˆæœ¬ï¼‰ å‚æ•°ï¼šn (int) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n \u0026lt;= 1: return n return fibonacci(n - 1) + fibonacci(n - 2) O(n!) - é˜¶ä¹˜æ—¶é—´ é˜¶ä¹˜æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„é˜¶ä¹˜å¢é•¿ï¼Œæ˜¯æœ€å·®çš„å¤æ‚åº¦ï¼Œå¸¸è§äºæš´åŠ›æœç´¢æ‰€æœ‰æ’åˆ—ç»„åˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ç¤ºä¾‹ï¼šç”Ÿæˆæ‰€æœ‰æ’åˆ— def permutations(arr): if len(arr) \u0026lt;= 1: return [arr] result = [] for i in range(len(arr)): rest = arr[:i] + arr[i+1:] for p in permutations(rest): result.append([arr[i]] + p) return result ç©ºé—´å¤æ‚åº¦ ç©ºé—´å¤æ‚åº¦è¡¡é‡ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­æ‰€éœ€é¢å¤–ç©ºé—´éšè¾“å…¥è§„æ¨¡å¢é•¿çš„é€Ÿç‡ã€‚\nO(1) - å¸¸æ•°ç©ºé—´ å¸¸æ•°ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåŸåœ°äº¤æ¢æ•°ç»„å…ƒç´  def swap_elements(arr, i, j): arr[i], arr[j] = arr[j], arr[i] # ä¸éœ€è¦é¢å¤–ç©ºé—´ O(n) - çº¿æ€§ç©ºé—´ çº¿æ€§ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šå¤åˆ¶æ•°ç»„ def copy_array(arr): return arr.copy() # éœ€è¦ä¸åŸæ•°ç»„å¤§å°ç›¸åŒçš„é¢å¤–ç©ºé—´ O(nÂ²) - å¹³æ–¹ç©ºé—´ å¹³æ–¹ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåˆ›å»ºäºŒç»´æ•°ç»„ def create_2d_array(n): return [[0 for _ in range(n)] for _ in range(n)] # éœ€è¦nÂ²çš„é¢å¤–ç©ºé—´ å¤æ‚åº¦åˆ†ææŠ€å·§ å¾ªç¯åˆ†æ å¯¹äºå¾ªç¯ç»“æ„ï¼Œå¤æ‚åº¦é€šå¸¸ç”±å¾ªç¯æ¬¡æ•°å’Œå¾ªç¯ä½“å†…çš„æ“ä½œå†³å®šã€‚\n1 2 3 4 5 6 7 8 9 10 # O(n) - å•å±‚å¾ªç¯ def example1(n): for i in range(n): # å¾ªç¯næ¬¡ print(i) # O(1)æ“ä½œ # O(nÂ²) - åµŒå¥—å¾ªç¯ def example2(n): for i in range(n): # å¤–å±‚å¾ªç¯næ¬¡ for j in range(n): # å†…å±‚å¾ªç¯næ¬¡ print(i, j) # O(1)æ“ä½œ é€’å½’åˆ†æ å¯¹äºé€’å½’ç®—æ³•ï¼Œå¯ä»¥ä½¿ç”¨é€’å½’æ ‘æˆ–ä¸»å®šç†(Master Theorem)æ¥åˆ†æå¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 # é€’å½’æ ‘åˆ†æï¼šå½’å¹¶æ’åº # T(n) = 2T(n/2) + O(n) # æ¯å±‚æ€»å¤æ‚åº¦ä¸ºO(n)ï¼Œå…±æœ‰log nå±‚ï¼Œå› æ­¤æ€»å¤æ‚åº¦ä¸ºO(n log n) def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) # T(n/2) right = merge_sort(arr[mid:]) # T(n/2) return merge(left, right) # O(n) å‡æ‘Šåˆ†æ å‡æ‘Šåˆ†æç”¨äºè®¡ç®—ä¸€ç³»åˆ—æ“ä½œçš„å¹³å‡å¤æ‚åº¦ï¼Œå³ä½¿æŸäº›æ“ä½œå¯èƒ½å¾ˆè€—æ—¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åŠ¨æ€æ•°ç»„çš„å‡æ‘Šåˆ†æ # è™½ç„¶å¶å°”éœ€è¦O(n)æ—¶é—´æ‰©å®¹ï¼Œä½†næ¬¡appendæ“ä½œçš„æ€»æ—¶é—´ä¸ºO(n) # å› æ­¤æ¯æ¬¡appendçš„å‡æ‘Šæ—¶é—´ä¸ºO(1) class DynamicArray: def __init__(self): self.capacity = 1 self.size = 0 self.array = [None] * self.capacity def append(self, item): if self.size == self.capacity: self._resize(2 * self.capacity) # O(n)æ“ä½œï¼Œä½†ä¸é¢‘ç¹ self.array[self.size] = item self.size += 1 def _resize(self, new_capacity): new_array = [None] * new_capacity for i in range(self.size): new_array[i] = self.array[i] self.array = new_array self.capacity = new_capacity ç®—æ³•ä¼˜åŒ–ç­–ç•¥ æ—¶é—´ä¼˜åŒ–ç­–ç•¥ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„æ˜¯ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºé¢‘ç¹æŸ¥æ‰¾æ“ä½œï¼Œå“ˆå¸Œè¡¨(O(1))æ¯”æ•°ç»„(O(n))æ›´é«˜æ•ˆã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨å“ˆå¸Œè¡¨ä¼˜åŒ–æŸ¥æ‰¾ def find_duplicates(arr): seen = set() duplicates = [] for item in arr: if item in seen: # O(1)æŸ¥æ‰¾ duplicates.append(item) else: seen.add(item) return duplicates é¢„è®¡ç®—å’Œç¼“å­˜ å¯¹äºé‡å¤è®¡ç®—ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®¡ç®—æˆ–ç¼“å­˜æŠ€æœ¯é¿å…é‡å¤å·¥ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— \u0026#34;\u0026#34;\u0026#34; ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— å‚æ•°ï¼šn (int), cache (dict) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n, cache={}): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n in cache: return cache[n] if n \u0026lt;= 1: return n result = fibonacci(n - 1, cache) + fibonacci(n - 2, cache) cache[n] = result return result ä½è¿ç®—ä¼˜åŒ– ä½è¿ç®—é€šå¸¸æ¯”ç®—æœ¯è¿ç®—æ›´å¿«ï¼Œå¯ä»¥ç”¨äºæŸäº›ç‰¹å®šåœºæ™¯çš„ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨ä½è¿ç®—åˆ¤æ–­å¥‡å¶ def is_even(n): return (n \u0026amp; 1) == 0 # æ¯”n % 2 == 0æ›´å¿« # ä½¿ç”¨ä½è¿ç®—äº¤æ¢å˜é‡ def swap(a, b): a = a ^ b b = a ^ b a = a ^ b return a, b å¹¶è¡Œè®¡ç®— å¯¹äºå¯ä»¥å¹¶è¡Œå¤„ç†çš„é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å¤šçº¿ç¨‹æˆ–å¤šè¿›ç¨‹åŠ é€Ÿã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† import concurrent.futures def process_data(data): # å¤„ç†æ•°æ®çš„å‡½æ•°ï¼Œè¿”å›å¤„ç†ç»“æœ result = ... # æ ¹æ®å®é™…éœ€æ±‚å¤„ç† return result def parallel_process(data_list, num_workers=4): with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor: results = list(executor.map(process_data, data_list)) return results ç©ºé—´ä¼˜åŒ–ç­–ç•¥ åŸåœ°ç®—æ³• åŸåœ°ç®—æ³•ä¸éœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´æˆ–åªéœ€è¦å¸¸æ•°çº§åˆ«çš„é¢å¤–ç©ºé—´ã€‚\n1 2 3 4 5 6 7 8 # åŸåœ°åè½¬æ•°ç»„ def reverse_array(arr): left, right = 0, len(arr) - 1 while left \u0026lt; right: arr[left], arr[right] = arr[right], arr[left] left += 1 right -= 1 return arr æ•°æ®å‹ç¼© å¯¹äºå¤§è§„æ¨¡æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å‹ç¼©æŠ€æœ¯å‡å°‘å­˜å‚¨éœ€æ±‚ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨ç¨€ç–çŸ©é˜µè¡¨ç¤ºä¼˜åŒ–å­˜å‚¨ class SparseMatrix: def __init__(self, rows, cols): self.rows = rows self.cols = cols self.data = {} # åªå­˜å‚¨éé›¶å…ƒç´  def set(self, i, j, value): if value != 0: self.data[(i, j)] = value elif (i, j) in self.data: del self.data[(i, j)] def get(self, i, j): return self.data.get((i, j), 0) æƒ°æ€§è®¡ç®— æƒ°æ€§è®¡ç®—åªåœ¨éœ€è¦æ—¶æ‰è®¡ç®—ç»“æœï¼Œå¯ä»¥èŠ‚çœä¸å¿…è¦çš„è®¡ç®—å’Œå­˜å‚¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æƒ°æ€§è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ— def lazy_fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b # ä½¿ç”¨ç”Ÿæˆå™¨ fib = lazy_fibonacci() for _ in range(10): print(next(fib)) æ—¶ç©ºæƒè¡¡ æœ‰æ—¶å¯ä»¥é€šè¿‡å¢åŠ ç©ºé—´ä½¿ç”¨æ¥å‡å°‘æ—¶é—´å¤æ‚åº¦ï¼Œæˆ–è€…é€šè¿‡å¢åŠ æ—¶é—´å¤æ‚åº¦æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\nç©ºé—´æ¢æ—¶é—´ ä½¿ç”¨é¢å¤–çš„ç©ºé—´æ¥å­˜å‚¨ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–æœ€é•¿å…¬å…±å­åºåˆ— def longest_common_subsequence(text1, text2): m, n = len(text1), len(text2) # åˆ›å»ºäºŒç»´æ•°ç»„å­˜å‚¨ä¸­é—´ç»“æœ dp = [[0] * (n + 1) for _ in range(m + 1)] for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: dp[i][j] = dp[i - 1][j - 1] + 1 else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[m][n] æ—¶é—´æ¢ç©ºé—´ é€šè¿‡å¢åŠ è®¡ç®—æ—¶é—´æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ def fibonacci_with_rolling_array(n): if n \u0026lt;= 1: return n # åªä¿å­˜æœ€è¿‘çš„ä¸¤ä¸ªå€¼ a, b = 0, 1 for _ in range(2, n + 1): a, b = b, a + b return b å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ æ’åºç®—æ³•ä¼˜åŒ– å¿«é€Ÿæ’åºä¼˜åŒ– å¿«é€Ÿæ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)ï¼Œä½†åœ¨æœ€åæƒ…å†µä¸‹ä¼šé€€åŒ–åˆ°O(nÂ²)ã€‚ä»¥ä¸‹æ˜¯å‡ ç§ä¼˜åŒ–æ–¹æ³•ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def optimized_quick_sort(arr): # ä½¿ç”¨ä¸‰æ•°å–ä¸­æ³•é€‰æ‹©åŸºå‡†ï¼Œé¿å…æœ€åæƒ…å†µ def median_of_three(left, right): mid = (left + right) // 2 if arr[left] \u0026gt; arr[mid]: arr[left], arr[mid] = arr[mid], arr[left] if arr[left] \u0026gt; arr[right]: arr[left], arr[right] = arr[right], arr[left] if arr[mid] \u0026gt; arr[right]: arr[mid], arr[right] = arr[right], arr[mid] return mid def partition(left, right): # é€‰æ‹©åŸºå‡† pivot_idx = median_of_three(left, right) pivot = arr[pivot_idx] # å°†åŸºå‡†ç§»åˆ°æœ€å³è¾¹ arr[pivot_idx], arr[right] = arr[right], arr[pivot_idx] i = left for j in range(left, right): if arr[j] \u0026lt;= pivot: arr[i], arr[j] = arr[j], arr[i] i += 1 # å°†åŸºå‡†ç§»åˆ°æ­£ç¡®ä½ç½® arr[i], arr[right] = arr[right], arr[i] return i def sort(left, right): # å°æ•°ç»„ä½¿ç”¨æ’å…¥æ’åº if right - left + 1 \u0026lt;= 20: insertion_sort(arr, left, right) return if left \u0026lt; right: pivot_idx = partition(left, right) sort(left, pivot_idx - 1) sort(pivot_idx + 1, right) def insertion_sort(arr, left, right): for i in range(left + 1, right + 1): key = arr[i] j = i - 1 while j \u0026gt;= left and arr[j] \u0026gt; key: arr[j + 1] = arr[j] j -= 1 arr[j + 1] = key sort(0, len(arr) - 1) return arr è®¡æ•°æ’åºä¼˜åŒ– è®¡æ•°æ’åºæ˜¯ä¸€ç§éæ¯”è¾ƒæ’åºç®—æ³•ï¼Œé€‚ç”¨äºæ•´æ•°ä¸”èŒƒå›´ä¸å¤§çš„æƒ…å†µã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def counting_sort(arr, max_val=None): if not arr: return arr if max_val is None: max_val = max(arr) # åˆ›å»ºè®¡æ•°æ•°ç»„ count = [0] * (max_val + 1) # ç»Ÿè®¡æ¯ä¸ªå…ƒç´ çš„å‡ºç°æ¬¡æ•° for num in arr: count[num] += 1 # è®¡ç®—ç´¯ç§¯è®¡æ•° for i in range(1, len(count)): count[i] += count[i - 1] # æ„å»ºæ’åºç»“æœ result = [0] * len(arr) for num in reversed(arr): result[count[num] - 1] = num count[num] -= 1 return result æœç´¢ç®—æ³•ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ç§é«˜æ•ˆçš„æœç´¢ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(log n)ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def binary_search_optimized(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: # é˜²æ­¢æ•´æ•°æº¢å‡º mid = left + (right - left) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 è·³è¡¨æœç´¢ä¼˜åŒ– è·³è¡¨æ˜¯ä¸€ç§æ¦‚ç‡æ•°æ®ç»“æ„ï¼Œå…è®¸å¿«é€Ÿæœç´¢ï¼Œç±»ä¼¼äºå¹³è¡¡æ ‘ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import random class SkipNode: def __init__(self, val=None, level=0): self.val = val self.next = [None] * level class SkipList: def __init__(self, max_level=16, p=0.5): self.max_level = max_level self.p = p self.level = 1 self.head = SkipNode(None, max_level) def random_level(self): level = 1 while random.random() \u0026lt; self.p and level \u0026lt; self.max_level: level += 1 return level def insert(self, val): update = [None] * self.max_level current = self.head # æ‰¾åˆ°æ’å…¥ä½ç½® for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] update[i] = current # åˆ›å»ºæ–°èŠ‚ç‚¹ node_level = self.random_level() if node_level \u0026gt; self.level: for i in range(self.level, node_level): update[i] = self.head self.level = node_level # æ’å…¥æ–°èŠ‚ç‚¹ new_node = SkipNode(val, node_level) for i in range(node_level): new_node.next[i] = update[i].next[i] update[i].next[i] = new_node def search(self, val): current = self.head for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] current = current.next[0] if current and current.val == val: return True return False å›¾ç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ç”¨äºå¯»æ‰¾å•æºæœ€çŸ­è·¯å¾„ï¼Œå¯ä»¥ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import heapq def dijkstra_optimized(graph, start): n = len(graph) dist = [float(\u0026#39;inf\u0026#39;)] * n dist[start] = 0 # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ— pq = [(0, start)] while pq: current_dist, u = heapq.heappop(pq) # å¦‚æœå·²ç»æ‰¾åˆ°æ›´çŸ­è·¯å¾„ï¼Œè·³è¿‡ if current_dist \u0026gt; dist[u]: continue for v, weight in graph[u]: distance = current_dist + weight if distance \u0026lt; dist[v]: dist[v] = distance heapq.heappush(pq, (distance, v)) return dist A*ç®—æ³•ä¼˜åŒ– A*ç®—æ³•æ˜¯ä¸€ç§å¯å‘å¼æœç´¢ç®—æ³•ï¼Œå¸¸ç”¨äºè·¯å¾„è§„åˆ’ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import heapq def a_star_search(graph, start, goal, heuristic): # ä¼˜å…ˆé˜Ÿåˆ—ï¼š(f_score, node) open_set = [(0, start)] # ä»èµ·ç‚¹åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„å®é™…ä»£ä»· g_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} g_score[start] = 0 # ä»èµ·ç‚¹ç»è¿‡æ¯ä¸ªèŠ‚ç‚¹åˆ°ç»ˆç‚¹çš„ä¼°è®¡ä»£ä»· f_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} f_score[start] = heuristic(start, goal) # è®°å½•è·¯å¾„ came_from = {} while open_set: current_f, current = heapq.heappop(open_set) if current == goal: # é‡å»ºè·¯å¾„ path = [current] while current in came_from: current = came_from[current] path.append(current) return path[::-1] for neighbor in graph[current]: # è®¡ç®—ä»èµ·ç‚¹åˆ°é‚»å±…çš„ä¸´æ—¶g_score tentative_g_score = g_score[current] + graph[current][neighbor] if tentative_g_score \u0026lt; g_score[neighbor]: # æ‰¾åˆ°æ›´å¥½çš„è·¯å¾„ came_from[neighbor] = current g_score[neighbor] = tentative_g_score f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, goal) heapq.heappush(open_set, (f_score[neighbor], neighbor)) return None # æ²¡æœ‰æ‰¾åˆ°è·¯å¾„ åŠ¨æ€è§„åˆ’ä¼˜åŒ– çŠ¶æ€å‹ç¼© å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ä½è¿ç®—è¿›è¡ŒçŠ¶æ€å‹ç¼©ï¼Œå‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # æ—…è¡Œå•†é—®é¢˜(TSP)çš„çŠ¶æ€å‹ç¼©ä¼˜åŒ– def tsp_dp(distances): n = len(distances) # dp[mask][i]è¡¨ç¤ºè®¿é—®è¿‡maskä¸­çš„åŸå¸‚ï¼Œæœ€ååœç•™åœ¨åŸå¸‚içš„æœ€çŸ­è·ç¦» dp = [[float(\u0026#39;inf\u0026#39;)] * n for _ in range(1 \u0026lt;\u0026lt; n)] dp[1][0] = 0 # ä»åŸå¸‚0å¼€å§‹ for mask in range(1 \u0026lt;\u0026lt; n): for i in range(n): if mask \u0026amp; (1 \u0026lt;\u0026lt; i): # å¦‚æœåŸå¸‚iåœ¨maskä¸­ for j in range(n): if not mask \u0026amp; (1 \u0026lt;\u0026lt; j): # å¦‚æœåŸå¸‚jä¸åœ¨maskä¸­ new_mask = mask | (1 \u0026lt;\u0026lt; j) dp[new_mask][j] = min(dp[new_mask][j], dp[mask][i] + distances[i][j]) # è®¡ç®—å›åˆ°èµ·ç‚¹çš„æœ€çŸ­è·ç¦» final_mask = (1 \u0026lt;\u0026lt; n) - 1 min_distance = float(\u0026#39;inf\u0026#39;) for i in range(1, n): min_distance = min(min_distance, dp[final_mask][i] + distances[i][0]) return min_distance æ»šåŠ¨æ•°ç»„ä¼˜åŒ– å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # æœ€é•¿å…¬å…±å­åºåˆ—çš„æ»šåŠ¨æ•°ç»„ä¼˜åŒ– def lcs_rolling_array(text1, text2): m, n = len(text1), len(text2) # ä½¿ç”¨ä¸¤è¡Œæ•°ç»„ä»£æ›¿å®Œæ•´çš„äºŒç»´æ•°ç»„ prev = [0] * (n + 1) curr = [0] * (n + 1) for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: curr[j] = prev[j - 1] + 1 else: curr[j] = max(prev[j], curr[j - 1]) # æ»šåŠ¨æ•°ç»„ prev, curr = curr, prev curr = [0] * (n + 1) return prev[n] å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æ å›¾åƒå¤„ç†ä¸­çš„ä¼˜åŒ– å·ç§¯è¿ç®—ä¼˜åŒ– å·ç§¯è¿ç®—æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import numpy as np def naive_convolution(image, kernel): # åŸå§‹å·ç§¯å®ç° height, width = image.shape k_height, k_width = kernel.shape output = np.zeros((height - k_height + 1, width - k_width + 1)) for i in range(output.shape[0]): for j in range(output.shape[1]): output[i, j] = np.sum(image[i:i+k_height, j:j+k_width] * kernel) return output def optimized_convolution(image, kernel): # ä½¿ç”¨FFTåŠ é€Ÿå·ç§¯ from scipy.signal import fftconvolve return fftconvolve(image, kernel, mode=\u0026#39;valid\u0026#39;) def separable_convolution(image, kernel): # å¯åˆ†ç¦»å·ç§¯ä¼˜åŒ– # å¦‚æœkernelå¯ä»¥åˆ†ç¦»ä¸ºæ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªä¸€ç»´æ ¸ # ä¾‹å¦‚ï¼škernel = h_kernel * v_kernel^T # å‡è®¾kernelæ˜¯å¯åˆ†ç¦»çš„ u, s, vh = np.linalg.svd(kernel) h_kernel = u[:, 0] * np.sqrt(s[0]) v_kernel = vh[0, :] * np.sqrt(s[0]) # å…ˆè¿›è¡Œæ°´å¹³å·ç§¯ temp = np.zeros_like(image) for i in range(image.shape[0]): temp[i, :] = np.convolve(image[i, :], h_kernel, mode=\u0026#39;valid\u0026#39;) # å†è¿›è¡Œå‚ç›´å·ç§¯ output = np.zeros((temp.shape[0] - len(v_kernel) + 1, temp.shape[1])) for j in range(temp.shape[1]): output[:, j] = np.convolve(temp[:, j], v_kernel, mode=\u0026#39;valid\u0026#39;) return output å›¾åƒé‡‘å­—å¡”ä¼˜åŒ– å›¾åƒé‡‘å­—å¡”æ˜¯ä¸€ç§å¤šå°ºåº¦è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥ç”¨äºåŠ é€Ÿå›¾åƒå¤„ç†ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def build_gaussian_pyramid(image, levels): pyramid = [image] for _ in range(levels - 1): # ä¸‹é‡‡æ · image = cv2.pyrDown(image) pyramid.append(image) return pyramid def process_with_pyramid(image, process_func, levels=4): # æ„å»ºé‡‘å­—å¡” pyramid = build_gaussian_pyramid(image, levels) # ä»æœ€ç²—çº§åˆ«å¼€å§‹å¤„ç† result = process_func(pyramid[-1]) # é€çº§ä¸Šé‡‡æ ·å¹¶ç»†åŒ– for i in range(levels - 2, -1, -1): # ä¸Šé‡‡æ ·ç»“æœ result = cv2.pyrUp(result) # è°ƒæ•´å¤§å°ä»¥åŒ¹é…å½“å‰çº§åˆ« result = cv2.resize(result, (pyramid[i].shape[1], pyramid[i].shape[0])) # ä¸å½“å‰çº§åˆ«ç»“åˆ result = process_func(pyramid[i], result) return result æœºå™¨å­¦ä¹ ä¸­çš„ä¼˜åŒ– æ¢¯åº¦ä¸‹é™ä¼˜åŒ– æ¢¯åº¦ä¸‹é™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ï¼Œæœ‰å¤šç§å˜ä½“ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import numpy as np def gradient_descent(X, y, learning_rate=0.01, epochs=1000): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def stochastic_gradient_descent(X, y, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): for i in range(m): # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ xi = X[i:i+1] yi = y[i:i+1] # è®¡ç®—é¢„æµ‹å€¼ prediction = xi.dot(theta) # è®¡ç®—è¯¯å·® error = prediction - yi # è®¡ç®—æ¢¯åº¦ gradient = xi.T.dot(error) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def mini_batch_gradient_descent(X, y, batch_size=32, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # éšæœºæ‰“ä¹±æ•°æ® indices = np.random.permutation(m) X_shuffled = X[indices] y_shuffled = y[indices] # åˆ†æ‰¹å¤„ç† for i in range(0, m, batch_size): X_batch = X_shuffled[i:i+batch_size] y_batch = y_shuffled[i:i+batch_size] # è®¡ç®—é¢„æµ‹å€¼ predictions = X_batch.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y_batch # è®¡ç®—æ¢¯åº¦ gradient = X_batch.T.dot(error) / len(X_batch) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def momentum_gradient_descent(X, y, learning_rate=0.01, momentum=0.9, epochs=1000): m, n = X.shape theta = np.zeros(n) velocity = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°é€Ÿåº¦ velocity = momentum * velocity - learning_rate * gradient # æ›´æ–°å‚æ•° theta += velocity return theta çŸ©é˜µè¿ç®—ä¼˜åŒ– åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼ŒçŸ©é˜µè¿ç®—æ˜¯æ ¸å¿ƒæ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import numpy as np def naive_matrix_multiply(A, B): # åŸå§‹çŸ©é˜µä¹˜æ³•å®ç° m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(m): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] return C def blocked_matrix_multiply(A, B, block_size=32): # åˆ†å—çŸ©é˜µä¹˜æ³•ä¼˜åŒ– m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(0, m, block_size): for j in range(0, p, block_size): for k in range(0, n, block_size): # å¤„ç†å½“å‰å— for ii in range(i, min(i + block_size, m)): for jj in range(j, min(j + block_size, p)): for kk in range(k, min(k + block_size, n)): C[ii, jj] += A[ii, kk] * B[kk, jj] return C def vectorized_matrix_multiply(A, B): # å‘é‡åŒ–çŸ©é˜µä¹˜æ³•ï¼ˆä½¿ç”¨NumPyå†…ç½®å‡½æ•°ï¼‰ return np.dot(A, B) def parallel_matrix_multiply(A, B): # å¹¶è¡ŒçŸ©é˜µä¹˜æ³• from concurrent.futures import ThreadPoolExecutor m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) def compute_row(i): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] with ThreadPoolExecutor() as executor: executor.map(compute_row, range(m)) return C æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ– ç´¢å¼•ä¼˜åŒ– ç´¢å¼•æ˜¯æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–çš„å…³é”®ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æŸ¥è¯¢é€Ÿåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # ç®€å•çš„Bæ ‘ç´¢å¼•å®ç° class BTreeNode: def __init__(self, leaf=False): self.keys = [] self.children = [] self.leaf = leaf class BTree: def __init__(self, t): self.root = BTreeNode(leaf=True) self.t = t # æœ€å°åº¦æ•° def search(self, key, node=None): if node is None: node = self.root i = 0 while i \u0026lt; len(node.keys) and key \u0026gt; node.keys[i]: i += 1 if i \u0026lt; len(node.keys) and key == node.keys[i]: return True # æ‰¾åˆ°é”® if node.leaf: return False # æœªæ‰¾åˆ°é”® return self.search(key, node.children[i]) def insert(self, key): root = self.root if len(root.keys) == (2 * self.t) - 1: # æ ¹èŠ‚ç‚¹å·²æ»¡ï¼Œåˆ›å»ºæ–°æ ¹èŠ‚ç‚¹ new_root = BTreeNode() new_root.children.append(self.root) self.root = new_root self._split_child(new_root, 0) self._insert_nonfull(new_root, key) else: self._insert_nonfull(root, key) def _split_child(self, parent, index): t = self.t y = parent.children[index] z = BTreeNode(leaf=y.leaf) # å°†yçš„ä¸­é—´é”®æå‡åˆ°çˆ¶èŠ‚ç‚¹ parent.keys.insert(index, y.keys[t-1]) # å°†yçš„ååŠéƒ¨åˆ†é”®å¤åˆ¶åˆ°z z.keys = y.keys[t:(2*t-1)] # å¦‚æœyä¸æ˜¯å¶å­èŠ‚ç‚¹ï¼Œå¤åˆ¶å­èŠ‚ç‚¹ if not y.leaf: z.children = y.children[t:(2*t)] # æ›´æ–°yçš„é”®å’Œå­èŠ‚ç‚¹ y.keys = y.keys[0:(t-1)] y.children = y.children[0:t] # å°†zæ’å…¥çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹åˆ—è¡¨ parent.children.insert(index + 1, z) def _insert_nonfull(self, node, key): i = len(node.keys) - 1 if node.leaf: # åœ¨å¶å­èŠ‚ç‚¹ä¸­æ’å…¥é”® node.keys.append(0) while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: node.keys[i+1] = node.keys[i] i -= 1 node.keys[i+1] = key else: # æ‰¾åˆ°åˆé€‚çš„å­èŠ‚ç‚¹ while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: i -= 1 i += 1 # å¦‚æœå­èŠ‚ç‚¹å·²æ»¡ï¼Œå…ˆåˆ†è£‚ if len(node.children[i].keys) == (2 * self.t) - 1: self._split_child(node, i) if key \u0026gt; node.keys[i]: i += 1 self._insert_nonfull(node.children[i], key) æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ– æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–æ˜¯æ•°æ®åº“ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¯ä»¥é€šè¿‡å¤šç§ç­–ç•¥ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class QueryOptimizer: def __init__(self, database): self.database = database def optimize_query(self, query): # è§£ææŸ¥è¯¢ parsed_query = self._parse_query(query) # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = self._generate_execution_plans(parsed_query) # è¯„ä¼°æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬ plan_costs = [self._estimate_cost(plan) for plan in plans] # é€‰æ‹©æˆæœ¬æœ€ä½çš„è®¡åˆ’ best_plan = plans[plan_costs.index(min(plan_costs))] return best_plan def _parse_query(self, query): # ç®€åŒ–çš„æŸ¥è¯¢è§£æ # å®é™…å®ç°ä¼šæ›´å¤æ‚ return { \u0026#39;tables\u0026#39;: query.get(\u0026#39;tables\u0026#39;, []), \u0026#39;conditions\u0026#39;: query.get(\u0026#39;conditions\u0026#39;, []), \u0026#39;projections\u0026#39;: query.get(\u0026#39;projections\u0026#39;, []), \u0026#39;order_by\u0026#39;: query.get(\u0026#39;order_by\u0026#39;, []), \u0026#39;limit\u0026#39;: query.get(\u0026#39;limit\u0026#39;, None) } def _generate_execution_plans(self, parsed_query): # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = [] # ç®€å•å®ç°ï¼šåªè€ƒè™‘è¡¨è¿æ¥é¡ºåº tables = parsed_query[\u0026#39;tables\u0026#39;] # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è¡¨è¿æ¥é¡ºåº from itertools import permutations for table_order in permutations(tables): plan = { \u0026#39;table_order\u0026#39;: table_order, \u0026#39;join_method\u0026#39;: \u0026#39;nested_loop\u0026#39;, # å¯ä»¥æ˜¯nested_loop, hash_join, merge_join \u0026#39;access_method\u0026#39;: {table: \u0026#39;index_scan\u0026#39; for table in tables}, # å¯ä»¥æ˜¯full_scan, index_scan \u0026#39;conditions\u0026#39;: parsed_query[\u0026#39;conditions\u0026#39;], \u0026#39;projections\u0026#39;: parsed_query[\u0026#39;projections\u0026#39;], \u0026#39;order_by\u0026#39;: parsed_query[\u0026#39;order_by\u0026#39;], \u0026#39;limit\u0026#39;: parsed_query[\u0026#39;limit\u0026#39;] } plans.append(plan) return plans def _estimate_cost(self, plan): # ä¼°è®¡æ‰§è¡Œè®¡åˆ’çš„æˆæœ¬ cost = 0 # ä¼°è®¡è¡¨è®¿é—®æˆæœ¬ for table in plan[\u0026#39;table_order\u0026#39;]: access_method = plan[\u0026#39;access_method\u0026#39;][table] table_stats = self.database.get_table_stats(table) if access_method == \u0026#39;full_scan\u0026#39;: cost += table_stats[\u0026#39;row_count\u0026#39;] elif access_method == \u0026#39;index_scan\u0026#39;: # å‡è®¾ç´¢å¼•å¯ä»¥è¿‡æ»¤æ‰90%çš„æ•°æ® cost += table_stats[\u0026#39;row_count\u0026#39;] * 0.1 # ä¼°è®¡è¿æ¥æˆæœ¬ for i in range(len(plan[\u0026#39;table_order\u0026#39;]) - 1): join_method = plan[\u0026#39;join_method\u0026#39;] if join_method == \u0026#39;nested_loop\u0026#39;: # åµŒå¥—å¾ªç¯è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] * right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;hash_join\u0026#39;: # å“ˆå¸Œè¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;merge_join\u0026#39;: # åˆå¹¶è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] # ä¼°è®¡æ’åºæˆæœ¬ if plan[\u0026#39;order_by\u0026#39;]: # å‡è®¾æ’åºæˆæœ¬ä¸ºn log n result_size = cost # ç®€åŒ–å‡è®¾ cost += result_size * np.log2(result_size) return cost æ€§èƒ½åˆ†æå·¥å…· æ—¶é—´åˆ†æå·¥å…· Pythonä¸­çš„æ—¶é—´åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import time import timeit import cProfile import pstats def time_function(func, *args, **kwargs): # ç®€å•çš„æ—¶é—´æµ‹é‡ start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f\u0026#34;å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: {end_time - start_time:.6f} ç§’\u0026#34;) return result def benchmark_function(func, *args, **kwargs): # ä½¿ç”¨timeitè¿›è¡Œæ›´ç²¾ç¡®çš„åŸºå‡†æµ‹è¯• import functools wrapped = functools.partial(func, *args, **kwargs) time_taken = timeit.timeit(wrapped, number=1000) print(f\u0026#34;å‡½æ•° {func.__name__} å¹³å‡æ‰§è¡Œæ—¶é—´: {time_taken/1000:.6f} ç§’\u0026#34;) return func(*args, **kwargs) def profile_function(func, *args, **kwargs): # ä½¿ç”¨cProfileè¿›è¡Œè¯¦ç»†æ€§èƒ½åˆ†æ profiler = cProfile.Profile() profiler.enable() result = func(*args, **kwargs) profiler.disable() stats = pstats.Stats(profiler).sort_stats(\u0026#39;cumulative\u0026#39;) stats.print_stats() return result å†…å­˜åˆ†æå·¥å…· Pythonä¸­çš„å†…å­˜åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import sys import tracemalloc import objgraph def get_object_size(obj): # è·å–å¯¹è±¡çš„å†…å­˜å¤§å° return sys.getsizeof(obj) def trace_memory(func, *args, **kwargs): # è·Ÿè¸ªå†…å­˜ä½¿ç”¨æƒ…å†µ tracemalloc.start() result = func(*args, **kwargs) snapshot = tracemalloc.take_snapshot() top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) print(\u0026#34;[ å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œ ]\u0026#34;) for stat in top_stats[:10]: print(stat) tracemalloc.stop() return result def analyze_object_growth(func, *args, **kwargs): # åˆ†æå¯¹è±¡å¢é•¿æƒ…å†µ objgraph.show_growth() result = func(*args, **kwargs) objgraph.show_growth() return result å¯è§†åŒ–åˆ†æå·¥å…· ä½¿ç”¨matplotlibå¯è§†åŒ–æ€§èƒ½æ•°æ® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import matplotlib.pyplot as plt import numpy as np def plot_time_complexity(algorithms, input_sizes, title=\u0026#34;æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒ\u0026#34;): # ç»˜åˆ¶ç®—æ³•æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒå›¾ plt.figure(figsize=(10, 6)) for name, func in algorithms.items(): times = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡æ‰§è¡Œæ—¶é—´ start_time = time.time() func(test_data) end_time = time.time() times.append(end_time - start_time) plt.plot(input_sizes, times, label=name, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;æ‰§è¡Œæ—¶é—´ (ç§’)\u0026#39;) plt.title(title) plt.legend() plt.grid(True) plt.show() def generate_test_data(size): # ç”Ÿæˆæµ‹è¯•æ•°æ® return np.random.rand(size) def plot_memory_usage(func, input_sizes, title=\u0026#34;å†…å­˜ä½¿ç”¨æƒ…å†µ\u0026#34;): # ç»˜åˆ¶å‡½æ•°å†…å­˜ä½¿ç”¨æƒ…å†µå›¾ memory_usage = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡å†…å­˜ä½¿ç”¨ tracemalloc.start() func(test_data) snapshot = tracemalloc.take_snapshot() current, peak = tracemalloc.get_traced_memory() tracemalloc.stop() memory_usage.append(peak / (1024 * 1024)) # è½¬æ¢ä¸ºMB plt.figure(figsize=(10, 6)) plt.plot(input_sizes, memory_usage, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;å†…å­˜ä½¿ç”¨ (MB)\u0026#39;) plt.title(title) plt.grid(True) plt.show() æ€»ç»“ ç®—æ³•ä¼˜åŒ–æ˜¯æå‡è½¯ä»¶æ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚æœ¬æ–‡ä»ç®—æ³•å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä»‹ç»äº†æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦çš„æ¦‚å¿µåŠåˆ†ææ–¹æ³•ï¼Œç„¶åè¯¦ç»†æ¢è®¨äº†å„ç§ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬æ—¶é—´ä¼˜åŒ–ã€ç©ºé—´ä¼˜åŒ–å’Œæ—¶ç©ºæƒè¡¡ã€‚\né€šè¿‡å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ï¼Œå¦‚æ’åºç®—æ³•ã€æœç´¢ç®—æ³•ã€å›¾ç®—æ³•å’ŒåŠ¨æ€è§„åˆ’çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬äº†è§£äº†å¦‚ä½•å°†ç†è®ºåº”ç”¨åˆ°å®è·µä¸­ã€‚å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æå±•ç¤ºäº†ç®—æ³•ä¼˜åŒ–åœ¨å›¾åƒå¤„ç†ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®åº“æŸ¥è¯¢ç­‰é¢†åŸŸçš„å…·ä½“åº”ç”¨ã€‚\næœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†å„ç§æ€§èƒ½åˆ†æå·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\nç®—æ³•ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­å­¦ä¹ å’Œå®è·µçš„è¿‡ç¨‹ã€‚éšç€æŠ€æœ¯çš„å‘å±•ï¼Œæ–°çš„ä¼˜åŒ–æ–¹æ³•å’Œå·¥å…·ä¸æ–­æ¶Œç°ã€‚æŒæ¡è¿™äº›ä¼˜åŒ–æŠ€å·§ï¼Œä¸ä»…èƒ½å¤Ÿæé«˜ä»£ç æ€§èƒ½ï¼Œè¿˜èƒ½åŸ¹å…»ç³»ç»Ÿæ€ç»´å’Œé—®é¢˜è§£å†³èƒ½åŠ›ï¼Œä¸ºæˆä¸ºä¸€åä¼˜ç§€çš„è½¯ä»¶å·¥ç¨‹å¸ˆå¥ å®šåŸºç¡€ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…æ·±å…¥ç†è§£ç®—æ³•ä¼˜åŒ–çš„åŸç†å’Œæ–¹æ³•ï¼Œå¹¶åœ¨å®é™…å¼€å‘ä¸­çµæ´»åº”ç”¨ï¼Œåˆ›é€ å‡ºæ›´é«˜æ•ˆã€æ›´ä¼˜é›…çš„ä»£ç ã€‚\n","permalink":"http://localhost:1313/posts/algorithm-optimization/","summary":"\u003ch1 id=\"ç®—æ³•ä¼˜åŒ–ä»ç†è®ºåˆ°å®è·µ\"\u003eç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ\u003c/h1\u003e\n\u003cp\u003eåœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\u003c/p\u003e","title":"ç®—æ³•ä¼˜åŒ–ï¼šæå‡ä»£ç æ€§èƒ½çš„å®ç”¨æŠ€å·§"},{"content":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\nå›¾åƒçš„åŸºæœ¬è¡¨ç¤º åƒç´ ä¸å›¾åƒçŸ©é˜µ åœ¨æ•°å­—ä¸–ç•Œä¸­ï¼Œå›¾åƒç”±åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚å¯¹äºç°åº¦å›¾åƒï¼Œæ¯ä¸ªåƒç´ çš„å€¼è¡¨ç¤ºäº®åº¦ï¼Œé€šå¸¸èŒƒå›´æ˜¯0ï¼ˆé»‘è‰²ï¼‰åˆ°255ï¼ˆç™½è‰²ï¼‰ã€‚å¯¹äºå½©è‰²å›¾åƒï¼Œé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“è¡¨ç¤ºï¼Œæ¯ä¸ªé€šé“çš„å€¼èŒƒå›´ä¹Ÿæ˜¯0åˆ°255ã€‚\nåœ¨è®¡ç®—æœºä¸­ï¼Œå›¾åƒé€šå¸¸è¡¨ç¤ºä¸ºçŸ©é˜µã€‚ç°åº¦å›¾åƒæ˜¯äºŒç»´çŸ©é˜µï¼Œè€Œå½©è‰²å›¾åƒæ˜¯ä¸‰ç»´çŸ©é˜µï¼ˆé«˜åº¦Ã—å®½åº¦Ã—é€šé“æ•°ï¼‰ã€‚\n1 2 3 4 5 6 7 8 # Pythonä¸­ä½¿ç”¨NumPyè¡¨ç¤ºå›¾åƒ import numpy as np # åˆ›å»ºä¸€ä¸ª100x100çš„ç°åº¦å›¾åƒï¼ˆå…¨é»‘ï¼‰ gray_image = np.zeros((100, 100), dtype=np.uint8) # åˆ›å»ºä¸€ä¸ª100x100x3çš„å½©è‰²å›¾åƒï¼ˆå…¨é»‘ï¼‰ color_image = np.zeros((100, 100, 3), dtype=np.uint8) å›¾åƒç±»å‹ äºŒå€¼å›¾åƒï¼šæ¯ä¸ªåƒç´ åªæœ‰ä¸¤ä¸ªå¯èƒ½çš„å€¼ï¼ˆé€šå¸¸æ˜¯0å’Œ1ï¼‰ï¼Œè¡¨ç¤ºé»‘ç™½ä¸¤è‰²ã€‚ ç°åº¦å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰ä¸€ä¸ªå€¼ï¼Œè¡¨ç¤ºä»é»‘åˆ°ç™½çš„ç°åº¦çº§åˆ«ã€‚ å½©è‰²å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰å¤šä¸ªå€¼ï¼Œé€šå¸¸ä½¿ç”¨RGBã€HSVæˆ–CMYKç­‰é¢œè‰²æ¨¡å‹è¡¨ç¤ºã€‚ å¤šå…‰è°±å›¾åƒï¼šåŒ…å«å¤šä¸ªå…‰è°±é€šé“çš„å›¾åƒï¼Œå¦‚å«æ˜Ÿå›¾åƒã€‚ 3Då›¾åƒï¼šè¡¨ç¤ºä¸‰ç»´ç©ºé—´æ•°æ®çš„å›¾åƒï¼Œå¦‚åŒ»å­¦CTæ‰«æã€‚ åŸºæœ¬å›¾åƒæ“ä½œ å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨Pythonçš„OpenCVåº“å¯ä»¥è½»æ¾è¯»å–å’Œæ˜¾ç¤ºå›¾åƒï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 import cv2 import matplotlib.pyplot as plt # è¯»å–å›¾åƒ image = cv2.imread(\u0026#39;image.jpg\u0026#39;) # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆOpenCVé»˜è®¤ä½¿ç”¨BGRï¼Œè€Œmatplotlibä½¿ç”¨RGBï¼‰ image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() å›¾åƒç¼©æ”¾ä¸æ—‹è½¬ 1 2 3 4 5 6 7 8 # ç¼©æ”¾å›¾åƒ resized_image = cv2.resize(image, (width, height)) # æ—‹è½¬å›¾åƒ (h, w) = image.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) # æ—‹è½¬45åº¦ï¼Œç¼©æ”¾å› å­ä¸º1.0 rotated_image = cv2.warpAffine(image, M, (w, h)) å›¾åƒè£å‰ªä¸æ‹¼æ¥ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image[100:400, 200:500] # æ‹¼æ¥å›¾åƒ (æ°´å¹³æ‹¼æ¥) horizontal_concat = np.hstack((image1, image2)) # å‚ç›´æ‹¼æ¥ vertical_concat = np.vstack((image1, image2)) å›¾åƒå¢å¼ºæŠ€æœ¯ äº®åº¦ä¸å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 # äº®åº¦è°ƒæ•´ (å¢åŠ 50ä¸ªå•ä½) brightness_image = cv2.add(image, np.ones(image.shape, dtype=np.uint8) * 50) # å¯¹æ¯”åº¦è°ƒæ•´ (1.5å€) contrast_image = cv2.multiply(image, 1.5) ç›´æ–¹å›¾å‡è¡¡åŒ– ç›´æ–¹å›¾å‡è¡¡åŒ–æ˜¯ä¸€ç§å¢å¼ºå›¾åƒå¯¹æ¯”åº¦çš„æ–¹æ³•ï¼Œé€šè¿‡é‡æ–°åˆ†å¸ƒå›¾åƒçš„åƒç´ å¼ºåº¦ï¼Œä½¿å…¶ç›´æ–¹å›¾å¹³å¦åŒ–ã€‚\n1 2 3 # ç°åº¦å›¾åƒç›´æ–¹å›¾å‡è¡¡åŒ– gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) equalized_image = cv2.equalizeHist(gray_image) ä¼½é©¬æ ¡æ­£ ä¼½é©¬æ ¡æ­£ç”¨äºè°ƒæ•´å›¾åƒçš„äº®åº¦ï¼Œç‰¹åˆ«é€‚ç”¨äºæ˜¾ç¤ºè®¾å¤‡çš„éçº¿æ€§å“åº”ã€‚\ngamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼\n1 2 3 4 5 6 7 8 9 # ä¼½é©¬æ ¡æ­£å‡½æ•° def gamma_correction(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) gamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼ å›¾åƒæ»¤æ³¢ å›¾åƒæ»¤æ³¢æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œç”¨äºå»å™ªã€è¾¹ç¼˜æ£€æµ‹å’Œç‰¹å¾æå–ç­‰ä»»åŠ¡ã€‚\nå‡å€¼æ»¤æ³¢ å‡å€¼æ»¤æ³¢æ˜¯æœ€ç®€å•çš„æ»¤æ³¢æ–¹æ³•ä¹‹ä¸€ï¼Œå®ƒç”¨é‚»åŸŸåƒç´ çš„å¹³å‡å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ã€‚\n1 2 # 5x5å‡å€¼æ»¤æ³¢ blurred_image = cv2.blur(image, (5, 5)) é«˜æ–¯æ»¤æ³¢ é«˜æ–¯æ»¤æ³¢ä½¿ç”¨é«˜æ–¯å‡½æ•°ä½œä¸ºæƒé‡ï¼Œå¯¹é‚»åŸŸåƒç´ è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å™ªå£°åŒæ—¶ä¿ç•™è¾¹ç¼˜ä¿¡æ¯ã€‚\n1 2 # 5x5é«˜æ–¯æ»¤æ³¢ gaussian_blurred = cv2.GaussianBlur(image, (5, 5), 0) ä¸­å€¼æ»¤æ³¢ ä¸­å€¼æ»¤æ³¢ç”¨é‚»åŸŸåƒç´ çš„ä¸­å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ï¼Œå¯¹äºå»é™¤æ¤’ç›å™ªå£°ç‰¹åˆ«æœ‰æ•ˆã€‚\n1 2 # 5x5ä¸­å€¼æ»¤æ³¢ median_blurred = cv2.medianBlur(image, 5) åŒè¾¹æ»¤æ³¢ åŒè¾¹æ»¤æ³¢åœ¨è€ƒè™‘ç©ºé—´é‚»è¿‘åº¦çš„åŒæ—¶ï¼Œä¹Ÿè€ƒè™‘åƒç´ å€¼çš„ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿåœ¨å¹³æ»‘å›¾åƒçš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ã€‚\n1 2 # åŒè¾¹æ»¤æ³¢ bilateral_filtered = cv2.bilateralFilter(image, 9, 75, 75) è¾¹ç¼˜æ£€æµ‹ è¾¹ç¼˜æ£€æµ‹æ˜¯å›¾åƒå¤„ç†ä¸­çš„é‡è¦ä»»åŠ¡ï¼Œç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“è¾¹ç•Œã€‚\nSobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Sobelè¾¹ç¼˜æ£€æµ‹ sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3) # æ°´å¹³æ–¹å‘ sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3) # å‚ç›´æ–¹å‘ # è®¡ç®—æ¢¯åº¦å¹…å€¼ gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2) # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´ gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255) Cannyè¾¹ç¼˜æ£€æµ‹ Cannyè¾¹ç¼˜æ£€æµ‹æ˜¯ä¸€ç§å¤šé˜¶æ®µçš„è¾¹ç¼˜æ£€æµ‹ç®—æ³•ï¼Œè¢«è®¤ä¸ºæ˜¯ç›®å‰æœ€ä¼˜çš„è¾¹ç¼˜æ£€æµ‹æ–¹æ³•ä¹‹ä¸€ã€‚\n1 2 # Cannyè¾¹ç¼˜æ£€æµ‹ edges = cv2.Canny(gray, 100, 200) # é˜ˆå€¼1å’Œé˜ˆå€¼2 Laplacianç®—å­ 1 2 3 # Laplacianè¾¹ç¼˜æ£€æµ‹ laplacian = cv2.Laplacian(gray, cv2.CV_64F) laplacian = np.uint8(np.absolute(laplacian)) å½¢æ€å­¦æ“ä½œ å½¢æ€å­¦æ“ä½œåŸºäºå›¾åƒçš„å½¢çŠ¶ï¼Œå¸¸ç”¨äºäºŒå€¼å›¾åƒçš„å¤„ç†ã€‚\nè…èš€ä¸è†¨èƒ€ 1 2 3 4 5 6 7 8 # åˆ›å»ºä¸€ä¸ª5x5çš„æ ¸ kernel = np.ones((5, 5), np.uint8) # è…èš€æ“ä½œ eroded_image = cv2.erode(binary_image, kernel, iterations=1) # è†¨èƒ€æ“ä½œ dilated_image = cv2.dilate(binary_image, kernel, iterations=1) å¼€è¿ç®—ä¸é—­è¿ç®— 1 2 3 4 5 # å¼€è¿ç®—ï¼ˆå…ˆè…èš€åè†¨èƒ€ï¼‰ opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel) # é—­è¿ç®—ï¼ˆå…ˆè†¨èƒ€åè…èš€ï¼‰ closing = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel) å½¢æ€å­¦æ¢¯åº¦ 1 2 # å½¢æ€å­¦æ¢¯åº¦ï¼ˆè†¨èƒ€å‡è…èš€ï¼‰ gradient = cv2.morphologyEx(binary_image, cv2.MORPH_GRADIENT, kernel) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²æ˜¯å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡çš„è¿‡ç¨‹ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦ä»»åŠ¡ã€‚\né˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 # å…¨å±€é˜ˆå€¼åˆ†å‰² _, thresholded = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_threshold = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) åˆ†æ°´å²­ç®—æ³• åˆ†æ°´å²­ç®—æ³•æ˜¯ä¸€ç§åŸºäºæ‹“æ‰‘ç†è®ºçš„å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºå¯¹æ¥è§¦ç‰©ä½“çš„åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 # æ ‡è®°èƒŒæ™¯å’Œå‰æ™¯ ret, markers = cv2.connectedComponents(sure_foreground) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(image, markers) image[markers == -1] = [255, 0, 0] # æ ‡è®°åˆ†æ°´å²­è¾¹ç•Œ K-meansèšç±» 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # å°†å›¾åƒé‡å¡‘ä¸º2Dæ•°ç»„ pixel_values = image.reshape((-1, 3)) pixel_values = np.float32(pixel_values) # å®šä¹‰åœæ­¢æ ‡å‡†å’ŒKå€¼ criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2) k = 3 # åº”ç”¨K-meansèšç±» _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) # è½¬æ¢å›åŸå§‹å›¾åƒå½¢çŠ¶å¹¶åº”ç”¨èšç±»ç»“æœ centers = np.uint8(centers) segmented_image = centers[labels.flatten()] segmented_image = segmented_image.reshape(image.shape) å›¾åƒç‰¹å¾æå– ç‰¹å¾æå–æ˜¯ä»å›¾åƒä¸­æå–æœ‰æ„ä¹‰ä¿¡æ¯çš„è¿‡ç¨‹ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥ç”¨äºå›¾åƒè¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢ç­‰ä»»åŠ¡ã€‚\nè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 # Harrisè§’ç‚¹æ£€æµ‹ gray = np.float32(gray) harris_corners = cv2.cornerHarris(gray, 2, 3, 0.04) harris_corners = cv2.dilate(harris_corners, None) # æ ‡è®°è§’ç‚¹ image[harris_corners \u0026gt; 0.01 * harris_corners.max()] = [0, 0, 255] SIFTç‰¹å¾ SIFTï¼ˆScale-Invariant Feature Transformï¼‰æ˜¯ä¸€ç§ç”¨äºæ£€æµ‹å’Œæè¿°å›¾åƒå±€éƒ¨ç‰¹å¾çš„ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray, keypoints, None) ORBç‰¹å¾ ORBæ˜¯ä¸€ç§å¿«é€Ÿçš„ç‰¹å¾æ£€æµ‹å™¨å’Œæè¿°ç¬¦ï¼Œç»“åˆäº†FASTå…³é”®ç‚¹æ£€æµ‹å™¨å’ŒBRIEFæè¿°ç¬¦ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray, keypoints, None) åº”ç”¨åœºæ™¯ å›¾åƒå¤„ç†æŠ€æœ¯å¹¿æ³›åº”ç”¨äºå„ä¸ªé¢†åŸŸï¼š\nåŒ»å­¦å½±åƒï¼šCTã€MRIå›¾åƒçš„åˆ†æå’Œè¯Šæ–­ï¼Œç»†èƒè®¡æ•°ï¼Œç—…å˜æ£€æµ‹ç­‰ã€‚ è‡ªåŠ¨é©¾é©¶ï¼šè½¦é“çº¿æ£€æµ‹ï¼Œéšœç¢ç‰©è¯†åˆ«ï¼Œäº¤é€šæ ‡å¿—è¯†åˆ«ç­‰ã€‚ å®‰é˜²ç›‘æ§ï¼šäººè„¸è¯†åˆ«ï¼Œè¡Œä¸ºåˆ†æï¼Œå¼‚å¸¸æ£€æµ‹ç­‰ã€‚ å·¥ä¸šæ£€æµ‹ï¼šäº§å“ç¼ºé™·æ£€æµ‹ï¼Œå°ºå¯¸æµ‹é‡ï¼Œè´¨é‡æ§åˆ¶ç­‰ã€‚ é¥æ„Ÿå›¾åƒï¼šåœŸåœ°åˆ©ç”¨åˆ†ç±»ï¼Œç¯å¢ƒç›‘æµ‹ï¼Œç¾å®³è¯„ä¼°ç­‰ã€‚ å¢å¼ºç°å®ï¼šå›¾åƒé…å‡†ï¼Œç›®æ ‡è·Ÿè¸ªï¼Œåœºæ™¯ç†è§£ç­‰ã€‚ æ•°å­—å¨±ä¹ï¼šå›¾åƒç¾åŒ–ï¼Œç‰¹æ•ˆå¤„ç†ï¼Œè™šæ‹Ÿç°å®ç­‰ã€‚ æ€»ç»“ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰çš„åŸºç¡€ï¼Œæ¶µç›–äº†ä»åŸºæœ¬çš„åƒç´ æ“ä½œåˆ°å¤æ‚çš„ç‰¹å¾æå–å’Œåˆ†æã€‚æœ¬æ–‡ä»‹ç»äº†å›¾åƒçš„åŸºæœ¬è¡¨ç¤ºã€åŸºæœ¬æ“ä½œã€å›¾åƒå¢å¼ºæŠ€æœ¯ã€æ»¤æ³¢æ–¹æ³•ã€è¾¹ç¼˜æ£€æµ‹ã€å½¢æ€å­¦æ“ä½œã€å›¾åƒåˆ†å‰²å’Œç‰¹å¾æå–ç­‰å†…å®¹ã€‚\næŒæ¡è¿™äº›åŸºç¡€çŸ¥è¯†å¯¹äºè¿›ä¸€æ­¥å­¦ä¹ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ è‡³å…³é‡è¦ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸éœ€è¦æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©åˆé€‚çš„å›¾åƒå¤„ç†æ–¹æ³•ï¼Œå¹¶å¯èƒ½éœ€è¦ç»„åˆå¤šç§æŠ€æœ¯æ¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¸å¤šä¼ ç»Ÿçš„å›¾åƒå¤„ç†ä»»åŠ¡ç°åœ¨ä¹Ÿå¯ä»¥é€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•å®ç°ï¼Œä½†ç†è§£ä¼ ç»Ÿå›¾åƒå¤„ç†çš„åŸºæœ¬åŸç†ä»ç„¶éå¸¸é‡è¦ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ å…¥é—¨å›¾åƒå¤„ç†é¢†åŸŸï¼Œä¸ºåç»­çš„å­¦ä¹ å’Œç ”ç©¶æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\n","permalink":"http://localhost:1313/posts/image-processing-basics/","summary":"\u003ch1 id=\"å›¾åƒå¤„ç†åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eå›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eå›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\u003c/p\u003e","title":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°æ»¤æ³¢"},{"content":"404 - é¡µé¢ä¸å­˜åœ¨ æŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\næ‚¨å¯ä»¥å°è¯•ï¼š è¿”å›é¦–é¡µ æŸ¥çœ‹æ–‡ç« åˆ—è¡¨ ä½¿ç”¨æœç´¢åŠŸèƒ½ æŸ¥çœ‹ç½‘ç«™åœ°å›¾ å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡å…³äºé¡µé¢ä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\n","permalink":"http://localhost:1313/404/","summary":"\u003ch1 id=\"404---é¡µé¢ä¸å­˜åœ¨\"\u003e404 - é¡µé¢ä¸å­˜åœ¨\u003c/h1\u003e\n\u003cp\u003eæŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\u003c/p\u003e\n\u003ch2 id=\"æ‚¨å¯ä»¥å°è¯•\"\u003eæ‚¨å¯ä»¥å°è¯•ï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/\"\u003eè¿”å›é¦–é¡µ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/\"\u003eæŸ¥çœ‹æ–‡ç« åˆ—è¡¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/search/\"\u003eä½¿ç”¨æœç´¢åŠŸèƒ½\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sitemap.xml\"\u003eæŸ¥çœ‹ç½‘ç«™åœ°å›¾\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eå¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡\u003ca href=\"/about/\"\u003eå…³äºé¡µé¢\u003c/a\u003eä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\u003c/p\u003e","title":"404 é¡µé¢ä¸å­˜åœ¨"},{"content":"ä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\næŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\nå‘å¸ƒäº 2025å¹´9æœˆ24æ—¥ ä¸Šåˆ10:30\n","permalink":"http://localhost:1313/thoughts/2025-09-24-first-thought/","summary":"\u003cp\u003eä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\u003c/p\u003e\n\u003cp\u003eæŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\u003c/p\u003e","title":"åšå®¢éšæƒ³åŠŸèƒ½ä¸Šçº¿äº†"},{"content":"ç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\næœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\nå‘å¸ƒäº 2025å¹´9æœˆ23æ—¥ ä¸‹åˆ3:45\n","permalink":"http://localhost:1313/thoughts/2025-09-23-meditation/","summary":"\u003cp\u003eç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\u003c/p\u003e\n\u003cp\u003eæœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\u003c/p\u003e","title":"å…³äºå†¥æƒ³å’Œç”Ÿæ´»å¹³è¡¡çš„æ€è€ƒ"},{"content":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š Gitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\nGitåŸºç¡€æ¦‚å¿µ ä»€ä¹ˆæ˜¯Gitï¼Ÿ Gitæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œç”±Linus Torvaldsäº2005å¹´åˆ›å»ºã€‚ä¸é›†ä¸­å¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ˆå¦‚SVNï¼‰ä¸åŒï¼ŒGitçš„æ¯ä¸ªå¼€å‘è€…éƒ½æ‹¥æœ‰å®Œæ•´çš„ä»£ç ä»“åº“å‰¯æœ¬ï¼Œè¿™ä½¿å¾—Gitåœ¨é€Ÿåº¦ã€æ•°æ®å®Œæ•´æ€§å’Œæ”¯æŒåˆ†å¸ƒå¼å¼€å‘æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚\nGitçš„åŸºæœ¬å·¥ä½œåŒº Gitæœ‰ä¸‰ä¸ªä¸»è¦çš„å·¥ä½œåŒºï¼š\nå·¥ä½œåŒº(Working Directory)ï¼šä½ å½“å‰æ­£åœ¨å·¥ä½œçš„ç›®å½•ï¼ŒåŒ…å«é¡¹ç›®çš„æ‰€æœ‰æ–‡ä»¶ã€‚ æš‚å­˜åŒº(Staging Area)ï¼šä¹Ÿç§°ä¸º\u0026quot;ç´¢å¼•(Index)\u0026quot;ï¼Œæ˜¯ä¸€ä¸ªä¸´æ—¶ä¿å­˜ä¿®æ”¹çš„åœ°æ–¹ã€‚ æœ¬åœ°ä»“åº“(Local Repository)ï¼šGitä¿å­˜é¡¹ç›®å…ƒæ•°æ®å’Œå¯¹è±¡æ•°æ®åº“çš„åœ°æ–¹ã€‚ æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªè¿œç¨‹ä»“åº“(Remote Repository)ï¼Œé€šå¸¸æ˜¯æ‰˜ç®¡åœ¨GitHubã€GitLabç­‰å¹³å°ä¸Šçš„ä»“åº“ï¼Œç”¨äºå›¢é˜Ÿåä½œå’Œå¤‡ä»½ã€‚\nGitçš„åŸºæœ¬å·¥ä½œæµç¨‹ Gitçš„åŸºæœ¬å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\nåœ¨å·¥ä½œåŒºä¿®æ”¹æ–‡ä»¶ ä½¿ç”¨git addå°†ä¿®æ”¹æ·»åŠ åˆ°æš‚å­˜åŒº ä½¿ç”¨git commitå°†æš‚å­˜åŒºçš„å†…å®¹æäº¤åˆ°æœ¬åœ°ä»“åº“ ä½¿ç”¨git pushå°†æœ¬åœ°ä»“åº“çš„ä¿®æ”¹æ¨é€åˆ°è¿œç¨‹ä»“åº“ GitåŸºæœ¬å‘½ä»¤ åˆå§‹åŒ–é…ç½® é…ç½®ç”¨æˆ·ä¿¡æ¯ 1 2 3 4 5 6 7 8 # é…ç½®å…¨å±€ç”¨æˆ·å git config --global user.name \u0026#34;Your Name\u0026#34; # é…ç½®å…¨å±€é‚®ç®± git config --global user.email \u0026#34;your.email@example.com\u0026#34; # æŸ¥çœ‹é…ç½® git config --list åˆå§‹åŒ–ä»“åº“ 1 2 3 4 5 # åœ¨å½“å‰ç›®å½•åˆå§‹åŒ–Gitä»“åº“ git init # å…‹éš†è¿œç¨‹ä»“åº“ git clone https://github.com/username/repository.git åŸºæœ¬æ“ä½œ æŸ¥çœ‹çŠ¶æ€ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # æŸ¥çœ‹å·¥ä½œåŒºçŠ¶æ€ git status # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä¿®æ”¹æƒ…å†µ # æŸ¥çœ‹ç®€åŒ–çŠ¶æ€ git status -s # ç®€åŒ–è¾“å‡ºï¼Œé€‚åˆå¿«é€ŸæŸ¥çœ‹ # æŸ¥çœ‹æäº¤å†å² git log # æ˜¾ç¤ºè¯¦ç»†æäº¤è®°å½• # æŸ¥çœ‹ç®€æ´æäº¤å†å² git log --oneline # æ¯æ¡æäº¤ä¸€è¡Œï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ # æŸ¥çœ‹å›¾å½¢åŒ–æäº¤å†å² git log --graph --oneline --all æ·»åŠ å’Œæäº¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ·»åŠ æŒ‡å®šæ–‡ä»¶åˆ°æš‚å­˜åŒº git add filename # æ·»åŠ æ‰€æœ‰ä¿®æ”¹åˆ°æš‚å­˜åŒº git add . # æ·»åŠ æ‰€æœ‰ä¿®æ”¹ï¼ˆåŒ…æ‹¬æ–°æ–‡ä»¶ï¼‰åˆ°æš‚å­˜åŒº git add -A # æäº¤æš‚å­˜åŒºå†…å®¹ git commit -m \u0026#34;Commit message\u0026#34; # è·³è¿‡æš‚å­˜åŒºç›´æ¥æäº¤ git commit -a -m \u0026#34;Commit message\u0026#34; # ä¿®æ”¹æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯ git commit --amend æŸ¥çœ‹å’Œæ¯”è¾ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æŸ¥çœ‹å·¥ä½œåŒºä¸æš‚å­˜åŒºçš„å·®å¼‚ git diff # æŸ¥çœ‹æš‚å­˜åŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff --staged # æŸ¥çœ‹å·¥ä½œåŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff HEAD # æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶çš„å·®å¼‚ git diff filename # æŸ¥çœ‹æŒ‡å®šæäº¤çš„å·®å¼‚ git diff commit1 commit2 æ’¤é”€æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ’¤é”€å·¥ä½œåŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°æš‚å­˜åŒºçŠ¶æ€ï¼‰ git checkout -- filename # æ’¤é”€æš‚å­˜åŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°å·¥ä½œåŒºçŠ¶æ€ï¼‰ git reset HEAD filename # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~1 # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~1 # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~n # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~n è¿œç¨‹ä»“åº“æ“ä½œ æ·»åŠ å’Œç®¡ç†è¿œç¨‹ä»“åº“ 1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹è¿œç¨‹ä»“åº“ git remote -v # æ·»åŠ è¿œç¨‹ä»“åº“ git remote add origin https://github.com/username/repository.git # åˆ é™¤è¿œç¨‹ä»“åº“ git remote remove origin # ä¿®æ”¹è¿œç¨‹ä»“åº“URL git remote set-url origin https://github.com/username/new-repository.git æ¨é€å’Œæ‹‰å– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin main # æ¨é€å¹¶è®¾ç½®ä¸Šæ¸¸åˆ†æ”¯ git push -u origin main # æ‹‰å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ git pull origin main # è·å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ï¼ˆä¸åˆå¹¶ï¼‰ git fetch origin # åˆå¹¶è¿œç¨‹åˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge origin/main åˆ†æ”¯ç®¡ç† åˆ†æ”¯çš„åŸºæœ¬æ“ä½œ åˆ›å»ºå’Œåˆ‡æ¢åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # åˆ›å»ºæ–°åˆ†æ”¯ git branch feature-branch # åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯ git checkout feature-branch # åˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯ git checkout -b feature-branch # æŸ¥çœ‹æ‰€æœ‰åˆ†æ”¯ git branch -a # æŸ¥çœ‹æœ¬åœ°åˆ†æ”¯ git branch # æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯ git branch -r åˆå¹¶åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 # åˆ‡æ¢åˆ°ç›®æ ‡åˆ†æ”¯ git checkout main # åˆå¹¶æŒ‡å®šåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge feature-branch # åˆ é™¤å·²åˆå¹¶çš„åˆ†æ”¯ git branch -d feature-branch # å¼ºåˆ¶åˆ é™¤åˆ†æ”¯ï¼ˆå³ä½¿æœªåˆå¹¶ï¼‰ git branch -D feature-branch è§£å†³åˆå¹¶å†²çª å½“åˆå¹¶åˆ†æ”¯æ—¶ï¼Œå¦‚æœä¸¤ä¸ªåˆ†æ”¯å¯¹åŒä¸€æ–‡ä»¶çš„åŒä¸€éƒ¨åˆ†è¿›è¡Œäº†ä¸åŒçš„ä¿®æ”¹ï¼Œå°±ä¼šäº§ç”Ÿåˆå¹¶å†²çªã€‚è§£å†³åˆå¹¶å†²çªçš„æ­¥éª¤å¦‚ä¸‹ï¼š\næ‰§è¡Œgit mergeå‘½ä»¤ï¼ŒGitä¼šæ ‡è®°å†²çªæ–‡ä»¶ æ‰“å¼€å†²çªæ–‡ä»¶ï¼ŒæŸ¥çœ‹å†²çªæ ‡è®°ï¼ˆ\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;, =======, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;ï¼‰ æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶ï¼Œè§£å†³å†²çª ä½¿ç”¨git addæ ‡è®°å†²çªå·²è§£å†³ ä½¿ç”¨git commitå®Œæˆåˆå¹¶ 1 2 3 4 5 6 7 8 9 10 11 # åˆå¹¶åˆ†æ”¯ï¼ˆå‡è®¾äº§ç”Ÿå†²çªï¼‰ git merge feature-branch # æŸ¥çœ‹å†²çªçŠ¶æ€ git status # æ‰‹åŠ¨è§£å†³å†²çªåï¼Œæ ‡è®°å·²è§£å†³ git add conflicted-file # å®Œæˆåˆå¹¶ git commit å˜åŸº(Rebase) å˜åŸºæ˜¯å°†ä¸€ç³»åˆ—æäº¤åº”ç”¨åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šçš„æ“ä½œï¼Œå®ƒå¯ä»¥ä½¿æäº¤å†å²æ›´åŠ çº¿æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # å˜åŸºå½“å‰åˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main # å˜åŸºæŒ‡å®šåˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main feature-branch # äº¤äº’å¼å˜åŸºï¼ˆå¯ä»¥ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æäº¤ï¼‰ git rebase -i HEAD~3 # ç»§ç»­å˜åŸºï¼ˆè§£å†³å†²çªåï¼‰ git rebase --continue # å–æ¶ˆå˜åŸº git rebase --abort æ ‡ç­¾ç®¡ç† æ ‡ç­¾ç”¨äºæ ‡è®°é‡è¦çš„æäº¤ç‚¹ï¼Œé€šå¸¸ç”¨äºç‰ˆæœ¬å‘å¸ƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # åˆ›å»ºè½»é‡æ ‡ç­¾ git tag v1.0.0 # åˆ›å»ºå¸¦æ³¨é‡Šçš„æ ‡ç­¾ git tag -a v1.0.0 -m \u0026#34;Version 1.0.0 release\u0026#34; # æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾ git tag # æŸ¥çœ‹æ ‡ç­¾ä¿¡æ¯ git show v1.0.0 # æ¨é€æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin v1.0.0 # æ¨é€æ‰€æœ‰æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin --tags # åˆ é™¤æœ¬åœ°æ ‡ç­¾ git tag -d v1.0.0 # åˆ é™¤è¿œç¨‹æ ‡ç­¾ git push origin :refs/tags/v1.0.0 Gitå·¥ä½œæµæ¨¡å‹ é›†ä¸­å¼å·¥ä½œæµ é›†ä¸­å¼å·¥ä½œæµæ˜¯æœ€ç®€å•çš„å·¥ä½œæµï¼Œç±»ä¼¼äºSVNçš„å·¥ä½œæ–¹å¼ã€‚æ‰€æœ‰å¼€å‘è€…ç›´æ¥åœ¨ä¸»åˆ†æ”¯ä¸Šå·¥ä½œï¼Œé€‚åˆå°å‹é¡¹ç›®æˆ–ä¸ªäººé¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nå…‹éš†ä»“åº“ åœ¨ä¸»åˆ†æ”¯ä¸Šä¿®æ”¹ä»£ç  æäº¤ä¿®æ”¹ æ¨é€åˆ°è¿œç¨‹ä»“åº“ ä¼˜ç‚¹ï¼š\nç®€å•ç›´è§‚ æ— éœ€å­¦ä¹ åˆ†æ”¯ç®¡ç† ç¼ºç‚¹ï¼š\nå®¹æ˜“äº§ç”Ÿå†²çª ä¸é€‚åˆå›¢é˜Ÿåä½œ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµä¸ºæ¯ä¸ªæ–°åŠŸèƒ½åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„åˆ†æ”¯ï¼Œå¼€å‘å®Œæˆåå†åˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»ä¸»åˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›ä¸»åˆ†æ”¯ åˆ é™¤åŠŸèƒ½åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # åˆ‡æ¢åˆ°ä¸»åˆ†æ”¯ git checkout main # åˆå¹¶åŠŸèƒ½åˆ†æ”¯ git merge feature/new-feature # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature ä¼˜ç‚¹ï¼š\nåŠŸèƒ½éš”ç¦»ï¼Œå‡å°‘å†²çª ä¸»åˆ†æ”¯ä¿æŒç¨³å®š ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\néœ€è¦ç®¡ç†å¤šä¸ªåˆ†æ”¯ åˆå¹¶å¯èƒ½äº§ç”Ÿå†²çª Git Flowå·¥ä½œæµ Git Flowæ˜¯ä¸€ç§æ›´å¤æ‚çš„å·¥ä½œæµï¼Œå®šä¹‰äº†ä¸¥æ ¼çš„åˆ†æ”¯æ¨¡å‹ï¼Œé€‚ç”¨äºå¤§å‹é¡¹ç›®å’Œæ­£å¼å‘å¸ƒã€‚\nåˆ†æ”¯ç±»å‹ï¼š\nmainï¼šä¸»åˆ†æ”¯ï¼Œå§‹ç»ˆä¿æŒå¯å‘å¸ƒçŠ¶æ€ developï¼šå¼€å‘åˆ†æ”¯ï¼Œé›†æˆæ‰€æœ‰åŠŸèƒ½ featureï¼šåŠŸèƒ½åˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œå®Œæˆååˆå¹¶å›develop releaseï¼šå‘å¸ƒåˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œç”¨äºå‡†å¤‡å‘å¸ƒ hotfixï¼šä¿®å¤åˆ†æ”¯ï¼Œä»mainåˆ›å»ºï¼Œç”¨äºç´§æ€¥ä¿®å¤ å·¥ä½œæµç¨‹ï¼š\nä»developåˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›develop ä»developåˆ›å»ºå‘å¸ƒåˆ†æ”¯ æµ‹è¯•å’Œä¿®å¤ åˆå¹¶å‘å¸ƒåˆ†æ”¯åˆ°mainå’Œdevelop ä»mainåˆ›å»ºä¿®å¤åˆ†æ”¯ ä¿®å¤ååˆå¹¶åˆ°mainå’Œdevelop 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # åˆå§‹åŒ–Git Flow git flow init # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git flow feature start new-feature # å®ŒæˆåŠŸèƒ½åˆ†æ”¯ git flow feature finish new-feature # åˆ›å»ºå‘å¸ƒåˆ†æ”¯ git flow release start v1.0.0 # å®Œæˆå‘å¸ƒåˆ†æ”¯ git flow release finish v1.0.0 # åˆ›å»ºä¿®å¤åˆ†æ”¯ git flow hotfix start critical-fix # å®Œæˆä¿®å¤åˆ†æ”¯ git flow hotfix finish critical-fix ä¼˜ç‚¹ï¼š\nç»“æ„æ¸…æ™°ï¼ŒèŒè´£æ˜ç¡® é€‚åˆæ­£å¼å‘å¸ƒ æ”¯æŒç´§æ€¥ä¿®å¤ ç¼ºç‚¹ï¼š\næµç¨‹å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜ åˆ†æ”¯ç®¡ç†ç¹ç å¯¹äºå°å‹é¡¹ç›®è¿‡äºå¤æ‚ GitHub Flowå·¥ä½œæµ GitHub Flowæ˜¯GitHubä½¿ç”¨çš„ä¸€ç§ç®€åŒ–å·¥ä½œæµï¼Œé€‚åˆæŒç»­éƒ¨ç½²çš„é¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºPull Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ éƒ¨ç½² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitHubä¸Šåˆ›å»ºPull Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature git push origin --delete feature/new-feature ä¼˜ç‚¹ï¼š\nç®€å•æ˜äº† é€‚åˆæŒç»­éƒ¨ç½² ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\nä¸é€‚åˆéœ€è¦é•¿æœŸç»´æŠ¤å¤šä¸ªç‰ˆæœ¬çš„é¡¹ç›® ç¼ºå°‘æ˜ç¡®çš„å‘å¸ƒæµç¨‹ GitLab Flowå·¥ä½œæµ GitLab Flowæ˜¯GitLabæ¨èçš„å·¥ä½œæµï¼Œç»“åˆäº†GitHub Flowå’ŒGit Flowçš„ä¼˜ç‚¹ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºMerge Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ ä»mainåˆ›å»ºç¯å¢ƒåˆ†æ”¯ï¼ˆå¦‚stagingã€productionï¼‰ éƒ¨ç½²åˆ°ä¸åŒç¯å¢ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitLabä¸Šåˆ›å»ºMerge Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ›å»ºç¯å¢ƒåˆ†æ”¯ git checkout -b production main git push origin production # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ # ... ä¼˜ç‚¹ï¼š\nç®€å•ä¸”çµæ´» æ”¯æŒå¤šç¯å¢ƒéƒ¨ç½² é€‚åˆæŒç»­äº¤ä»˜ ç¼ºç‚¹ï¼š\nç¯å¢ƒåˆ†æ”¯ç®¡ç†éœ€è¦é¢å¤–å·¥ä½œ å¯¹äºå¤§å‹é¡¹ç›®å¯èƒ½ä¸å¤Ÿä¸¥æ ¼ Gité«˜çº§æŠ€å·§ é’©å­(Hooks) Gité’©å­æ˜¯åœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è‡ªåŠ¨æ‰§è¡Œçš„è„šæœ¬ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚\nå¸¸ç”¨é’©å­ç±»å‹ å®¢æˆ·ç«¯é’©å­ï¼š\npre-commitï¼šæäº¤å‰è¿è¡Œ commit-msgï¼šç¼–è¾‘æäº¤ä¿¡æ¯åè¿è¡Œ pre-pushï¼šæ¨é€å‰è¿è¡Œ æœåŠ¡å™¨ç«¯é’©å­ï¼š\npre-receiveï¼šæ¥æ”¶æ¨é€æ—¶è¿è¡Œ updateï¼šæ›´æ–°åˆ†æ”¯æ—¶è¿è¡Œ post-receiveï¼šæ¥æ”¶æ¨é€åè¿è¡Œ ç¤ºä¾‹ï¼špre-commité’©å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/sh # .git/hooks/pre-commit # æ£€æŸ¥ä»£ç é£æ ¼ npm run lint # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;ä»£ç é£æ ¼æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi # è¿è¡Œæµ‹è¯• npm test # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;æµ‹è¯•å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi å­æ¨¡å—(Submodules) Gitå­æ¨¡å—å…è®¸ä½ å°†ä¸€ä¸ªGitä»“åº“ä½œä¸ºå¦ä¸€ä¸ªGitä»“åº“çš„å­ç›®å½•ã€‚\næ·»åŠ å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 # æ·»åŠ å­æ¨¡å— git submodule add https://github.com/username/submodule-repository.git path/to/submodule # åˆå§‹åŒ–å­æ¨¡å— git submodule init # æ›´æ–°å­æ¨¡å— git submodule update # é€’å½’å…‹éš†åŒ…å«å­æ¨¡å—çš„ä»“åº“ git clone --recursive https://github.com/username/repository.git æ›´æ–°å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 12 # è¿›å…¥å­æ¨¡å—ç›®å½• cd path/to/submodule # æ‹‰å–æœ€æ–°ä»£ç  git pull origin main # è¿”å›ä¸»ä»“åº“ cd .. # æäº¤å­æ¨¡å—æ›´æ–° git add path/to/submodule git commit -m \u0026#34;Update submodule\u0026#34; å˜åŸº(Rebase)é«˜çº§ç”¨æ³• äº¤äº’å¼å˜åŸº äº¤äº’å¼å˜åŸºå…è®¸ä½ ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æˆ–é‡æ–°æ’åºæäº¤ã€‚\n1 2 # å¯¹æœ€è¿‘çš„3ä¸ªæäº¤è¿›è¡Œäº¤äº’å¼å˜åŸº git rebase -i HEAD~3 åœ¨æ‰“å¼€çš„ç¼–è¾‘å™¨ä¸­ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„å†…å®¹ï¼š\npick f7f3f6d Commit message 1 pick 310154e Commit message 2 pick a5f4a0d Commit message 3 # Rebase 1234567..a5f4a0d onto 1234567 (3 commands) # # Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to re-use the original merge # . commit\u0026#39;s author and message. # # These lines can be re-ordered; they are executed from top to bottom. ä½ å¯ä»¥é€šè¿‡ä¿®æ”¹å‘½ä»¤å‰çš„å…³é”®å­—æ¥æ”¹å˜æäº¤çš„å¤„ç†æ–¹å¼ã€‚\nå˜åŸº vs åˆå¹¶ å˜åŸºå’Œåˆå¹¶éƒ½æ˜¯æ•´åˆåˆ†æ”¯æ›´æ”¹çš„æ–¹æ³•ï¼Œä½†å®ƒä»¬æœ‰ä¸åŒçš„å·¥ä½œæ–¹å¼ï¼š\nåˆå¹¶(Merge)ï¼š\nåˆ›å»ºä¸€ä¸ªæ–°çš„\u0026quot;åˆå¹¶æäº¤\u0026quot; ä¿ç•™å®Œæ•´çš„åˆ†æ”¯å†å² é€‚åˆå…¬å…±åˆ†æ”¯ å˜åŸº(Rebase)ï¼š\nå°†æäº¤é‡æ–°åº”ç”¨åˆ°ç›®æ ‡åˆ†æ”¯ åˆ›å»ºçº¿æ€§çš„æäº¤å†å² é€‚åˆç§æœ‰åˆ†æ”¯ 1 2 3 4 5 6 7 # åˆå¹¶åˆ†æ”¯ git checkout main git merge feature-branch # å˜åŸºåˆ†æ”¯ git checkout feature-branch git rebase main å‚¨è—(Stash) å‚¨è—å…è®¸ä½ ä¸´æ—¶ä¿å­˜æœªæäº¤çš„ä¿®æ”¹ï¼Œä»¥ä¾¿åˆ‡æ¢åˆ†æ”¯æˆ–æ‰§è¡Œå…¶ä»–æ“ä½œã€‚\nåŸºæœ¬å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # å‚¨è—å½“å‰ä¿®æ”¹ git stash # å‚¨è—å¹¶æ·»åŠ è¯´æ˜ git stash save \u0026#34;Work in progress\u0026#34; # æŸ¥çœ‹å‚¨è—åˆ—è¡¨ git stash list # åº”ç”¨æœ€æ–°å‚¨è—ï¼ˆä¸åˆ é™¤ï¼‰ git stash apply # åº”ç”¨å¹¶åˆ é™¤æœ€æ–°å‚¨è— git stash pop # åº”ç”¨æŒ‡å®šå‚¨è— git stash apply stash@{1} # åˆ é™¤æŒ‡å®šå‚¨è— git stash drop stash@{1} # æ¸…é™¤æ‰€æœ‰å‚¨è— git stash clear é«˜çº§å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 # å‚¨è—æœªè·Ÿè¸ªçš„æ–‡ä»¶ git stash -u # å‚¨è—åŒ…æ‹¬å¿½ç•¥çš„æ–‡ä»¶ git stash -a # ä»å‚¨è—åˆ›å»ºåˆ†æ”¯ git stash branch new-branch stash@{1} ç­¾é€‰(Cherry-pick) ç­¾é€‰å…è®¸ä½ é€‰æ‹©ç‰¹å®šçš„æäº¤ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°å½“å‰åˆ†æ”¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ç­¾é€‰æŒ‡å®šæäº¤ git cherry-pick commit-hash # ç­¾é€‰ä½†ä¸æäº¤ git cherry-pick -n commit-hash # ç­¾é€‰å¹¶ç¼–è¾‘æäº¤ä¿¡æ¯ git cherry-pick -e commit-hash # ç­¾é€‰å¤šä¸ªæäº¤ git cherry-pick commit1 commit2 commit3 # ç­¾é€‰ä¸€ç³»åˆ—æäº¤ git cherry-pick commit1..commit3 # ä¸­æ­¢ç­¾é€‰ git cherry-pick --abort # ç»§ç»­ç­¾é€‰ï¼ˆè§£å†³å†²çªåï¼‰ git cherry-pick --continue å¼•ç”¨æ—¥å¿—(Reflog) å¼•ç”¨æ—¥å¿—è®°å½•äº†Gitä»“åº“ä¸­æ‰€æœ‰å¼•ç”¨çš„æ›´æ–°ï¼ŒåŒ…æ‹¬è¢«åˆ é™¤çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹å¼•ç”¨æ—¥å¿— git reflog # æŸ¥çœ‹æŒ‡å®šåˆ†æ”¯çš„å¼•ç”¨æ—¥å¿— git reflog show main # æŸ¥çœ‹å¼•ç”¨æ—¥å¿—å¹¶æ˜¾ç¤ºå·®å¼‚ git reflog show --stat # æ¢å¤è¢«åˆ é™¤çš„æäº¤ git reset --hard HEAD@{1} äºŒåˆ†æŸ¥æ‰¾(Bisect) äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºå¿«é€Ÿå®šä½å¼•å…¥é—®é¢˜çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # å¼€å§‹äºŒåˆ†æŸ¥æ‰¾ git bisect start # æ ‡è®°å½“å‰æäº¤ä¸ºæœ‰é—®é¢˜ git bisect bad # æ ‡è®°å·²çŸ¥æ­£å¸¸çš„æäº¤ git bisect good commit-hash # Gitä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸€ä¸ªä¸­é—´æäº¤ï¼Œæµ‹è¯•åæ ‡è®°ä¸ºgoodæˆ–bad git bisect good # æˆ– git bisect bad # é‡å¤æµ‹è¯•è¿‡ç¨‹ï¼Œç›´åˆ°æ‰¾åˆ°é—®é¢˜æäº¤ # ç»“æŸäºŒåˆ†æŸ¥æ‰¾ git bisect reset Gitæœ€ä½³å®è·µ æäº¤è§„èŒƒ æäº¤ä¿¡æ¯æ ¼å¼ è‰¯å¥½çš„æäº¤ä¿¡æ¯åº”è¯¥æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶éµå¾ªä¸€å®šçš„æ ¼å¼ï¼š\n\u0026lt;ç±»å‹\u0026gt;(\u0026lt;èŒƒå›´\u0026gt;): \u0026lt;ä¸»é¢˜\u0026gt; \u0026lt;è¯¦ç»†æè¿°\u0026gt; \u0026lt;é¡µè„š\u0026gt; ç±»å‹ï¼š\nfeatï¼šæ–°åŠŸèƒ½ fixï¼šä¿®å¤bug docsï¼šæ–‡æ¡£æ›´æ–° styleï¼šä»£ç æ ¼å¼ï¼ˆä¸å½±å“ä»£ç è¿è¡Œçš„å˜åŠ¨ï¼‰ refactorï¼šé‡æ„ï¼ˆæ—¢ä¸æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¹Ÿä¸æ˜¯ä¿®æ”¹bugçš„ä»£ç å˜åŠ¨ï¼‰ perfï¼šæ€§èƒ½ä¼˜åŒ– testï¼šå¢åŠ æµ‹è¯• choreï¼šæ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨ èŒƒå›´ï¼šå¯é€‰ï¼Œç”¨äºè¯´æ˜æäº¤å½±å“çš„èŒƒå›´ï¼Œå¦‚docs, api, coreç­‰ã€‚\nä¸»é¢˜ï¼šç®€æ´æè¿°æäº¤å†…å®¹ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦ã€‚\nè¯¦ç»†æè¿°ï¼šå¯é€‰ï¼Œè¯¦ç»†æè¿°æäº¤å†…å®¹ï¼Œæ¯è¡Œä¸è¶…è¿‡72ä¸ªå­—ç¬¦ã€‚\né¡µè„šï¼šå¯é€‰ï¼Œç”¨äºæ ‡è®°Breaking Changesæˆ–å…³é—­Issueã€‚\nç¤ºä¾‹æäº¤ä¿¡æ¯ feat(api): add user authentication endpoint Add a new endpoint for user authentication using JWT tokens. The endpoint supports both username/password and social login methods. Closes #123 åˆ†æ”¯å‘½åè§„èŒƒ è‰¯å¥½çš„åˆ†æ”¯å‘½åå¯ä»¥æé«˜å›¢é˜Ÿåä½œæ•ˆç‡ï¼š\n\u0026lt;ç±»å‹\u0026gt;/\u0026lt;æè¿°\u0026gt; ä¾‹å¦‚ï¼š feature/user-authentication fix/login-bug docs/api-documentation refactor/user-service ä»£ç å®¡æŸ¥ ä»£ç å®¡æŸ¥æ˜¯ä¿è¯ä»£ç è´¨é‡çš„é‡è¦ç¯èŠ‚ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å»ºè®®ï¼š\nä¿æŒå°çš„æäº¤ï¼šæ¯æ¬¡æäº¤åº”è¯¥åªå…³æ³¨ä¸€ä¸ªåŠŸèƒ½æˆ–ä¿®å¤ï¼Œä¾¿äºå®¡æŸ¥ã€‚ æä¾›æ¸…æ™°çš„æè¿°ï¼šåœ¨Pull Requestä¸­è¯¦ç»†è¯´æ˜ä¿®æ”¹å†…å®¹å’ŒåŸå› ã€‚ è‡ªåŠ¨åŒ–æ£€æŸ¥ï¼šä½¿ç”¨CI/CDå·¥å…·è‡ªåŠ¨è¿è¡Œæµ‹è¯•å’Œä»£ç é£æ ¼æ£€æŸ¥ã€‚ å…³æ³¨ä»£ç é€»è¾‘ï¼šä¸ä»…å…³æ³¨ä»£ç é£æ ¼ï¼Œè¿˜è¦å…³æ³¨é€»è¾‘æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚ æä¾›å»ºè®¾æ€§åé¦ˆï¼šå°Šé‡ä»–äººï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚ å¸¸è§é—®é¢˜è§£å†³ æ’¤é”€å·²æ¨é€çš„æäº¤ 1 2 3 4 5 6 7 # æ–¹æ³•1ï¼šåˆ›å»ºæ–°çš„æäº¤æ¥æ’¤é”€ git revert commit-hash git push origin main # æ–¹æ³•2ï¼šå¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git reset --hard HEAD~1 git push --force origin main åˆå¹¶é”™è¯¯çš„åˆ†æ”¯ 1 2 3 4 5 # æ’¤é”€åˆå¹¶ git reset --hard HEAD~1 # å¦‚æœå·²ç»æ¨é€ git revert -m 1 commit-hash æ¸…ç†å†å²è®°å½• 1 2 3 4 5 # äº¤äº’å¼å˜åŸºæ¸…ç†å†å² git rebase -i HEAD~n # å¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git push --force origin main å¤„ç†å¤§æ–‡ä»¶ 1 2 3 4 5 6 7 8 9 10 # æŸ¥æ‰¾å¤§æ–‡ä»¶ git rev-list --objects --all | git cat-file --batch-check=\u0026#39;%(objecttype) %(objectname) %(objectsize) %(rest)\u0026#39; | sed -n \u0026#39;s/^blob //p\u0026#39; | sort -nrk 2 | head -n 10 # ä½¿ç”¨BFG Repo-Cleaneræ¸…ç†å¤§æ–‡ä»¶ java -jar bfg.jar --strip-blobs-bigger-than 100M my-repo.git # æ¸…ç†å¹¶æ¨é€ git reflog expire --expire=now --all git gc --prune=now --aggressive git push --force origin main æ€»ç»“ Gitæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ŒæŒæ¡å…¶å·¥ä½œæµç¨‹å¯¹äºç°ä»£è½¯ä»¶å¼€å‘è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»Gitçš„åŸºæœ¬æ¦‚å¿µå’Œå‘½ä»¤å¼€å§‹ï¼Œé€æ­¥ä»‹ç»äº†åˆ†æ”¯ç®¡ç†ã€å„ç§å·¥ä½œæµæ¨¡å‹ä»¥åŠé«˜çº§æŠ€å·§ã€‚\né€šè¿‡å­¦ä¹ å’Œå®è·µè¿™äº›å†…å®¹ï¼Œä½ å¯ä»¥ï¼š\né«˜æ•ˆç®¡ç†ä¸ªäººé¡¹ç›®çš„ç‰ˆæœ¬ ä¸å›¢é˜Ÿæˆå‘˜åä½œå¼€å‘ å¤„ç†å¤æ‚çš„åˆå¹¶å’Œå†²çª ä½¿ç”¨é«˜çº§åŠŸèƒ½æé«˜å·¥ä½œæ•ˆç‡ è®°ä½ï¼ŒGitçš„å¼ºå¤§ä¹‹å¤„åœ¨äºå…¶çµæ´»æ€§ï¼Œä½ å¯ä»¥æ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥ä½œæµç¨‹å’Œå·¥å…·ã€‚åŒæ—¶ï¼Œè‰¯å¥½çš„å®è·µä¹ æƒ¯ï¼ˆå¦‚æ¸…æ™°çš„æäº¤ä¿¡æ¯ã€è§„èŒƒçš„åˆ†æ”¯å‘½åï¼‰å°†ä½¿ä½ çš„å¼€å‘è¿‡ç¨‹æ›´åŠ é¡ºç•…ã€‚\næœ€åï¼ŒGitæ˜¯ä¸€ä¸ªä¸æ–­å‘å±•çš„å·¥å…·ï¼ŒæŒç»­å­¦ä¹ å’Œæ¢ç´¢æ–°åŠŸèƒ½å°†å¸®åŠ©ä½ æ›´å¥½åœ°åˆ©ç”¨è¿™ä¸ªå¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ æŒæ¡Gitå·¥ä½œæµç¨‹ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚\n","permalink":"http://localhost:1313/posts/git-workflow/","summary":"\u003ch1 id=\"gitå·¥ä½œæµç¨‹ä»å…¥é—¨åˆ°ç²¾é€š\"\u003eGitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š\u003c/h1\u003e\n\u003cp\u003eGitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\u003c/p\u003e","title":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š"},{"content":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\nå›¾åƒåŸºç¡€ å›¾åƒè¡¨ç¤º æ•°å­—å›¾åƒçš„æ¦‚å¿µ æ•°å­—å›¾åƒæ˜¯ç”±æœ‰é™æ•°é‡çš„åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆçš„äºŒç»´çŸ©é˜µã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import numpy as np import matplotlib.pyplot as plt # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç°åº¦å›¾åƒ # 5x5çš„ç°åº¦å›¾åƒï¼Œå€¼èŒƒå›´0-255 gray_image = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ], dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert gray_image is not None, \u0026#34;ç°åº¦å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # æ˜¾ç¤ºå›¾åƒ plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Grayscale Image\u0026#39;) plt.colorbar() plt.show() å½©è‰²å›¾åƒè¡¨ç¤º å½©è‰²å›¾åƒé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“æ¥è¡¨ç¤ºã€‚æ¯ä¸ªåƒç´ ç”±ä¸‰ä¸ªå€¼ç»„æˆï¼Œåˆ†åˆ«ä»£è¡¨çº¢ã€ç»¿ã€è“ä¸‰ä¸ªé¢œè‰²é€šé“çš„å¼ºåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰²å›¾åƒ # 5x5x3çš„RGBå›¾åƒï¼Œå€¼èŒƒå›´0-255 color_image = np.zeros((5, 5, 3), dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert color_image is not None, \u0026#34;å½©è‰²å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # è®¾ç½®çº¢è‰²é€šé“ color_image[:, :, 0] = np.array([ [255, 200, 150, 100, 50], [230, 180, 130, 80, 30], [210, 160, 110, 60, 10], [190, 140, 90, 40, 0], [170, 120, 70, 20, 0] ]) # è®¾ç½®ç»¿è‰²é€šé“ color_image[:, :, 1] = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ]) # è®¾ç½®è“è‰²é€šé“ color_image[:, :, 2] = np.array([ [0, 30, 60, 90, 120], [50, 80, 110, 140, 170], [100, 130, 160, 190, 200], [150, 180, 210, 220, 230], [200, 230, 240, 250, 255] ]) # æ˜¾ç¤ºå›¾åƒ plt.imshow(color_image) plt.title(\u0026#39;Color Image\u0026#39;) plt.show() å…¶ä»–é¢œè‰²ç©ºé—´ é™¤äº†RGBï¼Œè¿˜æœ‰å…¶ä»–å¸¸ç”¨çš„é¢œè‰²ç©ºé—´ï¼Œå¦‚HSVï¼ˆè‰²ç›¸ã€é¥±å’Œåº¦ã€æ˜åº¦ï¼‰å’ŒLabï¼ˆäº®åº¦ã€aé€šé“ã€bé€šé“ï¼‰ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import cv2 # å°†RGBå›¾åƒè½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´ hsv_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2HSV) # å°†RGBå›¾åƒè½¬æ¢ä¸ºLabé¢œè‰²ç©ºé—´ lab_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2Lab) # æ˜¾ç¤ºä¸åŒé¢œè‰²ç©ºé—´çš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(color_image) plt.title(\u0026#39;RGB Image\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(hsv_image) plt.title(\u0026#39;HSV Image\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(lab_image) plt.title(\u0026#39;Lab Image\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå±æ€§ åˆ†è¾¨ç‡ å›¾åƒåˆ†è¾¨ç‡æ˜¯æŒ‡å›¾åƒä¸­åƒç´ çš„æ•°é‡ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºå®½åº¦Ã—é«˜åº¦ï¼ˆå¦‚1920Ã—1080ï¼‰ã€‚é«˜åˆ†è¾¨ç‡å›¾åƒåŒ…å«æ›´å¤šç»†èŠ‚ï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šçš„å­˜å‚¨ç©ºé—´å’Œå¤„ç†æ—¶é—´ã€‚\n1 2 3 4 5 6 # è·å–å›¾åƒåˆ†è¾¨ç‡ height, width = gray_image.shape print(f\u0026#34;ç°åº¦å›¾åƒåˆ†è¾¨ç‡: {width}x{height}\u0026#34;) height, width, channels = color_image.shape print(f\u0026#34;å½©è‰²å›¾åƒåˆ†è¾¨ç‡: {width}x{height}, é€šé“æ•°: {channels}\u0026#34;) ä½æ·±åº¦ ä½æ·±åº¦æ˜¯æŒ‡æ¯ä¸ªåƒç´ ä½¿ç”¨çš„ä½æ•°ï¼Œå†³å®šäº†å›¾åƒå¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ã€‚å¸¸è§çš„ä½æ·±åº¦æœ‰8ä½ï¼ˆ256ä¸ªç°åº¦çº§ï¼‰ã€24ä½ï¼ˆRGBå„8ä½ï¼Œçº¦1670ä¸‡ç§é¢œè‰²ï¼‰ç­‰ã€‚\n1 2 3 4 5 6 7 8 9 10 # æ£€æŸ¥å›¾åƒçš„ä½æ·±åº¦ print(f\u0026#34;ç°åº¦å›¾åƒæ•°æ®ç±»å‹: {gray_image.dtype}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ•°æ®ç±»å‹: {color_image.dtype}\u0026#34;) # è®¡ç®—å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ gray_levels = 2 ** (gray_image.itemsize * 8) color_levels = 2 ** (color_image.itemsize * 8) print(f\u0026#34;ç°åº¦å›¾åƒå¯ä»¥è¡¨ç¤ºçš„ç°åº¦çº§æ•°: {gray_levels}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ¯ä¸ªé€šé“å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²çº§æ•°: {color_levels}\u0026#34;) å›¾åƒåŸºæœ¬å¤„ç† å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨OpenCVè¯»å–å›¾åƒ OpenCVæ˜¯ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„è®¡ç®—æœºè§†è§‰åº“ï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import cv2 # è¯»å–å›¾åƒ # æ³¨æ„ï¼šOpenCVé»˜è®¤ä»¥BGRæ ¼å¼è¯»å–å½©è‰²å›¾åƒ image_bgr = cv2.imread(\u0026#39;example.jpg\u0026#39;) # æ£€æŸ¥å›¾åƒæ˜¯å¦æˆåŠŸè¯»å– if image_bgr is None: print(\u0026#34;æ— æ³•è¯»å–å›¾åƒ\u0026#34;) else: # è½¬æ¢ä¸ºRGBæ ¼å¼ä»¥ä¾¿æ­£ç¡®æ˜¾ç¤º image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.title(\u0026#39;Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() ä½¿ç”¨PIL/Pillowè¯»å–å›¾åƒ Pillowæ˜¯Pythonå›¾åƒå¤„ç†åº“ï¼Œæä¾›äº†ç®€å•æ˜“ç”¨çš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from PIL import Image # è¯»å–å›¾åƒ image = Image.open(\u0026#39;example.jpg\u0026#39;) # æ˜¾ç¤ºå›¾åƒ image.show() # è½¬æ¢ä¸ºnumpyæ•°ç»„ image_array = np.array(image) # æ˜¾ç¤ºå›¾åƒä¿¡æ¯ print(f\u0026#34;å›¾åƒå¤§å°: {image.size}\u0026#34;) print(f\u0026#34;å›¾åƒæ¨¡å¼: {image.mode}\u0026#34;) print(f\u0026#34;å›¾åƒæ•°ç»„å½¢çŠ¶: {image_array.shape}\u0026#34;) å›¾åƒåŸºæœ¬æ“ä½œ è£å‰ªå›¾åƒ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image_rgb[50:200, 100:300] # æ˜¾ç¤ºè£å‰ªåçš„å›¾åƒ plt.imshow(cropped_image) plt.title(\u0026#39;Cropped Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() è°ƒæ•´å›¾åƒå¤§å° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # ä½¿ç”¨OpenCVè°ƒæ•´å›¾åƒå¤§å° resized_cv2 = cv2.resize(image_rgb, (300, 200)) # ä½¿ç”¨PILè°ƒæ•´å›¾åƒå¤§å° resized_pil = Image.fromarray(image_rgb).resize((300, 200)) # æ˜¾ç¤ºè°ƒæ•´å¤§å°åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(resized_cv2) plt.title(\u0026#39;Resized with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(resized_pil) plt.title(\u0026#39;Resized with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() æ—‹è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ä½¿ç”¨OpenCVæ—‹è½¬å›¾åƒ (h, w) = image_rgb.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) rotated_cv2 = cv2.warpAffine(image_rgb, M, (w, h)) # ä½¿ç”¨PILæ—‹è½¬å›¾åƒ rotated_pil = Image.fromarray(image_rgb).rotate(45) # æ˜¾ç¤ºæ—‹è½¬åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(rotated_cv2) plt.title(\u0026#39;Rotated with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(rotated_pil) plt.title(\u0026#39;Rotated with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç¿»è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # æ°´å¹³ç¿»è½¬ flipped_h = cv2.flip(image_rgb, 1) # å‚ç›´ç¿»è½¬ flipped_v = cv2.flip(image_rgb, 0) # æ°´å¹³å’Œå‚ç›´ç¿»è½¬ flipped_hv = cv2.flip(image_rgb, -1) # æ˜¾ç¤ºç¿»è½¬åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(flipped_h) plt.title(\u0026#39;Horizontal Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(flipped_v) plt.title(\u0026#39;Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(flipped_hv) plt.title(\u0026#39;Horizontal and Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå¢å¼º äº®åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ äº®åº¦ brightness_increase = cv2.convertScaleAbs(image_rgb, alpha=1.2, beta=50) # å‡å°‘äº®åº¦ brightness_decrease = cv2.convertScaleAbs(image_rgb, alpha=1.0, beta=-50) # æ˜¾ç¤ºäº®åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(brightness_increase) plt.title(\u0026#39;Increased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(brightness_decrease) plt.title(\u0026#39;Decreased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ å¯¹æ¯”åº¦ contrast_increase = cv2.convertScaleAbs(image_rgb, alpha=1.5, beta=0) # å‡å°‘å¯¹æ¯”åº¦ contrast_decrease = cv2.convertScaleAbs(image_rgb, alpha=0.5, beta=0) # æ˜¾ç¤ºå¯¹æ¯”åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(contrast_increase) plt.title(\u0026#39;Increased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(contrast_decrease) plt.title(\u0026#39;Decreased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›´æ–¹å›¾å‡è¡¡åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # ç›´æ–¹å›¾å‡è¡¡åŒ– equalized_image = cv2.equalizeHist(gray_image) # æ˜¾ç¤ºç›´æ–¹å›¾å‡è¡¡åŒ–å‰åçš„å›¾åƒå’Œç›´æ–¹å›¾ plt.figure(figsize=(15, 10)) # åŸå§‹å›¾åƒ plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Grayscale Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # å‡è¡¡åŒ–åçš„å›¾åƒ plt.subplot(2, 2, 2) plt.imshow(equalized_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Equalized Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # åŸå§‹ç›´æ–¹å›¾ plt.subplot(2, 2, 3) plt.hist(gray_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Original Histogram\u0026#39;) # å‡è¡¡åŒ–åçš„ç›´æ–¹å›¾ plt.subplot(2, 2, 4) plt.hist(equalized_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Equalized Histogram\u0026#39;) plt.tight_layout() plt.show() ä¼½é©¬æ ¡æ­£ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def adjust_gamma(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) # åº”ç”¨ä¸åŒçš„ä¼½é©¬å€¼ gamma_1_5 = adjust_gamma(image_rgb, 1.5) gamma_0_5 = adjust_gamma(image_rgb, 0.5) # æ˜¾ç¤ºä¼½é©¬æ ¡æ­£åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image (Î³=1.0)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(gamma_1_5) plt.title(\u0026#39;Gamma=1.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(gamma_0_5) plt.title(\u0026#39;Gamma=0.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒæ»¤æ³¢ å‡å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # åº”ç”¨ä¸åŒå¤§å°çš„å‡å€¼æ»¤æ³¢ blur_3x3 = cv2.blur(gray_image, (3, 3)) blur_5x5 = cv2.blur(gray_image, (5, 5)) blur_7x7 = cv2.blur(gray_image, (7, 7)) # æ˜¾ç¤ºå‡å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(blur_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(blur_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(blur_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() é«˜æ–¯æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°å’Œæ ‡å‡†å·®çš„é«˜æ–¯æ»¤æ³¢ gaussian_3x3 = cv2.GaussianBlur(gray_image, (3, 3), 0) gaussian_5x5 = cv2.GaussianBlur(gray_image, (5, 5), 0) gaussian_7x7 = cv2.GaussianBlur(gray_image, (7, 7), 0) # æ˜¾ç¤ºé«˜æ–¯æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(gaussian_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(gaussian_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(gaussian_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ä¸­å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°çš„ä¸­å€¼æ»¤æ³¢ median_3 = cv2.medianBlur(gray_image, 3) median_5 = cv2.medianBlur(gray_image, 5) median_7 = cv2.medianBlur(gray_image, 7) # æ˜¾ç¤ºä¸­å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(median_3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(median_5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(median_7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åŒè¾¹æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨åŒè¾¹æ»¤æ³¢ bilateral = cv2.bilateralFilter(gray_image, 9, 75, 75) # æ˜¾ç¤ºåŒè¾¹æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(bilateral, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Bilateral Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è¾¹ç¼˜æ£€æµ‹ Sobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # åº”ç”¨Sobelç®—å­ sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3) sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3) sobel_xy = cv2.Sobel(gray_image, cv2.CV_64F, 1, 1, ksize=3) # è½¬æ¢å›uint8 sobel_x = cv2.convertScaleAbs(sobel_x) sobel_y = cv2.convertScaleAbs(sobel_y) sobel_xy = cv2.convertScaleAbs(sobel_xy) # æ˜¾ç¤ºSobelè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(sobel_x, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel X\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(sobel_y, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel Y\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(sobel_xy, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel XY\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Laplacianç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # åº”ç”¨Laplacianç®—å­ laplacian = cv2.Laplacian(gray_image, cv2.CV_64F) laplacian = cv2.convertScaleAbs(laplacian) # æ˜¾ç¤ºLaplacianè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(laplacian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Laplacian Edge Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Cannyè¾¹ç¼˜æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨Cannyè¾¹ç¼˜æ£€æµ‹ canny_low = cv2.Canny(gray_image, 50, 150) canny_high = cv2.Canny(gray_image, 100, 200) # æ˜¾ç¤ºCannyè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(canny_low, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (50, 150)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(canny_high, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (100, 200)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒåˆ†å‰² é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # åº”ç”¨ä¸åŒç±»å‹çš„é˜ˆå€¼åˆ†å‰² ret, thresh_binary = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY) ret, thresh_binary_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV) ret, thresh_trunc = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TRUNC) ret, thresh_tozero = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO) ret, thresh_tozero_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO_INV) # æ˜¾ç¤ºé˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 2) plt.imshow(thresh_binary, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 3) plt.imshow(thresh_binary_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 4) plt.imshow(thresh_trunc, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Truncated Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 5) plt.imshow(thresh_tozero, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 6) plt.imshow(thresh_tozero_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_mean = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2) adaptive_gaussian = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) # æ˜¾ç¤ºè‡ªé€‚åº”é˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(adaptive_mean, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Mean Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(adaptive_gaussian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Gaussian Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Otsué˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨Otsué˜ˆå€¼åˆ†å‰² ret, otsu = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # æ˜¾ç¤ºOtsué˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(otsu, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;Otsu Threshold (Threshold={ret})\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åˆ†æ°´å²­ç®—æ³• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # åˆ›å»ºä¸€ä¸ªç®€å•çš„äºŒå€¼å›¾åƒ binary_image = np.zeros((300, 300), dtype=np.uint8) cv2.circle(binary_image, (100, 100), 50, 255, -1) cv2.circle(binary_image, (200, 200), 50, 255, -1) # åº”ç”¨è·ç¦»å˜æ¢ dist_transform = cv2.distanceTransform(binary_image, cv2.DIST_L2, 5) ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0) sure_fg = np.uint8(sure_fg) # æœªçŸ¥åŒºåŸŸ unknown = cv2.subtract(binary_image, sure_fg) # æ ‡è®°æ ‡ç­¾ ret, markers = cv2.connectedComponents(sure_fg) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR), markers) # æ˜¾ç¤ºåˆ†æ°´å²­ç®—æ³•ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(binary_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(dist_transform, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Distance Transform\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(markers, cmap=\u0026#39;jet\u0026#39;) plt.title(\u0026#39;Watershed Segmentation\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç‰¹å¾æå– Harrisè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # åº”ç”¨Harrisè§’ç‚¹æ£€æµ‹ gray_float = np.float32(gray_image) harris_corners = cv2.cornerHarris(gray_float, 2, 3, 0.04) # æ‰©å¤§è§’ç‚¹æ ‡è®° harris_corners = cv2.dilate(harris_corners, None) # è®¾ç½®é˜ˆå€¼ threshold = 0.01 * harris_corners.max() corner_image = image_rgb.copy() corner_image[harris_corners \u0026gt; threshold] = [255, 0, 0] # æ˜¾ç¤ºHarrisè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(corner_image) plt.title(\u0026#39;Harris Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Shi-Tomasiè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åº”ç”¨Shi-Tomasiè§’ç‚¹æ£€æµ‹ corners = cv2.goodFeaturesToTrack(gray_image, 100, 0.01, 10) corners = np.int0(corners) # ç»˜åˆ¶è§’ç‚¹ shi_tomasi_image = image_rgb.copy() for corner in corners: x, y = corner.ravel() cv2.circle(shi_tomasi_image, (x, y), 3, 255, -1) # æ˜¾ç¤ºShi-Tomasiè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(shi_tomasi_image) plt.title(\u0026#39;Shi-Tomasi Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() SIFTç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºSIFTç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(sift_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;SIFT Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ORBç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºORBç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(orb_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;ORB Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›®æ ‡æ£€æµ‹ Haarçº§è”åˆ†ç±»å™¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # åŠ è½½Haarçº§è”åˆ†ç±»å™¨ face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_frontalface_default.xml\u0026#39;) eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_eye.xml\u0026#39;) # æ£€æµ‹äººè„¸å’Œçœ¼ç› faces = face_cascade.detectMultiScale(gray_image, 1.3, 5) face_eye_image = image_rgb.copy() for (x, y, w, h) in faces: cv2.rectangle(face_eye_image, (x, y), (x+w, y+h), (255, 0, 0), 2) roi_gray = gray_image[y:y+h, x:x+w] roi_color = face_eye_image[y:y+h, x:x+w] eyes = eye_cascade.detectMultiScale(roi_gray) for (ex, ey, ew, eh) in eyes: cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2) # æ˜¾ç¤ºHaarçº§è”åˆ†ç±»å™¨æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(face_eye_image) plt.title(\u0026#39;Haar Cascade Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() HOGç‰¹å¾ä¸SVM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from skimage.feature import hog from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score # æå–HOGç‰¹å¾ def extract_hog_features(images): features = [] for image in images: # è®¡ç®—HOGç‰¹å¾ fd = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False) features.append(fd) return np.array(features) # å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›æ ‡è®°çš„å›¾åƒæ•°æ® # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦çœŸå®æ•°æ® # X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2) # æå–è®­ç»ƒå’Œæµ‹è¯•é›†çš„HOGç‰¹å¾ # X_train_hog = extract_hog_features(X_train) # X_test_hog = extract_hog_features(X_test) # è®­ç»ƒSVMåˆ†ç±»å™¨ # svm = SVC(kernel=\u0026#39;linear\u0026#39;) # svm.fit(X_train_hog, y_train) # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° # y_pred = svm.predict(X_test_hog) # accuracy = accuracy_score(y_test, y_pred) # print(f\u0026#34;Accuracy: {accuracy}\u0026#34;) æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ä»£ç ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®‰è£…ç›¸åº”çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ # å¦‚TensorFlowæˆ–PyTorchï¼Œä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ # ä½¿ç”¨TensorFlowå’Œé¢„è®­ç»ƒçš„SSDæ¨¡å‹ \u0026#34;\u0026#34;\u0026#34; import tensorflow as tf # åŠ è½½é¢„è®­ç»ƒçš„SSDæ¨¡å‹ model = tf.saved_model.load(\u0026#39;ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\u0026#39;) # é¢„å¤„ç†å›¾åƒ input_tensor = tf.convert_to_tensor(image_rgb) input_tensor = input_tensor[tf.newaxis, ...] # è¿è¡Œæ¨¡å‹ detections = model(input_tensor) # è§£ææ£€æµ‹ç»“æœ num_detections = int(detections.pop(\u0026#39;num_detections\u0026#39;)) detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()} detections[\u0026#39;num_detections\u0026#39;] = num_detections # è¿‡æ»¤æ£€æµ‹ç»“æœ min_score_thresh = 0.5 detections[\u0026#39;detection_classes\u0026#39;] = detections[\u0026#39;detection_classes\u0026#39;].astype(np.int64) indexes = np.where(detections[\u0026#39;detection_scores\u0026#39;] \u0026gt; min_score_thresh)[0] # ç»˜åˆ¶æ£€æµ‹ç»“æœ result_image = image_rgb.copy() for i in indexes: class_id = detections[\u0026#39;detection_classes\u0026#39;][i] score = detections[\u0026#39;detection_scores\u0026#39;][i] bbox = detections[\u0026#39;detection_boxes\u0026#39;][i] # å°†å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†è½¬æ¢ä¸ºåƒç´ åæ ‡ h, w, _ = image_rgb.shape y1, x1, y2, x2 = bbox y1, x1, y2, x2 = int(y1 * h), int(x1 * w), int(y2 * h), int(x2 * w) # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾ cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2) label = f\u0026#34;{class_id}: {score:.2f}\u0026#34; cv2.putText(result_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # æ˜¾ç¤ºæ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(result_image) plt.title(\u0026#39;Deep Learning Object Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() \u0026#34;\u0026#34;\u0026#34; æ€»ç»“ è®¡ç®—æœºè§†è§‰æ˜¯ä¸€ä¸ªå¹¿æ³›è€Œæ·±å…¥çš„é¢†åŸŸï¼Œæœ¬æ–‡ä»‹ç»äº†ä»åŸºç¡€çš„å›¾åƒè¡¨ç¤ºå’Œå¤„ç†åˆ°é«˜çº§çš„ç‰¹å¾æå–å’Œç›®æ ‡æ£€æµ‹çš„åŸºæœ¬æ¦‚å¿µå’Œæ–¹æ³•ã€‚é€šè¿‡å­¦ä¹ è¿™äº›åŸºç¡€çŸ¥è¯†ï¼Œè¯»è€…å¯ä»¥ä¸ºè¿›ä¸€æ­¥æ¢ç´¢è®¡ç®—æœºè§†è§‰çš„æ›´é«˜çº§ä¸»é¢˜æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸæ­£åœ¨ç»å†å¿«é€Ÿå˜é©ã€‚ä¼ ç»Ÿçš„è®¡ç®—æœºè§†è§‰æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ ç›¸ç»“åˆï¼Œæ­£åœ¨æ¨åŠ¨è®¡ç®—æœºè§†è§‰åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ä¸æ–­æ‹“å±•ã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºè§†è§‰çš„åŸºæœ¬åŸç†ï¼Œå¹¶æ¿€å‘è¿›ä¸€æ­¥å­¦ä¹ å’Œæ¢ç´¢çš„å…´è¶£ã€‚\nåœ¨æœªæ¥ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å°†ç»§ç»­å‘å±•ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€å¢å¼ºç°å®ã€æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸå‘æŒ¥è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚æŒæ¡è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå°†ä¸ºè¯»è€…åœ¨è¿™ä¸€å……æ»¡æœºé‡çš„é¢†åŸŸä¸­å‘å±•æä¾›æœ‰åŠ›æ”¯æŒã€‚\n","permalink":"http://localhost:1313/posts/computer-vision-basics/","summary":"\u003ch1 id=\"è®¡ç®—æœºè§†è§‰åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eè®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eè®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\u003c/p\u003e","title":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£"},{"content":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\næ·±åº¦å­¦ä¹ ä¸å›¾åƒå¤„ç† ä¼ ç»Ÿå›¾åƒå¤„ç†çš„å±€é™æ€§ ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ä¸»è¦ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ç‰¹å¾æå–å™¨å’Œç®—æ³•ï¼Œè¿™äº›æ–¹æ³•è™½ç„¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š\nç‰¹å¾è®¾è®¡å›°éš¾ï¼šéœ€è¦é¢†åŸŸä¸“å®¶è®¾è®¡ç‰¹å¾ï¼Œè€—æ—¶ä¸”éš¾ä»¥æ³›åŒ–ã€‚ é€‚åº”æ€§å·®ï¼šå¯¹å…‰ç…§ã€è§’åº¦ã€å°ºåº¦ç­‰å˜åŒ–æ•æ„Ÿã€‚ å¤æ‚åœºæ™¯å¤„ç†èƒ½åŠ›æœ‰é™ï¼šéš¾ä»¥å¤„ç†å¤æ‚èƒŒæ™¯å’Œå¤šå˜çš„ç¯å¢ƒã€‚ ç«¯åˆ°ç«¯å­¦ä¹ å›°éš¾ï¼šé€šå¸¸éœ€è¦å¤šä¸ªæ­¥éª¤ç»„åˆï¼Œéš¾ä»¥å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚ æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿ æ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œé€šè¿‡è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„è®¸å¤šå±€é™ï¼š\nè‡ªåŠ¨ç‰¹å¾æå–ï¼šæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾ï¼Œç½‘ç»œè‡ªåŠ¨å­¦ä¹ æœ€ä¼˜è¡¨ç¤ºã€‚ å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ï¼šå¤šå±‚ç½‘ç»œç»“æ„å¯ä»¥å­¦ä¹ å¤æ‚çš„ç‰¹å¾å±‚æ¬¡ã€‚ ç«¯åˆ°ç«¯å­¦ä¹ ï¼šä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºï¼Œæ•´ä¸ªè¿‡ç¨‹å¯ä¼˜åŒ–ã€‚ é€‚åº”æ€§å¼ºï¼šå¯¹å„ç§å˜åŒ–å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ã€‚ å¤§æ•°æ®é©±åŠ¨ï¼šèƒ½å¤Ÿåˆ©ç”¨å¤§é‡æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚ å·ç§¯ç¥ç»ç½‘ç»œ(CNN) å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†é¢†åŸŸæœ€æˆåŠŸçš„åº”ç”¨ä¹‹ä¸€ï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäºç”Ÿç‰©è§†è§‰ç³»ç»Ÿã€‚\nCNNçš„åŸºæœ¬ç»“æ„ å…¸å‹çš„CNNç”±ä»¥ä¸‹å‡ ç§å±‚ç»„æˆï¼š\nå·ç§¯å±‚(Convolutional Layer)ï¼šä½¿ç”¨å·ç§¯æ ¸æå–å±€éƒ¨ç‰¹å¾ã€‚ æ± åŒ–å±‚(Pooling Layer)ï¼šé™ä½ç©ºé—´ç»´åº¦ï¼Œå‡å°‘è®¡ç®—é‡ã€‚ æ¿€æ´»å‡½æ•°å±‚(Activation Layer)ï¼šå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚ å…¨è¿æ¥å±‚(Fully Connected Layer)ï¼šæ•´åˆç‰¹å¾ï¼Œè¿›è¡Œæœ€ç»ˆåˆ†ç±»æˆ–å›å½’ã€‚ å½’ä¸€åŒ–å±‚(Normalization Layer)ï¼šå¦‚æ‰¹å½’ä¸€åŒ–(Batch Normalization)ï¼ŒåŠ é€Ÿè®­ç»ƒã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # ä½¿ç”¨PyTorchæ„å»ºç®€å•çš„CNN import torch import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self, num_classes=10): super(SimpleCNN, self).__init__() self.features = nn.Sequential( # å·ç§¯å±‚1 nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚2 nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚3 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2) ) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(128 * 28 * 28, 512), # è¾“å…¥å°ºå¯¸éœ€ä¸ç‰¹å¾å›¾å°ºå¯¸ä¸€è‡´ nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(512, num_classes) ) def forward(self, x): # x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, 3, 224, 224) æˆ–æ ¹æ®å®é™…è¾“å…¥è°ƒæ•´ # è¿”å›åˆ†ç±»ç»“æœ x = self.features(x) x = x.view(x.size(0), -1) x = self.classifier(x) return x ç»å…¸CNNæ¶æ„ LeNet-5 LeNet-5æ˜¯æœ€æ—©çš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œç”±Yann LeCunåœ¨1998å¹´æå‡ºï¼Œä¸»è¦ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class LeNet5(nn.Module): def __init__(self): super(LeNet5, self).__init__() self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1) self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = torch.relu(self.conv1(x)) x = self.pool1(x) x = torch.relu(self.conv2(x)) x = self.pool2(x) x = x.view(-1, 16 * 5 * 5) x = torch.relu(self.fc1(x)) x = torch.relu(self.fc2(x)) x = self.fc3(x) return x AlexNet AlexNetåœ¨2012å¹´ImageNetç«èµ›ä¸­å–å¾—äº†çªç ´æ€§æˆç»©ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å´›èµ·ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class AlexNet(nn.Module): def __init__(self, num_classes=1000): super(AlexNet, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x VGGNet VGGNetä»¥å…¶ç®€æ´çš„ç»“æ„å’Œå‡ºè‰²çš„æ€§èƒ½è‘—ç§°ï¼Œä¸»è¦ç‰¹ç‚¹æ˜¯ä½¿ç”¨å°å°ºå¯¸å·ç§¯æ ¸å’Œæ·±å±‚ç½‘ç»œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class VGG16(nn.Module): def __init__(self, num_classes=1000): super(VGG16, self).__init__() self.features = nn.Sequential( # Block 1 nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 2 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 3 nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 4 nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 5 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) self.classifier = nn.Sequential( nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x ResNet ResNeté€šè¿‡å¼•å…¥æ®‹å·®è¿æ¥è§£å†³äº†æ·±å±‚ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—æ„å»ºæ•°ç™¾ç”šè‡³ä¸Šåƒå±‚çš„ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample self.stride = stride def forward(self, x): identity = x out = self.conv1(x) out = self.bn1(out) out = nn.ReLU(inplace=True)(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = nn.ReLU(inplace=True)(out) return out class ResNet(nn.Module): def __init__(self, block, layers, num_classes=1000): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2) self.layer3 = self._make_layer(block, 256, layers[2], stride=2) self.layer4 = self._make_layer(block, 512, layers[3], stride=2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def _make_layer(self, block, channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != channels * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channels, channels * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channels * block.expansion), ) layers = [] layers.append(block(self.in_channels, channels, stride, downsample)) self.in_channels = channels * block.expansion for _ in range(1, blocks): layers.append(block(self.in_channels, channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = nn.ReLU(inplace=True)(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x def resnet18(): return ResNet(BasicBlock, [2, 2, 2, 2]) CNNåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒåˆ†ç±» å›¾åƒåˆ†ç±»æ˜¯CNNæœ€åŸºæœ¬çš„åº”ç”¨ï¼Œé€šè¿‡è®­ç»ƒç½‘ç»œè¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNetè¿›è¡Œå›¾åƒåˆ†ç±» import torchvision.models as models import torchvision.transforms as transforms from PIL import Image # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = models.resnet18(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image) input_batch = input_tensor.unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_batch) # è·å–é¢„æµ‹ç»“æœ _, predicted_idx = torch.max(output, 1) ç›®æ ‡æ£€æµ‹ ç›®æ ‡æ£€æµ‹ä¸ä»…è¯†åˆ«å›¾åƒä¸­çš„å¯¹è±¡ï¼Œè¿˜ç¡®å®šå®ƒä»¬çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # ä½¿ç”¨Faster R-CNNè¿›è¡Œç›®æ ‡æ£€æµ‹ import torchvision from torchvision.models.detection import fasterrcnn_resnet50_fpn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fasterrcnn_resnet50_fpn(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† transform = transforms.Compose([transforms.ToTensor()]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) image_tensor = transform(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): predictions = model(image_tensor) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡ï¼ŒåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ä½¿ç”¨FCNè¿›è¡Œè¯­ä¹‰åˆ†å‰² from torchvision.models.segmentation import fcn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fcn.fcn_resnet50(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_tensor)[\u0026#39;out\u0026#39;] ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN) ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ˜¯ç”±Ian Goodfellowåœ¨2014å¹´æå‡ºçš„ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚\nGANçš„åŸºæœ¬åŸç† GANç”±ä¸¤ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼š\nç”Ÿæˆå™¨(Generator)ï¼šè¯•å›¾ç”Ÿæˆé€¼çœŸçš„æ•°æ®ï¼Œä»¥æ¬ºéª—åˆ¤åˆ«å™¨ã€‚ åˆ¤åˆ«å™¨(Discriminator)ï¼šè¯•å›¾åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆå™¨ç”Ÿæˆçš„å‡æ•°æ®ã€‚ è¿™ä¸¤ä¸ªç½‘ç»œé€šè¿‡å¯¹æŠ—è®­ç»ƒä¸æ–­æ”¹è¿›ï¼Œæœ€ç»ˆç”Ÿæˆå™¨èƒ½å¤Ÿç”Ÿæˆä¸çœŸå®æ•°æ®åˆ†å¸ƒç›¸ä¼¼çš„æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€å•çš„GANå®ç° import torch import torch.nn as nn class Generator(nn.Module): def __init__(self, latent_dim, img_shape): super(Generator, self).__init__() self.img_shape = img_shape def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *self.img_shape) return img class Discriminator(nn.Module): def __init__(self, img_shape): super(Discriminator, self).__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, img): img_flat = img.view(img.size(0), -1) validity = self.model(img_flat) return validity GANçš„è®­ç»ƒè¿‡ç¨‹ GANçš„è®­ç»ƒè¿‡ç¨‹æ˜¯ä¸€ä¸ªæå°æå¤§åšå¼ˆé—®é¢˜ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # GANè®­ç»ƒå¾ªç¯ import torch.optim as optim # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨ latent_dim = 100 img_shape = (1, 28, 28) # MNISTå›¾åƒå¤§å° generator = Generator(latent_dim, img_shape) discriminator = Discriminator(img_shape) # ä¼˜åŒ–å™¨ optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # æŸå¤±å‡½æ•° adversarial_loss = torch.nn.BCELoss() # è®­ç»ƒå‚æ•° n_epochs = 200 batch_size = 64 for epoch in range(n_epochs): for i, (imgs, _) in enumerate(dataloader): # çœŸå®å’Œå‡çš„æ ‡ç­¾ real = torch.ones(imgs.size(0), 1) fake = torch.zeros(imgs.size(0), 1) # è®­ç»ƒç”Ÿæˆå™¨ optimizer_G.zero_grad() z = torch.randn(imgs.size(0), latent_dim) gen_imgs = generator(z) g_loss = adversarial_loss(discriminator(gen_imgs), real) g_loss.backward() optimizer_G.step() # è®­ç»ƒåˆ¤åˆ«å™¨ optimizer_D.zero_grad() real_loss = adversarial_loss(discriminator(imgs), real) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2 d_loss.backward() optimizer_D.step() å¸¸è§çš„GANå˜ä½“ DCGAN (Deep Convolutional GAN) DCGANå°†CNNç»“æ„å¼•å…¥GANï¼Œæé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class DCGAN_Generator(nn.Module): def __init__(self, latent_dim, channels=1): super(DCGAN_Generator, self).__init__() self.init_size = 7 # åˆå§‹å¤§å° self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2)) self.conv_blocks = nn.Sequential( nn.BatchNorm2d(128), nn.Upsample(scale_factor=2), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.BatchNorm2d(128, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Upsample(scale_factor=2), nn.Conv2d(128, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Conv2d(64, channels, 3, stride=1, padding=1), nn.Tanh(), ) def forward(self, z): out = self.l1(z) out = out.view(out.shape[0], 128, self.init_size, self.init_size) img = self.conv_blocks(out) return img CycleGAN CycleGANç”¨äºåœ¨æ²¡æœ‰æˆå¯¹è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ResidualBlock(nn.Module): def __init__(self, in_features): super(ResidualBlock, self).__init__() self.block = nn.Sequential( nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features), nn.ReLU(inplace=True), nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features) ) def forward(self, x): return x + self.block(x) class GeneratorResNet(nn.Module): def __init__(self, input_shape, num_residual_blocks): super(GeneratorResNet, self).__init__() channels = input_shape[0] # åˆå§‹å·ç§¯å— out_features = 64 model = [ nn.ReflectionPad2d(3), nn.Conv2d(channels, out_features, 7), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # ä¸‹é‡‡æ · for _ in range(2): out_features *= 2 model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # æ®‹å·®å— for _ in range(num_residual_blocks): model += [ResidualBlock(out_features)] # ä¸Šé‡‡æ · for _ in range(2): out_features //= 2 model += [ nn.Upsample(scale_factor=2), nn.Conv2d(in_features, out_features, 3, stride=1, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # è¾“å‡ºå±‚ model += [nn.ReflectionPad2d(3), nn.Conv2d(out_features, channels, 7), nn.Tanh()] self.model = nn.Sequential(*model) def forward(self, x): return self.model(x) StyleGAN StyleGANé€šè¿‡é£æ ¼æ§åˆ¶ç”Ÿæˆé«˜è´¨é‡çš„äººè„¸å›¾åƒï¼Œå…·æœ‰å‡ºè‰²çš„å¯æ§æ€§å’Œå¤šæ ·æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class StyleGAN_Generator(nn.Module): def __init__(self, latent_dim, n_mlp=8): super(StyleGAN_Generator, self).__init__() # æ˜ å°„ç½‘ç»œ layers = [] for i in range(n_mlp): layers.append(nn.Linear(latent_dim, latent_dim)) layers.append(nn.LeakyReLU(0.2)) self.mapping = nn.Sequential(*layers) # åˆæˆç½‘ç»œ self.synthesis = self._build_synthesis_network(latent_dim) def _build_synthesis_network(self, latent_dim): # è¿™é‡Œç®€åŒ–äº†StyleGANçš„åˆæˆç½‘ç»œç»“æ„ # å®é™…çš„StyleGANç»“æ„æ›´ä¸ºå¤æ‚ï¼ŒåŒ…æ‹¬AdaINã€å™ªå£°æ³¨å…¥ç­‰ layers = nn.ModuleList() # åˆå§‹å¸¸æ•° self.constant_input = nn.Parameter(torch.randn(1, 512, 4, 4)) # ç”Ÿæˆå— in_channels = 512 for i in range(8): # 8ä¸ªä¸Šé‡‡æ ·å— out_channels = min(512, 512 // (2 ** (i // 2))) layers.append(StyleGAN_Block(in_channels, out_channels, upsample=(i \u0026gt; 0))) in_channels = out_channels # è¾“å‡ºå±‚ layers.append(nn.Conv2d(in_channels, 3, 1)) layers.append(nn.Tanh()) return nn.Sequential(*layers) def forward(self, z): # é€šè¿‡æ˜ å°„ç½‘ç»œ w = self.mapping(z) # é€šè¿‡åˆæˆç½‘ç»œ x = self.synthesis(w) return x class StyleGAN_Block(nn.Module): def __init__(self, in_channels, out_channels, upsample=False): super(StyleGAN_Block, self).__init__() self.upsample = upsample if upsample: self.up = nn.Upsample(scale_factor=2, mode=\u0026#39;bilinear\u0026#39;, align_corners=False) self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1) self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1) self.activate = nn.LeakyReLU(0.2) def forward(self, x): if self.upsample: x = self.up(x) x = self.conv1(x) x = self.activate(x) x = self.conv2(x) x = self.activate(x) return x GANåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒç”Ÿæˆ GANå¯ä»¥ç”Ÿæˆå„ç§ç±»å‹çš„å›¾åƒï¼Œä»ç®€å•çš„äººè„¸åˆ°å¤æ‚çš„åœºæ™¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨é¢„è®­ç»ƒçš„StyleGANç”Ÿæˆäººè„¸ import torch from stylegan2_pytorch import Generator # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = Generator(256, 512, 8).cuda() # å‡è®¾æœ‰é¢„è®­ç»ƒæƒé‡ model.load_state_dict(torch.load(\u0026#39;stylegan2-ffhq-config-f.pt\u0026#39;)) model.eval() # ç”Ÿæˆéšæœºæ½œåœ¨å‘é‡ z = torch.randn(1, 512).cuda() # ç”Ÿæˆå›¾åƒ with torch.no_grad(): img = model(z) å›¾åƒä¿®å¤ GANå¯ä»¥ç”¨äºä¿®å¤å›¾åƒä¸­çš„ç¼ºå¤±éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # ç®€åŒ–çš„å›¾åƒä¿®å¤æ¨¡å‹ class ImageInpainting(nn.Module): def __init__(self): super(ImageInpainting, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(4, 64, 7, stride=1, padding=3), # 4é€šé“ï¼šRGB + mask nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 512, 3, stride=2, padding=1), nn.ReLU(inplace=True), ) # ä¸­é—´å±‚ self.middle = nn.Sequential( nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 7, stride=1, padding=3), nn.Tanh(), ) def forward(self, x, mask): # è¿æ¥å›¾åƒå’Œæ©ç  x_masked = x * (1 - mask) input = torch.cat([x_masked, mask], dim=1) # ç¼–ç  x = self.encoder(input) # ä¸­é—´å¤„ç† x = self.middle(x) # è§£ç  x = self.decoder(x) # ç»„åˆåŸå§‹å›¾åƒå’Œç”Ÿæˆéƒ¨åˆ† output = x * mask + x_masked return output å›¾åƒè¶…åˆ†è¾¨ç‡ GANå¯ä»¥ç”¨äºå°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 # SRGANç”Ÿæˆå™¨ class SRGAN_Generator(nn.Module): def __init__(self, scale_factor=4): super(SRGAN_Generator, self).__init__() # åˆå§‹å·ç§¯ self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4) self.relu = nn.ReLU(inplace=True) # æ®‹å·®å— residual_blocks = [] for _ in range(16): residual_blocks.append(ResidualBlock(64)) self.residual_blocks = nn.Sequential(*residual_blocks) # ä¸Šé‡‡æ · upsampling = [] for _ in range(int(math.log(scale_factor, 2))): upsampling.append(nn.Conv2d(64, 256, 3, stride=1, padding=1)) upsampling.append(nn.PixelShuffle(2)) upsampling.append(nn.ReLU(inplace=True)) self.upsampling = nn.Sequential(*upsampling) # è¾“å‡ºå±‚ self.conv2 = nn.Conv2d(64, 3, 9, stride=1, padding=4) self.tanh = nn.Tanh() def forward(self, x): # åˆå§‹å·ç§¯ x = self.conv1(x) residual = x x = self.relu(x) # æ®‹å·®å— x = self.residual_blocks(x) # æ®‹å·®è¿æ¥ x = x + residual # ä¸Šé‡‡æ · x = self.upsampling(x) # è¾“å‡º x = self.conv2(x) x = self.tanh(x) return x class ResidualBlock(nn.Module): def __init__(self, channels): super(ResidualBlock, self).__init__() self.conv1 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(channels) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = out + residual return out é£æ ¼è¿ç§» GANå¯ä»¥å®ç°ä»ä¸€ç§è‰ºæœ¯é£æ ¼åˆ°å¦ä¸€ç§é£æ ¼çš„å›¾åƒè½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€åŒ–çš„é£æ ¼è¿ç§»ç½‘ç»œ class StyleTransfer(nn.Module): def __init__(self): super(StyleTransfer, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 9, stride=1, padding=4), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(inplace=True), ) # æ®‹å·®å— residual_blocks = [] for _ in range(5): residual_blocks.append(ResidualBlock(128)) self.residual_blocks = nn.Sequential(*residual_blocks) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 3, 9, stride=1, padding=4), nn.Tanh(), ) def forward(self, x): # ç¼–ç  x = self.encoder(x) # æ®‹å·®å¤„ç† x = self.residual_blocks(x) # è§£ç  x = self.decoder(x) return x å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ è‡ªç¼–ç å™¨(Autoencoder) è‡ªç¼–ç å™¨æ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç¼–ç å™¨å°†è¾“å…¥å‹ç¼©ä¸ºä½ç»´è¡¨ç¤ºï¼Œå†é€šè¿‡è§£ç å™¨é‡æ„åŸå§‹è¾“å…¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Autoencoder(nn.Module): def __init__(self, latent_dim): super(Autoencoder, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), nn.Linear(128 * 4 * 4, latent_dim), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def forward(self, x): z = self.encoder(x) x_reconstructed = self.decoder(z) return x_reconstructed, z å˜åˆ†è‡ªç¼–ç å™¨(VAE) å˜åˆ†è‡ªç¼–ç å™¨æ˜¯è‡ªç¼–ç å™¨çš„æ¦‚ç‡ç‰ˆæœ¬ï¼Œå¯ä»¥ç”Ÿæˆæ–°çš„æ•°æ®æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class VAE(nn.Module): def __init__(self, latent_dim): super(VAE, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), ) # å‡å€¼å’Œæ–¹å·® self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim) self.fc_var = nn.Linear(128 * 4 * 4, latent_dim) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def encode(self, x): h = self.encoder(x) mu = self.fc_mu(h) log_var = self.fc_var(h) return mu, log_var def reparameterize(self, mu, log_var): std = torch.exp(0.5 * log_var) eps = torch.randn_like(std) z = mu + eps * std return z def decode(self, z): return self.decoder(z) def forward(self, x): mu, log_var = self.encode(x) z = self.reparameterize(mu, log_var) x_reconstructed = self.decode(z) return x_reconstructed, mu, log_var æ‰©æ•£æ¨¡å‹(Diffusion Model) æ‰©æ•£æ¨¡å‹æ˜¯è¿‘å¹´æ¥å…´èµ·çš„ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡é€æ­¥æ·»åŠ å’Œå»é™¤å™ªå£°æ¥ç”Ÿæˆå›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class DiffusionModel(nn.Module): def __init__(self, timesteps=1000): super(DiffusionModel, self).__init__() self.timesteps = timesteps # å™ªå£°è°ƒåº¦å™¨ self.beta = torch.linspace(0.0001, 0.02, timesteps) self.alpha = 1. - self.beta self.alpha_hat = torch.cumprod(self.alpha, dim=0) # U-Netç»“æ„ self.unet = self._build_unet() def _build_unet(self): # ç®€åŒ–çš„U-Netç»“æ„ return nn.Sequential( # ä¸‹é‡‡æ · nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), # ä¸­é—´å±‚ nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), # ä¸Šé‡‡æ · nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 3, padding=1), ) def forward(self, x, t): # æ·»åŠ æ—¶é—´åµŒå…¥ t_emb = self._get_time_embedding(t, x.shape[0]) t_emb = t_emb.view(-1, 1, 1, 1).expand(-1, 3, x.shape[2], x.shape[3]) x = torch.cat([x, t_emb], dim=1) # é€šè¿‡U-Neté¢„æµ‹å™ªå£° noise_pred = self.unet(x) return noise_pred def _get_time_embedding(self, t, batch_size): # ç®€åŒ–çš„æ—¶é—´åµŒå…¥ t = t.view(-1, 1) t = t.float() / self.timesteps t = t * 2 * math.pi sin_t = torch.sin(t) cos_t = torch.cos(t) t_emb = torch.cat([sin_t, cos_t], dim=1) t_emb = t_emb.repeat(1, 3) # æ‰©å±•åˆ°3é€šé“ return t_emb def sample(self, x_shape): # ä»çº¯å™ªå£°å¼€å§‹ x = torch.randn(x_shape) # é€æ­¥å»å™ª for t in reversed(range(self.timesteps)): t_batch = torch.full((x_shape[0],), t, dtype=torch.long) noise_pred = self.forward(x, t_batch) # è®¡ç®—å»å™ªåçš„å›¾åƒ alpha_t = self.alpha[t] alpha_hat_t = self.alpha_hat[t] beta_t = self.beta[t] if t \u0026gt; 0: noise = torch.randn_like(x) else: noise = torch.zeros_like(x) x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * noise_pred) + torch.sqrt(beta_t) * noise return x è§†è§‰Transformer(ViT) è§†è§‰Transformerå°†Transformeræ¶æ„åº”ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸Šå–å¾—äº†ä¸CNNç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 class PatchEmbed(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768): super(PatchEmbed, self).__init__() self.img_size = img_size self.patch_size = patch_size self.n_patches = (img_size // patch_size) ** 2 self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size) def forward(self, x): x = self.proj(x) # (B, embed_dim, n_patches ** 0.5, n_patches ** 0.5) x = x.flatten(2) # (B, embed_dim, n_patches) x = x.transpose(1, 2) # (B, n_patches, embed_dim) return x class Attention(nn.Module): def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.): super(Attention, self).__init__() self.n_heads = n_heads self.dim = dim self.head_dim = dim // n_heads self.scale = self.head_dim ** -0.5 self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias) self.attn_drop = nn.Dropout(attn_p) self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_p) def forward(self, x): n_samples, n_tokens, dim = x.shape qkv = self.qkv(x) # (n_samples, n_tokens, 3 * dim) qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim) qkv = qkv.permute(2, 0, 3, 1, 4) # (3, n_samples, n_heads, n_tokens, head_dim) q, k, v = qkv[0], qkv[1], qkv[2] k_t = k.transpose(-2, -1) # (n_samples, n_heads, head_dim, n_tokens) dp = (q @ k_t) * self.scale # (n_samples, n_heads, n_tokens, n_tokens) attn = dp.softmax(dim=-1) # (n_samples, n_heads, n_tokens, n_tokens) attn = self.attn_drop(attn) weighted_avg = attn @ v # (n_samples, n_heads, n_tokens, head_dim) weighted_avg = weighted_avg.transpose(1, 2) # (n_samples, n_tokens, n_heads, head_dim) weighted_avg = weighted_avg.flatten(2) # (n_samples, n_tokens, dim) x = self.proj(weighted_avg) x = self.proj_drop(x) return x class MLP(nn.Module): def __init__(self, in_features, hidden_features, out_features, p=0.): super(MLP, self).__init__() self.fc1 = nn.Linear(in_features, hidden_features) self.act = nn.GELU() self.fc2 = nn.Linear(hidden_features, out_features) self.drop = nn.Dropout(p) def forward(self, x): x = self.fc1(x) x = self.act(x) x = self.drop(x) x = self.fc2(x) x = self.drop(x) return x class Block(nn.Module): def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(Block, self).__init__() self.norm1 = nn.LayerNorm(dim, eps=1e-6) self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p) self.norm2 = nn.LayerNorm(dim, eps=1e-6) hidden_features = int(dim * mlp_ratio) self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim, p=p) def forward(self, x): x = x + self.attn(self.norm1(x)) x = x + self.mlp(self.norm2(x)) return x class VisionTransformer(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, n_classes=1000, embed_dim=768, depth=12, n_heads=12, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(VisionTransformer, self).__init__() self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_channels=in_channels, embed_dim=embed_dim) self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) self.pos_embed = nn.Parameter(torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)) self.pos_drop = nn.Dropout(p=p) self.blocks = nn.ModuleList([ Block(dim=embed_dim, n_heads=n_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, p=p, attn_p=attn_p) for _ in range(depth) ]) self.norm = nn.LayerNorm(embed_dim, eps=1e-6) self.head = nn.Linear(embed_dim, n_classes) def forward(self, x): n_samples = x.shape[0] x = self.patch_embed(x) cls_token = self.cls_token.expand(n_samples, -1, -1) x = torch.cat((cls_token, x), dim=1) x = x + self.pos_embed x = self.pos_drop(x) for block in self.blocks: x = block(x) x = self.norm(x) cls_token_final = x[:, 0] x = self.head(cls_token_final) return x æ·±åº¦å­¦ä¹ å›¾åƒå¤„ç†çš„æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘ å½“å‰æŒ‘æˆ˜ æ•°æ®éœ€æ±‚ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜ã€‚ è®¡ç®—èµ„æºï¼šè®­ç»ƒå¤§å‹æ¨¡å‹éœ€è¦å¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚ å¯è§£é‡Šæ€§ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸è¢«è§†ä¸º\u0026quot;é»‘ç›’\u0026quot;ï¼Œéš¾ä»¥è§£é‡Šå…¶å†³ç­–è¿‡ç¨‹ã€‚ æ³›åŒ–èƒ½åŠ›ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®åˆ†å¸ƒå¤–è¡¨ç°ä¸ä½³ï¼Œé²æ£’æ€§æœ‰å¾…æé«˜ã€‚ é¢†åŸŸé€‚åº”ï¼šå°†æ¨¡å‹ä»ä¸€ä¸ªé¢†åŸŸè¿ç§»åˆ°å¦ä¸€ä¸ªé¢†åŸŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ æœªæ¥æ–¹å‘ è‡ªç›‘ç£å­¦ä¹ ï¼šå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä»æœªæ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ ã€‚ å°æ ·æœ¬å­¦ä¹ ï¼šä½¿æ¨¡å‹èƒ½å¤Ÿä»å°‘é‡æ ·æœ¬ä¸­å­¦ä¹ ã€‚ å¤šæ¨¡æ€å­¦ä¹ ï¼šç»“åˆå›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€çš„ä¿¡æ¯ã€‚ ç¥ç»æ¶æ„æœç´¢ï¼šè‡ªåŠ¨è®¾è®¡æœ€ä¼˜çš„ç½‘ç»œç»“æ„ã€‚ æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿï¼šä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œã€‚ å¯è§£é‡ŠAIï¼šæé«˜æ¨¡å‹çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚ é²æ£’æ€§å¢å¼ºï¼šæé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ ·æœ¬å’Œåˆ†å¸ƒå¤–æ•°æ®çš„é²æ£’æ€§ã€‚ æ€»ç»“ æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯CNNå’ŒGANï¼Œå·²ç»å½»åº•æ”¹å˜äº†å›¾åƒå¤„ç†é¢†åŸŸã€‚ä»å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆå’Œé£æ ¼è¿ç§»ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­éƒ½å–å¾—äº†ä»¤äººç©ç›®çš„æˆæœã€‚\nCNNé€šè¿‡å…¶å±€éƒ¨è¿æ¥å’Œæƒå€¼å…±äº«çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆåœ°æå–å›¾åƒçš„å±‚æ¬¡ç‰¹å¾ï¼Œæˆä¸ºå›¾åƒå¤„ç†çš„åŸºç¡€æ¶æ„ã€‚GANé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä¸ºå›¾åƒç”Ÿæˆå’Œè½¬æ¢ä»»åŠ¡æä¾›äº†å¼ºå¤§çš„å·¥å…·ã€‚\né™¤äº†CNNå’ŒGANï¼Œè‡ªç¼–ç å™¨ã€å˜åˆ†è‡ªç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹å’Œè§†è§‰Transformerç­‰æ¨¡å‹ä¹Ÿåœ¨å›¾åƒå¤„ç†ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œä¸æ–­æ¨åŠ¨ç€è¯¥é¢†åŸŸçš„å‘å±•ã€‚\nå°½ç®¡æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†ä»é¢ä¸´æ•°æ®éœ€æ±‚ã€è®¡ç®—èµ„æºã€å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚æœªæ¥ï¼Œè‡ªç›‘ç£å­¦ä¹ ã€å°æ ·æœ¬å­¦ä¹ ã€å¤šæ¨¡æ€å­¦ä¹ ç­‰æ–¹å‘å°†å¼•é¢†å›¾åƒå¤„ç†é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚\nä½œä¸ºå›¾åƒç®—æ³•å·¥ç¨‹å¸ˆï¼Œäº†è§£å’ŒæŒæ¡è¿™äº›æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹äºè§£å†³å®é™…é—®é¢˜è‡³å…³é‡è¦ã€‚é€šè¿‡ä¸æ–­å­¦ä¹ å’Œå®è·µï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°åº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œæ¨åŠ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åˆ›æ–°å’Œå‘å±•ã€‚\n","permalink":"http://localhost:1313/posts/deep-learning-image-processing/","summary":"\u003ch1 id=\"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ä»cnnåˆ°gan\"\u003eæ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN\u003c/h1\u003e\n\u003cp\u003eæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\u003c/p\u003e","title":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨"},{"content":"ç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ åœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\nç®—æ³•å¤æ‚åº¦åˆ†æ æ—¶é—´å¤æ‚åº¦ æ—¶é—´å¤æ‚åº¦æ˜¯è¡¡é‡ç®—æ³•æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡å¢é•¿è€Œå¢é•¿çš„é€Ÿç‡ã€‚å¸¸è§çš„æ—¶é—´å¤æ‚åº¦ä»ä½åˆ°é«˜ä¾æ¬¡ä¸ºï¼š\nO(1) - å¸¸æ•°æ—¶é—´ å¸¸æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ï¼Œæ˜¯æœ€ç†æƒ³çš„å¤æ‚åº¦ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šè·å–æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´  def get_first_element(arr): return arr[0] # æ— è®ºæ•°ç»„å¤šå¤§ï¼Œæ‰§è¡Œæ—¶é—´ç›¸åŒ O(log n) - å¯¹æ•°æ—¶é—´ å¯¹æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„å¯¹æ•°å¢é•¿ï¼Œå¸¸è§äºåˆ†æ²»ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šäºŒåˆ†æŸ¥æ‰¾ å‚æ•°ï¼šarr (List[int])ï¼Œtarget (int) è¿”å›ï¼šç›®æ ‡ç´¢å¼•æˆ–-1 \u0026#34;\u0026#34;\u0026#34; def binary_search(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: mid = (left + right) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 O(n) - çº¿æ€§æ—¶é—´ çº¿æ€§æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 4 5 6 7 # ç¤ºä¾‹ï¼šæŸ¥æ‰¾æ•°ç»„ä¸­çš„æœ€å¤§å€¼ def find_max(arr): max_val = arr[0] for val in arr: if val \u0026gt; max_val: max_val = val return max_val O(n log n) - çº¿æ€§å¯¹æ•°æ—¶é—´ çº¿æ€§å¯¹æ•°æ—¶é—´ç®—æ³•å¸¸è§äºé«˜æ•ˆçš„æ’åºç®—æ³•ï¼Œå¦‚å¿«é€Ÿæ’åºã€å½’å¹¶æ’åºã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # ç¤ºä¾‹ï¼šå½’å¹¶æ’åº def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) right = merge_sort(arr[mid:]) return merge(left, right) def merge(left, right): result = [] i = j = 0 while i \u0026lt; len(left) and j \u0026lt; len(right): if left[i] \u0026lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result.extend(left[i:]) result.extend(right[j:]) return result O(nÂ²) - å¹³æ–¹æ—¶é—´ å¹³æ–¹æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ï¼Œå¸¸è§äºç®€å•çš„æ’åºç®—æ³•å’ŒåµŒå¥—å¾ªç¯ã€‚\n1 2 3 4 5 6 7 8 # ç¤ºä¾‹ï¼šå†’æ³¡æ’åº def bubble_sort(arr): n = len(arr) for i in range(n): for j in range(0, n - i - 1): if arr[j] \u0026gt; arr[j + 1]: arr[j], arr[j + 1] = arr[j + 1], arr[j] return arr O(2â¿) - æŒ‡æ•°æ—¶é—´ æŒ‡æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡æŒ‡æ•°å¢é•¿ï¼Œé€šå¸¸ç”¨äºè§£å†³NPéš¾é—®é¢˜ã€‚\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šé€’å½’è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼ˆä½æ•ˆç‰ˆæœ¬ï¼‰ å‚æ•°ï¼šn (int) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n \u0026lt;= 1: return n return fibonacci(n - 1) + fibonacci(n - 2) O(n!) - é˜¶ä¹˜æ—¶é—´ é˜¶ä¹˜æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„é˜¶ä¹˜å¢é•¿ï¼Œæ˜¯æœ€å·®çš„å¤æ‚åº¦ï¼Œå¸¸è§äºæš´åŠ›æœç´¢æ‰€æœ‰æ’åˆ—ç»„åˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ç¤ºä¾‹ï¼šç”Ÿæˆæ‰€æœ‰æ’åˆ— def permutations(arr): if len(arr) \u0026lt;= 1: return [arr] result = [] for i in range(len(arr)): rest = arr[:i] + arr[i+1:] for p in permutations(rest): result.append([arr[i]] + p) return result ç©ºé—´å¤æ‚åº¦ ç©ºé—´å¤æ‚åº¦è¡¡é‡ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­æ‰€éœ€é¢å¤–ç©ºé—´éšè¾“å…¥è§„æ¨¡å¢é•¿çš„é€Ÿç‡ã€‚\nO(1) - å¸¸æ•°ç©ºé—´ å¸¸æ•°ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåŸåœ°äº¤æ¢æ•°ç»„å…ƒç´  def swap_elements(arr, i, j): arr[i], arr[j] = arr[j], arr[i] # ä¸éœ€è¦é¢å¤–ç©ºé—´ O(n) - çº¿æ€§ç©ºé—´ çº¿æ€§ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šå¤åˆ¶æ•°ç»„ def copy_array(arr): return arr.copy() # éœ€è¦ä¸åŸæ•°ç»„å¤§å°ç›¸åŒçš„é¢å¤–ç©ºé—´ O(nÂ²) - å¹³æ–¹ç©ºé—´ å¹³æ–¹ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåˆ›å»ºäºŒç»´æ•°ç»„ def create_2d_array(n): return [[0 for _ in range(n)] for _ in range(n)] # éœ€è¦nÂ²çš„é¢å¤–ç©ºé—´ å¤æ‚åº¦åˆ†ææŠ€å·§ å¾ªç¯åˆ†æ å¯¹äºå¾ªç¯ç»“æ„ï¼Œå¤æ‚åº¦é€šå¸¸ç”±å¾ªç¯æ¬¡æ•°å’Œå¾ªç¯ä½“å†…çš„æ“ä½œå†³å®šã€‚\n1 2 3 4 5 6 7 8 9 10 # O(n) - å•å±‚å¾ªç¯ def example1(n): for i in range(n): # å¾ªç¯næ¬¡ print(i) # O(1)æ“ä½œ # O(nÂ²) - åµŒå¥—å¾ªç¯ def example2(n): for i in range(n): # å¤–å±‚å¾ªç¯næ¬¡ for j in range(n): # å†…å±‚å¾ªç¯næ¬¡ print(i, j) # O(1)æ“ä½œ é€’å½’åˆ†æ å¯¹äºé€’å½’ç®—æ³•ï¼Œå¯ä»¥ä½¿ç”¨é€’å½’æ ‘æˆ–ä¸»å®šç†(Master Theorem)æ¥åˆ†æå¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 # é€’å½’æ ‘åˆ†æï¼šå½’å¹¶æ’åº # T(n) = 2T(n/2) + O(n) # æ¯å±‚æ€»å¤æ‚åº¦ä¸ºO(n)ï¼Œå…±æœ‰log nå±‚ï¼Œå› æ­¤æ€»å¤æ‚åº¦ä¸ºO(n log n) def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) # T(n/2) right = merge_sort(arr[mid:]) # T(n/2) return merge(left, right) # O(n) å‡æ‘Šåˆ†æ å‡æ‘Šåˆ†æç”¨äºè®¡ç®—ä¸€ç³»åˆ—æ“ä½œçš„å¹³å‡å¤æ‚åº¦ï¼Œå³ä½¿æŸäº›æ“ä½œå¯èƒ½å¾ˆè€—æ—¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åŠ¨æ€æ•°ç»„çš„å‡æ‘Šåˆ†æ # è™½ç„¶å¶å°”éœ€è¦O(n)æ—¶é—´æ‰©å®¹ï¼Œä½†næ¬¡appendæ“ä½œçš„æ€»æ—¶é—´ä¸ºO(n) # å› æ­¤æ¯æ¬¡appendçš„å‡æ‘Šæ—¶é—´ä¸ºO(1) class DynamicArray: def __init__(self): self.capacity = 1 self.size = 0 self.array = [None] * self.capacity def append(self, item): if self.size == self.capacity: self._resize(2 * self.capacity) # O(n)æ“ä½œï¼Œä½†ä¸é¢‘ç¹ self.array[self.size] = item self.size += 1 def _resize(self, new_capacity): new_array = [None] * new_capacity for i in range(self.size): new_array[i] = self.array[i] self.array = new_array self.capacity = new_capacity ç®—æ³•ä¼˜åŒ–ç­–ç•¥ æ—¶é—´ä¼˜åŒ–ç­–ç•¥ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„æ˜¯ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºé¢‘ç¹æŸ¥æ‰¾æ“ä½œï¼Œå“ˆå¸Œè¡¨(O(1))æ¯”æ•°ç»„(O(n))æ›´é«˜æ•ˆã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨å“ˆå¸Œè¡¨ä¼˜åŒ–æŸ¥æ‰¾ def find_duplicates(arr): seen = set() duplicates = [] for item in arr: if item in seen: # O(1)æŸ¥æ‰¾ duplicates.append(item) else: seen.add(item) return duplicates é¢„è®¡ç®—å’Œç¼“å­˜ å¯¹äºé‡å¤è®¡ç®—ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®¡ç®—æˆ–ç¼“å­˜æŠ€æœ¯é¿å…é‡å¤å·¥ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— \u0026#34;\u0026#34;\u0026#34; ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— å‚æ•°ï¼šn (int), cache (dict) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n, cache={}): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n in cache: return cache[n] if n \u0026lt;= 1: return n result = fibonacci(n - 1, cache) + fibonacci(n - 2, cache) cache[n] = result return result ä½è¿ç®—ä¼˜åŒ– ä½è¿ç®—é€šå¸¸æ¯”ç®—æœ¯è¿ç®—æ›´å¿«ï¼Œå¯ä»¥ç”¨äºæŸäº›ç‰¹å®šåœºæ™¯çš„ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨ä½è¿ç®—åˆ¤æ–­å¥‡å¶ def is_even(n): return (n \u0026amp; 1) == 0 # æ¯”n % 2 == 0æ›´å¿« # ä½¿ç”¨ä½è¿ç®—äº¤æ¢å˜é‡ def swap(a, b): a = a ^ b b = a ^ b a = a ^ b return a, b å¹¶è¡Œè®¡ç®— å¯¹äºå¯ä»¥å¹¶è¡Œå¤„ç†çš„é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å¤šçº¿ç¨‹æˆ–å¤šè¿›ç¨‹åŠ é€Ÿã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† import concurrent.futures def process_data(data): # å¤„ç†æ•°æ®çš„å‡½æ•°ï¼Œè¿”å›å¤„ç†ç»“æœ result = ... # æ ¹æ®å®é™…éœ€æ±‚å¤„ç† return result def parallel_process(data_list, num_workers=4): with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor: results = list(executor.map(process_data, data_list)) return results ç©ºé—´ä¼˜åŒ–ç­–ç•¥ åŸåœ°ç®—æ³• åŸåœ°ç®—æ³•ä¸éœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´æˆ–åªéœ€è¦å¸¸æ•°çº§åˆ«çš„é¢å¤–ç©ºé—´ã€‚\n1 2 3 4 5 6 7 8 # åŸåœ°åè½¬æ•°ç»„ def reverse_array(arr): left, right = 0, len(arr) - 1 while left \u0026lt; right: arr[left], arr[right] = arr[right], arr[left] left += 1 right -= 1 return arr æ•°æ®å‹ç¼© å¯¹äºå¤§è§„æ¨¡æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å‹ç¼©æŠ€æœ¯å‡å°‘å­˜å‚¨éœ€æ±‚ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨ç¨€ç–çŸ©é˜µè¡¨ç¤ºä¼˜åŒ–å­˜å‚¨ class SparseMatrix: def __init__(self, rows, cols): self.rows = rows self.cols = cols self.data = {} # åªå­˜å‚¨éé›¶å…ƒç´  def set(self, i, j, value): if value != 0: self.data[(i, j)] = value elif (i, j) in self.data: del self.data[(i, j)] def get(self, i, j): return self.data.get((i, j), 0) æƒ°æ€§è®¡ç®— æƒ°æ€§è®¡ç®—åªåœ¨éœ€è¦æ—¶æ‰è®¡ç®—ç»“æœï¼Œå¯ä»¥èŠ‚çœä¸å¿…è¦çš„è®¡ç®—å’Œå­˜å‚¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æƒ°æ€§è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ— def lazy_fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b # ä½¿ç”¨ç”Ÿæˆå™¨ fib = lazy_fibonacci() for _ in range(10): print(next(fib)) æ—¶ç©ºæƒè¡¡ æœ‰æ—¶å¯ä»¥é€šè¿‡å¢åŠ ç©ºé—´ä½¿ç”¨æ¥å‡å°‘æ—¶é—´å¤æ‚åº¦ï¼Œæˆ–è€…é€šè¿‡å¢åŠ æ—¶é—´å¤æ‚åº¦æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\nç©ºé—´æ¢æ—¶é—´ ä½¿ç”¨é¢å¤–çš„ç©ºé—´æ¥å­˜å‚¨ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–æœ€é•¿å…¬å…±å­åºåˆ— def longest_common_subsequence(text1, text2): m, n = len(text1), len(text2) # åˆ›å»ºäºŒç»´æ•°ç»„å­˜å‚¨ä¸­é—´ç»“æœ dp = [[0] * (n + 1) for _ in range(m + 1)] for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: dp[i][j] = dp[i - 1][j - 1] + 1 else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[m][n] æ—¶é—´æ¢ç©ºé—´ é€šè¿‡å¢åŠ è®¡ç®—æ—¶é—´æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ def fibonacci_with_rolling_array(n): if n \u0026lt;= 1: return n # åªä¿å­˜æœ€è¿‘çš„ä¸¤ä¸ªå€¼ a, b = 0, 1 for _ in range(2, n + 1): a, b = b, a + b return b å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ æ’åºç®—æ³•ä¼˜åŒ– å¿«é€Ÿæ’åºä¼˜åŒ– å¿«é€Ÿæ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)ï¼Œä½†åœ¨æœ€åæƒ…å†µä¸‹ä¼šé€€åŒ–åˆ°O(nÂ²)ã€‚ä»¥ä¸‹æ˜¯å‡ ç§ä¼˜åŒ–æ–¹æ³•ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def optimized_quick_sort(arr): # ä½¿ç”¨ä¸‰æ•°å–ä¸­æ³•é€‰æ‹©åŸºå‡†ï¼Œé¿å…æœ€åæƒ…å†µ def median_of_three(left, right): mid = (left + right) // 2 if arr[left] \u0026gt; arr[mid]: arr[left], arr[mid] = arr[mid], arr[left] if arr[left] \u0026gt; arr[right]: arr[left], arr[right] = arr[right], arr[left] if arr[mid] \u0026gt; arr[right]: arr[mid], arr[right] = arr[right], arr[mid] return mid def partition(left, right): # é€‰æ‹©åŸºå‡† pivot_idx = median_of_three(left, right) pivot = arr[pivot_idx] # å°†åŸºå‡†ç§»åˆ°æœ€å³è¾¹ arr[pivot_idx], arr[right] = arr[right], arr[pivot_idx] i = left for j in range(left, right): if arr[j] \u0026lt;= pivot: arr[i], arr[j] = arr[j], arr[i] i += 1 # å°†åŸºå‡†ç§»åˆ°æ­£ç¡®ä½ç½® arr[i], arr[right] = arr[right], arr[i] return i def sort(left, right): # å°æ•°ç»„ä½¿ç”¨æ’å…¥æ’åº if right - left + 1 \u0026lt;= 20: insertion_sort(arr, left, right) return if left \u0026lt; right: pivot_idx = partition(left, right) sort(left, pivot_idx - 1) sort(pivot_idx + 1, right) def insertion_sort(arr, left, right): for i in range(left + 1, right + 1): key = arr[i] j = i - 1 while j \u0026gt;= left and arr[j] \u0026gt; key: arr[j + 1] = arr[j] j -= 1 arr[j + 1] = key sort(0, len(arr) - 1) return arr è®¡æ•°æ’åºä¼˜åŒ– è®¡æ•°æ’åºæ˜¯ä¸€ç§éæ¯”è¾ƒæ’åºç®—æ³•ï¼Œé€‚ç”¨äºæ•´æ•°ä¸”èŒƒå›´ä¸å¤§çš„æƒ…å†µã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def counting_sort(arr, max_val=None): if not arr: return arr if max_val is None: max_val = max(arr) # åˆ›å»ºè®¡æ•°æ•°ç»„ count = [0] * (max_val + 1) # ç»Ÿè®¡æ¯ä¸ªå…ƒç´ çš„å‡ºç°æ¬¡æ•° for num in arr: count[num] += 1 # è®¡ç®—ç´¯ç§¯è®¡æ•° for i in range(1, len(count)): count[i] += count[i - 1] # æ„å»ºæ’åºç»“æœ result = [0] * len(arr) for num in reversed(arr): result[count[num] - 1] = num count[num] -= 1 return result æœç´¢ç®—æ³•ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ç§é«˜æ•ˆçš„æœç´¢ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(log n)ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def binary_search_optimized(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: # é˜²æ­¢æ•´æ•°æº¢å‡º mid = left + (right - left) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 è·³è¡¨æœç´¢ä¼˜åŒ– è·³è¡¨æ˜¯ä¸€ç§æ¦‚ç‡æ•°æ®ç»“æ„ï¼Œå…è®¸å¿«é€Ÿæœç´¢ï¼Œç±»ä¼¼äºå¹³è¡¡æ ‘ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import random class SkipNode: def __init__(self, val=None, level=0): self.val = val self.next = [None] * level class SkipList: def __init__(self, max_level=16, p=0.5): self.max_level = max_level self.p = p self.level = 1 self.head = SkipNode(None, max_level) def random_level(self): level = 1 while random.random() \u0026lt; self.p and level \u0026lt; self.max_level: level += 1 return level def insert(self, val): update = [None] * self.max_level current = self.head # æ‰¾åˆ°æ’å…¥ä½ç½® for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] update[i] = current # åˆ›å»ºæ–°èŠ‚ç‚¹ node_level = self.random_level() if node_level \u0026gt; self.level: for i in range(self.level, node_level): update[i] = self.head self.level = node_level # æ’å…¥æ–°èŠ‚ç‚¹ new_node = SkipNode(val, node_level) for i in range(node_level): new_node.next[i] = update[i].next[i] update[i].next[i] = new_node def search(self, val): current = self.head for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] current = current.next[0] if current and current.val == val: return True return False å›¾ç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ç”¨äºå¯»æ‰¾å•æºæœ€çŸ­è·¯å¾„ï¼Œå¯ä»¥ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import heapq def dijkstra_optimized(graph, start): n = len(graph) dist = [float(\u0026#39;inf\u0026#39;)] * n dist[start] = 0 # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ— pq = [(0, start)] while pq: current_dist, u = heapq.heappop(pq) # å¦‚æœå·²ç»æ‰¾åˆ°æ›´çŸ­è·¯å¾„ï¼Œè·³è¿‡ if current_dist \u0026gt; dist[u]: continue for v, weight in graph[u]: distance = current_dist + weight if distance \u0026lt; dist[v]: dist[v] = distance heapq.heappush(pq, (distance, v)) return dist A*ç®—æ³•ä¼˜åŒ– A*ç®—æ³•æ˜¯ä¸€ç§å¯å‘å¼æœç´¢ç®—æ³•ï¼Œå¸¸ç”¨äºè·¯å¾„è§„åˆ’ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import heapq def a_star_search(graph, start, goal, heuristic): # ä¼˜å…ˆé˜Ÿåˆ—ï¼š(f_score, node) open_set = [(0, start)] # ä»èµ·ç‚¹åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„å®é™…ä»£ä»· g_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} g_score[start] = 0 # ä»èµ·ç‚¹ç»è¿‡æ¯ä¸ªèŠ‚ç‚¹åˆ°ç»ˆç‚¹çš„ä¼°è®¡ä»£ä»· f_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} f_score[start] = heuristic(start, goal) # è®°å½•è·¯å¾„ came_from = {} while open_set: current_f, current = heapq.heappop(open_set) if current == goal: # é‡å»ºè·¯å¾„ path = [current] while current in came_from: current = came_from[current] path.append(current) return path[::-1] for neighbor in graph[current]: # è®¡ç®—ä»èµ·ç‚¹åˆ°é‚»å±…çš„ä¸´æ—¶g_score tentative_g_score = g_score[current] + graph[current][neighbor] if tentative_g_score \u0026lt; g_score[neighbor]: # æ‰¾åˆ°æ›´å¥½çš„è·¯å¾„ came_from[neighbor] = current g_score[neighbor] = tentative_g_score f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, goal) heapq.heappush(open_set, (f_score[neighbor], neighbor)) return None # æ²¡æœ‰æ‰¾åˆ°è·¯å¾„ åŠ¨æ€è§„åˆ’ä¼˜åŒ– çŠ¶æ€å‹ç¼© å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ä½è¿ç®—è¿›è¡ŒçŠ¶æ€å‹ç¼©ï¼Œå‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # æ—…è¡Œå•†é—®é¢˜(TSP)çš„çŠ¶æ€å‹ç¼©ä¼˜åŒ– def tsp_dp(distances): n = len(distances) # dp[mask][i]è¡¨ç¤ºè®¿é—®è¿‡maskä¸­çš„åŸå¸‚ï¼Œæœ€ååœç•™åœ¨åŸå¸‚içš„æœ€çŸ­è·ç¦» dp = [[float(\u0026#39;inf\u0026#39;)] * n for _ in range(1 \u0026lt;\u0026lt; n)] dp[1][0] = 0 # ä»åŸå¸‚0å¼€å§‹ for mask in range(1 \u0026lt;\u0026lt; n): for i in range(n): if mask \u0026amp; (1 \u0026lt;\u0026lt; i): # å¦‚æœåŸå¸‚iåœ¨maskä¸­ for j in range(n): if not mask \u0026amp; (1 \u0026lt;\u0026lt; j): # å¦‚æœåŸå¸‚jä¸åœ¨maskä¸­ new_mask = mask | (1 \u0026lt;\u0026lt; j) dp[new_mask][j] = min(dp[new_mask][j], dp[mask][i] + distances[i][j]) # è®¡ç®—å›åˆ°èµ·ç‚¹çš„æœ€çŸ­è·ç¦» final_mask = (1 \u0026lt;\u0026lt; n) - 1 min_distance = float(\u0026#39;inf\u0026#39;) for i in range(1, n): min_distance = min(min_distance, dp[final_mask][i] + distances[i][0]) return min_distance æ»šåŠ¨æ•°ç»„ä¼˜åŒ– å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # æœ€é•¿å…¬å…±å­åºåˆ—çš„æ»šåŠ¨æ•°ç»„ä¼˜åŒ– def lcs_rolling_array(text1, text2): m, n = len(text1), len(text2) # ä½¿ç”¨ä¸¤è¡Œæ•°ç»„ä»£æ›¿å®Œæ•´çš„äºŒç»´æ•°ç»„ prev = [0] * (n + 1) curr = [0] * (n + 1) for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: curr[j] = prev[j - 1] + 1 else: curr[j] = max(prev[j], curr[j - 1]) # æ»šåŠ¨æ•°ç»„ prev, curr = curr, prev curr = [0] * (n + 1) return prev[n] å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æ å›¾åƒå¤„ç†ä¸­çš„ä¼˜åŒ– å·ç§¯è¿ç®—ä¼˜åŒ– å·ç§¯è¿ç®—æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import numpy as np def naive_convolution(image, kernel): # åŸå§‹å·ç§¯å®ç° height, width = image.shape k_height, k_width = kernel.shape output = np.zeros((height - k_height + 1, width - k_width + 1)) for i in range(output.shape[0]): for j in range(output.shape[1]): output[i, j] = np.sum(image[i:i+k_height, j:j+k_width] * kernel) return output def optimized_convolution(image, kernel): # ä½¿ç”¨FFTåŠ é€Ÿå·ç§¯ from scipy.signal import fftconvolve return fftconvolve(image, kernel, mode=\u0026#39;valid\u0026#39;) def separable_convolution(image, kernel): # å¯åˆ†ç¦»å·ç§¯ä¼˜åŒ– # å¦‚æœkernelå¯ä»¥åˆ†ç¦»ä¸ºæ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªä¸€ç»´æ ¸ # ä¾‹å¦‚ï¼škernel = h_kernel * v_kernel^T # å‡è®¾kernelæ˜¯å¯åˆ†ç¦»çš„ u, s, vh = np.linalg.svd(kernel) h_kernel = u[:, 0] * np.sqrt(s[0]) v_kernel = vh[0, :] * np.sqrt(s[0]) # å…ˆè¿›è¡Œæ°´å¹³å·ç§¯ temp = np.zeros_like(image) for i in range(image.shape[0]): temp[i, :] = np.convolve(image[i, :], h_kernel, mode=\u0026#39;valid\u0026#39;) # å†è¿›è¡Œå‚ç›´å·ç§¯ output = np.zeros((temp.shape[0] - len(v_kernel) + 1, temp.shape[1])) for j in range(temp.shape[1]): output[:, j] = np.convolve(temp[:, j], v_kernel, mode=\u0026#39;valid\u0026#39;) return output å›¾åƒé‡‘å­—å¡”ä¼˜åŒ– å›¾åƒé‡‘å­—å¡”æ˜¯ä¸€ç§å¤šå°ºåº¦è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥ç”¨äºåŠ é€Ÿå›¾åƒå¤„ç†ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def build_gaussian_pyramid(image, levels): pyramid = [image] for _ in range(levels - 1): # ä¸‹é‡‡æ · image = cv2.pyrDown(image) pyramid.append(image) return pyramid def process_with_pyramid(image, process_func, levels=4): # æ„å»ºé‡‘å­—å¡” pyramid = build_gaussian_pyramid(image, levels) # ä»æœ€ç²—çº§åˆ«å¼€å§‹å¤„ç† result = process_func(pyramid[-1]) # é€çº§ä¸Šé‡‡æ ·å¹¶ç»†åŒ– for i in range(levels - 2, -1, -1): # ä¸Šé‡‡æ ·ç»“æœ result = cv2.pyrUp(result) # è°ƒæ•´å¤§å°ä»¥åŒ¹é…å½“å‰çº§åˆ« result = cv2.resize(result, (pyramid[i].shape[1], pyramid[i].shape[0])) # ä¸å½“å‰çº§åˆ«ç»“åˆ result = process_func(pyramid[i], result) return result æœºå™¨å­¦ä¹ ä¸­çš„ä¼˜åŒ– æ¢¯åº¦ä¸‹é™ä¼˜åŒ– æ¢¯åº¦ä¸‹é™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ï¼Œæœ‰å¤šç§å˜ä½“ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import numpy as np def gradient_descent(X, y, learning_rate=0.01, epochs=1000): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def stochastic_gradient_descent(X, y, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): for i in range(m): # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ xi = X[i:i+1] yi = y[i:i+1] # è®¡ç®—é¢„æµ‹å€¼ prediction = xi.dot(theta) # è®¡ç®—è¯¯å·® error = prediction - yi # è®¡ç®—æ¢¯åº¦ gradient = xi.T.dot(error) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def mini_batch_gradient_descent(X, y, batch_size=32, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # éšæœºæ‰“ä¹±æ•°æ® indices = np.random.permutation(m) X_shuffled = X[indices] y_shuffled = y[indices] # åˆ†æ‰¹å¤„ç† for i in range(0, m, batch_size): X_batch = X_shuffled[i:i+batch_size] y_batch = y_shuffled[i:i+batch_size] # è®¡ç®—é¢„æµ‹å€¼ predictions = X_batch.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y_batch # è®¡ç®—æ¢¯åº¦ gradient = X_batch.T.dot(error) / len(X_batch) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def momentum_gradient_descent(X, y, learning_rate=0.01, momentum=0.9, epochs=1000): m, n = X.shape theta = np.zeros(n) velocity = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°é€Ÿåº¦ velocity = momentum * velocity - learning_rate * gradient # æ›´æ–°å‚æ•° theta += velocity return theta çŸ©é˜µè¿ç®—ä¼˜åŒ– åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼ŒçŸ©é˜µè¿ç®—æ˜¯æ ¸å¿ƒæ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import numpy as np def naive_matrix_multiply(A, B): # åŸå§‹çŸ©é˜µä¹˜æ³•å®ç° m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(m): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] return C def blocked_matrix_multiply(A, B, block_size=32): # åˆ†å—çŸ©é˜µä¹˜æ³•ä¼˜åŒ– m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(0, m, block_size): for j in range(0, p, block_size): for k in range(0, n, block_size): # å¤„ç†å½“å‰å— for ii in range(i, min(i + block_size, m)): for jj in range(j, min(j + block_size, p)): for kk in range(k, min(k + block_size, n)): C[ii, jj] += A[ii, kk] * B[kk, jj] return C def vectorized_matrix_multiply(A, B): # å‘é‡åŒ–çŸ©é˜µä¹˜æ³•ï¼ˆä½¿ç”¨NumPyå†…ç½®å‡½æ•°ï¼‰ return np.dot(A, B) def parallel_matrix_multiply(A, B): # å¹¶è¡ŒçŸ©é˜µä¹˜æ³• from concurrent.futures import ThreadPoolExecutor m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) def compute_row(i): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] with ThreadPoolExecutor() as executor: executor.map(compute_row, range(m)) return C æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ– ç´¢å¼•ä¼˜åŒ– ç´¢å¼•æ˜¯æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–çš„å…³é”®ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æŸ¥è¯¢é€Ÿåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # ç®€å•çš„Bæ ‘ç´¢å¼•å®ç° class BTreeNode: def __init__(self, leaf=False): self.keys = [] self.children = [] self.leaf = leaf class BTree: def __init__(self, t): self.root = BTreeNode(leaf=True) self.t = t # æœ€å°åº¦æ•° def search(self, key, node=None): if node is None: node = self.root i = 0 while i \u0026lt; len(node.keys) and key \u0026gt; node.keys[i]: i += 1 if i \u0026lt; len(node.keys) and key == node.keys[i]: return True # æ‰¾åˆ°é”® if node.leaf: return False # æœªæ‰¾åˆ°é”® return self.search(key, node.children[i]) def insert(self, key): root = self.root if len(root.keys) == (2 * self.t) - 1: # æ ¹èŠ‚ç‚¹å·²æ»¡ï¼Œåˆ›å»ºæ–°æ ¹èŠ‚ç‚¹ new_root = BTreeNode() new_root.children.append(self.root) self.root = new_root self._split_child(new_root, 0) self._insert_nonfull(new_root, key) else: self._insert_nonfull(root, key) def _split_child(self, parent, index): t = self.t y = parent.children[index] z = BTreeNode(leaf=y.leaf) # å°†yçš„ä¸­é—´é”®æå‡åˆ°çˆ¶èŠ‚ç‚¹ parent.keys.insert(index, y.keys[t-1]) # å°†yçš„ååŠéƒ¨åˆ†é”®å¤åˆ¶åˆ°z z.keys = y.keys[t:(2*t-1)] # å¦‚æœyä¸æ˜¯å¶å­èŠ‚ç‚¹ï¼Œå¤åˆ¶å­èŠ‚ç‚¹ if not y.leaf: z.children = y.children[t:(2*t)] # æ›´æ–°yçš„é”®å’Œå­èŠ‚ç‚¹ y.keys = y.keys[0:(t-1)] y.children = y.children[0:t] # å°†zæ’å…¥çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹åˆ—è¡¨ parent.children.insert(index + 1, z) def _insert_nonfull(self, node, key): i = len(node.keys) - 1 if node.leaf: # åœ¨å¶å­èŠ‚ç‚¹ä¸­æ’å…¥é”® node.keys.append(0) while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: node.keys[i+1] = node.keys[i] i -= 1 node.keys[i+1] = key else: # æ‰¾åˆ°åˆé€‚çš„å­èŠ‚ç‚¹ while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: i -= 1 i += 1 # å¦‚æœå­èŠ‚ç‚¹å·²æ»¡ï¼Œå…ˆåˆ†è£‚ if len(node.children[i].keys) == (2 * self.t) - 1: self._split_child(node, i) if key \u0026gt; node.keys[i]: i += 1 self._insert_nonfull(node.children[i], key) æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ– æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–æ˜¯æ•°æ®åº“ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¯ä»¥é€šè¿‡å¤šç§ç­–ç•¥ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class QueryOptimizer: def __init__(self, database): self.database = database def optimize_query(self, query): # è§£ææŸ¥è¯¢ parsed_query = self._parse_query(query) # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = self._generate_execution_plans(parsed_query) # è¯„ä¼°æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬ plan_costs = [self._estimate_cost(plan) for plan in plans] # é€‰æ‹©æˆæœ¬æœ€ä½çš„è®¡åˆ’ best_plan = plans[plan_costs.index(min(plan_costs))] return best_plan def _parse_query(self, query): # ç®€åŒ–çš„æŸ¥è¯¢è§£æ # å®é™…å®ç°ä¼šæ›´å¤æ‚ return { \u0026#39;tables\u0026#39;: query.get(\u0026#39;tables\u0026#39;, []), \u0026#39;conditions\u0026#39;: query.get(\u0026#39;conditions\u0026#39;, []), \u0026#39;projections\u0026#39;: query.get(\u0026#39;projections\u0026#39;, []), \u0026#39;order_by\u0026#39;: query.get(\u0026#39;order_by\u0026#39;, []), \u0026#39;limit\u0026#39;: query.get(\u0026#39;limit\u0026#39;, None) } def _generate_execution_plans(self, parsed_query): # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = [] # ç®€å•å®ç°ï¼šåªè€ƒè™‘è¡¨è¿æ¥é¡ºåº tables = parsed_query[\u0026#39;tables\u0026#39;] # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è¡¨è¿æ¥é¡ºåº from itertools import permutations for table_order in permutations(tables): plan = { \u0026#39;table_order\u0026#39;: table_order, \u0026#39;join_method\u0026#39;: \u0026#39;nested_loop\u0026#39;, # å¯ä»¥æ˜¯nested_loop, hash_join, merge_join \u0026#39;access_method\u0026#39;: {table: \u0026#39;index_scan\u0026#39; for table in tables}, # å¯ä»¥æ˜¯full_scan, index_scan \u0026#39;conditions\u0026#39;: parsed_query[\u0026#39;conditions\u0026#39;], \u0026#39;projections\u0026#39;: parsed_query[\u0026#39;projections\u0026#39;], \u0026#39;order_by\u0026#39;: parsed_query[\u0026#39;order_by\u0026#39;], \u0026#39;limit\u0026#39;: parsed_query[\u0026#39;limit\u0026#39;] } plans.append(plan) return plans def _estimate_cost(self, plan): # ä¼°è®¡æ‰§è¡Œè®¡åˆ’çš„æˆæœ¬ cost = 0 # ä¼°è®¡è¡¨è®¿é—®æˆæœ¬ for table in plan[\u0026#39;table_order\u0026#39;]: access_method = plan[\u0026#39;access_method\u0026#39;][table] table_stats = self.database.get_table_stats(table) if access_method == \u0026#39;full_scan\u0026#39;: cost += table_stats[\u0026#39;row_count\u0026#39;] elif access_method == \u0026#39;index_scan\u0026#39;: # å‡è®¾ç´¢å¼•å¯ä»¥è¿‡æ»¤æ‰90%çš„æ•°æ® cost += table_stats[\u0026#39;row_count\u0026#39;] * 0.1 # ä¼°è®¡è¿æ¥æˆæœ¬ for i in range(len(plan[\u0026#39;table_order\u0026#39;]) - 1): join_method = plan[\u0026#39;join_method\u0026#39;] if join_method == \u0026#39;nested_loop\u0026#39;: # åµŒå¥—å¾ªç¯è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] * right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;hash_join\u0026#39;: # å“ˆå¸Œè¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;merge_join\u0026#39;: # åˆå¹¶è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] # ä¼°è®¡æ’åºæˆæœ¬ if plan[\u0026#39;order_by\u0026#39;]: # å‡è®¾æ’åºæˆæœ¬ä¸ºn log n result_size = cost # ç®€åŒ–å‡è®¾ cost += result_size * np.log2(result_size) return cost æ€§èƒ½åˆ†æå·¥å…· æ—¶é—´åˆ†æå·¥å…· Pythonä¸­çš„æ—¶é—´åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import time import timeit import cProfile import pstats def time_function(func, *args, **kwargs): # ç®€å•çš„æ—¶é—´æµ‹é‡ start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f\u0026#34;å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: {end_time - start_time:.6f} ç§’\u0026#34;) return result def benchmark_function(func, *args, **kwargs): # ä½¿ç”¨timeitè¿›è¡Œæ›´ç²¾ç¡®çš„åŸºå‡†æµ‹è¯• import functools wrapped = functools.partial(func, *args, **kwargs) time_taken = timeit.timeit(wrapped, number=1000) print(f\u0026#34;å‡½æ•° {func.__name__} å¹³å‡æ‰§è¡Œæ—¶é—´: {time_taken/1000:.6f} ç§’\u0026#34;) return func(*args, **kwargs) def profile_function(func, *args, **kwargs): # ä½¿ç”¨cProfileè¿›è¡Œè¯¦ç»†æ€§èƒ½åˆ†æ profiler = cProfile.Profile() profiler.enable() result = func(*args, **kwargs) profiler.disable() stats = pstats.Stats(profiler).sort_stats(\u0026#39;cumulative\u0026#39;) stats.print_stats() return result å†…å­˜åˆ†æå·¥å…· Pythonä¸­çš„å†…å­˜åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import sys import tracemalloc import objgraph def get_object_size(obj): # è·å–å¯¹è±¡çš„å†…å­˜å¤§å° return sys.getsizeof(obj) def trace_memory(func, *args, **kwargs): # è·Ÿè¸ªå†…å­˜ä½¿ç”¨æƒ…å†µ tracemalloc.start() result = func(*args, **kwargs) snapshot = tracemalloc.take_snapshot() top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) print(\u0026#34;[ å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œ ]\u0026#34;) for stat in top_stats[:10]: print(stat) tracemalloc.stop() return result def analyze_object_growth(func, *args, **kwargs): # åˆ†æå¯¹è±¡å¢é•¿æƒ…å†µ objgraph.show_growth() result = func(*args, **kwargs) objgraph.show_growth() return result å¯è§†åŒ–åˆ†æå·¥å…· ä½¿ç”¨matplotlibå¯è§†åŒ–æ€§èƒ½æ•°æ® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import matplotlib.pyplot as plt import numpy as np def plot_time_complexity(algorithms, input_sizes, title=\u0026#34;æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒ\u0026#34;): # ç»˜åˆ¶ç®—æ³•æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒå›¾ plt.figure(figsize=(10, 6)) for name, func in algorithms.items(): times = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡æ‰§è¡Œæ—¶é—´ start_time = time.time() func(test_data) end_time = time.time() times.append(end_time - start_time) plt.plot(input_sizes, times, label=name, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;æ‰§è¡Œæ—¶é—´ (ç§’)\u0026#39;) plt.title(title) plt.legend() plt.grid(True) plt.show() def generate_test_data(size): # ç”Ÿæˆæµ‹è¯•æ•°æ® return np.random.rand(size) def plot_memory_usage(func, input_sizes, title=\u0026#34;å†…å­˜ä½¿ç”¨æƒ…å†µ\u0026#34;): # ç»˜åˆ¶å‡½æ•°å†…å­˜ä½¿ç”¨æƒ…å†µå›¾ memory_usage = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡å†…å­˜ä½¿ç”¨ tracemalloc.start() func(test_data) snapshot = tracemalloc.take_snapshot() current, peak = tracemalloc.get_traced_memory() tracemalloc.stop() memory_usage.append(peak / (1024 * 1024)) # è½¬æ¢ä¸ºMB plt.figure(figsize=(10, 6)) plt.plot(input_sizes, memory_usage, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;å†…å­˜ä½¿ç”¨ (MB)\u0026#39;) plt.title(title) plt.grid(True) plt.show() æ€»ç»“ ç®—æ³•ä¼˜åŒ–æ˜¯æå‡è½¯ä»¶æ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚æœ¬æ–‡ä»ç®—æ³•å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä»‹ç»äº†æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦çš„æ¦‚å¿µåŠåˆ†ææ–¹æ³•ï¼Œç„¶åè¯¦ç»†æ¢è®¨äº†å„ç§ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬æ—¶é—´ä¼˜åŒ–ã€ç©ºé—´ä¼˜åŒ–å’Œæ—¶ç©ºæƒè¡¡ã€‚\né€šè¿‡å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ï¼Œå¦‚æ’åºç®—æ³•ã€æœç´¢ç®—æ³•ã€å›¾ç®—æ³•å’ŒåŠ¨æ€è§„åˆ’çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬äº†è§£äº†å¦‚ä½•å°†ç†è®ºåº”ç”¨åˆ°å®è·µä¸­ã€‚å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æå±•ç¤ºäº†ç®—æ³•ä¼˜åŒ–åœ¨å›¾åƒå¤„ç†ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®åº“æŸ¥è¯¢ç­‰é¢†åŸŸçš„å…·ä½“åº”ç”¨ã€‚\næœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†å„ç§æ€§èƒ½åˆ†æå·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\nç®—æ³•ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­å­¦ä¹ å’Œå®è·µçš„è¿‡ç¨‹ã€‚éšç€æŠ€æœ¯çš„å‘å±•ï¼Œæ–°çš„ä¼˜åŒ–æ–¹æ³•å’Œå·¥å…·ä¸æ–­æ¶Œç°ã€‚æŒæ¡è¿™äº›ä¼˜åŒ–æŠ€å·§ï¼Œä¸ä»…èƒ½å¤Ÿæé«˜ä»£ç æ€§èƒ½ï¼Œè¿˜èƒ½åŸ¹å…»ç³»ç»Ÿæ€ç»´å’Œé—®é¢˜è§£å†³èƒ½åŠ›ï¼Œä¸ºæˆä¸ºä¸€åä¼˜ç§€çš„è½¯ä»¶å·¥ç¨‹å¸ˆå¥ å®šåŸºç¡€ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…æ·±å…¥ç†è§£ç®—æ³•ä¼˜åŒ–çš„åŸç†å’Œæ–¹æ³•ï¼Œå¹¶åœ¨å®é™…å¼€å‘ä¸­çµæ´»åº”ç”¨ï¼Œåˆ›é€ å‡ºæ›´é«˜æ•ˆã€æ›´ä¼˜é›…çš„ä»£ç ã€‚\n","permalink":"http://localhost:1313/posts/algorithm-optimization/","summary":"\u003ch1 id=\"ç®—æ³•ä¼˜åŒ–ä»ç†è®ºåˆ°å®è·µ\"\u003eç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ\u003c/h1\u003e\n\u003cp\u003eåœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\u003c/p\u003e","title":"ç®—æ³•ä¼˜åŒ–ï¼šæå‡ä»£ç æ€§èƒ½çš„å®ç”¨æŠ€å·§"},{"content":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\nå›¾åƒçš„åŸºæœ¬è¡¨ç¤º åƒç´ ä¸å›¾åƒçŸ©é˜µ åœ¨æ•°å­—ä¸–ç•Œä¸­ï¼Œå›¾åƒç”±åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚å¯¹äºç°åº¦å›¾åƒï¼Œæ¯ä¸ªåƒç´ çš„å€¼è¡¨ç¤ºäº®åº¦ï¼Œé€šå¸¸èŒƒå›´æ˜¯0ï¼ˆé»‘è‰²ï¼‰åˆ°255ï¼ˆç™½è‰²ï¼‰ã€‚å¯¹äºå½©è‰²å›¾åƒï¼Œé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“è¡¨ç¤ºï¼Œæ¯ä¸ªé€šé“çš„å€¼èŒƒå›´ä¹Ÿæ˜¯0åˆ°255ã€‚\nåœ¨è®¡ç®—æœºä¸­ï¼Œå›¾åƒé€šå¸¸è¡¨ç¤ºä¸ºçŸ©é˜µã€‚ç°åº¦å›¾åƒæ˜¯äºŒç»´çŸ©é˜µï¼Œè€Œå½©è‰²å›¾åƒæ˜¯ä¸‰ç»´çŸ©é˜µï¼ˆé«˜åº¦Ã—å®½åº¦Ã—é€šé“æ•°ï¼‰ã€‚\n1 2 3 4 5 6 7 8 # Pythonä¸­ä½¿ç”¨NumPyè¡¨ç¤ºå›¾åƒ import numpy as np # åˆ›å»ºä¸€ä¸ª100x100çš„ç°åº¦å›¾åƒï¼ˆå…¨é»‘ï¼‰ gray_image = np.zeros((100, 100), dtype=np.uint8) # åˆ›å»ºä¸€ä¸ª100x100x3çš„å½©è‰²å›¾åƒï¼ˆå…¨é»‘ï¼‰ color_image = np.zeros((100, 100, 3), dtype=np.uint8) å›¾åƒç±»å‹ äºŒå€¼å›¾åƒï¼šæ¯ä¸ªåƒç´ åªæœ‰ä¸¤ä¸ªå¯èƒ½çš„å€¼ï¼ˆé€šå¸¸æ˜¯0å’Œ1ï¼‰ï¼Œè¡¨ç¤ºé»‘ç™½ä¸¤è‰²ã€‚ ç°åº¦å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰ä¸€ä¸ªå€¼ï¼Œè¡¨ç¤ºä»é»‘åˆ°ç™½çš„ç°åº¦çº§åˆ«ã€‚ å½©è‰²å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰å¤šä¸ªå€¼ï¼Œé€šå¸¸ä½¿ç”¨RGBã€HSVæˆ–CMYKç­‰é¢œè‰²æ¨¡å‹è¡¨ç¤ºã€‚ å¤šå…‰è°±å›¾åƒï¼šåŒ…å«å¤šä¸ªå…‰è°±é€šé“çš„å›¾åƒï¼Œå¦‚å«æ˜Ÿå›¾åƒã€‚ 3Då›¾åƒï¼šè¡¨ç¤ºä¸‰ç»´ç©ºé—´æ•°æ®çš„å›¾åƒï¼Œå¦‚åŒ»å­¦CTæ‰«æã€‚ åŸºæœ¬å›¾åƒæ“ä½œ å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨Pythonçš„OpenCVåº“å¯ä»¥è½»æ¾è¯»å–å’Œæ˜¾ç¤ºå›¾åƒï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 import cv2 import matplotlib.pyplot as plt # è¯»å–å›¾åƒ image = cv2.imread(\u0026#39;image.jpg\u0026#39;) # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆOpenCVé»˜è®¤ä½¿ç”¨BGRï¼Œè€Œmatplotlibä½¿ç”¨RGBï¼‰ image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() å›¾åƒç¼©æ”¾ä¸æ—‹è½¬ 1 2 3 4 5 6 7 8 # ç¼©æ”¾å›¾åƒ resized_image = cv2.resize(image, (width, height)) # æ—‹è½¬å›¾åƒ (h, w) = image.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) # æ—‹è½¬45åº¦ï¼Œç¼©æ”¾å› å­ä¸º1.0 rotated_image = cv2.warpAffine(image, M, (w, h)) å›¾åƒè£å‰ªä¸æ‹¼æ¥ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image[100:400, 200:500] # æ‹¼æ¥å›¾åƒ (æ°´å¹³æ‹¼æ¥) horizontal_concat = np.hstack((image1, image2)) # å‚ç›´æ‹¼æ¥ vertical_concat = np.vstack((image1, image2)) å›¾åƒå¢å¼ºæŠ€æœ¯ äº®åº¦ä¸å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 # äº®åº¦è°ƒæ•´ (å¢åŠ 50ä¸ªå•ä½) brightness_image = cv2.add(image, np.ones(image.shape, dtype=np.uint8) * 50) # å¯¹æ¯”åº¦è°ƒæ•´ (1.5å€) contrast_image = cv2.multiply(image, 1.5) ç›´æ–¹å›¾å‡è¡¡åŒ– ç›´æ–¹å›¾å‡è¡¡åŒ–æ˜¯ä¸€ç§å¢å¼ºå›¾åƒå¯¹æ¯”åº¦çš„æ–¹æ³•ï¼Œé€šè¿‡é‡æ–°åˆ†å¸ƒå›¾åƒçš„åƒç´ å¼ºåº¦ï¼Œä½¿å…¶ç›´æ–¹å›¾å¹³å¦åŒ–ã€‚\n1 2 3 # ç°åº¦å›¾åƒç›´æ–¹å›¾å‡è¡¡åŒ– gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) equalized_image = cv2.equalizeHist(gray_image) ä¼½é©¬æ ¡æ­£ ä¼½é©¬æ ¡æ­£ç”¨äºè°ƒæ•´å›¾åƒçš„äº®åº¦ï¼Œç‰¹åˆ«é€‚ç”¨äºæ˜¾ç¤ºè®¾å¤‡çš„éçº¿æ€§å“åº”ã€‚\ngamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼\n1 2 3 4 5 6 7 8 9 # ä¼½é©¬æ ¡æ­£å‡½æ•° def gamma_correction(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) gamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼ å›¾åƒæ»¤æ³¢ å›¾åƒæ»¤æ³¢æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œç”¨äºå»å™ªã€è¾¹ç¼˜æ£€æµ‹å’Œç‰¹å¾æå–ç­‰ä»»åŠ¡ã€‚\nå‡å€¼æ»¤æ³¢ å‡å€¼æ»¤æ³¢æ˜¯æœ€ç®€å•çš„æ»¤æ³¢æ–¹æ³•ä¹‹ä¸€ï¼Œå®ƒç”¨é‚»åŸŸåƒç´ çš„å¹³å‡å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ã€‚\n1 2 # 5x5å‡å€¼æ»¤æ³¢ blurred_image = cv2.blur(image, (5, 5)) é«˜æ–¯æ»¤æ³¢ é«˜æ–¯æ»¤æ³¢ä½¿ç”¨é«˜æ–¯å‡½æ•°ä½œä¸ºæƒé‡ï¼Œå¯¹é‚»åŸŸåƒç´ è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å™ªå£°åŒæ—¶ä¿ç•™è¾¹ç¼˜ä¿¡æ¯ã€‚\n1 2 # 5x5é«˜æ–¯æ»¤æ³¢ gaussian_blurred = cv2.GaussianBlur(image, (5, 5), 0) ä¸­å€¼æ»¤æ³¢ ä¸­å€¼æ»¤æ³¢ç”¨é‚»åŸŸåƒç´ çš„ä¸­å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ï¼Œå¯¹äºå»é™¤æ¤’ç›å™ªå£°ç‰¹åˆ«æœ‰æ•ˆã€‚\n1 2 # 5x5ä¸­å€¼æ»¤æ³¢ median_blurred = cv2.medianBlur(image, 5) åŒè¾¹æ»¤æ³¢ åŒè¾¹æ»¤æ³¢åœ¨è€ƒè™‘ç©ºé—´é‚»è¿‘åº¦çš„åŒæ—¶ï¼Œä¹Ÿè€ƒè™‘åƒç´ å€¼çš„ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿåœ¨å¹³æ»‘å›¾åƒçš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ã€‚\n1 2 # åŒè¾¹æ»¤æ³¢ bilateral_filtered = cv2.bilateralFilter(image, 9, 75, 75) è¾¹ç¼˜æ£€æµ‹ è¾¹ç¼˜æ£€æµ‹æ˜¯å›¾åƒå¤„ç†ä¸­çš„é‡è¦ä»»åŠ¡ï¼Œç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“è¾¹ç•Œã€‚\nSobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Sobelè¾¹ç¼˜æ£€æµ‹ sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3) # æ°´å¹³æ–¹å‘ sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3) # å‚ç›´æ–¹å‘ # è®¡ç®—æ¢¯åº¦å¹…å€¼ gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2) # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´ gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255) Cannyè¾¹ç¼˜æ£€æµ‹ Cannyè¾¹ç¼˜æ£€æµ‹æ˜¯ä¸€ç§å¤šé˜¶æ®µçš„è¾¹ç¼˜æ£€æµ‹ç®—æ³•ï¼Œè¢«è®¤ä¸ºæ˜¯ç›®å‰æœ€ä¼˜çš„è¾¹ç¼˜æ£€æµ‹æ–¹æ³•ä¹‹ä¸€ã€‚\n1 2 # Cannyè¾¹ç¼˜æ£€æµ‹ edges = cv2.Canny(gray, 100, 200) # é˜ˆå€¼1å’Œé˜ˆå€¼2 Laplacianç®—å­ 1 2 3 # Laplacianè¾¹ç¼˜æ£€æµ‹ laplacian = cv2.Laplacian(gray, cv2.CV_64F) laplacian = np.uint8(np.absolute(laplacian)) å½¢æ€å­¦æ“ä½œ å½¢æ€å­¦æ“ä½œåŸºäºå›¾åƒçš„å½¢çŠ¶ï¼Œå¸¸ç”¨äºäºŒå€¼å›¾åƒçš„å¤„ç†ã€‚\nè…èš€ä¸è†¨èƒ€ 1 2 3 4 5 6 7 8 # åˆ›å»ºä¸€ä¸ª5x5çš„æ ¸ kernel = np.ones((5, 5), np.uint8) # è…èš€æ“ä½œ eroded_image = cv2.erode(binary_image, kernel, iterations=1) # è†¨èƒ€æ“ä½œ dilated_image = cv2.dilate(binary_image, kernel, iterations=1) å¼€è¿ç®—ä¸é—­è¿ç®— 1 2 3 4 5 # å¼€è¿ç®—ï¼ˆå…ˆè…èš€åè†¨èƒ€ï¼‰ opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel) # é—­è¿ç®—ï¼ˆå…ˆè†¨èƒ€åè…èš€ï¼‰ closing = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel) å½¢æ€å­¦æ¢¯åº¦ 1 2 # å½¢æ€å­¦æ¢¯åº¦ï¼ˆè†¨èƒ€å‡è…èš€ï¼‰ gradient = cv2.morphologyEx(binary_image, cv2.MORPH_GRADIENT, kernel) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²æ˜¯å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡çš„è¿‡ç¨‹ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦ä»»åŠ¡ã€‚\né˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 # å…¨å±€é˜ˆå€¼åˆ†å‰² _, thresholded = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_threshold = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) åˆ†æ°´å²­ç®—æ³• åˆ†æ°´å²­ç®—æ³•æ˜¯ä¸€ç§åŸºäºæ‹“æ‰‘ç†è®ºçš„å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºå¯¹æ¥è§¦ç‰©ä½“çš„åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 # æ ‡è®°èƒŒæ™¯å’Œå‰æ™¯ ret, markers = cv2.connectedComponents(sure_foreground) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(image, markers) image[markers == -1] = [255, 0, 0] # æ ‡è®°åˆ†æ°´å²­è¾¹ç•Œ K-meansèšç±» 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # å°†å›¾åƒé‡å¡‘ä¸º2Dæ•°ç»„ pixel_values = image.reshape((-1, 3)) pixel_values = np.float32(pixel_values) # å®šä¹‰åœæ­¢æ ‡å‡†å’ŒKå€¼ criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2) k = 3 # åº”ç”¨K-meansèšç±» _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) # è½¬æ¢å›åŸå§‹å›¾åƒå½¢çŠ¶å¹¶åº”ç”¨èšç±»ç»“æœ centers = np.uint8(centers) segmented_image = centers[labels.flatten()] segmented_image = segmented_image.reshape(image.shape) å›¾åƒç‰¹å¾æå– ç‰¹å¾æå–æ˜¯ä»å›¾åƒä¸­æå–æœ‰æ„ä¹‰ä¿¡æ¯çš„è¿‡ç¨‹ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥ç”¨äºå›¾åƒè¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢ç­‰ä»»åŠ¡ã€‚\nè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 # Harrisè§’ç‚¹æ£€æµ‹ gray = np.float32(gray) harris_corners = cv2.cornerHarris(gray, 2, 3, 0.04) harris_corners = cv2.dilate(harris_corners, None) # æ ‡è®°è§’ç‚¹ image[harris_corners \u0026gt; 0.01 * harris_corners.max()] = [0, 0, 255] SIFTç‰¹å¾ SIFTï¼ˆScale-Invariant Feature Transformï¼‰æ˜¯ä¸€ç§ç”¨äºæ£€æµ‹å’Œæè¿°å›¾åƒå±€éƒ¨ç‰¹å¾çš„ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray, keypoints, None) ORBç‰¹å¾ ORBæ˜¯ä¸€ç§å¿«é€Ÿçš„ç‰¹å¾æ£€æµ‹å™¨å’Œæè¿°ç¬¦ï¼Œç»“åˆäº†FASTå…³é”®ç‚¹æ£€æµ‹å™¨å’ŒBRIEFæè¿°ç¬¦ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray, keypoints, None) åº”ç”¨åœºæ™¯ å›¾åƒå¤„ç†æŠ€æœ¯å¹¿æ³›åº”ç”¨äºå„ä¸ªé¢†åŸŸï¼š\nåŒ»å­¦å½±åƒï¼šCTã€MRIå›¾åƒçš„åˆ†æå’Œè¯Šæ–­ï¼Œç»†èƒè®¡æ•°ï¼Œç—…å˜æ£€æµ‹ç­‰ã€‚ è‡ªåŠ¨é©¾é©¶ï¼šè½¦é“çº¿æ£€æµ‹ï¼Œéšœç¢ç‰©è¯†åˆ«ï¼Œäº¤é€šæ ‡å¿—è¯†åˆ«ç­‰ã€‚ å®‰é˜²ç›‘æ§ï¼šäººè„¸è¯†åˆ«ï¼Œè¡Œä¸ºåˆ†æï¼Œå¼‚å¸¸æ£€æµ‹ç­‰ã€‚ å·¥ä¸šæ£€æµ‹ï¼šäº§å“ç¼ºé™·æ£€æµ‹ï¼Œå°ºå¯¸æµ‹é‡ï¼Œè´¨é‡æ§åˆ¶ç­‰ã€‚ é¥æ„Ÿå›¾åƒï¼šåœŸåœ°åˆ©ç”¨åˆ†ç±»ï¼Œç¯å¢ƒç›‘æµ‹ï¼Œç¾å®³è¯„ä¼°ç­‰ã€‚ å¢å¼ºç°å®ï¼šå›¾åƒé…å‡†ï¼Œç›®æ ‡è·Ÿè¸ªï¼Œåœºæ™¯ç†è§£ç­‰ã€‚ æ•°å­—å¨±ä¹ï¼šå›¾åƒç¾åŒ–ï¼Œç‰¹æ•ˆå¤„ç†ï¼Œè™šæ‹Ÿç°å®ç­‰ã€‚ æ€»ç»“ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰çš„åŸºç¡€ï¼Œæ¶µç›–äº†ä»åŸºæœ¬çš„åƒç´ æ“ä½œåˆ°å¤æ‚çš„ç‰¹å¾æå–å’Œåˆ†æã€‚æœ¬æ–‡ä»‹ç»äº†å›¾åƒçš„åŸºæœ¬è¡¨ç¤ºã€åŸºæœ¬æ“ä½œã€å›¾åƒå¢å¼ºæŠ€æœ¯ã€æ»¤æ³¢æ–¹æ³•ã€è¾¹ç¼˜æ£€æµ‹ã€å½¢æ€å­¦æ“ä½œã€å›¾åƒåˆ†å‰²å’Œç‰¹å¾æå–ç­‰å†…å®¹ã€‚\næŒæ¡è¿™äº›åŸºç¡€çŸ¥è¯†å¯¹äºè¿›ä¸€æ­¥å­¦ä¹ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ è‡³å…³é‡è¦ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸éœ€è¦æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©åˆé€‚çš„å›¾åƒå¤„ç†æ–¹æ³•ï¼Œå¹¶å¯èƒ½éœ€è¦ç»„åˆå¤šç§æŠ€æœ¯æ¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¸å¤šä¼ ç»Ÿçš„å›¾åƒå¤„ç†ä»»åŠ¡ç°åœ¨ä¹Ÿå¯ä»¥é€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•å®ç°ï¼Œä½†ç†è§£ä¼ ç»Ÿå›¾åƒå¤„ç†çš„åŸºæœ¬åŸç†ä»ç„¶éå¸¸é‡è¦ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ å…¥é—¨å›¾åƒå¤„ç†é¢†åŸŸï¼Œä¸ºåç»­çš„å­¦ä¹ å’Œç ”ç©¶æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\n","permalink":"http://localhost:1313/posts/image-processing-basics/","summary":"\u003ch1 id=\"å›¾åƒå¤„ç†åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eå›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eå›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\u003c/p\u003e","title":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°æ»¤æ³¢"},{"content":"404 - é¡µé¢ä¸å­˜åœ¨ æŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\næ‚¨å¯ä»¥å°è¯•ï¼š è¿”å›é¦–é¡µ æŸ¥çœ‹æ–‡ç« åˆ—è¡¨ ä½¿ç”¨æœç´¢åŠŸèƒ½ æŸ¥çœ‹ç½‘ç«™åœ°å›¾ å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡å…³äºé¡µé¢ä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\n","permalink":"http://localhost:1313/404/","summary":"\u003ch1 id=\"404---é¡µé¢ä¸å­˜åœ¨\"\u003e404 - é¡µé¢ä¸å­˜åœ¨\u003c/h1\u003e\n\u003cp\u003eæŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\u003c/p\u003e\n\u003ch2 id=\"æ‚¨å¯ä»¥å°è¯•\"\u003eæ‚¨å¯ä»¥å°è¯•ï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/\"\u003eè¿”å›é¦–é¡µ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/\"\u003eæŸ¥çœ‹æ–‡ç« åˆ—è¡¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/search/\"\u003eä½¿ç”¨æœç´¢åŠŸèƒ½\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sitemap.xml\"\u003eæŸ¥çœ‹ç½‘ç«™åœ°å›¾\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eå¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡\u003ca href=\"/about/\"\u003eå…³äºé¡µé¢\u003c/a\u003eä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\u003c/p\u003e","title":"404 é¡µé¢ä¸å­˜åœ¨"},{"content":"ä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\næŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\nå‘å¸ƒäº 2025å¹´9æœˆ24æ—¥ ä¸Šåˆ10:30\n","permalink":"http://localhost:1313/thoughts/2025-09-24-first-thought/","summary":"\u003cp\u003eä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\u003c/p\u003e\n\u003cp\u003eæŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\u003c/p\u003e","title":"åšå®¢éšæƒ³åŠŸèƒ½ä¸Šçº¿äº†"},{"content":"ç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\næœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\nå‘å¸ƒäº 2025å¹´9æœˆ23æ—¥ ä¸‹åˆ3:45\n","permalink":"http://localhost:1313/thoughts/2025-09-23-meditation/","summary":"\u003cp\u003eç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\u003c/p\u003e\n\u003cp\u003eæœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\u003c/p\u003e","title":"å…³äºå†¥æƒ³å’Œç”Ÿæ´»å¹³è¡¡çš„æ€è€ƒ"},{"content":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š Gitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\nGitåŸºç¡€æ¦‚å¿µ ä»€ä¹ˆæ˜¯Gitï¼Ÿ Gitæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œç”±Linus Torvaldsäº2005å¹´åˆ›å»ºã€‚ä¸é›†ä¸­å¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ˆå¦‚SVNï¼‰ä¸åŒï¼ŒGitçš„æ¯ä¸ªå¼€å‘è€…éƒ½æ‹¥æœ‰å®Œæ•´çš„ä»£ç ä»“åº“å‰¯æœ¬ï¼Œè¿™ä½¿å¾—Gitåœ¨é€Ÿåº¦ã€æ•°æ®å®Œæ•´æ€§å’Œæ”¯æŒåˆ†å¸ƒå¼å¼€å‘æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚\nGitçš„åŸºæœ¬å·¥ä½œåŒº Gitæœ‰ä¸‰ä¸ªä¸»è¦çš„å·¥ä½œåŒºï¼š\nå·¥ä½œåŒº(Working Directory)ï¼šä½ å½“å‰æ­£åœ¨å·¥ä½œçš„ç›®å½•ï¼ŒåŒ…å«é¡¹ç›®çš„æ‰€æœ‰æ–‡ä»¶ã€‚ æš‚å­˜åŒº(Staging Area)ï¼šä¹Ÿç§°ä¸º\u0026quot;ç´¢å¼•(Index)\u0026quot;ï¼Œæ˜¯ä¸€ä¸ªä¸´æ—¶ä¿å­˜ä¿®æ”¹çš„åœ°æ–¹ã€‚ æœ¬åœ°ä»“åº“(Local Repository)ï¼šGitä¿å­˜é¡¹ç›®å…ƒæ•°æ®å’Œå¯¹è±¡æ•°æ®åº“çš„åœ°æ–¹ã€‚ æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªè¿œç¨‹ä»“åº“(Remote Repository)ï¼Œé€šå¸¸æ˜¯æ‰˜ç®¡åœ¨GitHubã€GitLabç­‰å¹³å°ä¸Šçš„ä»“åº“ï¼Œç”¨äºå›¢é˜Ÿåä½œå’Œå¤‡ä»½ã€‚\nGitçš„åŸºæœ¬å·¥ä½œæµç¨‹ Gitçš„åŸºæœ¬å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\nåœ¨å·¥ä½œåŒºä¿®æ”¹æ–‡ä»¶ ä½¿ç”¨git addå°†ä¿®æ”¹æ·»åŠ åˆ°æš‚å­˜åŒº ä½¿ç”¨git commitå°†æš‚å­˜åŒºçš„å†…å®¹æäº¤åˆ°æœ¬åœ°ä»“åº“ ä½¿ç”¨git pushå°†æœ¬åœ°ä»“åº“çš„ä¿®æ”¹æ¨é€åˆ°è¿œç¨‹ä»“åº“ GitåŸºæœ¬å‘½ä»¤ åˆå§‹åŒ–é…ç½® é…ç½®ç”¨æˆ·ä¿¡æ¯ 1 2 3 4 5 6 7 8 # é…ç½®å…¨å±€ç”¨æˆ·å git config --global user.name \u0026#34;Your Name\u0026#34; # é…ç½®å…¨å±€é‚®ç®± git config --global user.email \u0026#34;your.email@example.com\u0026#34; # æŸ¥çœ‹é…ç½® git config --list åˆå§‹åŒ–ä»“åº“ 1 2 3 4 5 # åœ¨å½“å‰ç›®å½•åˆå§‹åŒ–Gitä»“åº“ git init # å…‹éš†è¿œç¨‹ä»“åº“ git clone https://github.com/username/repository.git åŸºæœ¬æ“ä½œ æŸ¥çœ‹çŠ¶æ€ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # æŸ¥çœ‹å·¥ä½œåŒºçŠ¶æ€ git status # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä¿®æ”¹æƒ…å†µ # æŸ¥çœ‹ç®€åŒ–çŠ¶æ€ git status -s # ç®€åŒ–è¾“å‡ºï¼Œé€‚åˆå¿«é€ŸæŸ¥çœ‹ # æŸ¥çœ‹æäº¤å†å² git log # æ˜¾ç¤ºè¯¦ç»†æäº¤è®°å½• # æŸ¥çœ‹ç®€æ´æäº¤å†å² git log --oneline # æ¯æ¡æäº¤ä¸€è¡Œï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ # æŸ¥çœ‹å›¾å½¢åŒ–æäº¤å†å² git log --graph --oneline --all æ·»åŠ å’Œæäº¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ·»åŠ æŒ‡å®šæ–‡ä»¶åˆ°æš‚å­˜åŒº git add filename # æ·»åŠ æ‰€æœ‰ä¿®æ”¹åˆ°æš‚å­˜åŒº git add . # æ·»åŠ æ‰€æœ‰ä¿®æ”¹ï¼ˆåŒ…æ‹¬æ–°æ–‡ä»¶ï¼‰åˆ°æš‚å­˜åŒº git add -A # æäº¤æš‚å­˜åŒºå†…å®¹ git commit -m \u0026#34;Commit message\u0026#34; # è·³è¿‡æš‚å­˜åŒºç›´æ¥æäº¤ git commit -a -m \u0026#34;Commit message\u0026#34; # ä¿®æ”¹æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯ git commit --amend æŸ¥çœ‹å’Œæ¯”è¾ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æŸ¥çœ‹å·¥ä½œåŒºä¸æš‚å­˜åŒºçš„å·®å¼‚ git diff # æŸ¥çœ‹æš‚å­˜åŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff --staged # æŸ¥çœ‹å·¥ä½œåŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff HEAD # æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶çš„å·®å¼‚ git diff filename # æŸ¥çœ‹æŒ‡å®šæäº¤çš„å·®å¼‚ git diff commit1 commit2 æ’¤é”€æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ’¤é”€å·¥ä½œåŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°æš‚å­˜åŒºçŠ¶æ€ï¼‰ git checkout -- filename # æ’¤é”€æš‚å­˜åŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°å·¥ä½œåŒºçŠ¶æ€ï¼‰ git reset HEAD filename # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~1 # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~1 # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~n # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~n è¿œç¨‹ä»“åº“æ“ä½œ æ·»åŠ å’Œç®¡ç†è¿œç¨‹ä»“åº“ 1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹è¿œç¨‹ä»“åº“ git remote -v # æ·»åŠ è¿œç¨‹ä»“åº“ git remote add origin https://github.com/username/repository.git # åˆ é™¤è¿œç¨‹ä»“åº“ git remote remove origin # ä¿®æ”¹è¿œç¨‹ä»“åº“URL git remote set-url origin https://github.com/username/new-repository.git æ¨é€å’Œæ‹‰å– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin main # æ¨é€å¹¶è®¾ç½®ä¸Šæ¸¸åˆ†æ”¯ git push -u origin main # æ‹‰å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ git pull origin main # è·å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ï¼ˆä¸åˆå¹¶ï¼‰ git fetch origin # åˆå¹¶è¿œç¨‹åˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge origin/main åˆ†æ”¯ç®¡ç† åˆ†æ”¯çš„åŸºæœ¬æ“ä½œ åˆ›å»ºå’Œåˆ‡æ¢åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # åˆ›å»ºæ–°åˆ†æ”¯ git branch feature-branch # åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯ git checkout feature-branch # åˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯ git checkout -b feature-branch # æŸ¥çœ‹æ‰€æœ‰åˆ†æ”¯ git branch -a # æŸ¥çœ‹æœ¬åœ°åˆ†æ”¯ git branch # æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯ git branch -r åˆå¹¶åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 # åˆ‡æ¢åˆ°ç›®æ ‡åˆ†æ”¯ git checkout main # åˆå¹¶æŒ‡å®šåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge feature-branch # åˆ é™¤å·²åˆå¹¶çš„åˆ†æ”¯ git branch -d feature-branch # å¼ºåˆ¶åˆ é™¤åˆ†æ”¯ï¼ˆå³ä½¿æœªåˆå¹¶ï¼‰ git branch -D feature-branch è§£å†³åˆå¹¶å†²çª å½“åˆå¹¶åˆ†æ”¯æ—¶ï¼Œå¦‚æœä¸¤ä¸ªåˆ†æ”¯å¯¹åŒä¸€æ–‡ä»¶çš„åŒä¸€éƒ¨åˆ†è¿›è¡Œäº†ä¸åŒçš„ä¿®æ”¹ï¼Œå°±ä¼šäº§ç”Ÿåˆå¹¶å†²çªã€‚è§£å†³åˆå¹¶å†²çªçš„æ­¥éª¤å¦‚ä¸‹ï¼š\næ‰§è¡Œgit mergeå‘½ä»¤ï¼ŒGitä¼šæ ‡è®°å†²çªæ–‡ä»¶ æ‰“å¼€å†²çªæ–‡ä»¶ï¼ŒæŸ¥çœ‹å†²çªæ ‡è®°ï¼ˆ\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;, =======, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;ï¼‰ æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶ï¼Œè§£å†³å†²çª ä½¿ç”¨git addæ ‡è®°å†²çªå·²è§£å†³ ä½¿ç”¨git commitå®Œæˆåˆå¹¶ 1 2 3 4 5 6 7 8 9 10 11 # åˆå¹¶åˆ†æ”¯ï¼ˆå‡è®¾äº§ç”Ÿå†²çªï¼‰ git merge feature-branch # æŸ¥çœ‹å†²çªçŠ¶æ€ git status # æ‰‹åŠ¨è§£å†³å†²çªåï¼Œæ ‡è®°å·²è§£å†³ git add conflicted-file # å®Œæˆåˆå¹¶ git commit å˜åŸº(Rebase) å˜åŸºæ˜¯å°†ä¸€ç³»åˆ—æäº¤åº”ç”¨åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šçš„æ“ä½œï¼Œå®ƒå¯ä»¥ä½¿æäº¤å†å²æ›´åŠ çº¿æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # å˜åŸºå½“å‰åˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main # å˜åŸºæŒ‡å®šåˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main feature-branch # äº¤äº’å¼å˜åŸºï¼ˆå¯ä»¥ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æäº¤ï¼‰ git rebase -i HEAD~3 # ç»§ç»­å˜åŸºï¼ˆè§£å†³å†²çªåï¼‰ git rebase --continue # å–æ¶ˆå˜åŸº git rebase --abort æ ‡ç­¾ç®¡ç† æ ‡ç­¾ç”¨äºæ ‡è®°é‡è¦çš„æäº¤ç‚¹ï¼Œé€šå¸¸ç”¨äºç‰ˆæœ¬å‘å¸ƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # åˆ›å»ºè½»é‡æ ‡ç­¾ git tag v1.0.0 # åˆ›å»ºå¸¦æ³¨é‡Šçš„æ ‡ç­¾ git tag -a v1.0.0 -m \u0026#34;Version 1.0.0 release\u0026#34; # æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾ git tag # æŸ¥çœ‹æ ‡ç­¾ä¿¡æ¯ git show v1.0.0 # æ¨é€æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin v1.0.0 # æ¨é€æ‰€æœ‰æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin --tags # åˆ é™¤æœ¬åœ°æ ‡ç­¾ git tag -d v1.0.0 # åˆ é™¤è¿œç¨‹æ ‡ç­¾ git push origin :refs/tags/v1.0.0 Gitå·¥ä½œæµæ¨¡å‹ é›†ä¸­å¼å·¥ä½œæµ é›†ä¸­å¼å·¥ä½œæµæ˜¯æœ€ç®€å•çš„å·¥ä½œæµï¼Œç±»ä¼¼äºSVNçš„å·¥ä½œæ–¹å¼ã€‚æ‰€æœ‰å¼€å‘è€…ç›´æ¥åœ¨ä¸»åˆ†æ”¯ä¸Šå·¥ä½œï¼Œé€‚åˆå°å‹é¡¹ç›®æˆ–ä¸ªäººé¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nå…‹éš†ä»“åº“ åœ¨ä¸»åˆ†æ”¯ä¸Šä¿®æ”¹ä»£ç  æäº¤ä¿®æ”¹ æ¨é€åˆ°è¿œç¨‹ä»“åº“ ä¼˜ç‚¹ï¼š\nç®€å•ç›´è§‚ æ— éœ€å­¦ä¹ åˆ†æ”¯ç®¡ç† ç¼ºç‚¹ï¼š\nå®¹æ˜“äº§ç”Ÿå†²çª ä¸é€‚åˆå›¢é˜Ÿåä½œ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµä¸ºæ¯ä¸ªæ–°åŠŸèƒ½åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„åˆ†æ”¯ï¼Œå¼€å‘å®Œæˆåå†åˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»ä¸»åˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›ä¸»åˆ†æ”¯ åˆ é™¤åŠŸèƒ½åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # åˆ‡æ¢åˆ°ä¸»åˆ†æ”¯ git checkout main # åˆå¹¶åŠŸèƒ½åˆ†æ”¯ git merge feature/new-feature # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature ä¼˜ç‚¹ï¼š\nåŠŸèƒ½éš”ç¦»ï¼Œå‡å°‘å†²çª ä¸»åˆ†æ”¯ä¿æŒç¨³å®š ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\néœ€è¦ç®¡ç†å¤šä¸ªåˆ†æ”¯ åˆå¹¶å¯èƒ½äº§ç”Ÿå†²çª Git Flowå·¥ä½œæµ Git Flowæ˜¯ä¸€ç§æ›´å¤æ‚çš„å·¥ä½œæµï¼Œå®šä¹‰äº†ä¸¥æ ¼çš„åˆ†æ”¯æ¨¡å‹ï¼Œé€‚ç”¨äºå¤§å‹é¡¹ç›®å’Œæ­£å¼å‘å¸ƒã€‚\nåˆ†æ”¯ç±»å‹ï¼š\nmainï¼šä¸»åˆ†æ”¯ï¼Œå§‹ç»ˆä¿æŒå¯å‘å¸ƒçŠ¶æ€ developï¼šå¼€å‘åˆ†æ”¯ï¼Œé›†æˆæ‰€æœ‰åŠŸèƒ½ featureï¼šåŠŸèƒ½åˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œå®Œæˆååˆå¹¶å›develop releaseï¼šå‘å¸ƒåˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œç”¨äºå‡†å¤‡å‘å¸ƒ hotfixï¼šä¿®å¤åˆ†æ”¯ï¼Œä»mainåˆ›å»ºï¼Œç”¨äºç´§æ€¥ä¿®å¤ å·¥ä½œæµç¨‹ï¼š\nä»developåˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›develop ä»developåˆ›å»ºå‘å¸ƒåˆ†æ”¯ æµ‹è¯•å’Œä¿®å¤ åˆå¹¶å‘å¸ƒåˆ†æ”¯åˆ°mainå’Œdevelop ä»mainåˆ›å»ºä¿®å¤åˆ†æ”¯ ä¿®å¤ååˆå¹¶åˆ°mainå’Œdevelop 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # åˆå§‹åŒ–Git Flow git flow init # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git flow feature start new-feature # å®ŒæˆåŠŸèƒ½åˆ†æ”¯ git flow feature finish new-feature # åˆ›å»ºå‘å¸ƒåˆ†æ”¯ git flow release start v1.0.0 # å®Œæˆå‘å¸ƒåˆ†æ”¯ git flow release finish v1.0.0 # åˆ›å»ºä¿®å¤åˆ†æ”¯ git flow hotfix start critical-fix # å®Œæˆä¿®å¤åˆ†æ”¯ git flow hotfix finish critical-fix ä¼˜ç‚¹ï¼š\nç»“æ„æ¸…æ™°ï¼ŒèŒè´£æ˜ç¡® é€‚åˆæ­£å¼å‘å¸ƒ æ”¯æŒç´§æ€¥ä¿®å¤ ç¼ºç‚¹ï¼š\næµç¨‹å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜ åˆ†æ”¯ç®¡ç†ç¹ç å¯¹äºå°å‹é¡¹ç›®è¿‡äºå¤æ‚ GitHub Flowå·¥ä½œæµ GitHub Flowæ˜¯GitHubä½¿ç”¨çš„ä¸€ç§ç®€åŒ–å·¥ä½œæµï¼Œé€‚åˆæŒç»­éƒ¨ç½²çš„é¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºPull Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ éƒ¨ç½² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitHubä¸Šåˆ›å»ºPull Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature git push origin --delete feature/new-feature ä¼˜ç‚¹ï¼š\nç®€å•æ˜äº† é€‚åˆæŒç»­éƒ¨ç½² ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\nä¸é€‚åˆéœ€è¦é•¿æœŸç»´æŠ¤å¤šä¸ªç‰ˆæœ¬çš„é¡¹ç›® ç¼ºå°‘æ˜ç¡®çš„å‘å¸ƒæµç¨‹ GitLab Flowå·¥ä½œæµ GitLab Flowæ˜¯GitLabæ¨èçš„å·¥ä½œæµï¼Œç»“åˆäº†GitHub Flowå’ŒGit Flowçš„ä¼˜ç‚¹ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºMerge Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ ä»mainåˆ›å»ºç¯å¢ƒåˆ†æ”¯ï¼ˆå¦‚stagingã€productionï¼‰ éƒ¨ç½²åˆ°ä¸åŒç¯å¢ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitLabä¸Šåˆ›å»ºMerge Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ›å»ºç¯å¢ƒåˆ†æ”¯ git checkout -b production main git push origin production # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ # ... ä¼˜ç‚¹ï¼š\nç®€å•ä¸”çµæ´» æ”¯æŒå¤šç¯å¢ƒéƒ¨ç½² é€‚åˆæŒç»­äº¤ä»˜ ç¼ºç‚¹ï¼š\nç¯å¢ƒåˆ†æ”¯ç®¡ç†éœ€è¦é¢å¤–å·¥ä½œ å¯¹äºå¤§å‹é¡¹ç›®å¯èƒ½ä¸å¤Ÿä¸¥æ ¼ Gité«˜çº§æŠ€å·§ é’©å­(Hooks) Gité’©å­æ˜¯åœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è‡ªåŠ¨æ‰§è¡Œçš„è„šæœ¬ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚\nå¸¸ç”¨é’©å­ç±»å‹ å®¢æˆ·ç«¯é’©å­ï¼š\npre-commitï¼šæäº¤å‰è¿è¡Œ commit-msgï¼šç¼–è¾‘æäº¤ä¿¡æ¯åè¿è¡Œ pre-pushï¼šæ¨é€å‰è¿è¡Œ æœåŠ¡å™¨ç«¯é’©å­ï¼š\npre-receiveï¼šæ¥æ”¶æ¨é€æ—¶è¿è¡Œ updateï¼šæ›´æ–°åˆ†æ”¯æ—¶è¿è¡Œ post-receiveï¼šæ¥æ”¶æ¨é€åè¿è¡Œ ç¤ºä¾‹ï¼špre-commité’©å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/sh # .git/hooks/pre-commit # æ£€æŸ¥ä»£ç é£æ ¼ npm run lint # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;ä»£ç é£æ ¼æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi # è¿è¡Œæµ‹è¯• npm test # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;æµ‹è¯•å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi å­æ¨¡å—(Submodules) Gitå­æ¨¡å—å…è®¸ä½ å°†ä¸€ä¸ªGitä»“åº“ä½œä¸ºå¦ä¸€ä¸ªGitä»“åº“çš„å­ç›®å½•ã€‚\næ·»åŠ å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 # æ·»åŠ å­æ¨¡å— git submodule add https://github.com/username/submodule-repository.git path/to/submodule # åˆå§‹åŒ–å­æ¨¡å— git submodule init # æ›´æ–°å­æ¨¡å— git submodule update # é€’å½’å…‹éš†åŒ…å«å­æ¨¡å—çš„ä»“åº“ git clone --recursive https://github.com/username/repository.git æ›´æ–°å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 12 # è¿›å…¥å­æ¨¡å—ç›®å½• cd path/to/submodule # æ‹‰å–æœ€æ–°ä»£ç  git pull origin main # è¿”å›ä¸»ä»“åº“ cd .. # æäº¤å­æ¨¡å—æ›´æ–° git add path/to/submodule git commit -m \u0026#34;Update submodule\u0026#34; å˜åŸº(Rebase)é«˜çº§ç”¨æ³• äº¤äº’å¼å˜åŸº äº¤äº’å¼å˜åŸºå…è®¸ä½ ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æˆ–é‡æ–°æ’åºæäº¤ã€‚\n1 2 # å¯¹æœ€è¿‘çš„3ä¸ªæäº¤è¿›è¡Œäº¤äº’å¼å˜åŸº git rebase -i HEAD~3 åœ¨æ‰“å¼€çš„ç¼–è¾‘å™¨ä¸­ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„å†…å®¹ï¼š\npick f7f3f6d Commit message 1 pick 310154e Commit message 2 pick a5f4a0d Commit message 3 # Rebase 1234567..a5f4a0d onto 1234567 (3 commands) # # Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to re-use the original merge # . commit\u0026#39;s author and message. # # These lines can be re-ordered; they are executed from top to bottom. ä½ å¯ä»¥é€šè¿‡ä¿®æ”¹å‘½ä»¤å‰çš„å…³é”®å­—æ¥æ”¹å˜æäº¤çš„å¤„ç†æ–¹å¼ã€‚\nå˜åŸº vs åˆå¹¶ å˜åŸºå’Œåˆå¹¶éƒ½æ˜¯æ•´åˆåˆ†æ”¯æ›´æ”¹çš„æ–¹æ³•ï¼Œä½†å®ƒä»¬æœ‰ä¸åŒçš„å·¥ä½œæ–¹å¼ï¼š\nåˆå¹¶(Merge)ï¼š\nåˆ›å»ºä¸€ä¸ªæ–°çš„\u0026quot;åˆå¹¶æäº¤\u0026quot; ä¿ç•™å®Œæ•´çš„åˆ†æ”¯å†å² é€‚åˆå…¬å…±åˆ†æ”¯ å˜åŸº(Rebase)ï¼š\nå°†æäº¤é‡æ–°åº”ç”¨åˆ°ç›®æ ‡åˆ†æ”¯ åˆ›å»ºçº¿æ€§çš„æäº¤å†å² é€‚åˆç§æœ‰åˆ†æ”¯ 1 2 3 4 5 6 7 # åˆå¹¶åˆ†æ”¯ git checkout main git merge feature-branch # å˜åŸºåˆ†æ”¯ git checkout feature-branch git rebase main å‚¨è—(Stash) å‚¨è—å…è®¸ä½ ä¸´æ—¶ä¿å­˜æœªæäº¤çš„ä¿®æ”¹ï¼Œä»¥ä¾¿åˆ‡æ¢åˆ†æ”¯æˆ–æ‰§è¡Œå…¶ä»–æ“ä½œã€‚\nåŸºæœ¬å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # å‚¨è—å½“å‰ä¿®æ”¹ git stash # å‚¨è—å¹¶æ·»åŠ è¯´æ˜ git stash save \u0026#34;Work in progress\u0026#34; # æŸ¥çœ‹å‚¨è—åˆ—è¡¨ git stash list # åº”ç”¨æœ€æ–°å‚¨è—ï¼ˆä¸åˆ é™¤ï¼‰ git stash apply # åº”ç”¨å¹¶åˆ é™¤æœ€æ–°å‚¨è— git stash pop # åº”ç”¨æŒ‡å®šå‚¨è— git stash apply stash@{1} # åˆ é™¤æŒ‡å®šå‚¨è— git stash drop stash@{1} # æ¸…é™¤æ‰€æœ‰å‚¨è— git stash clear é«˜çº§å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 # å‚¨è—æœªè·Ÿè¸ªçš„æ–‡ä»¶ git stash -u # å‚¨è—åŒ…æ‹¬å¿½ç•¥çš„æ–‡ä»¶ git stash -a # ä»å‚¨è—åˆ›å»ºåˆ†æ”¯ git stash branch new-branch stash@{1} ç­¾é€‰(Cherry-pick) ç­¾é€‰å…è®¸ä½ é€‰æ‹©ç‰¹å®šçš„æäº¤ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°å½“å‰åˆ†æ”¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ç­¾é€‰æŒ‡å®šæäº¤ git cherry-pick commit-hash # ç­¾é€‰ä½†ä¸æäº¤ git cherry-pick -n commit-hash # ç­¾é€‰å¹¶ç¼–è¾‘æäº¤ä¿¡æ¯ git cherry-pick -e commit-hash # ç­¾é€‰å¤šä¸ªæäº¤ git cherry-pick commit1 commit2 commit3 # ç­¾é€‰ä¸€ç³»åˆ—æäº¤ git cherry-pick commit1..commit3 # ä¸­æ­¢ç­¾é€‰ git cherry-pick --abort # ç»§ç»­ç­¾é€‰ï¼ˆè§£å†³å†²çªåï¼‰ git cherry-pick --continue å¼•ç”¨æ—¥å¿—(Reflog) å¼•ç”¨æ—¥å¿—è®°å½•äº†Gitä»“åº“ä¸­æ‰€æœ‰å¼•ç”¨çš„æ›´æ–°ï¼ŒåŒ…æ‹¬è¢«åˆ é™¤çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹å¼•ç”¨æ—¥å¿— git reflog # æŸ¥çœ‹æŒ‡å®šåˆ†æ”¯çš„å¼•ç”¨æ—¥å¿— git reflog show main # æŸ¥çœ‹å¼•ç”¨æ—¥å¿—å¹¶æ˜¾ç¤ºå·®å¼‚ git reflog show --stat # æ¢å¤è¢«åˆ é™¤çš„æäº¤ git reset --hard HEAD@{1} äºŒåˆ†æŸ¥æ‰¾(Bisect) äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºå¿«é€Ÿå®šä½å¼•å…¥é—®é¢˜çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # å¼€å§‹äºŒåˆ†æŸ¥æ‰¾ git bisect start # æ ‡è®°å½“å‰æäº¤ä¸ºæœ‰é—®é¢˜ git bisect bad # æ ‡è®°å·²çŸ¥æ­£å¸¸çš„æäº¤ git bisect good commit-hash # Gitä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸€ä¸ªä¸­é—´æäº¤ï¼Œæµ‹è¯•åæ ‡è®°ä¸ºgoodæˆ–bad git bisect good # æˆ– git bisect bad # é‡å¤æµ‹è¯•è¿‡ç¨‹ï¼Œç›´åˆ°æ‰¾åˆ°é—®é¢˜æäº¤ # ç»“æŸäºŒåˆ†æŸ¥æ‰¾ git bisect reset Gitæœ€ä½³å®è·µ æäº¤è§„èŒƒ æäº¤ä¿¡æ¯æ ¼å¼ è‰¯å¥½çš„æäº¤ä¿¡æ¯åº”è¯¥æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶éµå¾ªä¸€å®šçš„æ ¼å¼ï¼š\n\u0026lt;ç±»å‹\u0026gt;(\u0026lt;èŒƒå›´\u0026gt;): \u0026lt;ä¸»é¢˜\u0026gt; \u0026lt;è¯¦ç»†æè¿°\u0026gt; \u0026lt;é¡µè„š\u0026gt; ç±»å‹ï¼š\nfeatï¼šæ–°åŠŸèƒ½ fixï¼šä¿®å¤bug docsï¼šæ–‡æ¡£æ›´æ–° styleï¼šä»£ç æ ¼å¼ï¼ˆä¸å½±å“ä»£ç è¿è¡Œçš„å˜åŠ¨ï¼‰ refactorï¼šé‡æ„ï¼ˆæ—¢ä¸æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¹Ÿä¸æ˜¯ä¿®æ”¹bugçš„ä»£ç å˜åŠ¨ï¼‰ perfï¼šæ€§èƒ½ä¼˜åŒ– testï¼šå¢åŠ æµ‹è¯• choreï¼šæ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨ èŒƒå›´ï¼šå¯é€‰ï¼Œç”¨äºè¯´æ˜æäº¤å½±å“çš„èŒƒå›´ï¼Œå¦‚docs, api, coreç­‰ã€‚\nä¸»é¢˜ï¼šç®€æ´æè¿°æäº¤å†…å®¹ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦ã€‚\nè¯¦ç»†æè¿°ï¼šå¯é€‰ï¼Œè¯¦ç»†æè¿°æäº¤å†…å®¹ï¼Œæ¯è¡Œä¸è¶…è¿‡72ä¸ªå­—ç¬¦ã€‚\né¡µè„šï¼šå¯é€‰ï¼Œç”¨äºæ ‡è®°Breaking Changesæˆ–å…³é—­Issueã€‚\nç¤ºä¾‹æäº¤ä¿¡æ¯ feat(api): add user authentication endpoint Add a new endpoint for user authentication using JWT tokens. The endpoint supports both username/password and social login methods. Closes #123 åˆ†æ”¯å‘½åè§„èŒƒ è‰¯å¥½çš„åˆ†æ”¯å‘½åå¯ä»¥æé«˜å›¢é˜Ÿåä½œæ•ˆç‡ï¼š\n\u0026lt;ç±»å‹\u0026gt;/\u0026lt;æè¿°\u0026gt; ä¾‹å¦‚ï¼š feature/user-authentication fix/login-bug docs/api-documentation refactor/user-service ä»£ç å®¡æŸ¥ ä»£ç å®¡æŸ¥æ˜¯ä¿è¯ä»£ç è´¨é‡çš„é‡è¦ç¯èŠ‚ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å»ºè®®ï¼š\nä¿æŒå°çš„æäº¤ï¼šæ¯æ¬¡æäº¤åº”è¯¥åªå…³æ³¨ä¸€ä¸ªåŠŸèƒ½æˆ–ä¿®å¤ï¼Œä¾¿äºå®¡æŸ¥ã€‚ æä¾›æ¸…æ™°çš„æè¿°ï¼šåœ¨Pull Requestä¸­è¯¦ç»†è¯´æ˜ä¿®æ”¹å†…å®¹å’ŒåŸå› ã€‚ è‡ªåŠ¨åŒ–æ£€æŸ¥ï¼šä½¿ç”¨CI/CDå·¥å…·è‡ªåŠ¨è¿è¡Œæµ‹è¯•å’Œä»£ç é£æ ¼æ£€æŸ¥ã€‚ å…³æ³¨ä»£ç é€»è¾‘ï¼šä¸ä»…å…³æ³¨ä»£ç é£æ ¼ï¼Œè¿˜è¦å…³æ³¨é€»è¾‘æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚ æä¾›å»ºè®¾æ€§åé¦ˆï¼šå°Šé‡ä»–äººï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚ å¸¸è§é—®é¢˜è§£å†³ æ’¤é”€å·²æ¨é€çš„æäº¤ 1 2 3 4 5 6 7 # æ–¹æ³•1ï¼šåˆ›å»ºæ–°çš„æäº¤æ¥æ’¤é”€ git revert commit-hash git push origin main # æ–¹æ³•2ï¼šå¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git reset --hard HEAD~1 git push --force origin main åˆå¹¶é”™è¯¯çš„åˆ†æ”¯ 1 2 3 4 5 # æ’¤é”€åˆå¹¶ git reset --hard HEAD~1 # å¦‚æœå·²ç»æ¨é€ git revert -m 1 commit-hash æ¸…ç†å†å²è®°å½• 1 2 3 4 5 # äº¤äº’å¼å˜åŸºæ¸…ç†å†å² git rebase -i HEAD~n # å¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git push --force origin main å¤„ç†å¤§æ–‡ä»¶ 1 2 3 4 5 6 7 8 9 10 # æŸ¥æ‰¾å¤§æ–‡ä»¶ git rev-list --objects --all | git cat-file --batch-check=\u0026#39;%(objecttype) %(objectname) %(objectsize) %(rest)\u0026#39; | sed -n \u0026#39;s/^blob //p\u0026#39; | sort -nrk 2 | head -n 10 # ä½¿ç”¨BFG Repo-Cleaneræ¸…ç†å¤§æ–‡ä»¶ java -jar bfg.jar --strip-blobs-bigger-than 100M my-repo.git # æ¸…ç†å¹¶æ¨é€ git reflog expire --expire=now --all git gc --prune=now --aggressive git push --force origin main æ€»ç»“ Gitæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ŒæŒæ¡å…¶å·¥ä½œæµç¨‹å¯¹äºç°ä»£è½¯ä»¶å¼€å‘è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»Gitçš„åŸºæœ¬æ¦‚å¿µå’Œå‘½ä»¤å¼€å§‹ï¼Œé€æ­¥ä»‹ç»äº†åˆ†æ”¯ç®¡ç†ã€å„ç§å·¥ä½œæµæ¨¡å‹ä»¥åŠé«˜çº§æŠ€å·§ã€‚\né€šè¿‡å­¦ä¹ å’Œå®è·µè¿™äº›å†…å®¹ï¼Œä½ å¯ä»¥ï¼š\né«˜æ•ˆç®¡ç†ä¸ªäººé¡¹ç›®çš„ç‰ˆæœ¬ ä¸å›¢é˜Ÿæˆå‘˜åä½œå¼€å‘ å¤„ç†å¤æ‚çš„åˆå¹¶å’Œå†²çª ä½¿ç”¨é«˜çº§åŠŸèƒ½æé«˜å·¥ä½œæ•ˆç‡ è®°ä½ï¼ŒGitçš„å¼ºå¤§ä¹‹å¤„åœ¨äºå…¶çµæ´»æ€§ï¼Œä½ å¯ä»¥æ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥ä½œæµç¨‹å’Œå·¥å…·ã€‚åŒæ—¶ï¼Œè‰¯å¥½çš„å®è·µä¹ æƒ¯ï¼ˆå¦‚æ¸…æ™°çš„æäº¤ä¿¡æ¯ã€è§„èŒƒçš„åˆ†æ”¯å‘½åï¼‰å°†ä½¿ä½ çš„å¼€å‘è¿‡ç¨‹æ›´åŠ é¡ºç•…ã€‚\næœ€åï¼ŒGitæ˜¯ä¸€ä¸ªä¸æ–­å‘å±•çš„å·¥å…·ï¼ŒæŒç»­å­¦ä¹ å’Œæ¢ç´¢æ–°åŠŸèƒ½å°†å¸®åŠ©ä½ æ›´å¥½åœ°åˆ©ç”¨è¿™ä¸ªå¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ æŒæ¡Gitå·¥ä½œæµç¨‹ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚\n","permalink":"http://localhost:1313/posts/git-workflow/","summary":"\u003ch1 id=\"gitå·¥ä½œæµç¨‹ä»å…¥é—¨åˆ°ç²¾é€š\"\u003eGitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š\u003c/h1\u003e\n\u003cp\u003eGitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\u003c/p\u003e","title":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š"},{"content":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\nå›¾åƒåŸºç¡€ å›¾åƒè¡¨ç¤º æ•°å­—å›¾åƒçš„æ¦‚å¿µ æ•°å­—å›¾åƒæ˜¯ç”±æœ‰é™æ•°é‡çš„åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆçš„äºŒç»´çŸ©é˜µã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import numpy as np import matplotlib.pyplot as plt # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç°åº¦å›¾åƒ # 5x5çš„ç°åº¦å›¾åƒï¼Œå€¼èŒƒå›´0-255 gray_image = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ], dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert gray_image is not None, \u0026#34;ç°åº¦å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # æ˜¾ç¤ºå›¾åƒ plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Grayscale Image\u0026#39;) plt.colorbar() plt.show() å½©è‰²å›¾åƒè¡¨ç¤º å½©è‰²å›¾åƒé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“æ¥è¡¨ç¤ºã€‚æ¯ä¸ªåƒç´ ç”±ä¸‰ä¸ªå€¼ç»„æˆï¼Œåˆ†åˆ«ä»£è¡¨çº¢ã€ç»¿ã€è“ä¸‰ä¸ªé¢œè‰²é€šé“çš„å¼ºåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰²å›¾åƒ # 5x5x3çš„RGBå›¾åƒï¼Œå€¼èŒƒå›´0-255 color_image = np.zeros((5, 5, 3), dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert color_image is not None, \u0026#34;å½©è‰²å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # è®¾ç½®çº¢è‰²é€šé“ color_image[:, :, 0] = np.array([ [255, 200, 150, 100, 50], [230, 180, 130, 80, 30], [210, 160, 110, 60, 10], [190, 140, 90, 40, 0], [170, 120, 70, 20, 0] ]) # è®¾ç½®ç»¿è‰²é€šé“ color_image[:, :, 1] = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ]) # è®¾ç½®è“è‰²é€šé“ color_image[:, :, 2] = np.array([ [0, 30, 60, 90, 120], [50, 80, 110, 140, 170], [100, 130, 160, 190, 200], [150, 180, 210, 220, 230], [200, 230, 240, 250, 255] ]) # æ˜¾ç¤ºå›¾åƒ plt.imshow(color_image) plt.title(\u0026#39;Color Image\u0026#39;) plt.show() å…¶ä»–é¢œè‰²ç©ºé—´ é™¤äº†RGBï¼Œè¿˜æœ‰å…¶ä»–å¸¸ç”¨çš„é¢œè‰²ç©ºé—´ï¼Œå¦‚HSVï¼ˆè‰²ç›¸ã€é¥±å’Œåº¦ã€æ˜åº¦ï¼‰å’ŒLabï¼ˆäº®åº¦ã€aé€šé“ã€bé€šé“ï¼‰ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import cv2 # å°†RGBå›¾åƒè½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´ hsv_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2HSV) # å°†RGBå›¾åƒè½¬æ¢ä¸ºLabé¢œè‰²ç©ºé—´ lab_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2Lab) # æ˜¾ç¤ºä¸åŒé¢œè‰²ç©ºé—´çš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(color_image) plt.title(\u0026#39;RGB Image\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(hsv_image) plt.title(\u0026#39;HSV Image\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(lab_image) plt.title(\u0026#39;Lab Image\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå±æ€§ åˆ†è¾¨ç‡ å›¾åƒåˆ†è¾¨ç‡æ˜¯æŒ‡å›¾åƒä¸­åƒç´ çš„æ•°é‡ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºå®½åº¦Ã—é«˜åº¦ï¼ˆå¦‚1920Ã—1080ï¼‰ã€‚é«˜åˆ†è¾¨ç‡å›¾åƒåŒ…å«æ›´å¤šç»†èŠ‚ï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šçš„å­˜å‚¨ç©ºé—´å’Œå¤„ç†æ—¶é—´ã€‚\n1 2 3 4 5 6 # è·å–å›¾åƒåˆ†è¾¨ç‡ height, width = gray_image.shape print(f\u0026#34;ç°åº¦å›¾åƒåˆ†è¾¨ç‡: {width}x{height}\u0026#34;) height, width, channels = color_image.shape print(f\u0026#34;å½©è‰²å›¾åƒåˆ†è¾¨ç‡: {width}x{height}, é€šé“æ•°: {channels}\u0026#34;) ä½æ·±åº¦ ä½æ·±åº¦æ˜¯æŒ‡æ¯ä¸ªåƒç´ ä½¿ç”¨çš„ä½æ•°ï¼Œå†³å®šäº†å›¾åƒå¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ã€‚å¸¸è§çš„ä½æ·±åº¦æœ‰8ä½ï¼ˆ256ä¸ªç°åº¦çº§ï¼‰ã€24ä½ï¼ˆRGBå„8ä½ï¼Œçº¦1670ä¸‡ç§é¢œè‰²ï¼‰ç­‰ã€‚\n1 2 3 4 5 6 7 8 9 10 # æ£€æŸ¥å›¾åƒçš„ä½æ·±åº¦ print(f\u0026#34;ç°åº¦å›¾åƒæ•°æ®ç±»å‹: {gray_image.dtype}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ•°æ®ç±»å‹: {color_image.dtype}\u0026#34;) # è®¡ç®—å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ gray_levels = 2 ** (gray_image.itemsize * 8) color_levels = 2 ** (color_image.itemsize * 8) print(f\u0026#34;ç°åº¦å›¾åƒå¯ä»¥è¡¨ç¤ºçš„ç°åº¦çº§æ•°: {gray_levels}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ¯ä¸ªé€šé“å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²çº§æ•°: {color_levels}\u0026#34;) å›¾åƒåŸºæœ¬å¤„ç† å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨OpenCVè¯»å–å›¾åƒ OpenCVæ˜¯ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„è®¡ç®—æœºè§†è§‰åº“ï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import cv2 # è¯»å–å›¾åƒ # æ³¨æ„ï¼šOpenCVé»˜è®¤ä»¥BGRæ ¼å¼è¯»å–å½©è‰²å›¾åƒ image_bgr = cv2.imread(\u0026#39;example.jpg\u0026#39;) # æ£€æŸ¥å›¾åƒæ˜¯å¦æˆåŠŸè¯»å– if image_bgr is None: print(\u0026#34;æ— æ³•è¯»å–å›¾åƒ\u0026#34;) else: # è½¬æ¢ä¸ºRGBæ ¼å¼ä»¥ä¾¿æ­£ç¡®æ˜¾ç¤º image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.title(\u0026#39;Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() ä½¿ç”¨PIL/Pillowè¯»å–å›¾åƒ Pillowæ˜¯Pythonå›¾åƒå¤„ç†åº“ï¼Œæä¾›äº†ç®€å•æ˜“ç”¨çš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from PIL import Image # è¯»å–å›¾åƒ image = Image.open(\u0026#39;example.jpg\u0026#39;) # æ˜¾ç¤ºå›¾åƒ image.show() # è½¬æ¢ä¸ºnumpyæ•°ç»„ image_array = np.array(image) # æ˜¾ç¤ºå›¾åƒä¿¡æ¯ print(f\u0026#34;å›¾åƒå¤§å°: {image.size}\u0026#34;) print(f\u0026#34;å›¾åƒæ¨¡å¼: {image.mode}\u0026#34;) print(f\u0026#34;å›¾åƒæ•°ç»„å½¢çŠ¶: {image_array.shape}\u0026#34;) å›¾åƒåŸºæœ¬æ“ä½œ è£å‰ªå›¾åƒ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image_rgb[50:200, 100:300] # æ˜¾ç¤ºè£å‰ªåçš„å›¾åƒ plt.imshow(cropped_image) plt.title(\u0026#39;Cropped Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() è°ƒæ•´å›¾åƒå¤§å° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # ä½¿ç”¨OpenCVè°ƒæ•´å›¾åƒå¤§å° resized_cv2 = cv2.resize(image_rgb, (300, 200)) # ä½¿ç”¨PILè°ƒæ•´å›¾åƒå¤§å° resized_pil = Image.fromarray(image_rgb).resize((300, 200)) # æ˜¾ç¤ºè°ƒæ•´å¤§å°åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(resized_cv2) plt.title(\u0026#39;Resized with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(resized_pil) plt.title(\u0026#39;Resized with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() æ—‹è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ä½¿ç”¨OpenCVæ—‹è½¬å›¾åƒ (h, w) = image_rgb.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) rotated_cv2 = cv2.warpAffine(image_rgb, M, (w, h)) # ä½¿ç”¨PILæ—‹è½¬å›¾åƒ rotated_pil = Image.fromarray(image_rgb).rotate(45) # æ˜¾ç¤ºæ—‹è½¬åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(rotated_cv2) plt.title(\u0026#39;Rotated with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(rotated_pil) plt.title(\u0026#39;Rotated with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç¿»è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # æ°´å¹³ç¿»è½¬ flipped_h = cv2.flip(image_rgb, 1) # å‚ç›´ç¿»è½¬ flipped_v = cv2.flip(image_rgb, 0) # æ°´å¹³å’Œå‚ç›´ç¿»è½¬ flipped_hv = cv2.flip(image_rgb, -1) # æ˜¾ç¤ºç¿»è½¬åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(flipped_h) plt.title(\u0026#39;Horizontal Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(flipped_v) plt.title(\u0026#39;Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(flipped_hv) plt.title(\u0026#39;Horizontal and Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå¢å¼º äº®åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ äº®åº¦ brightness_increase = cv2.convertScaleAbs(image_rgb, alpha=1.2, beta=50) # å‡å°‘äº®åº¦ brightness_decrease = cv2.convertScaleAbs(image_rgb, alpha=1.0, beta=-50) # æ˜¾ç¤ºäº®åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(brightness_increase) plt.title(\u0026#39;Increased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(brightness_decrease) plt.title(\u0026#39;Decreased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ å¯¹æ¯”åº¦ contrast_increase = cv2.convertScaleAbs(image_rgb, alpha=1.5, beta=0) # å‡å°‘å¯¹æ¯”åº¦ contrast_decrease = cv2.convertScaleAbs(image_rgb, alpha=0.5, beta=0) # æ˜¾ç¤ºå¯¹æ¯”åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(contrast_increase) plt.title(\u0026#39;Increased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(contrast_decrease) plt.title(\u0026#39;Decreased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›´æ–¹å›¾å‡è¡¡åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # ç›´æ–¹å›¾å‡è¡¡åŒ– equalized_image = cv2.equalizeHist(gray_image) # æ˜¾ç¤ºç›´æ–¹å›¾å‡è¡¡åŒ–å‰åçš„å›¾åƒå’Œç›´æ–¹å›¾ plt.figure(figsize=(15, 10)) # åŸå§‹å›¾åƒ plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Grayscale Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # å‡è¡¡åŒ–åçš„å›¾åƒ plt.subplot(2, 2, 2) plt.imshow(equalized_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Equalized Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # åŸå§‹ç›´æ–¹å›¾ plt.subplot(2, 2, 3) plt.hist(gray_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Original Histogram\u0026#39;) # å‡è¡¡åŒ–åçš„ç›´æ–¹å›¾ plt.subplot(2, 2, 4) plt.hist(equalized_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Equalized Histogram\u0026#39;) plt.tight_layout() plt.show() ä¼½é©¬æ ¡æ­£ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def adjust_gamma(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) # åº”ç”¨ä¸åŒçš„ä¼½é©¬å€¼ gamma_1_5 = adjust_gamma(image_rgb, 1.5) gamma_0_5 = adjust_gamma(image_rgb, 0.5) # æ˜¾ç¤ºä¼½é©¬æ ¡æ­£åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image (Î³=1.0)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(gamma_1_5) plt.title(\u0026#39;Gamma=1.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(gamma_0_5) plt.title(\u0026#39;Gamma=0.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒæ»¤æ³¢ å‡å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # åº”ç”¨ä¸åŒå¤§å°çš„å‡å€¼æ»¤æ³¢ blur_3x3 = cv2.blur(gray_image, (3, 3)) blur_5x5 = cv2.blur(gray_image, (5, 5)) blur_7x7 = cv2.blur(gray_image, (7, 7)) # æ˜¾ç¤ºå‡å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(blur_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(blur_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(blur_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() é«˜æ–¯æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°å’Œæ ‡å‡†å·®çš„é«˜æ–¯æ»¤æ³¢ gaussian_3x3 = cv2.GaussianBlur(gray_image, (3, 3), 0) gaussian_5x5 = cv2.GaussianBlur(gray_image, (5, 5), 0) gaussian_7x7 = cv2.GaussianBlur(gray_image, (7, 7), 0) # æ˜¾ç¤ºé«˜æ–¯æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(gaussian_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(gaussian_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(gaussian_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ä¸­å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°çš„ä¸­å€¼æ»¤æ³¢ median_3 = cv2.medianBlur(gray_image, 3) median_5 = cv2.medianBlur(gray_image, 5) median_7 = cv2.medianBlur(gray_image, 7) # æ˜¾ç¤ºä¸­å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(median_3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(median_5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(median_7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åŒè¾¹æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨åŒè¾¹æ»¤æ³¢ bilateral = cv2.bilateralFilter(gray_image, 9, 75, 75) # æ˜¾ç¤ºåŒè¾¹æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(bilateral, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Bilateral Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è¾¹ç¼˜æ£€æµ‹ Sobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # åº”ç”¨Sobelç®—å­ sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3) sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3) sobel_xy = cv2.Sobel(gray_image, cv2.CV_64F, 1, 1, ksize=3) # è½¬æ¢å›uint8 sobel_x = cv2.convertScaleAbs(sobel_x) sobel_y = cv2.convertScaleAbs(sobel_y) sobel_xy = cv2.convertScaleAbs(sobel_xy) # æ˜¾ç¤ºSobelè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(sobel_x, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel X\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(sobel_y, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel Y\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(sobel_xy, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel XY\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Laplacianç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # åº”ç”¨Laplacianç®—å­ laplacian = cv2.Laplacian(gray_image, cv2.CV_64F) laplacian = cv2.convertScaleAbs(laplacian) # æ˜¾ç¤ºLaplacianè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(laplacian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Laplacian Edge Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Cannyè¾¹ç¼˜æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨Cannyè¾¹ç¼˜æ£€æµ‹ canny_low = cv2.Canny(gray_image, 50, 150) canny_high = cv2.Canny(gray_image, 100, 200) # æ˜¾ç¤ºCannyè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(canny_low, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (50, 150)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(canny_high, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (100, 200)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒåˆ†å‰² é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # åº”ç”¨ä¸åŒç±»å‹çš„é˜ˆå€¼åˆ†å‰² ret, thresh_binary = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY) ret, thresh_binary_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV) ret, thresh_trunc = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TRUNC) ret, thresh_tozero = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO) ret, thresh_tozero_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO_INV) # æ˜¾ç¤ºé˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 2) plt.imshow(thresh_binary, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 3) plt.imshow(thresh_binary_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 4) plt.imshow(thresh_trunc, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Truncated Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 5) plt.imshow(thresh_tozero, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 6) plt.imshow(thresh_tozero_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_mean = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2) adaptive_gaussian = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) # æ˜¾ç¤ºè‡ªé€‚åº”é˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(adaptive_mean, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Mean Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(adaptive_gaussian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Gaussian Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Otsué˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨Otsué˜ˆå€¼åˆ†å‰² ret, otsu = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # æ˜¾ç¤ºOtsué˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(otsu, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;Otsu Threshold (Threshold={ret})\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åˆ†æ°´å²­ç®—æ³• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # åˆ›å»ºä¸€ä¸ªç®€å•çš„äºŒå€¼å›¾åƒ binary_image = np.zeros((300, 300), dtype=np.uint8) cv2.circle(binary_image, (100, 100), 50, 255, -1) cv2.circle(binary_image, (200, 200), 50, 255, -1) # åº”ç”¨è·ç¦»å˜æ¢ dist_transform = cv2.distanceTransform(binary_image, cv2.DIST_L2, 5) ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0) sure_fg = np.uint8(sure_fg) # æœªçŸ¥åŒºåŸŸ unknown = cv2.subtract(binary_image, sure_fg) # æ ‡è®°æ ‡ç­¾ ret, markers = cv2.connectedComponents(sure_fg) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR), markers) # æ˜¾ç¤ºåˆ†æ°´å²­ç®—æ³•ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(binary_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(dist_transform, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Distance Transform\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(markers, cmap=\u0026#39;jet\u0026#39;) plt.title(\u0026#39;Watershed Segmentation\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç‰¹å¾æå– Harrisè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # åº”ç”¨Harrisè§’ç‚¹æ£€æµ‹ gray_float = np.float32(gray_image) harris_corners = cv2.cornerHarris(gray_float, 2, 3, 0.04) # æ‰©å¤§è§’ç‚¹æ ‡è®° harris_corners = cv2.dilate(harris_corners, None) # è®¾ç½®é˜ˆå€¼ threshold = 0.01 * harris_corners.max() corner_image = image_rgb.copy() corner_image[harris_corners \u0026gt; threshold] = [255, 0, 0] # æ˜¾ç¤ºHarrisè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(corner_image) plt.title(\u0026#39;Harris Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Shi-Tomasiè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åº”ç”¨Shi-Tomasiè§’ç‚¹æ£€æµ‹ corners = cv2.goodFeaturesToTrack(gray_image, 100, 0.01, 10) corners = np.int0(corners) # ç»˜åˆ¶è§’ç‚¹ shi_tomasi_image = image_rgb.copy() for corner in corners: x, y = corner.ravel() cv2.circle(shi_tomasi_image, (x, y), 3, 255, -1) # æ˜¾ç¤ºShi-Tomasiè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(shi_tomasi_image) plt.title(\u0026#39;Shi-Tomasi Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() SIFTç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºSIFTç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(sift_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;SIFT Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ORBç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºORBç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(orb_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;ORB Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›®æ ‡æ£€æµ‹ Haarçº§è”åˆ†ç±»å™¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # åŠ è½½Haarçº§è”åˆ†ç±»å™¨ face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_frontalface_default.xml\u0026#39;) eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_eye.xml\u0026#39;) # æ£€æµ‹äººè„¸å’Œçœ¼ç› faces = face_cascade.detectMultiScale(gray_image, 1.3, 5) face_eye_image = image_rgb.copy() for (x, y, w, h) in faces: cv2.rectangle(face_eye_image, (x, y), (x+w, y+h), (255, 0, 0), 2) roi_gray = gray_image[y:y+h, x:x+w] roi_color = face_eye_image[y:y+h, x:x+w] eyes = eye_cascade.detectMultiScale(roi_gray) for (ex, ey, ew, eh) in eyes: cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2) # æ˜¾ç¤ºHaarçº§è”åˆ†ç±»å™¨æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(face_eye_image) plt.title(\u0026#39;Haar Cascade Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() HOGç‰¹å¾ä¸SVM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from skimage.feature import hog from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score # æå–HOGç‰¹å¾ def extract_hog_features(images): features = [] for image in images: # è®¡ç®—HOGç‰¹å¾ fd = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False) features.append(fd) return np.array(features) # å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›æ ‡è®°çš„å›¾åƒæ•°æ® # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦çœŸå®æ•°æ® # X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2) # æå–è®­ç»ƒå’Œæµ‹è¯•é›†çš„HOGç‰¹å¾ # X_train_hog = extract_hog_features(X_train) # X_test_hog = extract_hog_features(X_test) # è®­ç»ƒSVMåˆ†ç±»å™¨ # svm = SVC(kernel=\u0026#39;linear\u0026#39;) # svm.fit(X_train_hog, y_train) # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° # y_pred = svm.predict(X_test_hog) # accuracy = accuracy_score(y_test, y_pred) # print(f\u0026#34;Accuracy: {accuracy}\u0026#34;) æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ä»£ç ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®‰è£…ç›¸åº”çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ # å¦‚TensorFlowæˆ–PyTorchï¼Œä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ # ä½¿ç”¨TensorFlowå’Œé¢„è®­ç»ƒçš„SSDæ¨¡å‹ \u0026#34;\u0026#34;\u0026#34; import tensorflow as tf # åŠ è½½é¢„è®­ç»ƒçš„SSDæ¨¡å‹ model = tf.saved_model.load(\u0026#39;ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\u0026#39;) # é¢„å¤„ç†å›¾åƒ input_tensor = tf.convert_to_tensor(image_rgb) input_tensor = input_tensor[tf.newaxis, ...] # è¿è¡Œæ¨¡å‹ detections = model(input_tensor) # è§£ææ£€æµ‹ç»“æœ num_detections = int(detections.pop(\u0026#39;num_detections\u0026#39;)) detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()} detections[\u0026#39;num_detections\u0026#39;] = num_detections # è¿‡æ»¤æ£€æµ‹ç»“æœ min_score_thresh = 0.5 detections[\u0026#39;detection_classes\u0026#39;] = detections[\u0026#39;detection_classes\u0026#39;].astype(np.int64) indexes = np.where(detections[\u0026#39;detection_scores\u0026#39;] \u0026gt; min_score_thresh)[0] # ç»˜åˆ¶æ£€æµ‹ç»“æœ result_image = image_rgb.copy() for i in indexes: class_id = detections[\u0026#39;detection_classes\u0026#39;][i] score = detections[\u0026#39;detection_scores\u0026#39;][i] bbox = detections[\u0026#39;detection_boxes\u0026#39;][i] # å°†å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†è½¬æ¢ä¸ºåƒç´ åæ ‡ h, w, _ = image_rgb.shape y1, x1, y2, x2 = bbox y1, x1, y2, x2 = int(y1 * h), int(x1 * w), int(y2 * h), int(x2 * w) # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾ cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2) label = f\u0026#34;{class_id}: {score:.2f}\u0026#34; cv2.putText(result_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # æ˜¾ç¤ºæ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(result_image) plt.title(\u0026#39;Deep Learning Object Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() \u0026#34;\u0026#34;\u0026#34; æ€»ç»“ è®¡ç®—æœºè§†è§‰æ˜¯ä¸€ä¸ªå¹¿æ³›è€Œæ·±å…¥çš„é¢†åŸŸï¼Œæœ¬æ–‡ä»‹ç»äº†ä»åŸºç¡€çš„å›¾åƒè¡¨ç¤ºå’Œå¤„ç†åˆ°é«˜çº§çš„ç‰¹å¾æå–å’Œç›®æ ‡æ£€æµ‹çš„åŸºæœ¬æ¦‚å¿µå’Œæ–¹æ³•ã€‚é€šè¿‡å­¦ä¹ è¿™äº›åŸºç¡€çŸ¥è¯†ï¼Œè¯»è€…å¯ä»¥ä¸ºè¿›ä¸€æ­¥æ¢ç´¢è®¡ç®—æœºè§†è§‰çš„æ›´é«˜çº§ä¸»é¢˜æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸæ­£åœ¨ç»å†å¿«é€Ÿå˜é©ã€‚ä¼ ç»Ÿçš„è®¡ç®—æœºè§†è§‰æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ ç›¸ç»“åˆï¼Œæ­£åœ¨æ¨åŠ¨è®¡ç®—æœºè§†è§‰åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ä¸æ–­æ‹“å±•ã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºè§†è§‰çš„åŸºæœ¬åŸç†ï¼Œå¹¶æ¿€å‘è¿›ä¸€æ­¥å­¦ä¹ å’Œæ¢ç´¢çš„å…´è¶£ã€‚\nåœ¨æœªæ¥ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å°†ç»§ç»­å‘å±•ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€å¢å¼ºç°å®ã€æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸå‘æŒ¥è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚æŒæ¡è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå°†ä¸ºè¯»è€…åœ¨è¿™ä¸€å……æ»¡æœºé‡çš„é¢†åŸŸä¸­å‘å±•æä¾›æœ‰åŠ›æ”¯æŒã€‚\n","permalink":"http://localhost:1313/posts/computer-vision-basics/","summary":"\u003ch1 id=\"è®¡ç®—æœºè§†è§‰åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eè®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eè®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\u003c/p\u003e","title":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£"},{"content":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\næ·±åº¦å­¦ä¹ ä¸å›¾åƒå¤„ç† ä¼ ç»Ÿå›¾åƒå¤„ç†çš„å±€é™æ€§ ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ä¸»è¦ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ç‰¹å¾æå–å™¨å’Œç®—æ³•ï¼Œè¿™äº›æ–¹æ³•è™½ç„¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š\nç‰¹å¾è®¾è®¡å›°éš¾ï¼šéœ€è¦é¢†åŸŸä¸“å®¶è®¾è®¡ç‰¹å¾ï¼Œè€—æ—¶ä¸”éš¾ä»¥æ³›åŒ–ã€‚ é€‚åº”æ€§å·®ï¼šå¯¹å…‰ç…§ã€è§’åº¦ã€å°ºåº¦ç­‰å˜åŒ–æ•æ„Ÿã€‚ å¤æ‚åœºæ™¯å¤„ç†èƒ½åŠ›æœ‰é™ï¼šéš¾ä»¥å¤„ç†å¤æ‚èƒŒæ™¯å’Œå¤šå˜çš„ç¯å¢ƒã€‚ ç«¯åˆ°ç«¯å­¦ä¹ å›°éš¾ï¼šé€šå¸¸éœ€è¦å¤šä¸ªæ­¥éª¤ç»„åˆï¼Œéš¾ä»¥å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚ æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿ æ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œé€šè¿‡è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„è®¸å¤šå±€é™ï¼š\nè‡ªåŠ¨ç‰¹å¾æå–ï¼šæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾ï¼Œç½‘ç»œè‡ªåŠ¨å­¦ä¹ æœ€ä¼˜è¡¨ç¤ºã€‚ å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ï¼šå¤šå±‚ç½‘ç»œç»“æ„å¯ä»¥å­¦ä¹ å¤æ‚çš„ç‰¹å¾å±‚æ¬¡ã€‚ ç«¯åˆ°ç«¯å­¦ä¹ ï¼šä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºï¼Œæ•´ä¸ªè¿‡ç¨‹å¯ä¼˜åŒ–ã€‚ é€‚åº”æ€§å¼ºï¼šå¯¹å„ç§å˜åŒ–å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ã€‚ å¤§æ•°æ®é©±åŠ¨ï¼šèƒ½å¤Ÿåˆ©ç”¨å¤§é‡æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚ å·ç§¯ç¥ç»ç½‘ç»œ(CNN) å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†é¢†åŸŸæœ€æˆåŠŸçš„åº”ç”¨ä¹‹ä¸€ï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäºç”Ÿç‰©è§†è§‰ç³»ç»Ÿã€‚\nCNNçš„åŸºæœ¬ç»“æ„ å…¸å‹çš„CNNç”±ä»¥ä¸‹å‡ ç§å±‚ç»„æˆï¼š\nå·ç§¯å±‚(Convolutional Layer)ï¼šä½¿ç”¨å·ç§¯æ ¸æå–å±€éƒ¨ç‰¹å¾ã€‚ æ± åŒ–å±‚(Pooling Layer)ï¼šé™ä½ç©ºé—´ç»´åº¦ï¼Œå‡å°‘è®¡ç®—é‡ã€‚ æ¿€æ´»å‡½æ•°å±‚(Activation Layer)ï¼šå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚ å…¨è¿æ¥å±‚(Fully Connected Layer)ï¼šæ•´åˆç‰¹å¾ï¼Œè¿›è¡Œæœ€ç»ˆåˆ†ç±»æˆ–å›å½’ã€‚ å½’ä¸€åŒ–å±‚(Normalization Layer)ï¼šå¦‚æ‰¹å½’ä¸€åŒ–(Batch Normalization)ï¼ŒåŠ é€Ÿè®­ç»ƒã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # ä½¿ç”¨PyTorchæ„å»ºç®€å•çš„CNN import torch import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self, num_classes=10): super(SimpleCNN, self).__init__() self.features = nn.Sequential( # å·ç§¯å±‚1 nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚2 nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚3 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2) ) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(128 * 28 * 28, 512), # è¾“å…¥å°ºå¯¸éœ€ä¸ç‰¹å¾å›¾å°ºå¯¸ä¸€è‡´ nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(512, num_classes) ) def forward(self, x): # x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, 3, 224, 224) æˆ–æ ¹æ®å®é™…è¾“å…¥è°ƒæ•´ # è¿”å›åˆ†ç±»ç»“æœ x = self.features(x) x = x.view(x.size(0), -1) x = self.classifier(x) return x ç»å…¸CNNæ¶æ„ LeNet-5 LeNet-5æ˜¯æœ€æ—©çš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œç”±Yann LeCunåœ¨1998å¹´æå‡ºï¼Œä¸»è¦ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class LeNet5(nn.Module): def __init__(self): super(LeNet5, self).__init__() self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1) self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = torch.relu(self.conv1(x)) x = self.pool1(x) x = torch.relu(self.conv2(x)) x = self.pool2(x) x = x.view(-1, 16 * 5 * 5) x = torch.relu(self.fc1(x)) x = torch.relu(self.fc2(x)) x = self.fc3(x) return x AlexNet AlexNetåœ¨2012å¹´ImageNetç«èµ›ä¸­å–å¾—äº†çªç ´æ€§æˆç»©ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å´›èµ·ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class AlexNet(nn.Module): def __init__(self, num_classes=1000): super(AlexNet, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x VGGNet VGGNetä»¥å…¶ç®€æ´çš„ç»“æ„å’Œå‡ºè‰²çš„æ€§èƒ½è‘—ç§°ï¼Œä¸»è¦ç‰¹ç‚¹æ˜¯ä½¿ç”¨å°å°ºå¯¸å·ç§¯æ ¸å’Œæ·±å±‚ç½‘ç»œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class VGG16(nn.Module): def __init__(self, num_classes=1000): super(VGG16, self).__init__() self.features = nn.Sequential( # Block 1 nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 2 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 3 nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 4 nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 5 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) self.classifier = nn.Sequential( nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x ResNet ResNeté€šè¿‡å¼•å…¥æ®‹å·®è¿æ¥è§£å†³äº†æ·±å±‚ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—æ„å»ºæ•°ç™¾ç”šè‡³ä¸Šåƒå±‚çš„ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample self.stride = stride def forward(self, x): identity = x out = self.conv1(x) out = self.bn1(out) out = nn.ReLU(inplace=True)(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = nn.ReLU(inplace=True)(out) return out class ResNet(nn.Module): def __init__(self, block, layers, num_classes=1000): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2) self.layer3 = self._make_layer(block, 256, layers[2], stride=2) self.layer4 = self._make_layer(block, 512, layers[3], stride=2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def _make_layer(self, block, channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != channels * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channels, channels * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channels * block.expansion), ) layers = [] layers.append(block(self.in_channels, channels, stride, downsample)) self.in_channels = channels * block.expansion for _ in range(1, blocks): layers.append(block(self.in_channels, channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = nn.ReLU(inplace=True)(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x def resnet18(): return ResNet(BasicBlock, [2, 2, 2, 2]) CNNåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒåˆ†ç±» å›¾åƒåˆ†ç±»æ˜¯CNNæœ€åŸºæœ¬çš„åº”ç”¨ï¼Œé€šè¿‡è®­ç»ƒç½‘ç»œè¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNetè¿›è¡Œå›¾åƒåˆ†ç±» import torchvision.models as models import torchvision.transforms as transforms from PIL import Image # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = models.resnet18(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image) input_batch = input_tensor.unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_batch) # è·å–é¢„æµ‹ç»“æœ _, predicted_idx = torch.max(output, 1) ç›®æ ‡æ£€æµ‹ ç›®æ ‡æ£€æµ‹ä¸ä»…è¯†åˆ«å›¾åƒä¸­çš„å¯¹è±¡ï¼Œè¿˜ç¡®å®šå®ƒä»¬çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # ä½¿ç”¨Faster R-CNNè¿›è¡Œç›®æ ‡æ£€æµ‹ import torchvision from torchvision.models.detection import fasterrcnn_resnet50_fpn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fasterrcnn_resnet50_fpn(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† transform = transforms.Compose([transforms.ToTensor()]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) image_tensor = transform(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): predictions = model(image_tensor) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡ï¼ŒåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ä½¿ç”¨FCNè¿›è¡Œè¯­ä¹‰åˆ†å‰² from torchvision.models.segmentation import fcn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fcn.fcn_resnet50(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_tensor)[\u0026#39;out\u0026#39;] ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN) ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ˜¯ç”±Ian Goodfellowåœ¨2014å¹´æå‡ºçš„ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚\nGANçš„åŸºæœ¬åŸç† GANç”±ä¸¤ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼š\nç”Ÿæˆå™¨(Generator)ï¼šè¯•å›¾ç”Ÿæˆé€¼çœŸçš„æ•°æ®ï¼Œä»¥æ¬ºéª—åˆ¤åˆ«å™¨ã€‚ åˆ¤åˆ«å™¨(Discriminator)ï¼šè¯•å›¾åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆå™¨ç”Ÿæˆçš„å‡æ•°æ®ã€‚ è¿™ä¸¤ä¸ªç½‘ç»œé€šè¿‡å¯¹æŠ—è®­ç»ƒä¸æ–­æ”¹è¿›ï¼Œæœ€ç»ˆç”Ÿæˆå™¨èƒ½å¤Ÿç”Ÿæˆä¸çœŸå®æ•°æ®åˆ†å¸ƒç›¸ä¼¼çš„æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€å•çš„GANå®ç° import torch import torch.nn as nn class Generator(nn.Module): def __init__(self, latent_dim, img_shape): super(Generator, self).__init__() self.img_shape = img_shape def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *self.img_shape) return img class Discriminator(nn.Module): def __init__(self, img_shape): super(Discriminator, self).__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, img): img_flat = img.view(img.size(0), -1) validity = self.model(img_flat) return validity GANçš„è®­ç»ƒè¿‡ç¨‹ GANçš„è®­ç»ƒè¿‡ç¨‹æ˜¯ä¸€ä¸ªæå°æå¤§åšå¼ˆé—®é¢˜ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # GANè®­ç»ƒå¾ªç¯ import torch.optim as optim # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨ latent_dim = 100 img_shape = (1, 28, 28) # MNISTå›¾åƒå¤§å° generator = Generator(latent_dim, img_shape) discriminator = Discriminator(img_shape) # ä¼˜åŒ–å™¨ optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # æŸå¤±å‡½æ•° adversarial_loss = torch.nn.BCELoss() # è®­ç»ƒå‚æ•° n_epochs = 200 batch_size = 64 for epoch in range(n_epochs): for i, (imgs, _) in enumerate(dataloader): # çœŸå®å’Œå‡çš„æ ‡ç­¾ real = torch.ones(imgs.size(0), 1) fake = torch.zeros(imgs.size(0), 1) # è®­ç»ƒç”Ÿæˆå™¨ optimizer_G.zero_grad() z = torch.randn(imgs.size(0), latent_dim) gen_imgs = generator(z) g_loss = adversarial_loss(discriminator(gen_imgs), real) g_loss.backward() optimizer_G.step() # è®­ç»ƒåˆ¤åˆ«å™¨ optimizer_D.zero_grad() real_loss = adversarial_loss(discriminator(imgs), real) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2 d_loss.backward() optimizer_D.step() å¸¸è§çš„GANå˜ä½“ DCGAN (Deep Convolutional GAN) DCGANå°†CNNç»“æ„å¼•å…¥GANï¼Œæé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class DCGAN_Generator(nn.Module): def __init__(self, latent_dim, channels=1): super(DCGAN_Generator, self).__init__() self.init_size = 7 # åˆå§‹å¤§å° self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2)) self.conv_blocks = nn.Sequential( nn.BatchNorm2d(128), nn.Upsample(scale_factor=2), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.BatchNorm2d(128, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Upsample(scale_factor=2), nn.Conv2d(128, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Conv2d(64, channels, 3, stride=1, padding=1), nn.Tanh(), ) def forward(self, z): out = self.l1(z) out = out.view(out.shape[0], 128, self.init_size, self.init_size) img = self.conv_blocks(out) return img CycleGAN CycleGANç”¨äºåœ¨æ²¡æœ‰æˆå¯¹è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ResidualBlock(nn.Module): def __init__(self, in_features): super(ResidualBlock, self).__init__() self.block = nn.Sequential( nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features), nn.ReLU(inplace=True), nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features) ) def forward(self, x): return x + self.block(x) class GeneratorResNet(nn.Module): def __init__(self, input_shape, num_residual_blocks): super(GeneratorResNet, self).__init__() channels = input_shape[0] # åˆå§‹å·ç§¯å— out_features = 64 model = [ nn.ReflectionPad2d(3), nn.Conv2d(channels, out_features, 7), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # ä¸‹é‡‡æ · for _ in range(2): out_features *= 2 model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # æ®‹å·®å— for _ in range(num_residual_blocks): model += [ResidualBlock(out_features)] # ä¸Šé‡‡æ · for _ in range(2): out_features //= 2 model += [ nn.Upsample(scale_factor=2), nn.Conv2d(in_features, out_features, 3, stride=1, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # è¾“å‡ºå±‚ model += [nn.ReflectionPad2d(3), nn.Conv2d(out_features, channels, 7), nn.Tanh()] self.model = nn.Sequential(*model) def forward(self, x): return self.model(x) StyleGAN StyleGANé€šè¿‡é£æ ¼æ§åˆ¶ç”Ÿæˆé«˜è´¨é‡çš„äººè„¸å›¾åƒï¼Œå…·æœ‰å‡ºè‰²çš„å¯æ§æ€§å’Œå¤šæ ·æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class StyleGAN_Generator(nn.Module): def __init__(self, latent_dim, n_mlp=8): super(StyleGAN_Generator, self).__init__() # æ˜ å°„ç½‘ç»œ layers = [] for i in range(n_mlp): layers.append(nn.Linear(latent_dim, latent_dim)) layers.append(nn.LeakyReLU(0.2)) self.mapping = nn.Sequential(*layers) # åˆæˆç½‘ç»œ self.synthesis = self._build_synthesis_network(latent_dim) def _build_synthesis_network(self, latent_dim): # è¿™é‡Œç®€åŒ–äº†StyleGANçš„åˆæˆç½‘ç»œç»“æ„ # å®é™…çš„StyleGANç»“æ„æ›´ä¸ºå¤æ‚ï¼ŒåŒ…æ‹¬AdaINã€å™ªå£°æ³¨å…¥ç­‰ layers = nn.ModuleList() # åˆå§‹å¸¸æ•° self.constant_input = nn.Parameter(torch.randn(1, 512, 4, 4)) # ç”Ÿæˆå— in_channels = 512 for i in range(8): # 8ä¸ªä¸Šé‡‡æ ·å— out_channels = min(512, 512 // (2 ** (i // 2))) layers.append(StyleGAN_Block(in_channels, out_channels, upsample=(i \u0026gt; 0))) in_channels = out_channels # è¾“å‡ºå±‚ layers.append(nn.Conv2d(in_channels, 3, 1)) layers.append(nn.Tanh()) return nn.Sequential(*layers) def forward(self, z): # é€šè¿‡æ˜ å°„ç½‘ç»œ w = self.mapping(z) # é€šè¿‡åˆæˆç½‘ç»œ x = self.synthesis(w) return x class StyleGAN_Block(nn.Module): def __init__(self, in_channels, out_channels, upsample=False): super(StyleGAN_Block, self).__init__() self.upsample = upsample if upsample: self.up = nn.Upsample(scale_factor=2, mode=\u0026#39;bilinear\u0026#39;, align_corners=False) self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1) self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1) self.activate = nn.LeakyReLU(0.2) def forward(self, x): if self.upsample: x = self.up(x) x = self.conv1(x) x = self.activate(x) x = self.conv2(x) x = self.activate(x) return x GANåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒç”Ÿæˆ GANå¯ä»¥ç”Ÿæˆå„ç§ç±»å‹çš„å›¾åƒï¼Œä»ç®€å•çš„äººè„¸åˆ°å¤æ‚çš„åœºæ™¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨é¢„è®­ç»ƒçš„StyleGANç”Ÿæˆäººè„¸ import torch from stylegan2_pytorch import Generator # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = Generator(256, 512, 8).cuda() # å‡è®¾æœ‰é¢„è®­ç»ƒæƒé‡ model.load_state_dict(torch.load(\u0026#39;stylegan2-ffhq-config-f.pt\u0026#39;)) model.eval() # ç”Ÿæˆéšæœºæ½œåœ¨å‘é‡ z = torch.randn(1, 512).cuda() # ç”Ÿæˆå›¾åƒ with torch.no_grad(): img = model(z) å›¾åƒä¿®å¤ GANå¯ä»¥ç”¨äºä¿®å¤å›¾åƒä¸­çš„ç¼ºå¤±éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # ç®€åŒ–çš„å›¾åƒä¿®å¤æ¨¡å‹ class ImageInpainting(nn.Module): def __init__(self): super(ImageInpainting, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(4, 64, 7, stride=1, padding=3), # 4é€šé“ï¼šRGB + mask nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 512, 3, stride=2, padding=1), nn.ReLU(inplace=True), ) # ä¸­é—´å±‚ self.middle = nn.Sequential( nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 7, stride=1, padding=3), nn.Tanh(), ) def forward(self, x, mask): # è¿æ¥å›¾åƒå’Œæ©ç  x_masked = x * (1 - mask) input = torch.cat([x_masked, mask], dim=1) # ç¼–ç  x = self.encoder(input) # ä¸­é—´å¤„ç† x = self.middle(x) # è§£ç  x = self.decoder(x) # ç»„åˆåŸå§‹å›¾åƒå’Œç”Ÿæˆéƒ¨åˆ† output = x * mask + x_masked return output å›¾åƒè¶…åˆ†è¾¨ç‡ GANå¯ä»¥ç”¨äºå°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 # SRGANç”Ÿæˆå™¨ class SRGAN_Generator(nn.Module): def __init__(self, scale_factor=4): super(SRGAN_Generator, self).__init__() # åˆå§‹å·ç§¯ self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4) self.relu = nn.ReLU(inplace=True) # æ®‹å·®å— residual_blocks = [] for _ in range(16): residual_blocks.append(ResidualBlock(64)) self.residual_blocks = nn.Sequential(*residual_blocks) # ä¸Šé‡‡æ · upsampling = [] for _ in range(int(math.log(scale_factor, 2))): upsampling.append(nn.Conv2d(64, 256, 3, stride=1, padding=1)) upsampling.append(nn.PixelShuffle(2)) upsampling.append(nn.ReLU(inplace=True)) self.upsampling = nn.Sequential(*upsampling) # è¾“å‡ºå±‚ self.conv2 = nn.Conv2d(64, 3, 9, stride=1, padding=4) self.tanh = nn.Tanh() def forward(self, x): # åˆå§‹å·ç§¯ x = self.conv1(x) residual = x x = self.relu(x) # æ®‹å·®å— x = self.residual_blocks(x) # æ®‹å·®è¿æ¥ x = x + residual # ä¸Šé‡‡æ · x = self.upsampling(x) # è¾“å‡º x = self.conv2(x) x = self.tanh(x) return x class ResidualBlock(nn.Module): def __init__(self, channels): super(ResidualBlock, self).__init__() self.conv1 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(channels) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = out + residual return out é£æ ¼è¿ç§» GANå¯ä»¥å®ç°ä»ä¸€ç§è‰ºæœ¯é£æ ¼åˆ°å¦ä¸€ç§é£æ ¼çš„å›¾åƒè½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€åŒ–çš„é£æ ¼è¿ç§»ç½‘ç»œ class StyleTransfer(nn.Module): def __init__(self): super(StyleTransfer, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 9, stride=1, padding=4), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(inplace=True), ) # æ®‹å·®å— residual_blocks = [] for _ in range(5): residual_blocks.append(ResidualBlock(128)) self.residual_blocks = nn.Sequential(*residual_blocks) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 3, 9, stride=1, padding=4), nn.Tanh(), ) def forward(self, x): # ç¼–ç  x = self.encoder(x) # æ®‹å·®å¤„ç† x = self.residual_blocks(x) # è§£ç  x = self.decoder(x) return x å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ è‡ªç¼–ç å™¨(Autoencoder) è‡ªç¼–ç å™¨æ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç¼–ç å™¨å°†è¾“å…¥å‹ç¼©ä¸ºä½ç»´è¡¨ç¤ºï¼Œå†é€šè¿‡è§£ç å™¨é‡æ„åŸå§‹è¾“å…¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Autoencoder(nn.Module): def __init__(self, latent_dim): super(Autoencoder, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), nn.Linear(128 * 4 * 4, latent_dim), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def forward(self, x): z = self.encoder(x) x_reconstructed = self.decoder(z) return x_reconstructed, z å˜åˆ†è‡ªç¼–ç å™¨(VAE) å˜åˆ†è‡ªç¼–ç å™¨æ˜¯è‡ªç¼–ç å™¨çš„æ¦‚ç‡ç‰ˆæœ¬ï¼Œå¯ä»¥ç”Ÿæˆæ–°çš„æ•°æ®æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class VAE(nn.Module): def __init__(self, latent_dim): super(VAE, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), ) # å‡å€¼å’Œæ–¹å·® self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim) self.fc_var = nn.Linear(128 * 4 * 4, latent_dim) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def encode(self, x): h = self.encoder(x) mu = self.fc_mu(h) log_var = self.fc_var(h) return mu, log_var def reparameterize(self, mu, log_var): std = torch.exp(0.5 * log_var) eps = torch.randn_like(std) z = mu + eps * std return z def decode(self, z): return self.decoder(z) def forward(self, x): mu, log_var = self.encode(x) z = self.reparameterize(mu, log_var) x_reconstructed = self.decode(z) return x_reconstructed, mu, log_var æ‰©æ•£æ¨¡å‹(Diffusion Model) æ‰©æ•£æ¨¡å‹æ˜¯è¿‘å¹´æ¥å…´èµ·çš„ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡é€æ­¥æ·»åŠ å’Œå»é™¤å™ªå£°æ¥ç”Ÿæˆå›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class DiffusionModel(nn.Module): def __init__(self, timesteps=1000): super(DiffusionModel, self).__init__() self.timesteps = timesteps # å™ªå£°è°ƒåº¦å™¨ self.beta = torch.linspace(0.0001, 0.02, timesteps) self.alpha = 1. - self.beta self.alpha_hat = torch.cumprod(self.alpha, dim=0) # U-Netç»“æ„ self.unet = self._build_unet() def _build_unet(self): # ç®€åŒ–çš„U-Netç»“æ„ return nn.Sequential( # ä¸‹é‡‡æ · nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), # ä¸­é—´å±‚ nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), # ä¸Šé‡‡æ · nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 3, padding=1), ) def forward(self, x, t): # æ·»åŠ æ—¶é—´åµŒå…¥ t_emb = self._get_time_embedding(t, x.shape[0]) t_emb = t_emb.view(-1, 1, 1, 1).expand(-1, 3, x.shape[2], x.shape[3]) x = torch.cat([x, t_emb], dim=1) # é€šè¿‡U-Neté¢„æµ‹å™ªå£° noise_pred = self.unet(x) return noise_pred def _get_time_embedding(self, t, batch_size): # ç®€åŒ–çš„æ—¶é—´åµŒå…¥ t = t.view(-1, 1) t = t.float() / self.timesteps t = t * 2 * math.pi sin_t = torch.sin(t) cos_t = torch.cos(t) t_emb = torch.cat([sin_t, cos_t], dim=1) t_emb = t_emb.repeat(1, 3) # æ‰©å±•åˆ°3é€šé“ return t_emb def sample(self, x_shape): # ä»çº¯å™ªå£°å¼€å§‹ x = torch.randn(x_shape) # é€æ­¥å»å™ª for t in reversed(range(self.timesteps)): t_batch = torch.full((x_shape[0],), t, dtype=torch.long) noise_pred = self.forward(x, t_batch) # è®¡ç®—å»å™ªåçš„å›¾åƒ alpha_t = self.alpha[t] alpha_hat_t = self.alpha_hat[t] beta_t = self.beta[t] if t \u0026gt; 0: noise = torch.randn_like(x) else: noise = torch.zeros_like(x) x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * noise_pred) + torch.sqrt(beta_t) * noise return x è§†è§‰Transformer(ViT) è§†è§‰Transformerå°†Transformeræ¶æ„åº”ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸Šå–å¾—äº†ä¸CNNç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 class PatchEmbed(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768): super(PatchEmbed, self).__init__() self.img_size = img_size self.patch_size = patch_size self.n_patches = (img_size // patch_size) ** 2 self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size) def forward(self, x): x = self.proj(x) # (B, embed_dim, n_patches ** 0.5, n_patches ** 0.5) x = x.flatten(2) # (B, embed_dim, n_patches) x = x.transpose(1, 2) # (B, n_patches, embed_dim) return x class Attention(nn.Module): def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.): super(Attention, self).__init__() self.n_heads = n_heads self.dim = dim self.head_dim = dim // n_heads self.scale = self.head_dim ** -0.5 self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias) self.attn_drop = nn.Dropout(attn_p) self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_p) def forward(self, x): n_samples, n_tokens, dim = x.shape qkv = self.qkv(x) # (n_samples, n_tokens, 3 * dim) qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim) qkv = qkv.permute(2, 0, 3, 1, 4) # (3, n_samples, n_heads, n_tokens, head_dim) q, k, v = qkv[0], qkv[1], qkv[2] k_t = k.transpose(-2, -1) # (n_samples, n_heads, head_dim, n_tokens) dp = (q @ k_t) * self.scale # (n_samples, n_heads, n_tokens, n_tokens) attn = dp.softmax(dim=-1) # (n_samples, n_heads, n_tokens, n_tokens) attn = self.attn_drop(attn) weighted_avg = attn @ v # (n_samples, n_heads, n_tokens, head_dim) weighted_avg = weighted_avg.transpose(1, 2) # (n_samples, n_tokens, n_heads, head_dim) weighted_avg = weighted_avg.flatten(2) # (n_samples, n_tokens, dim) x = self.proj(weighted_avg) x = self.proj_drop(x) return x class MLP(nn.Module): def __init__(self, in_features, hidden_features, out_features, p=0.): super(MLP, self).__init__() self.fc1 = nn.Linear(in_features, hidden_features) self.act = nn.GELU() self.fc2 = nn.Linear(hidden_features, out_features) self.drop = nn.Dropout(p) def forward(self, x): x = self.fc1(x) x = self.act(x) x = self.drop(x) x = self.fc2(x) x = self.drop(x) return x class Block(nn.Module): def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(Block, self).__init__() self.norm1 = nn.LayerNorm(dim, eps=1e-6) self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p) self.norm2 = nn.LayerNorm(dim, eps=1e-6) hidden_features = int(dim * mlp_ratio) self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim, p=p) def forward(self, x): x = x + self.attn(self.norm1(x)) x = x + self.mlp(self.norm2(x)) return x class VisionTransformer(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, n_classes=1000, embed_dim=768, depth=12, n_heads=12, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(VisionTransformer, self).__init__() self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_channels=in_channels, embed_dim=embed_dim) self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) self.pos_embed = nn.Parameter(torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)) self.pos_drop = nn.Dropout(p=p) self.blocks = nn.ModuleList([ Block(dim=embed_dim, n_heads=n_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, p=p, attn_p=attn_p) for _ in range(depth) ]) self.norm = nn.LayerNorm(embed_dim, eps=1e-6) self.head = nn.Linear(embed_dim, n_classes) def forward(self, x): n_samples = x.shape[0] x = self.patch_embed(x) cls_token = self.cls_token.expand(n_samples, -1, -1) x = torch.cat((cls_token, x), dim=1) x = x + self.pos_embed x = self.pos_drop(x) for block in self.blocks: x = block(x) x = self.norm(x) cls_token_final = x[:, 0] x = self.head(cls_token_final) return x æ·±åº¦å­¦ä¹ å›¾åƒå¤„ç†çš„æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘ å½“å‰æŒ‘æˆ˜ æ•°æ®éœ€æ±‚ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜ã€‚ è®¡ç®—èµ„æºï¼šè®­ç»ƒå¤§å‹æ¨¡å‹éœ€è¦å¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚ å¯è§£é‡Šæ€§ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸è¢«è§†ä¸º\u0026quot;é»‘ç›’\u0026quot;ï¼Œéš¾ä»¥è§£é‡Šå…¶å†³ç­–è¿‡ç¨‹ã€‚ æ³›åŒ–èƒ½åŠ›ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®åˆ†å¸ƒå¤–è¡¨ç°ä¸ä½³ï¼Œé²æ£’æ€§æœ‰å¾…æé«˜ã€‚ é¢†åŸŸé€‚åº”ï¼šå°†æ¨¡å‹ä»ä¸€ä¸ªé¢†åŸŸè¿ç§»åˆ°å¦ä¸€ä¸ªé¢†åŸŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ æœªæ¥æ–¹å‘ è‡ªç›‘ç£å­¦ä¹ ï¼šå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä»æœªæ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ ã€‚ å°æ ·æœ¬å­¦ä¹ ï¼šä½¿æ¨¡å‹èƒ½å¤Ÿä»å°‘é‡æ ·æœ¬ä¸­å­¦ä¹ ã€‚ å¤šæ¨¡æ€å­¦ä¹ ï¼šç»“åˆå›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€çš„ä¿¡æ¯ã€‚ ç¥ç»æ¶æ„æœç´¢ï¼šè‡ªåŠ¨è®¾è®¡æœ€ä¼˜çš„ç½‘ç»œç»“æ„ã€‚ æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿï¼šä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œã€‚ å¯è§£é‡ŠAIï¼šæé«˜æ¨¡å‹çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚ é²æ£’æ€§å¢å¼ºï¼šæé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ ·æœ¬å’Œåˆ†å¸ƒå¤–æ•°æ®çš„é²æ£’æ€§ã€‚ æ€»ç»“ æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯CNNå’ŒGANï¼Œå·²ç»å½»åº•æ”¹å˜äº†å›¾åƒå¤„ç†é¢†åŸŸã€‚ä»å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆå’Œé£æ ¼è¿ç§»ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­éƒ½å–å¾—äº†ä»¤äººç©ç›®çš„æˆæœã€‚\nCNNé€šè¿‡å…¶å±€éƒ¨è¿æ¥å’Œæƒå€¼å…±äº«çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆåœ°æå–å›¾åƒçš„å±‚æ¬¡ç‰¹å¾ï¼Œæˆä¸ºå›¾åƒå¤„ç†çš„åŸºç¡€æ¶æ„ã€‚GANé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä¸ºå›¾åƒç”Ÿæˆå’Œè½¬æ¢ä»»åŠ¡æä¾›äº†å¼ºå¤§çš„å·¥å…·ã€‚\né™¤äº†CNNå’ŒGANï¼Œè‡ªç¼–ç å™¨ã€å˜åˆ†è‡ªç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹å’Œè§†è§‰Transformerç­‰æ¨¡å‹ä¹Ÿåœ¨å›¾åƒå¤„ç†ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œä¸æ–­æ¨åŠ¨ç€è¯¥é¢†åŸŸçš„å‘å±•ã€‚\nå°½ç®¡æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†ä»é¢ä¸´æ•°æ®éœ€æ±‚ã€è®¡ç®—èµ„æºã€å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚æœªæ¥ï¼Œè‡ªç›‘ç£å­¦ä¹ ã€å°æ ·æœ¬å­¦ä¹ ã€å¤šæ¨¡æ€å­¦ä¹ ç­‰æ–¹å‘å°†å¼•é¢†å›¾åƒå¤„ç†é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚\nä½œä¸ºå›¾åƒç®—æ³•å·¥ç¨‹å¸ˆï¼Œäº†è§£å’ŒæŒæ¡è¿™äº›æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹äºè§£å†³å®é™…é—®é¢˜è‡³å…³é‡è¦ã€‚é€šè¿‡ä¸æ–­å­¦ä¹ å’Œå®è·µï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°åº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œæ¨åŠ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åˆ›æ–°å’Œå‘å±•ã€‚\n","permalink":"http://localhost:1313/posts/deep-learning-image-processing/","summary":"\u003ch1 id=\"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ä»cnnåˆ°gan\"\u003eæ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN\u003c/h1\u003e\n\u003cp\u003eæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\u003c/p\u003e","title":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨"},{"content":"ç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ åœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\nç®—æ³•å¤æ‚åº¦åˆ†æ æ—¶é—´å¤æ‚åº¦ æ—¶é—´å¤æ‚åº¦æ˜¯è¡¡é‡ç®—æ³•æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡å¢é•¿è€Œå¢é•¿çš„é€Ÿç‡ã€‚å¸¸è§çš„æ—¶é—´å¤æ‚åº¦ä»ä½åˆ°é«˜ä¾æ¬¡ä¸ºï¼š\nO(1) - å¸¸æ•°æ—¶é—´ å¸¸æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ï¼Œæ˜¯æœ€ç†æƒ³çš„å¤æ‚åº¦ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šè·å–æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´  def get_first_element(arr): return arr[0] # æ— è®ºæ•°ç»„å¤šå¤§ï¼Œæ‰§è¡Œæ—¶é—´ç›¸åŒ O(log n) - å¯¹æ•°æ—¶é—´ å¯¹æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„å¯¹æ•°å¢é•¿ï¼Œå¸¸è§äºåˆ†æ²»ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šäºŒåˆ†æŸ¥æ‰¾ å‚æ•°ï¼šarr (List[int])ï¼Œtarget (int) è¿”å›ï¼šç›®æ ‡ç´¢å¼•æˆ–-1 \u0026#34;\u0026#34;\u0026#34; def binary_search(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: mid = (left + right) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 O(n) - çº¿æ€§æ—¶é—´ çº¿æ€§æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 4 5 6 7 # ç¤ºä¾‹ï¼šæŸ¥æ‰¾æ•°ç»„ä¸­çš„æœ€å¤§å€¼ def find_max(arr): max_val = arr[0] for val in arr: if val \u0026gt; max_val: max_val = val return max_val O(n log n) - çº¿æ€§å¯¹æ•°æ—¶é—´ çº¿æ€§å¯¹æ•°æ—¶é—´ç®—æ³•å¸¸è§äºé«˜æ•ˆçš„æ’åºç®—æ³•ï¼Œå¦‚å¿«é€Ÿæ’åºã€å½’å¹¶æ’åºã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # ç¤ºä¾‹ï¼šå½’å¹¶æ’åº def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) right = merge_sort(arr[mid:]) return merge(left, right) def merge(left, right): result = [] i = j = 0 while i \u0026lt; len(left) and j \u0026lt; len(right): if left[i] \u0026lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result.extend(left[i:]) result.extend(right[j:]) return result O(nÂ²) - å¹³æ–¹æ—¶é—´ å¹³æ–¹æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ï¼Œå¸¸è§äºç®€å•çš„æ’åºç®—æ³•å’ŒåµŒå¥—å¾ªç¯ã€‚\n1 2 3 4 5 6 7 8 # ç¤ºä¾‹ï¼šå†’æ³¡æ’åº def bubble_sort(arr): n = len(arr) for i in range(n): for j in range(0, n - i - 1): if arr[j] \u0026gt; arr[j + 1]: arr[j], arr[j + 1] = arr[j + 1], arr[j] return arr O(2â¿) - æŒ‡æ•°æ—¶é—´ æŒ‡æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡æŒ‡æ•°å¢é•¿ï¼Œé€šå¸¸ç”¨äºè§£å†³NPéš¾é—®é¢˜ã€‚\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šé€’å½’è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼ˆä½æ•ˆç‰ˆæœ¬ï¼‰ å‚æ•°ï¼šn (int) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n \u0026lt;= 1: return n return fibonacci(n - 1) + fibonacci(n - 2) O(n!) - é˜¶ä¹˜æ—¶é—´ é˜¶ä¹˜æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„é˜¶ä¹˜å¢é•¿ï¼Œæ˜¯æœ€å·®çš„å¤æ‚åº¦ï¼Œå¸¸è§äºæš´åŠ›æœç´¢æ‰€æœ‰æ’åˆ—ç»„åˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ç¤ºä¾‹ï¼šç”Ÿæˆæ‰€æœ‰æ’åˆ— def permutations(arr): if len(arr) \u0026lt;= 1: return [arr] result = [] for i in range(len(arr)): rest = arr[:i] + arr[i+1:] for p in permutations(rest): result.append([arr[i]] + p) return result ç©ºé—´å¤æ‚åº¦ ç©ºé—´å¤æ‚åº¦è¡¡é‡ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­æ‰€éœ€é¢å¤–ç©ºé—´éšè¾“å…¥è§„æ¨¡å¢é•¿çš„é€Ÿç‡ã€‚\nO(1) - å¸¸æ•°ç©ºé—´ å¸¸æ•°ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåŸåœ°äº¤æ¢æ•°ç»„å…ƒç´  def swap_elements(arr, i, j): arr[i], arr[j] = arr[j], arr[i] # ä¸éœ€è¦é¢å¤–ç©ºé—´ O(n) - çº¿æ€§ç©ºé—´ çº¿æ€§ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šå¤åˆ¶æ•°ç»„ def copy_array(arr): return arr.copy() # éœ€è¦ä¸åŸæ•°ç»„å¤§å°ç›¸åŒçš„é¢å¤–ç©ºé—´ O(nÂ²) - å¹³æ–¹ç©ºé—´ å¹³æ–¹ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåˆ›å»ºäºŒç»´æ•°ç»„ def create_2d_array(n): return [[0 for _ in range(n)] for _ in range(n)] # éœ€è¦nÂ²çš„é¢å¤–ç©ºé—´ å¤æ‚åº¦åˆ†ææŠ€å·§ å¾ªç¯åˆ†æ å¯¹äºå¾ªç¯ç»“æ„ï¼Œå¤æ‚åº¦é€šå¸¸ç”±å¾ªç¯æ¬¡æ•°å’Œå¾ªç¯ä½“å†…çš„æ“ä½œå†³å®šã€‚\n1 2 3 4 5 6 7 8 9 10 # O(n) - å•å±‚å¾ªç¯ def example1(n): for i in range(n): # å¾ªç¯næ¬¡ print(i) # O(1)æ“ä½œ # O(nÂ²) - åµŒå¥—å¾ªç¯ def example2(n): for i in range(n): # å¤–å±‚å¾ªç¯næ¬¡ for j in range(n): # å†…å±‚å¾ªç¯næ¬¡ print(i, j) # O(1)æ“ä½œ é€’å½’åˆ†æ å¯¹äºé€’å½’ç®—æ³•ï¼Œå¯ä»¥ä½¿ç”¨é€’å½’æ ‘æˆ–ä¸»å®šç†(Master Theorem)æ¥åˆ†æå¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 # é€’å½’æ ‘åˆ†æï¼šå½’å¹¶æ’åº # T(n) = 2T(n/2) + O(n) # æ¯å±‚æ€»å¤æ‚åº¦ä¸ºO(n)ï¼Œå…±æœ‰log nå±‚ï¼Œå› æ­¤æ€»å¤æ‚åº¦ä¸ºO(n log n) def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) # T(n/2) right = merge_sort(arr[mid:]) # T(n/2) return merge(left, right) # O(n) å‡æ‘Šåˆ†æ å‡æ‘Šåˆ†æç”¨äºè®¡ç®—ä¸€ç³»åˆ—æ“ä½œçš„å¹³å‡å¤æ‚åº¦ï¼Œå³ä½¿æŸäº›æ“ä½œå¯èƒ½å¾ˆè€—æ—¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åŠ¨æ€æ•°ç»„çš„å‡æ‘Šåˆ†æ # è™½ç„¶å¶å°”éœ€è¦O(n)æ—¶é—´æ‰©å®¹ï¼Œä½†næ¬¡appendæ“ä½œçš„æ€»æ—¶é—´ä¸ºO(n) # å› æ­¤æ¯æ¬¡appendçš„å‡æ‘Šæ—¶é—´ä¸ºO(1) class DynamicArray: def __init__(self): self.capacity = 1 self.size = 0 self.array = [None] * self.capacity def append(self, item): if self.size == self.capacity: self._resize(2 * self.capacity) # O(n)æ“ä½œï¼Œä½†ä¸é¢‘ç¹ self.array[self.size] = item self.size += 1 def _resize(self, new_capacity): new_array = [None] * new_capacity for i in range(self.size): new_array[i] = self.array[i] self.array = new_array self.capacity = new_capacity ç®—æ³•ä¼˜åŒ–ç­–ç•¥ æ—¶é—´ä¼˜åŒ–ç­–ç•¥ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„æ˜¯ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºé¢‘ç¹æŸ¥æ‰¾æ“ä½œï¼Œå“ˆå¸Œè¡¨(O(1))æ¯”æ•°ç»„(O(n))æ›´é«˜æ•ˆã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨å“ˆå¸Œè¡¨ä¼˜åŒ–æŸ¥æ‰¾ def find_duplicates(arr): seen = set() duplicates = [] for item in arr: if item in seen: # O(1)æŸ¥æ‰¾ duplicates.append(item) else: seen.add(item) return duplicates é¢„è®¡ç®—å’Œç¼“å­˜ å¯¹äºé‡å¤è®¡ç®—ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®¡ç®—æˆ–ç¼“å­˜æŠ€æœ¯é¿å…é‡å¤å·¥ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— \u0026#34;\u0026#34;\u0026#34; ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— å‚æ•°ï¼šn (int), cache (dict) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n, cache={}): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n in cache: return cache[n] if n \u0026lt;= 1: return n result = fibonacci(n - 1, cache) + fibonacci(n - 2, cache) cache[n] = result return result ä½è¿ç®—ä¼˜åŒ– ä½è¿ç®—é€šå¸¸æ¯”ç®—æœ¯è¿ç®—æ›´å¿«ï¼Œå¯ä»¥ç”¨äºæŸäº›ç‰¹å®šåœºæ™¯çš„ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨ä½è¿ç®—åˆ¤æ–­å¥‡å¶ def is_even(n): return (n \u0026amp; 1) == 0 # æ¯”n % 2 == 0æ›´å¿« # ä½¿ç”¨ä½è¿ç®—äº¤æ¢å˜é‡ def swap(a, b): a = a ^ b b = a ^ b a = a ^ b return a, b å¹¶è¡Œè®¡ç®— å¯¹äºå¯ä»¥å¹¶è¡Œå¤„ç†çš„é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å¤šçº¿ç¨‹æˆ–å¤šè¿›ç¨‹åŠ é€Ÿã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† import concurrent.futures def process_data(data): # å¤„ç†æ•°æ®çš„å‡½æ•°ï¼Œè¿”å›å¤„ç†ç»“æœ result = ... # æ ¹æ®å®é™…éœ€æ±‚å¤„ç† return result def parallel_process(data_list, num_workers=4): with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor: results = list(executor.map(process_data, data_list)) return results ç©ºé—´ä¼˜åŒ–ç­–ç•¥ åŸåœ°ç®—æ³• åŸåœ°ç®—æ³•ä¸éœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´æˆ–åªéœ€è¦å¸¸æ•°çº§åˆ«çš„é¢å¤–ç©ºé—´ã€‚\n1 2 3 4 5 6 7 8 # åŸåœ°åè½¬æ•°ç»„ def reverse_array(arr): left, right = 0, len(arr) - 1 while left \u0026lt; right: arr[left], arr[right] = arr[right], arr[left] left += 1 right -= 1 return arr æ•°æ®å‹ç¼© å¯¹äºå¤§è§„æ¨¡æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å‹ç¼©æŠ€æœ¯å‡å°‘å­˜å‚¨éœ€æ±‚ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨ç¨€ç–çŸ©é˜µè¡¨ç¤ºä¼˜åŒ–å­˜å‚¨ class SparseMatrix: def __init__(self, rows, cols): self.rows = rows self.cols = cols self.data = {} # åªå­˜å‚¨éé›¶å…ƒç´  def set(self, i, j, value): if value != 0: self.data[(i, j)] = value elif (i, j) in self.data: del self.data[(i, j)] def get(self, i, j): return self.data.get((i, j), 0) æƒ°æ€§è®¡ç®— æƒ°æ€§è®¡ç®—åªåœ¨éœ€è¦æ—¶æ‰è®¡ç®—ç»“æœï¼Œå¯ä»¥èŠ‚çœä¸å¿…è¦çš„è®¡ç®—å’Œå­˜å‚¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æƒ°æ€§è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ— def lazy_fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b # ä½¿ç”¨ç”Ÿæˆå™¨ fib = lazy_fibonacci() for _ in range(10): print(next(fib)) æ—¶ç©ºæƒè¡¡ æœ‰æ—¶å¯ä»¥é€šè¿‡å¢åŠ ç©ºé—´ä½¿ç”¨æ¥å‡å°‘æ—¶é—´å¤æ‚åº¦ï¼Œæˆ–è€…é€šè¿‡å¢åŠ æ—¶é—´å¤æ‚åº¦æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\nç©ºé—´æ¢æ—¶é—´ ä½¿ç”¨é¢å¤–çš„ç©ºé—´æ¥å­˜å‚¨ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–æœ€é•¿å…¬å…±å­åºåˆ— def longest_common_subsequence(text1, text2): m, n = len(text1), len(text2) # åˆ›å»ºäºŒç»´æ•°ç»„å­˜å‚¨ä¸­é—´ç»“æœ dp = [[0] * (n + 1) for _ in range(m + 1)] for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: dp[i][j] = dp[i - 1][j - 1] + 1 else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[m][n] æ—¶é—´æ¢ç©ºé—´ é€šè¿‡å¢åŠ è®¡ç®—æ—¶é—´æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ def fibonacci_with_rolling_array(n): if n \u0026lt;= 1: return n # åªä¿å­˜æœ€è¿‘çš„ä¸¤ä¸ªå€¼ a, b = 0, 1 for _ in range(2, n + 1): a, b = b, a + b return b å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ æ’åºç®—æ³•ä¼˜åŒ– å¿«é€Ÿæ’åºä¼˜åŒ– å¿«é€Ÿæ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)ï¼Œä½†åœ¨æœ€åæƒ…å†µä¸‹ä¼šé€€åŒ–åˆ°O(nÂ²)ã€‚ä»¥ä¸‹æ˜¯å‡ ç§ä¼˜åŒ–æ–¹æ³•ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def optimized_quick_sort(arr): # ä½¿ç”¨ä¸‰æ•°å–ä¸­æ³•é€‰æ‹©åŸºå‡†ï¼Œé¿å…æœ€åæƒ…å†µ def median_of_three(left, right): mid = (left + right) // 2 if arr[left] \u0026gt; arr[mid]: arr[left], arr[mid] = arr[mid], arr[left] if arr[left] \u0026gt; arr[right]: arr[left], arr[right] = arr[right], arr[left] if arr[mid] \u0026gt; arr[right]: arr[mid], arr[right] = arr[right], arr[mid] return mid def partition(left, right): # é€‰æ‹©åŸºå‡† pivot_idx = median_of_three(left, right) pivot = arr[pivot_idx] # å°†åŸºå‡†ç§»åˆ°æœ€å³è¾¹ arr[pivot_idx], arr[right] = arr[right], arr[pivot_idx] i = left for j in range(left, right): if arr[j] \u0026lt;= pivot: arr[i], arr[j] = arr[j], arr[i] i += 1 # å°†åŸºå‡†ç§»åˆ°æ­£ç¡®ä½ç½® arr[i], arr[right] = arr[right], arr[i] return i def sort(left, right): # å°æ•°ç»„ä½¿ç”¨æ’å…¥æ’åº if right - left + 1 \u0026lt;= 20: insertion_sort(arr, left, right) return if left \u0026lt; right: pivot_idx = partition(left, right) sort(left, pivot_idx - 1) sort(pivot_idx + 1, right) def insertion_sort(arr, left, right): for i in range(left + 1, right + 1): key = arr[i] j = i - 1 while j \u0026gt;= left and arr[j] \u0026gt; key: arr[j + 1] = arr[j] j -= 1 arr[j + 1] = key sort(0, len(arr) - 1) return arr è®¡æ•°æ’åºä¼˜åŒ– è®¡æ•°æ’åºæ˜¯ä¸€ç§éæ¯”è¾ƒæ’åºç®—æ³•ï¼Œé€‚ç”¨äºæ•´æ•°ä¸”èŒƒå›´ä¸å¤§çš„æƒ…å†µã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def counting_sort(arr, max_val=None): if not arr: return arr if max_val is None: max_val = max(arr) # åˆ›å»ºè®¡æ•°æ•°ç»„ count = [0] * (max_val + 1) # ç»Ÿè®¡æ¯ä¸ªå…ƒç´ çš„å‡ºç°æ¬¡æ•° for num in arr: count[num] += 1 # è®¡ç®—ç´¯ç§¯è®¡æ•° for i in range(1, len(count)): count[i] += count[i - 1] # æ„å»ºæ’åºç»“æœ result = [0] * len(arr) for num in reversed(arr): result[count[num] - 1] = num count[num] -= 1 return result æœç´¢ç®—æ³•ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ç§é«˜æ•ˆçš„æœç´¢ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(log n)ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def binary_search_optimized(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: # é˜²æ­¢æ•´æ•°æº¢å‡º mid = left + (right - left) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 è·³è¡¨æœç´¢ä¼˜åŒ– è·³è¡¨æ˜¯ä¸€ç§æ¦‚ç‡æ•°æ®ç»“æ„ï¼Œå…è®¸å¿«é€Ÿæœç´¢ï¼Œç±»ä¼¼äºå¹³è¡¡æ ‘ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import random class SkipNode: def __init__(self, val=None, level=0): self.val = val self.next = [None] * level class SkipList: def __init__(self, max_level=16, p=0.5): self.max_level = max_level self.p = p self.level = 1 self.head = SkipNode(None, max_level) def random_level(self): level = 1 while random.random() \u0026lt; self.p and level \u0026lt; self.max_level: level += 1 return level def insert(self, val): update = [None] * self.max_level current = self.head # æ‰¾åˆ°æ’å…¥ä½ç½® for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] update[i] = current # åˆ›å»ºæ–°èŠ‚ç‚¹ node_level = self.random_level() if node_level \u0026gt; self.level: for i in range(self.level, node_level): update[i] = self.head self.level = node_level # æ’å…¥æ–°èŠ‚ç‚¹ new_node = SkipNode(val, node_level) for i in range(node_level): new_node.next[i] = update[i].next[i] update[i].next[i] = new_node def search(self, val): current = self.head for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] current = current.next[0] if current and current.val == val: return True return False å›¾ç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ç”¨äºå¯»æ‰¾å•æºæœ€çŸ­è·¯å¾„ï¼Œå¯ä»¥ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import heapq def dijkstra_optimized(graph, start): n = len(graph) dist = [float(\u0026#39;inf\u0026#39;)] * n dist[start] = 0 # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ— pq = [(0, start)] while pq: current_dist, u = heapq.heappop(pq) # å¦‚æœå·²ç»æ‰¾åˆ°æ›´çŸ­è·¯å¾„ï¼Œè·³è¿‡ if current_dist \u0026gt; dist[u]: continue for v, weight in graph[u]: distance = current_dist + weight if distance \u0026lt; dist[v]: dist[v] = distance heapq.heappush(pq, (distance, v)) return dist A*ç®—æ³•ä¼˜åŒ– A*ç®—æ³•æ˜¯ä¸€ç§å¯å‘å¼æœç´¢ç®—æ³•ï¼Œå¸¸ç”¨äºè·¯å¾„è§„åˆ’ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import heapq def a_star_search(graph, start, goal, heuristic): # ä¼˜å…ˆé˜Ÿåˆ—ï¼š(f_score, node) open_set = [(0, start)] # ä»èµ·ç‚¹åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„å®é™…ä»£ä»· g_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} g_score[start] = 0 # ä»èµ·ç‚¹ç»è¿‡æ¯ä¸ªèŠ‚ç‚¹åˆ°ç»ˆç‚¹çš„ä¼°è®¡ä»£ä»· f_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} f_score[start] = heuristic(start, goal) # è®°å½•è·¯å¾„ came_from = {} while open_set: current_f, current = heapq.heappop(open_set) if current == goal: # é‡å»ºè·¯å¾„ path = [current] while current in came_from: current = came_from[current] path.append(current) return path[::-1] for neighbor in graph[current]: # è®¡ç®—ä»èµ·ç‚¹åˆ°é‚»å±…çš„ä¸´æ—¶g_score tentative_g_score = g_score[current] + graph[current][neighbor] if tentative_g_score \u0026lt; g_score[neighbor]: # æ‰¾åˆ°æ›´å¥½çš„è·¯å¾„ came_from[neighbor] = current g_score[neighbor] = tentative_g_score f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, goal) heapq.heappush(open_set, (f_score[neighbor], neighbor)) return None # æ²¡æœ‰æ‰¾åˆ°è·¯å¾„ åŠ¨æ€è§„åˆ’ä¼˜åŒ– çŠ¶æ€å‹ç¼© å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ä½è¿ç®—è¿›è¡ŒçŠ¶æ€å‹ç¼©ï¼Œå‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # æ—…è¡Œå•†é—®é¢˜(TSP)çš„çŠ¶æ€å‹ç¼©ä¼˜åŒ– def tsp_dp(distances): n = len(distances) # dp[mask][i]è¡¨ç¤ºè®¿é—®è¿‡maskä¸­çš„åŸå¸‚ï¼Œæœ€ååœç•™åœ¨åŸå¸‚içš„æœ€çŸ­è·ç¦» dp = [[float(\u0026#39;inf\u0026#39;)] * n for _ in range(1 \u0026lt;\u0026lt; n)] dp[1][0] = 0 # ä»åŸå¸‚0å¼€å§‹ for mask in range(1 \u0026lt;\u0026lt; n): for i in range(n): if mask \u0026amp; (1 \u0026lt;\u0026lt; i): # å¦‚æœåŸå¸‚iåœ¨maskä¸­ for j in range(n): if not mask \u0026amp; (1 \u0026lt;\u0026lt; j): # å¦‚æœåŸå¸‚jä¸åœ¨maskä¸­ new_mask = mask | (1 \u0026lt;\u0026lt; j) dp[new_mask][j] = min(dp[new_mask][j], dp[mask][i] + distances[i][j]) # è®¡ç®—å›åˆ°èµ·ç‚¹çš„æœ€çŸ­è·ç¦» final_mask = (1 \u0026lt;\u0026lt; n) - 1 min_distance = float(\u0026#39;inf\u0026#39;) for i in range(1, n): min_distance = min(min_distance, dp[final_mask][i] + distances[i][0]) return min_distance æ»šåŠ¨æ•°ç»„ä¼˜åŒ– å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # æœ€é•¿å…¬å…±å­åºåˆ—çš„æ»šåŠ¨æ•°ç»„ä¼˜åŒ– def lcs_rolling_array(text1, text2): m, n = len(text1), len(text2) # ä½¿ç”¨ä¸¤è¡Œæ•°ç»„ä»£æ›¿å®Œæ•´çš„äºŒç»´æ•°ç»„ prev = [0] * (n + 1) curr = [0] * (n + 1) for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: curr[j] = prev[j - 1] + 1 else: curr[j] = max(prev[j], curr[j - 1]) # æ»šåŠ¨æ•°ç»„ prev, curr = curr, prev curr = [0] * (n + 1) return prev[n] å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æ å›¾åƒå¤„ç†ä¸­çš„ä¼˜åŒ– å·ç§¯è¿ç®—ä¼˜åŒ– å·ç§¯è¿ç®—æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import numpy as np def naive_convolution(image, kernel): # åŸå§‹å·ç§¯å®ç° height, width = image.shape k_height, k_width = kernel.shape output = np.zeros((height - k_height + 1, width - k_width + 1)) for i in range(output.shape[0]): for j in range(output.shape[1]): output[i, j] = np.sum(image[i:i+k_height, j:j+k_width] * kernel) return output def optimized_convolution(image, kernel): # ä½¿ç”¨FFTåŠ é€Ÿå·ç§¯ from scipy.signal import fftconvolve return fftconvolve(image, kernel, mode=\u0026#39;valid\u0026#39;) def separable_convolution(image, kernel): # å¯åˆ†ç¦»å·ç§¯ä¼˜åŒ– # å¦‚æœkernelå¯ä»¥åˆ†ç¦»ä¸ºæ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªä¸€ç»´æ ¸ # ä¾‹å¦‚ï¼škernel = h_kernel * v_kernel^T # å‡è®¾kernelæ˜¯å¯åˆ†ç¦»çš„ u, s, vh = np.linalg.svd(kernel) h_kernel = u[:, 0] * np.sqrt(s[0]) v_kernel = vh[0, :] * np.sqrt(s[0]) # å…ˆè¿›è¡Œæ°´å¹³å·ç§¯ temp = np.zeros_like(image) for i in range(image.shape[0]): temp[i, :] = np.convolve(image[i, :], h_kernel, mode=\u0026#39;valid\u0026#39;) # å†è¿›è¡Œå‚ç›´å·ç§¯ output = np.zeros((temp.shape[0] - len(v_kernel) + 1, temp.shape[1])) for j in range(temp.shape[1]): output[:, j] = np.convolve(temp[:, j], v_kernel, mode=\u0026#39;valid\u0026#39;) return output å›¾åƒé‡‘å­—å¡”ä¼˜åŒ– å›¾åƒé‡‘å­—å¡”æ˜¯ä¸€ç§å¤šå°ºåº¦è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥ç”¨äºåŠ é€Ÿå›¾åƒå¤„ç†ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def build_gaussian_pyramid(image, levels): pyramid = [image] for _ in range(levels - 1): # ä¸‹é‡‡æ · image = cv2.pyrDown(image) pyramid.append(image) return pyramid def process_with_pyramid(image, process_func, levels=4): # æ„å»ºé‡‘å­—å¡” pyramid = build_gaussian_pyramid(image, levels) # ä»æœ€ç²—çº§åˆ«å¼€å§‹å¤„ç† result = process_func(pyramid[-1]) # é€çº§ä¸Šé‡‡æ ·å¹¶ç»†åŒ– for i in range(levels - 2, -1, -1): # ä¸Šé‡‡æ ·ç»“æœ result = cv2.pyrUp(result) # è°ƒæ•´å¤§å°ä»¥åŒ¹é…å½“å‰çº§åˆ« result = cv2.resize(result, (pyramid[i].shape[1], pyramid[i].shape[0])) # ä¸å½“å‰çº§åˆ«ç»“åˆ result = process_func(pyramid[i], result) return result æœºå™¨å­¦ä¹ ä¸­çš„ä¼˜åŒ– æ¢¯åº¦ä¸‹é™ä¼˜åŒ– æ¢¯åº¦ä¸‹é™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ï¼Œæœ‰å¤šç§å˜ä½“ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import numpy as np def gradient_descent(X, y, learning_rate=0.01, epochs=1000): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def stochastic_gradient_descent(X, y, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): for i in range(m): # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ xi = X[i:i+1] yi = y[i:i+1] # è®¡ç®—é¢„æµ‹å€¼ prediction = xi.dot(theta) # è®¡ç®—è¯¯å·® error = prediction - yi # è®¡ç®—æ¢¯åº¦ gradient = xi.T.dot(error) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def mini_batch_gradient_descent(X, y, batch_size=32, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # éšæœºæ‰“ä¹±æ•°æ® indices = np.random.permutation(m) X_shuffled = X[indices] y_shuffled = y[indices] # åˆ†æ‰¹å¤„ç† for i in range(0, m, batch_size): X_batch = X_shuffled[i:i+batch_size] y_batch = y_shuffled[i:i+batch_size] # è®¡ç®—é¢„æµ‹å€¼ predictions = X_batch.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y_batch # è®¡ç®—æ¢¯åº¦ gradient = X_batch.T.dot(error) / len(X_batch) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def momentum_gradient_descent(X, y, learning_rate=0.01, momentum=0.9, epochs=1000): m, n = X.shape theta = np.zeros(n) velocity = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°é€Ÿåº¦ velocity = momentum * velocity - learning_rate * gradient # æ›´æ–°å‚æ•° theta += velocity return theta çŸ©é˜µè¿ç®—ä¼˜åŒ– åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼ŒçŸ©é˜µè¿ç®—æ˜¯æ ¸å¿ƒæ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import numpy as np def naive_matrix_multiply(A, B): # åŸå§‹çŸ©é˜µä¹˜æ³•å®ç° m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(m): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] return C def blocked_matrix_multiply(A, B, block_size=32): # åˆ†å—çŸ©é˜µä¹˜æ³•ä¼˜åŒ– m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(0, m, block_size): for j in range(0, p, block_size): for k in range(0, n, block_size): # å¤„ç†å½“å‰å— for ii in range(i, min(i + block_size, m)): for jj in range(j, min(j + block_size, p)): for kk in range(k, min(k + block_size, n)): C[ii, jj] += A[ii, kk] * B[kk, jj] return C def vectorized_matrix_multiply(A, B): # å‘é‡åŒ–çŸ©é˜µä¹˜æ³•ï¼ˆä½¿ç”¨NumPyå†…ç½®å‡½æ•°ï¼‰ return np.dot(A, B) def parallel_matrix_multiply(A, B): # å¹¶è¡ŒçŸ©é˜µä¹˜æ³• from concurrent.futures import ThreadPoolExecutor m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) def compute_row(i): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] with ThreadPoolExecutor() as executor: executor.map(compute_row, range(m)) return C æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ– ç´¢å¼•ä¼˜åŒ– ç´¢å¼•æ˜¯æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–çš„å…³é”®ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æŸ¥è¯¢é€Ÿåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # ç®€å•çš„Bæ ‘ç´¢å¼•å®ç° class BTreeNode: def __init__(self, leaf=False): self.keys = [] self.children = [] self.leaf = leaf class BTree: def __init__(self, t): self.root = BTreeNode(leaf=True) self.t = t # æœ€å°åº¦æ•° def search(self, key, node=None): if node is None: node = self.root i = 0 while i \u0026lt; len(node.keys) and key \u0026gt; node.keys[i]: i += 1 if i \u0026lt; len(node.keys) and key == node.keys[i]: return True # æ‰¾åˆ°é”® if node.leaf: return False # æœªæ‰¾åˆ°é”® return self.search(key, node.children[i]) def insert(self, key): root = self.root if len(root.keys) == (2 * self.t) - 1: # æ ¹èŠ‚ç‚¹å·²æ»¡ï¼Œåˆ›å»ºæ–°æ ¹èŠ‚ç‚¹ new_root = BTreeNode() new_root.children.append(self.root) self.root = new_root self._split_child(new_root, 0) self._insert_nonfull(new_root, key) else: self._insert_nonfull(root, key) def _split_child(self, parent, index): t = self.t y = parent.children[index] z = BTreeNode(leaf=y.leaf) # å°†yçš„ä¸­é—´é”®æå‡åˆ°çˆ¶èŠ‚ç‚¹ parent.keys.insert(index, y.keys[t-1]) # å°†yçš„ååŠéƒ¨åˆ†é”®å¤åˆ¶åˆ°z z.keys = y.keys[t:(2*t-1)] # å¦‚æœyä¸æ˜¯å¶å­èŠ‚ç‚¹ï¼Œå¤åˆ¶å­èŠ‚ç‚¹ if not y.leaf: z.children = y.children[t:(2*t)] # æ›´æ–°yçš„é”®å’Œå­èŠ‚ç‚¹ y.keys = y.keys[0:(t-1)] y.children = y.children[0:t] # å°†zæ’å…¥çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹åˆ—è¡¨ parent.children.insert(index + 1, z) def _insert_nonfull(self, node, key): i = len(node.keys) - 1 if node.leaf: # åœ¨å¶å­èŠ‚ç‚¹ä¸­æ’å…¥é”® node.keys.append(0) while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: node.keys[i+1] = node.keys[i] i -= 1 node.keys[i+1] = key else: # æ‰¾åˆ°åˆé€‚çš„å­èŠ‚ç‚¹ while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: i -= 1 i += 1 # å¦‚æœå­èŠ‚ç‚¹å·²æ»¡ï¼Œå…ˆåˆ†è£‚ if len(node.children[i].keys) == (2 * self.t) - 1: self._split_child(node, i) if key \u0026gt; node.keys[i]: i += 1 self._insert_nonfull(node.children[i], key) æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ– æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–æ˜¯æ•°æ®åº“ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¯ä»¥é€šè¿‡å¤šç§ç­–ç•¥ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class QueryOptimizer: def __init__(self, database): self.database = database def optimize_query(self, query): # è§£ææŸ¥è¯¢ parsed_query = self._parse_query(query) # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = self._generate_execution_plans(parsed_query) # è¯„ä¼°æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬ plan_costs = [self._estimate_cost(plan) for plan in plans] # é€‰æ‹©æˆæœ¬æœ€ä½çš„è®¡åˆ’ best_plan = plans[plan_costs.index(min(plan_costs))] return best_plan def _parse_query(self, query): # ç®€åŒ–çš„æŸ¥è¯¢è§£æ # å®é™…å®ç°ä¼šæ›´å¤æ‚ return { \u0026#39;tables\u0026#39;: query.get(\u0026#39;tables\u0026#39;, []), \u0026#39;conditions\u0026#39;: query.get(\u0026#39;conditions\u0026#39;, []), \u0026#39;projections\u0026#39;: query.get(\u0026#39;projections\u0026#39;, []), \u0026#39;order_by\u0026#39;: query.get(\u0026#39;order_by\u0026#39;, []), \u0026#39;limit\u0026#39;: query.get(\u0026#39;limit\u0026#39;, None) } def _generate_execution_plans(self, parsed_query): # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = [] # ç®€å•å®ç°ï¼šåªè€ƒè™‘è¡¨è¿æ¥é¡ºåº tables = parsed_query[\u0026#39;tables\u0026#39;] # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è¡¨è¿æ¥é¡ºåº from itertools import permutations for table_order in permutations(tables): plan = { \u0026#39;table_order\u0026#39;: table_order, \u0026#39;join_method\u0026#39;: \u0026#39;nested_loop\u0026#39;, # å¯ä»¥æ˜¯nested_loop, hash_join, merge_join \u0026#39;access_method\u0026#39;: {table: \u0026#39;index_scan\u0026#39; for table in tables}, # å¯ä»¥æ˜¯full_scan, index_scan \u0026#39;conditions\u0026#39;: parsed_query[\u0026#39;conditions\u0026#39;], \u0026#39;projections\u0026#39;: parsed_query[\u0026#39;projections\u0026#39;], \u0026#39;order_by\u0026#39;: parsed_query[\u0026#39;order_by\u0026#39;], \u0026#39;limit\u0026#39;: parsed_query[\u0026#39;limit\u0026#39;] } plans.append(plan) return plans def _estimate_cost(self, plan): # ä¼°è®¡æ‰§è¡Œè®¡åˆ’çš„æˆæœ¬ cost = 0 # ä¼°è®¡è¡¨è®¿é—®æˆæœ¬ for table in plan[\u0026#39;table_order\u0026#39;]: access_method = plan[\u0026#39;access_method\u0026#39;][table] table_stats = self.database.get_table_stats(table) if access_method == \u0026#39;full_scan\u0026#39;: cost += table_stats[\u0026#39;row_count\u0026#39;] elif access_method == \u0026#39;index_scan\u0026#39;: # å‡è®¾ç´¢å¼•å¯ä»¥è¿‡æ»¤æ‰90%çš„æ•°æ® cost += table_stats[\u0026#39;row_count\u0026#39;] * 0.1 # ä¼°è®¡è¿æ¥æˆæœ¬ for i in range(len(plan[\u0026#39;table_order\u0026#39;]) - 1): join_method = plan[\u0026#39;join_method\u0026#39;] if join_method == \u0026#39;nested_loop\u0026#39;: # åµŒå¥—å¾ªç¯è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] * right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;hash_join\u0026#39;: # å“ˆå¸Œè¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;merge_join\u0026#39;: # åˆå¹¶è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] # ä¼°è®¡æ’åºæˆæœ¬ if plan[\u0026#39;order_by\u0026#39;]: # å‡è®¾æ’åºæˆæœ¬ä¸ºn log n result_size = cost # ç®€åŒ–å‡è®¾ cost += result_size * np.log2(result_size) return cost æ€§èƒ½åˆ†æå·¥å…· æ—¶é—´åˆ†æå·¥å…· Pythonä¸­çš„æ—¶é—´åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import time import timeit import cProfile import pstats def time_function(func, *args, **kwargs): # ç®€å•çš„æ—¶é—´æµ‹é‡ start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f\u0026#34;å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: {end_time - start_time:.6f} ç§’\u0026#34;) return result def benchmark_function(func, *args, **kwargs): # ä½¿ç”¨timeitè¿›è¡Œæ›´ç²¾ç¡®çš„åŸºå‡†æµ‹è¯• import functools wrapped = functools.partial(func, *args, **kwargs) time_taken = timeit.timeit(wrapped, number=1000) print(f\u0026#34;å‡½æ•° {func.__name__} å¹³å‡æ‰§è¡Œæ—¶é—´: {time_taken/1000:.6f} ç§’\u0026#34;) return func(*args, **kwargs) def profile_function(func, *args, **kwargs): # ä½¿ç”¨cProfileè¿›è¡Œè¯¦ç»†æ€§èƒ½åˆ†æ profiler = cProfile.Profile() profiler.enable() result = func(*args, **kwargs) profiler.disable() stats = pstats.Stats(profiler).sort_stats(\u0026#39;cumulative\u0026#39;) stats.print_stats() return result å†…å­˜åˆ†æå·¥å…· Pythonä¸­çš„å†…å­˜åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import sys import tracemalloc import objgraph def get_object_size(obj): # è·å–å¯¹è±¡çš„å†…å­˜å¤§å° return sys.getsizeof(obj) def trace_memory(func, *args, **kwargs): # è·Ÿè¸ªå†…å­˜ä½¿ç”¨æƒ…å†µ tracemalloc.start() result = func(*args, **kwargs) snapshot = tracemalloc.take_snapshot() top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) print(\u0026#34;[ å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œ ]\u0026#34;) for stat in top_stats[:10]: print(stat) tracemalloc.stop() return result def analyze_object_growth(func, *args, **kwargs): # åˆ†æå¯¹è±¡å¢é•¿æƒ…å†µ objgraph.show_growth() result = func(*args, **kwargs) objgraph.show_growth() return result å¯è§†åŒ–åˆ†æå·¥å…· ä½¿ç”¨matplotlibå¯è§†åŒ–æ€§èƒ½æ•°æ® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import matplotlib.pyplot as plt import numpy as np def plot_time_complexity(algorithms, input_sizes, title=\u0026#34;æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒ\u0026#34;): # ç»˜åˆ¶ç®—æ³•æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒå›¾ plt.figure(figsize=(10, 6)) for name, func in algorithms.items(): times = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡æ‰§è¡Œæ—¶é—´ start_time = time.time() func(test_data) end_time = time.time() times.append(end_time - start_time) plt.plot(input_sizes, times, label=name, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;æ‰§è¡Œæ—¶é—´ (ç§’)\u0026#39;) plt.title(title) plt.legend() plt.grid(True) plt.show() def generate_test_data(size): # ç”Ÿæˆæµ‹è¯•æ•°æ® return np.random.rand(size) def plot_memory_usage(func, input_sizes, title=\u0026#34;å†…å­˜ä½¿ç”¨æƒ…å†µ\u0026#34;): # ç»˜åˆ¶å‡½æ•°å†…å­˜ä½¿ç”¨æƒ…å†µå›¾ memory_usage = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡å†…å­˜ä½¿ç”¨ tracemalloc.start() func(test_data) snapshot = tracemalloc.take_snapshot() current, peak = tracemalloc.get_traced_memory() tracemalloc.stop() memory_usage.append(peak / (1024 * 1024)) # è½¬æ¢ä¸ºMB plt.figure(figsize=(10, 6)) plt.plot(input_sizes, memory_usage, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;å†…å­˜ä½¿ç”¨ (MB)\u0026#39;) plt.title(title) plt.grid(True) plt.show() æ€»ç»“ ç®—æ³•ä¼˜åŒ–æ˜¯æå‡è½¯ä»¶æ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚æœ¬æ–‡ä»ç®—æ³•å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä»‹ç»äº†æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦çš„æ¦‚å¿µåŠåˆ†ææ–¹æ³•ï¼Œç„¶åè¯¦ç»†æ¢è®¨äº†å„ç§ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬æ—¶é—´ä¼˜åŒ–ã€ç©ºé—´ä¼˜åŒ–å’Œæ—¶ç©ºæƒè¡¡ã€‚\né€šè¿‡å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ï¼Œå¦‚æ’åºç®—æ³•ã€æœç´¢ç®—æ³•ã€å›¾ç®—æ³•å’ŒåŠ¨æ€è§„åˆ’çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬äº†è§£äº†å¦‚ä½•å°†ç†è®ºåº”ç”¨åˆ°å®è·µä¸­ã€‚å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æå±•ç¤ºäº†ç®—æ³•ä¼˜åŒ–åœ¨å›¾åƒå¤„ç†ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®åº“æŸ¥è¯¢ç­‰é¢†åŸŸçš„å…·ä½“åº”ç”¨ã€‚\næœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†å„ç§æ€§èƒ½åˆ†æå·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\nç®—æ³•ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­å­¦ä¹ å’Œå®è·µçš„è¿‡ç¨‹ã€‚éšç€æŠ€æœ¯çš„å‘å±•ï¼Œæ–°çš„ä¼˜åŒ–æ–¹æ³•å’Œå·¥å…·ä¸æ–­æ¶Œç°ã€‚æŒæ¡è¿™äº›ä¼˜åŒ–æŠ€å·§ï¼Œä¸ä»…èƒ½å¤Ÿæé«˜ä»£ç æ€§èƒ½ï¼Œè¿˜èƒ½åŸ¹å…»ç³»ç»Ÿæ€ç»´å’Œé—®é¢˜è§£å†³èƒ½åŠ›ï¼Œä¸ºæˆä¸ºä¸€åä¼˜ç§€çš„è½¯ä»¶å·¥ç¨‹å¸ˆå¥ å®šåŸºç¡€ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…æ·±å…¥ç†è§£ç®—æ³•ä¼˜åŒ–çš„åŸç†å’Œæ–¹æ³•ï¼Œå¹¶åœ¨å®é™…å¼€å‘ä¸­çµæ´»åº”ç”¨ï¼Œåˆ›é€ å‡ºæ›´é«˜æ•ˆã€æ›´ä¼˜é›…çš„ä»£ç ã€‚\n","permalink":"http://localhost:1313/posts/algorithm-optimization/","summary":"\u003ch1 id=\"ç®—æ³•ä¼˜åŒ–ä»ç†è®ºåˆ°å®è·µ\"\u003eç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ\u003c/h1\u003e\n\u003cp\u003eåœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\u003c/p\u003e","title":"ç®—æ³•ä¼˜åŒ–ï¼šæå‡ä»£ç æ€§èƒ½çš„å®ç”¨æŠ€å·§"},{"content":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\nå›¾åƒçš„åŸºæœ¬è¡¨ç¤º åƒç´ ä¸å›¾åƒçŸ©é˜µ åœ¨æ•°å­—ä¸–ç•Œä¸­ï¼Œå›¾åƒç”±åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚å¯¹äºç°åº¦å›¾åƒï¼Œæ¯ä¸ªåƒç´ çš„å€¼è¡¨ç¤ºäº®åº¦ï¼Œé€šå¸¸èŒƒå›´æ˜¯0ï¼ˆé»‘è‰²ï¼‰åˆ°255ï¼ˆç™½è‰²ï¼‰ã€‚å¯¹äºå½©è‰²å›¾åƒï¼Œé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“è¡¨ç¤ºï¼Œæ¯ä¸ªé€šé“çš„å€¼èŒƒå›´ä¹Ÿæ˜¯0åˆ°255ã€‚\nåœ¨è®¡ç®—æœºä¸­ï¼Œå›¾åƒé€šå¸¸è¡¨ç¤ºä¸ºçŸ©é˜µã€‚ç°åº¦å›¾åƒæ˜¯äºŒç»´çŸ©é˜µï¼Œè€Œå½©è‰²å›¾åƒæ˜¯ä¸‰ç»´çŸ©é˜µï¼ˆé«˜åº¦Ã—å®½åº¦Ã—é€šé“æ•°ï¼‰ã€‚\n1 2 3 4 5 6 7 8 # Pythonä¸­ä½¿ç”¨NumPyè¡¨ç¤ºå›¾åƒ import numpy as np # åˆ›å»ºä¸€ä¸ª100x100çš„ç°åº¦å›¾åƒï¼ˆå…¨é»‘ï¼‰ gray_image = np.zeros((100, 100), dtype=np.uint8) # åˆ›å»ºä¸€ä¸ª100x100x3çš„å½©è‰²å›¾åƒï¼ˆå…¨é»‘ï¼‰ color_image = np.zeros((100, 100, 3), dtype=np.uint8) å›¾åƒç±»å‹ äºŒå€¼å›¾åƒï¼šæ¯ä¸ªåƒç´ åªæœ‰ä¸¤ä¸ªå¯èƒ½çš„å€¼ï¼ˆé€šå¸¸æ˜¯0å’Œ1ï¼‰ï¼Œè¡¨ç¤ºé»‘ç™½ä¸¤è‰²ã€‚ ç°åº¦å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰ä¸€ä¸ªå€¼ï¼Œè¡¨ç¤ºä»é»‘åˆ°ç™½çš„ç°åº¦çº§åˆ«ã€‚ å½©è‰²å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰å¤šä¸ªå€¼ï¼Œé€šå¸¸ä½¿ç”¨RGBã€HSVæˆ–CMYKç­‰é¢œè‰²æ¨¡å‹è¡¨ç¤ºã€‚ å¤šå…‰è°±å›¾åƒï¼šåŒ…å«å¤šä¸ªå…‰è°±é€šé“çš„å›¾åƒï¼Œå¦‚å«æ˜Ÿå›¾åƒã€‚ 3Då›¾åƒï¼šè¡¨ç¤ºä¸‰ç»´ç©ºé—´æ•°æ®çš„å›¾åƒï¼Œå¦‚åŒ»å­¦CTæ‰«æã€‚ åŸºæœ¬å›¾åƒæ“ä½œ å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨Pythonçš„OpenCVåº“å¯ä»¥è½»æ¾è¯»å–å’Œæ˜¾ç¤ºå›¾åƒï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 import cv2 import matplotlib.pyplot as plt # è¯»å–å›¾åƒ image = cv2.imread(\u0026#39;image.jpg\u0026#39;) # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆOpenCVé»˜è®¤ä½¿ç”¨BGRï¼Œè€Œmatplotlibä½¿ç”¨RGBï¼‰ image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() å›¾åƒç¼©æ”¾ä¸æ—‹è½¬ 1 2 3 4 5 6 7 8 # ç¼©æ”¾å›¾åƒ resized_image = cv2.resize(image, (width, height)) # æ—‹è½¬å›¾åƒ (h, w) = image.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) # æ—‹è½¬45åº¦ï¼Œç¼©æ”¾å› å­ä¸º1.0 rotated_image = cv2.warpAffine(image, M, (w, h)) å›¾åƒè£å‰ªä¸æ‹¼æ¥ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image[100:400, 200:500] # æ‹¼æ¥å›¾åƒ (æ°´å¹³æ‹¼æ¥) horizontal_concat = np.hstack((image1, image2)) # å‚ç›´æ‹¼æ¥ vertical_concat = np.vstack((image1, image2)) å›¾åƒå¢å¼ºæŠ€æœ¯ äº®åº¦ä¸å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 # äº®åº¦è°ƒæ•´ (å¢åŠ 50ä¸ªå•ä½) brightness_image = cv2.add(image, np.ones(image.shape, dtype=np.uint8) * 50) # å¯¹æ¯”åº¦è°ƒæ•´ (1.5å€) contrast_image = cv2.multiply(image, 1.5) ç›´æ–¹å›¾å‡è¡¡åŒ– ç›´æ–¹å›¾å‡è¡¡åŒ–æ˜¯ä¸€ç§å¢å¼ºå›¾åƒå¯¹æ¯”åº¦çš„æ–¹æ³•ï¼Œé€šè¿‡é‡æ–°åˆ†å¸ƒå›¾åƒçš„åƒç´ å¼ºåº¦ï¼Œä½¿å…¶ç›´æ–¹å›¾å¹³å¦åŒ–ã€‚\n1 2 3 # ç°åº¦å›¾åƒç›´æ–¹å›¾å‡è¡¡åŒ– gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) equalized_image = cv2.equalizeHist(gray_image) ä¼½é©¬æ ¡æ­£ ä¼½é©¬æ ¡æ­£ç”¨äºè°ƒæ•´å›¾åƒçš„äº®åº¦ï¼Œç‰¹åˆ«é€‚ç”¨äºæ˜¾ç¤ºè®¾å¤‡çš„éçº¿æ€§å“åº”ã€‚\ngamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼\n1 2 3 4 5 6 7 8 9 # ä¼½é©¬æ ¡æ­£å‡½æ•° def gamma_correction(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) gamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼ å›¾åƒæ»¤æ³¢ å›¾åƒæ»¤æ³¢æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œç”¨äºå»å™ªã€è¾¹ç¼˜æ£€æµ‹å’Œç‰¹å¾æå–ç­‰ä»»åŠ¡ã€‚\nå‡å€¼æ»¤æ³¢ å‡å€¼æ»¤æ³¢æ˜¯æœ€ç®€å•çš„æ»¤æ³¢æ–¹æ³•ä¹‹ä¸€ï¼Œå®ƒç”¨é‚»åŸŸåƒç´ çš„å¹³å‡å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ã€‚\n1 2 # 5x5å‡å€¼æ»¤æ³¢ blurred_image = cv2.blur(image, (5, 5)) é«˜æ–¯æ»¤æ³¢ é«˜æ–¯æ»¤æ³¢ä½¿ç”¨é«˜æ–¯å‡½æ•°ä½œä¸ºæƒé‡ï¼Œå¯¹é‚»åŸŸåƒç´ è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å™ªå£°åŒæ—¶ä¿ç•™è¾¹ç¼˜ä¿¡æ¯ã€‚\n1 2 # 5x5é«˜æ–¯æ»¤æ³¢ gaussian_blurred = cv2.GaussianBlur(image, (5, 5), 0) ä¸­å€¼æ»¤æ³¢ ä¸­å€¼æ»¤æ³¢ç”¨é‚»åŸŸåƒç´ çš„ä¸­å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ï¼Œå¯¹äºå»é™¤æ¤’ç›å™ªå£°ç‰¹åˆ«æœ‰æ•ˆã€‚\n1 2 # 5x5ä¸­å€¼æ»¤æ³¢ median_blurred = cv2.medianBlur(image, 5) åŒè¾¹æ»¤æ³¢ åŒè¾¹æ»¤æ³¢åœ¨è€ƒè™‘ç©ºé—´é‚»è¿‘åº¦çš„åŒæ—¶ï¼Œä¹Ÿè€ƒè™‘åƒç´ å€¼çš„ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿåœ¨å¹³æ»‘å›¾åƒçš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ã€‚\n1 2 # åŒè¾¹æ»¤æ³¢ bilateral_filtered = cv2.bilateralFilter(image, 9, 75, 75) è¾¹ç¼˜æ£€æµ‹ è¾¹ç¼˜æ£€æµ‹æ˜¯å›¾åƒå¤„ç†ä¸­çš„é‡è¦ä»»åŠ¡ï¼Œç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“è¾¹ç•Œã€‚\nSobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Sobelè¾¹ç¼˜æ£€æµ‹ sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3) # æ°´å¹³æ–¹å‘ sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3) # å‚ç›´æ–¹å‘ # è®¡ç®—æ¢¯åº¦å¹…å€¼ gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2) # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´ gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255) Cannyè¾¹ç¼˜æ£€æµ‹ Cannyè¾¹ç¼˜æ£€æµ‹æ˜¯ä¸€ç§å¤šé˜¶æ®µçš„è¾¹ç¼˜æ£€æµ‹ç®—æ³•ï¼Œè¢«è®¤ä¸ºæ˜¯ç›®å‰æœ€ä¼˜çš„è¾¹ç¼˜æ£€æµ‹æ–¹æ³•ä¹‹ä¸€ã€‚\n1 2 # Cannyè¾¹ç¼˜æ£€æµ‹ edges = cv2.Canny(gray, 100, 200) # é˜ˆå€¼1å’Œé˜ˆå€¼2 Laplacianç®—å­ 1 2 3 # Laplacianè¾¹ç¼˜æ£€æµ‹ laplacian = cv2.Laplacian(gray, cv2.CV_64F) laplacian = np.uint8(np.absolute(laplacian)) å½¢æ€å­¦æ“ä½œ å½¢æ€å­¦æ“ä½œåŸºäºå›¾åƒçš„å½¢çŠ¶ï¼Œå¸¸ç”¨äºäºŒå€¼å›¾åƒçš„å¤„ç†ã€‚\nè…èš€ä¸è†¨èƒ€ 1 2 3 4 5 6 7 8 # åˆ›å»ºä¸€ä¸ª5x5çš„æ ¸ kernel = np.ones((5, 5), np.uint8) # è…èš€æ“ä½œ eroded_image = cv2.erode(binary_image, kernel, iterations=1) # è†¨èƒ€æ“ä½œ dilated_image = cv2.dilate(binary_image, kernel, iterations=1) å¼€è¿ç®—ä¸é—­è¿ç®— 1 2 3 4 5 # å¼€è¿ç®—ï¼ˆå…ˆè…èš€åè†¨èƒ€ï¼‰ opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel) # é—­è¿ç®—ï¼ˆå…ˆè†¨èƒ€åè…èš€ï¼‰ closing = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel) å½¢æ€å­¦æ¢¯åº¦ 1 2 # å½¢æ€å­¦æ¢¯åº¦ï¼ˆè†¨èƒ€å‡è…èš€ï¼‰ gradient = cv2.morphologyEx(binary_image, cv2.MORPH_GRADIENT, kernel) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²æ˜¯å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡çš„è¿‡ç¨‹ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦ä»»åŠ¡ã€‚\né˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 # å…¨å±€é˜ˆå€¼åˆ†å‰² _, thresholded = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_threshold = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) åˆ†æ°´å²­ç®—æ³• åˆ†æ°´å²­ç®—æ³•æ˜¯ä¸€ç§åŸºäºæ‹“æ‰‘ç†è®ºçš„å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºå¯¹æ¥è§¦ç‰©ä½“çš„åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 # æ ‡è®°èƒŒæ™¯å’Œå‰æ™¯ ret, markers = cv2.connectedComponents(sure_foreground) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(image, markers) image[markers == -1] = [255, 0, 0] # æ ‡è®°åˆ†æ°´å²­è¾¹ç•Œ K-meansèšç±» 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # å°†å›¾åƒé‡å¡‘ä¸º2Dæ•°ç»„ pixel_values = image.reshape((-1, 3)) pixel_values = np.float32(pixel_values) # å®šä¹‰åœæ­¢æ ‡å‡†å’ŒKå€¼ criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2) k = 3 # åº”ç”¨K-meansèšç±» _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) # è½¬æ¢å›åŸå§‹å›¾åƒå½¢çŠ¶å¹¶åº”ç”¨èšç±»ç»“æœ centers = np.uint8(centers) segmented_image = centers[labels.flatten()] segmented_image = segmented_image.reshape(image.shape) å›¾åƒç‰¹å¾æå– ç‰¹å¾æå–æ˜¯ä»å›¾åƒä¸­æå–æœ‰æ„ä¹‰ä¿¡æ¯çš„è¿‡ç¨‹ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥ç”¨äºå›¾åƒè¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢ç­‰ä»»åŠ¡ã€‚\nè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 # Harrisè§’ç‚¹æ£€æµ‹ gray = np.float32(gray) harris_corners = cv2.cornerHarris(gray, 2, 3, 0.04) harris_corners = cv2.dilate(harris_corners, None) # æ ‡è®°è§’ç‚¹ image[harris_corners \u0026gt; 0.01 * harris_corners.max()] = [0, 0, 255] SIFTç‰¹å¾ SIFTï¼ˆScale-Invariant Feature Transformï¼‰æ˜¯ä¸€ç§ç”¨äºæ£€æµ‹å’Œæè¿°å›¾åƒå±€éƒ¨ç‰¹å¾çš„ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray, keypoints, None) ORBç‰¹å¾ ORBæ˜¯ä¸€ç§å¿«é€Ÿçš„ç‰¹å¾æ£€æµ‹å™¨å’Œæè¿°ç¬¦ï¼Œç»“åˆäº†FASTå…³é”®ç‚¹æ£€æµ‹å™¨å’ŒBRIEFæè¿°ç¬¦ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray, keypoints, None) åº”ç”¨åœºæ™¯ å›¾åƒå¤„ç†æŠ€æœ¯å¹¿æ³›åº”ç”¨äºå„ä¸ªé¢†åŸŸï¼š\nåŒ»å­¦å½±åƒï¼šCTã€MRIå›¾åƒçš„åˆ†æå’Œè¯Šæ–­ï¼Œç»†èƒè®¡æ•°ï¼Œç—…å˜æ£€æµ‹ç­‰ã€‚ è‡ªåŠ¨é©¾é©¶ï¼šè½¦é“çº¿æ£€æµ‹ï¼Œéšœç¢ç‰©è¯†åˆ«ï¼Œäº¤é€šæ ‡å¿—è¯†åˆ«ç­‰ã€‚ å®‰é˜²ç›‘æ§ï¼šäººè„¸è¯†åˆ«ï¼Œè¡Œä¸ºåˆ†æï¼Œå¼‚å¸¸æ£€æµ‹ç­‰ã€‚ å·¥ä¸šæ£€æµ‹ï¼šäº§å“ç¼ºé™·æ£€æµ‹ï¼Œå°ºå¯¸æµ‹é‡ï¼Œè´¨é‡æ§åˆ¶ç­‰ã€‚ é¥æ„Ÿå›¾åƒï¼šåœŸåœ°åˆ©ç”¨åˆ†ç±»ï¼Œç¯å¢ƒç›‘æµ‹ï¼Œç¾å®³è¯„ä¼°ç­‰ã€‚ å¢å¼ºç°å®ï¼šå›¾åƒé…å‡†ï¼Œç›®æ ‡è·Ÿè¸ªï¼Œåœºæ™¯ç†è§£ç­‰ã€‚ æ•°å­—å¨±ä¹ï¼šå›¾åƒç¾åŒ–ï¼Œç‰¹æ•ˆå¤„ç†ï¼Œè™šæ‹Ÿç°å®ç­‰ã€‚ æ€»ç»“ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰çš„åŸºç¡€ï¼Œæ¶µç›–äº†ä»åŸºæœ¬çš„åƒç´ æ“ä½œåˆ°å¤æ‚çš„ç‰¹å¾æå–å’Œåˆ†æã€‚æœ¬æ–‡ä»‹ç»äº†å›¾åƒçš„åŸºæœ¬è¡¨ç¤ºã€åŸºæœ¬æ“ä½œã€å›¾åƒå¢å¼ºæŠ€æœ¯ã€æ»¤æ³¢æ–¹æ³•ã€è¾¹ç¼˜æ£€æµ‹ã€å½¢æ€å­¦æ“ä½œã€å›¾åƒåˆ†å‰²å’Œç‰¹å¾æå–ç­‰å†…å®¹ã€‚\næŒæ¡è¿™äº›åŸºç¡€çŸ¥è¯†å¯¹äºè¿›ä¸€æ­¥å­¦ä¹ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ è‡³å…³é‡è¦ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸éœ€è¦æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©åˆé€‚çš„å›¾åƒå¤„ç†æ–¹æ³•ï¼Œå¹¶å¯èƒ½éœ€è¦ç»„åˆå¤šç§æŠ€æœ¯æ¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¸å¤šä¼ ç»Ÿçš„å›¾åƒå¤„ç†ä»»åŠ¡ç°åœ¨ä¹Ÿå¯ä»¥é€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•å®ç°ï¼Œä½†ç†è§£ä¼ ç»Ÿå›¾åƒå¤„ç†çš„åŸºæœ¬åŸç†ä»ç„¶éå¸¸é‡è¦ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ å…¥é—¨å›¾åƒå¤„ç†é¢†åŸŸï¼Œä¸ºåç»­çš„å­¦ä¹ å’Œç ”ç©¶æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\n","permalink":"http://localhost:1313/posts/image-processing-basics/","summary":"\u003ch1 id=\"å›¾åƒå¤„ç†åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eå›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eå›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\u003c/p\u003e","title":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°æ»¤æ³¢"},{"content":"404 - é¡µé¢ä¸å­˜åœ¨ æŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\næ‚¨å¯ä»¥å°è¯•ï¼š è¿”å›é¦–é¡µ æŸ¥çœ‹æ–‡ç« åˆ—è¡¨ ä½¿ç”¨æœç´¢åŠŸèƒ½ æŸ¥çœ‹ç½‘ç«™åœ°å›¾ å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡å…³äºé¡µé¢ä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\n","permalink":"http://localhost:1313/404/","summary":"\u003ch1 id=\"404---é¡µé¢ä¸å­˜åœ¨\"\u003e404 - é¡µé¢ä¸å­˜åœ¨\u003c/h1\u003e\n\u003cp\u003eæŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\u003c/p\u003e\n\u003ch2 id=\"æ‚¨å¯ä»¥å°è¯•\"\u003eæ‚¨å¯ä»¥å°è¯•ï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/\"\u003eè¿”å›é¦–é¡µ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/\"\u003eæŸ¥çœ‹æ–‡ç« åˆ—è¡¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/search/\"\u003eä½¿ç”¨æœç´¢åŠŸèƒ½\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sitemap.xml\"\u003eæŸ¥çœ‹ç½‘ç«™åœ°å›¾\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eå¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡\u003ca href=\"/about/\"\u003eå…³äºé¡µé¢\u003c/a\u003eä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\u003c/p\u003e","title":"404 é¡µé¢ä¸å­˜åœ¨"},{"content":"ä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\næŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\nå‘å¸ƒäº 2025å¹´9æœˆ24æ—¥ ä¸Šåˆ10:30\n","permalink":"http://localhost:1313/thoughts/2025-09-24-first-thought/","summary":"\u003cp\u003eä»Šå¤©å¯¹åšå®¢è¿›è¡Œäº†ä¸€äº›ä¼˜åŒ–ï¼Œå¢åŠ äº†è¿™ä¸ª\u0026quot;éšæƒ³\u0026quot;é¡µé¢ï¼Œå¸Œæœ›å¯ä»¥æ›´æ–¹ä¾¿åœ°è®°å½•æ—¥å¸¸çš„æƒ³æ³•å’Œæ„Ÿæ‚Ÿã€‚\u003c/p\u003e\n\u003cp\u003eæŠ€æœ¯æ–¹é¢ï¼Œæœ€è¿‘åœ¨æ€è€ƒå¦‚ä½•æ›´å¥½åœ°ç»„ç»‡ä»£ç ç»“æ„ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚æœ‰æ—¶å€™ç®€å•çš„åŠŸèƒ½ä¹Ÿä¼šæœ‰å¤æ‚çš„å®ç°ï¼Œå…³é”®æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„æŠ½è±¡å±‚æ¬¡ã€‚\u003c/p\u003e","title":"åšå®¢éšæƒ³åŠŸèƒ½ä¸Šçº¿äº†"},{"content":"ç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\næœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\nå‘å¸ƒäº 2025å¹´9æœˆ23æ—¥ ä¸‹åˆ3:45\n","permalink":"http://localhost:1313/thoughts/2025-09-23-meditation/","summary":"\u003cp\u003eç”Ÿæ´»æ–¹é¢ï¼Œæ„Ÿè§‰æ—¶é—´è¿‡å¾—å¾ˆå¿«ï¼Œéœ€è¦æ›´å¥½åœ°å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ã€‚æœ€è¿‘å¼€å§‹å°è¯•æ¯å¤©å†¥æƒ³10åˆ†é’Ÿï¼Œå¸Œæœ›èƒ½å¸®åŠ©è‡ªå·±ä¿æŒä¸“æ³¨å’Œå¹³é™ã€‚\u003c/p\u003e\n\u003cp\u003eæœ‰æ—¶å€™åœä¸‹æ¥æ€è€ƒæ¯”ä¸€ç›´å¿™ç¢Œæ›´é‡è¦ã€‚ğŸ§˜â€â™‚ï¸\u003c/p\u003e","title":"å…³äºå†¥æƒ³å’Œç”Ÿæ´»å¹³è¡¡çš„æ€è€ƒ"},{"content":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š Gitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\nGitåŸºç¡€æ¦‚å¿µ ä»€ä¹ˆæ˜¯Gitï¼Ÿ Gitæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œç”±Linus Torvaldsäº2005å¹´åˆ›å»ºã€‚ä¸é›†ä¸­å¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ˆå¦‚SVNï¼‰ä¸åŒï¼ŒGitçš„æ¯ä¸ªå¼€å‘è€…éƒ½æ‹¥æœ‰å®Œæ•´çš„ä»£ç ä»“åº“å‰¯æœ¬ï¼Œè¿™ä½¿å¾—Gitåœ¨é€Ÿåº¦ã€æ•°æ®å®Œæ•´æ€§å’Œæ”¯æŒåˆ†å¸ƒå¼å¼€å‘æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚\nGitçš„åŸºæœ¬å·¥ä½œåŒº Gitæœ‰ä¸‰ä¸ªä¸»è¦çš„å·¥ä½œåŒºï¼š\nå·¥ä½œåŒº(Working Directory)ï¼šä½ å½“å‰æ­£åœ¨å·¥ä½œçš„ç›®å½•ï¼ŒåŒ…å«é¡¹ç›®çš„æ‰€æœ‰æ–‡ä»¶ã€‚ æš‚å­˜åŒº(Staging Area)ï¼šä¹Ÿç§°ä¸º\u0026quot;ç´¢å¼•(Index)\u0026quot;ï¼Œæ˜¯ä¸€ä¸ªä¸´æ—¶ä¿å­˜ä¿®æ”¹çš„åœ°æ–¹ã€‚ æœ¬åœ°ä»“åº“(Local Repository)ï¼šGitä¿å­˜é¡¹ç›®å…ƒæ•°æ®å’Œå¯¹è±¡æ•°æ®åº“çš„åœ°æ–¹ã€‚ æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªè¿œç¨‹ä»“åº“(Remote Repository)ï¼Œé€šå¸¸æ˜¯æ‰˜ç®¡åœ¨GitHubã€GitLabç­‰å¹³å°ä¸Šçš„ä»“åº“ï¼Œç”¨äºå›¢é˜Ÿåä½œå’Œå¤‡ä»½ã€‚\nGitçš„åŸºæœ¬å·¥ä½œæµç¨‹ Gitçš„åŸºæœ¬å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š\nåœ¨å·¥ä½œåŒºä¿®æ”¹æ–‡ä»¶ ä½¿ç”¨git addå°†ä¿®æ”¹æ·»åŠ åˆ°æš‚å­˜åŒº ä½¿ç”¨git commitå°†æš‚å­˜åŒºçš„å†…å®¹æäº¤åˆ°æœ¬åœ°ä»“åº“ ä½¿ç”¨git pushå°†æœ¬åœ°ä»“åº“çš„ä¿®æ”¹æ¨é€åˆ°è¿œç¨‹ä»“åº“ GitåŸºæœ¬å‘½ä»¤ åˆå§‹åŒ–é…ç½® é…ç½®ç”¨æˆ·ä¿¡æ¯ 1 2 3 4 5 6 7 8 # é…ç½®å…¨å±€ç”¨æˆ·å git config --global user.name \u0026#34;Your Name\u0026#34; # é…ç½®å…¨å±€é‚®ç®± git config --global user.email \u0026#34;your.email@example.com\u0026#34; # æŸ¥çœ‹é…ç½® git config --list åˆå§‹åŒ–ä»“åº“ 1 2 3 4 5 # åœ¨å½“å‰ç›®å½•åˆå§‹åŒ–Gitä»“åº“ git init # å…‹éš†è¿œç¨‹ä»“åº“ git clone https://github.com/username/repository.git åŸºæœ¬æ“ä½œ æŸ¥çœ‹çŠ¶æ€ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # æŸ¥çœ‹å·¥ä½œåŒºçŠ¶æ€ git status # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä¿®æ”¹æƒ…å†µ # æŸ¥çœ‹ç®€åŒ–çŠ¶æ€ git status -s # ç®€åŒ–è¾“å‡ºï¼Œé€‚åˆå¿«é€ŸæŸ¥çœ‹ # æŸ¥çœ‹æäº¤å†å² git log # æ˜¾ç¤ºè¯¦ç»†æäº¤è®°å½• # æŸ¥çœ‹ç®€æ´æäº¤å†å² git log --oneline # æ¯æ¡æäº¤ä¸€è¡Œï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ # æŸ¥çœ‹å›¾å½¢åŒ–æäº¤å†å² git log --graph --oneline --all æ·»åŠ å’Œæäº¤ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ·»åŠ æŒ‡å®šæ–‡ä»¶åˆ°æš‚å­˜åŒº git add filename # æ·»åŠ æ‰€æœ‰ä¿®æ”¹åˆ°æš‚å­˜åŒº git add . # æ·»åŠ æ‰€æœ‰ä¿®æ”¹ï¼ˆåŒ…æ‹¬æ–°æ–‡ä»¶ï¼‰åˆ°æš‚å­˜åŒº git add -A # æäº¤æš‚å­˜åŒºå†…å®¹ git commit -m \u0026#34;Commit message\u0026#34; # è·³è¿‡æš‚å­˜åŒºç›´æ¥æäº¤ git commit -a -m \u0026#34;Commit message\u0026#34; # ä¿®æ”¹æœ€åä¸€æ¬¡æäº¤ä¿¡æ¯ git commit --amend æŸ¥çœ‹å’Œæ¯”è¾ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æŸ¥çœ‹å·¥ä½œåŒºä¸æš‚å­˜åŒºçš„å·®å¼‚ git diff # æŸ¥çœ‹æš‚å­˜åŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff --staged # æŸ¥çœ‹å·¥ä½œåŒºä¸æœ¬åœ°ä»“åº“çš„å·®å¼‚ git diff HEAD # æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶çš„å·®å¼‚ git diff filename # æŸ¥çœ‹æŒ‡å®šæäº¤çš„å·®å¼‚ git diff commit1 commit2 æ’¤é”€æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # æ’¤é”€å·¥ä½œåŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°æš‚å­˜åŒºçŠ¶æ€ï¼‰ git checkout -- filename # æ’¤é”€æš‚å­˜åŒºçš„ä¿®æ”¹ï¼ˆæ¢å¤åˆ°å·¥ä½œåŒºçŠ¶æ€ï¼‰ git reset HEAD filename # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~1 # æ’¤é”€æœ€åä¸€æ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~1 # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¿ç•™ä¿®æ”¹ï¼‰ git reset --soft HEAD~n # æ’¤é”€å¤šæ¬¡æäº¤ï¼ˆä¸¢å¼ƒä¿®æ”¹ï¼‰ git reset --hard HEAD~n è¿œç¨‹ä»“åº“æ“ä½œ æ·»åŠ å’Œç®¡ç†è¿œç¨‹ä»“åº“ 1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹è¿œç¨‹ä»“åº“ git remote -v # æ·»åŠ è¿œç¨‹ä»“åº“ git remote add origin https://github.com/username/repository.git # åˆ é™¤è¿œç¨‹ä»“åº“ git remote remove origin # ä¿®æ”¹è¿œç¨‹ä»“åº“URL git remote set-url origin https://github.com/username/new-repository.git æ¨é€å’Œæ‹‰å– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin main # æ¨é€å¹¶è®¾ç½®ä¸Šæ¸¸åˆ†æ”¯ git push -u origin main # æ‹‰å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ git pull origin main # è·å–è¿œç¨‹ä»“åº“çš„ä¿®æ”¹ï¼ˆä¸åˆå¹¶ï¼‰ git fetch origin # åˆå¹¶è¿œç¨‹åˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge origin/main åˆ†æ”¯ç®¡ç† åˆ†æ”¯çš„åŸºæœ¬æ“ä½œ åˆ›å»ºå’Œåˆ‡æ¢åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # åˆ›å»ºæ–°åˆ†æ”¯ git branch feature-branch # åˆ‡æ¢åˆ°æŒ‡å®šåˆ†æ”¯ git checkout feature-branch # åˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯ git checkout -b feature-branch # æŸ¥çœ‹æ‰€æœ‰åˆ†æ”¯ git branch -a # æŸ¥çœ‹æœ¬åœ°åˆ†æ”¯ git branch # æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯ git branch -r åˆå¹¶åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 # åˆ‡æ¢åˆ°ç›®æ ‡åˆ†æ”¯ git checkout main # åˆå¹¶æŒ‡å®šåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ git merge feature-branch # åˆ é™¤å·²åˆå¹¶çš„åˆ†æ”¯ git branch -d feature-branch # å¼ºåˆ¶åˆ é™¤åˆ†æ”¯ï¼ˆå³ä½¿æœªåˆå¹¶ï¼‰ git branch -D feature-branch è§£å†³åˆå¹¶å†²çª å½“åˆå¹¶åˆ†æ”¯æ—¶ï¼Œå¦‚æœä¸¤ä¸ªåˆ†æ”¯å¯¹åŒä¸€æ–‡ä»¶çš„åŒä¸€éƒ¨åˆ†è¿›è¡Œäº†ä¸åŒçš„ä¿®æ”¹ï¼Œå°±ä¼šäº§ç”Ÿåˆå¹¶å†²çªã€‚è§£å†³åˆå¹¶å†²çªçš„æ­¥éª¤å¦‚ä¸‹ï¼š\næ‰§è¡Œgit mergeå‘½ä»¤ï¼ŒGitä¼šæ ‡è®°å†²çªæ–‡ä»¶ æ‰“å¼€å†²çªæ–‡ä»¶ï¼ŒæŸ¥çœ‹å†²çªæ ‡è®°ï¼ˆ\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;, =======, \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;ï¼‰ æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶ï¼Œè§£å†³å†²çª ä½¿ç”¨git addæ ‡è®°å†²çªå·²è§£å†³ ä½¿ç”¨git commitå®Œæˆåˆå¹¶ 1 2 3 4 5 6 7 8 9 10 11 # åˆå¹¶åˆ†æ”¯ï¼ˆå‡è®¾äº§ç”Ÿå†²çªï¼‰ git merge feature-branch # æŸ¥çœ‹å†²çªçŠ¶æ€ git status # æ‰‹åŠ¨è§£å†³å†²çªåï¼Œæ ‡è®°å·²è§£å†³ git add conflicted-file # å®Œæˆåˆå¹¶ git commit å˜åŸº(Rebase) å˜åŸºæ˜¯å°†ä¸€ç³»åˆ—æäº¤åº”ç”¨åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸Šçš„æ“ä½œï¼Œå®ƒå¯ä»¥ä½¿æäº¤å†å²æ›´åŠ çº¿æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # å˜åŸºå½“å‰åˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main # å˜åŸºæŒ‡å®šåˆ†æ”¯åˆ°ç›®æ ‡åˆ†æ”¯ git rebase main feature-branch # äº¤äº’å¼å˜åŸºï¼ˆå¯ä»¥ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æäº¤ï¼‰ git rebase -i HEAD~3 # ç»§ç»­å˜åŸºï¼ˆè§£å†³å†²çªåï¼‰ git rebase --continue # å–æ¶ˆå˜åŸº git rebase --abort æ ‡ç­¾ç®¡ç† æ ‡ç­¾ç”¨äºæ ‡è®°é‡è¦çš„æäº¤ç‚¹ï¼Œé€šå¸¸ç”¨äºç‰ˆæœ¬å‘å¸ƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # åˆ›å»ºè½»é‡æ ‡ç­¾ git tag v1.0.0 # åˆ›å»ºå¸¦æ³¨é‡Šçš„æ ‡ç­¾ git tag -a v1.0.0 -m \u0026#34;Version 1.0.0 release\u0026#34; # æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾ git tag # æŸ¥çœ‹æ ‡ç­¾ä¿¡æ¯ git show v1.0.0 # æ¨é€æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin v1.0.0 # æ¨é€æ‰€æœ‰æ ‡ç­¾åˆ°è¿œç¨‹ä»“åº“ git push origin --tags # åˆ é™¤æœ¬åœ°æ ‡ç­¾ git tag -d v1.0.0 # åˆ é™¤è¿œç¨‹æ ‡ç­¾ git push origin :refs/tags/v1.0.0 Gitå·¥ä½œæµæ¨¡å‹ é›†ä¸­å¼å·¥ä½œæµ é›†ä¸­å¼å·¥ä½œæµæ˜¯æœ€ç®€å•çš„å·¥ä½œæµï¼Œç±»ä¼¼äºSVNçš„å·¥ä½œæ–¹å¼ã€‚æ‰€æœ‰å¼€å‘è€…ç›´æ¥åœ¨ä¸»åˆ†æ”¯ä¸Šå·¥ä½œï¼Œé€‚åˆå°å‹é¡¹ç›®æˆ–ä¸ªäººé¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nå…‹éš†ä»“åº“ åœ¨ä¸»åˆ†æ”¯ä¸Šä¿®æ”¹ä»£ç  æäº¤ä¿®æ”¹ æ¨é€åˆ°è¿œç¨‹ä»“åº“ ä¼˜ç‚¹ï¼š\nç®€å•ç›´è§‚ æ— éœ€å­¦ä¹ åˆ†æ”¯ç®¡ç† ç¼ºç‚¹ï¼š\nå®¹æ˜“äº§ç”Ÿå†²çª ä¸é€‚åˆå›¢é˜Ÿåä½œ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµ åŠŸèƒ½åˆ†æ”¯å·¥ä½œæµä¸ºæ¯ä¸ªæ–°åŠŸèƒ½åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„åˆ†æ”¯ï¼Œå¼€å‘å®Œæˆåå†åˆå¹¶åˆ°ä¸»åˆ†æ”¯ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»ä¸»åˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›ä¸»åˆ†æ”¯ åˆ é™¤åŠŸèƒ½åˆ†æ”¯ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # åˆ‡æ¢åˆ°ä¸»åˆ†æ”¯ git checkout main # åˆå¹¶åŠŸèƒ½åˆ†æ”¯ git merge feature/new-feature # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature ä¼˜ç‚¹ï¼š\nåŠŸèƒ½éš”ç¦»ï¼Œå‡å°‘å†²çª ä¸»åˆ†æ”¯ä¿æŒç¨³å®š ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\néœ€è¦ç®¡ç†å¤šä¸ªåˆ†æ”¯ åˆå¹¶å¯èƒ½äº§ç”Ÿå†²çª Git Flowå·¥ä½œæµ Git Flowæ˜¯ä¸€ç§æ›´å¤æ‚çš„å·¥ä½œæµï¼Œå®šä¹‰äº†ä¸¥æ ¼çš„åˆ†æ”¯æ¨¡å‹ï¼Œé€‚ç”¨äºå¤§å‹é¡¹ç›®å’Œæ­£å¼å‘å¸ƒã€‚\nåˆ†æ”¯ç±»å‹ï¼š\nmainï¼šä¸»åˆ†æ”¯ï¼Œå§‹ç»ˆä¿æŒå¯å‘å¸ƒçŠ¶æ€ developï¼šå¼€å‘åˆ†æ”¯ï¼Œé›†æˆæ‰€æœ‰åŠŸèƒ½ featureï¼šåŠŸèƒ½åˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œå®Œæˆååˆå¹¶å›develop releaseï¼šå‘å¸ƒåˆ†æ”¯ï¼Œä»developåˆ›å»ºï¼Œç”¨äºå‡†å¤‡å‘å¸ƒ hotfixï¼šä¿®å¤åˆ†æ”¯ï¼Œä»mainåˆ›å»ºï¼Œç”¨äºç´§æ€¥ä¿®å¤ å·¥ä½œæµç¨‹ï¼š\nä»developåˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ å®Œæˆååˆå¹¶å›develop ä»developåˆ›å»ºå‘å¸ƒåˆ†æ”¯ æµ‹è¯•å’Œä¿®å¤ åˆå¹¶å‘å¸ƒåˆ†æ”¯åˆ°mainå’Œdevelop ä»mainåˆ›å»ºä¿®å¤åˆ†æ”¯ ä¿®å¤ååˆå¹¶åˆ°mainå’Œdevelop 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # åˆå§‹åŒ–Git Flow git flow init # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git flow feature start new-feature # å®ŒæˆåŠŸèƒ½åˆ†æ”¯ git flow feature finish new-feature # åˆ›å»ºå‘å¸ƒåˆ†æ”¯ git flow release start v1.0.0 # å®Œæˆå‘å¸ƒåˆ†æ”¯ git flow release finish v1.0.0 # åˆ›å»ºä¿®å¤åˆ†æ”¯ git flow hotfix start critical-fix # å®Œæˆä¿®å¤åˆ†æ”¯ git flow hotfix finish critical-fix ä¼˜ç‚¹ï¼š\nç»“æ„æ¸…æ™°ï¼ŒèŒè´£æ˜ç¡® é€‚åˆæ­£å¼å‘å¸ƒ æ”¯æŒç´§æ€¥ä¿®å¤ ç¼ºç‚¹ï¼š\næµç¨‹å¤æ‚ï¼Œå­¦ä¹ æˆæœ¬é«˜ åˆ†æ”¯ç®¡ç†ç¹ç å¯¹äºå°å‹é¡¹ç›®è¿‡äºå¤æ‚ GitHub Flowå·¥ä½œæµ GitHub Flowæ˜¯GitHubä½¿ç”¨çš„ä¸€ç§ç®€åŒ–å·¥ä½œæµï¼Œé€‚åˆæŒç»­éƒ¨ç½²çš„é¡¹ç›®ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºPull Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ éƒ¨ç½² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitHubä¸Šåˆ›å»ºPull Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ é™¤åŠŸèƒ½åˆ†æ”¯ git branch -d feature/new-feature git push origin --delete feature/new-feature ä¼˜ç‚¹ï¼š\nç®€å•æ˜äº† é€‚åˆæŒç»­éƒ¨ç½² ä¾¿äºä»£ç å®¡æŸ¥ ç¼ºç‚¹ï¼š\nä¸é€‚åˆéœ€è¦é•¿æœŸç»´æŠ¤å¤šä¸ªç‰ˆæœ¬çš„é¡¹ç›® ç¼ºå°‘æ˜ç¡®çš„å‘å¸ƒæµç¨‹ GitLab Flowå·¥ä½œæµ GitLab Flowæ˜¯GitLabæ¨èçš„å·¥ä½œæµï¼Œç»“åˆäº†GitHub Flowå’ŒGit Flowçš„ä¼˜ç‚¹ã€‚\nå·¥ä½œæµç¨‹ï¼š\nä»mainåˆ†æ”¯åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ åœ¨åŠŸèƒ½åˆ†æ”¯ä¸Šå¼€å‘ æ¨é€åˆ°è¿œç¨‹ä»“åº“ åˆ›å»ºMerge Request ä»£ç å®¡æŸ¥å’Œè®¨è®º åˆå¹¶åˆ°mainåˆ†æ”¯ ä»mainåˆ›å»ºç¯å¢ƒåˆ†æ”¯ï¼ˆå¦‚stagingã€productionï¼‰ éƒ¨ç½²åˆ°ä¸åŒç¯å¢ƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ git checkout -b feature/new-feature main # å¼€å‘åŠŸèƒ½... # æäº¤ä¿®æ”¹ git commit -a -m \u0026#34;Add new feature\u0026#34; # æ¨é€åˆ°è¿œç¨‹ä»“åº“ git push origin feature/new-feature # åœ¨GitLabä¸Šåˆ›å»ºMerge Request # å®¡æŸ¥é€šè¿‡åï¼Œåˆå¹¶åˆ°mainåˆ†æ”¯ git checkout main git pull origin main git merge feature/new-feature git push origin main # åˆ›å»ºç¯å¢ƒåˆ†æ”¯ git checkout -b production main git push origin production # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ # ... ä¼˜ç‚¹ï¼š\nç®€å•ä¸”çµæ´» æ”¯æŒå¤šç¯å¢ƒéƒ¨ç½² é€‚åˆæŒç»­äº¤ä»˜ ç¼ºç‚¹ï¼š\nç¯å¢ƒåˆ†æ”¯ç®¡ç†éœ€è¦é¢å¤–å·¥ä½œ å¯¹äºå¤§å‹é¡¹ç›®å¯èƒ½ä¸å¤Ÿä¸¥æ ¼ Gité«˜çº§æŠ€å·§ é’©å­(Hooks) Gité’©å­æ˜¯åœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è‡ªåŠ¨æ‰§è¡Œçš„è„šæœ¬ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚\nå¸¸ç”¨é’©å­ç±»å‹ å®¢æˆ·ç«¯é’©å­ï¼š\npre-commitï¼šæäº¤å‰è¿è¡Œ commit-msgï¼šç¼–è¾‘æäº¤ä¿¡æ¯åè¿è¡Œ pre-pushï¼šæ¨é€å‰è¿è¡Œ æœåŠ¡å™¨ç«¯é’©å­ï¼š\npre-receiveï¼šæ¥æ”¶æ¨é€æ—¶è¿è¡Œ updateï¼šæ›´æ–°åˆ†æ”¯æ—¶è¿è¡Œ post-receiveï¼šæ¥æ”¶æ¨é€åè¿è¡Œ ç¤ºä¾‹ï¼špre-commité’©å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/sh # .git/hooks/pre-commit # æ£€æŸ¥ä»£ç é£æ ¼ npm run lint # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;ä»£ç é£æ ¼æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi # è¿è¡Œæµ‹è¯• npm test # å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œé˜»æ­¢æäº¤ if [ $? -ne 0 ]; then echo \u0026#34;æµ‹è¯•å¤±è´¥ï¼Œè¯·ä¿®å¤åå†æäº¤\u0026#34; exit 1 fi å­æ¨¡å—(Submodules) Gitå­æ¨¡å—å…è®¸ä½ å°†ä¸€ä¸ªGitä»“åº“ä½œä¸ºå¦ä¸€ä¸ªGitä»“åº“çš„å­ç›®å½•ã€‚\næ·»åŠ å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 # æ·»åŠ å­æ¨¡å— git submodule add https://github.com/username/submodule-repository.git path/to/submodule # åˆå§‹åŒ–å­æ¨¡å— git submodule init # æ›´æ–°å­æ¨¡å— git submodule update # é€’å½’å…‹éš†åŒ…å«å­æ¨¡å—çš„ä»“åº“ git clone --recursive https://github.com/username/repository.git æ›´æ–°å­æ¨¡å— 1 2 3 4 5 6 7 8 9 10 11 12 # è¿›å…¥å­æ¨¡å—ç›®å½• cd path/to/submodule # æ‹‰å–æœ€æ–°ä»£ç  git pull origin main # è¿”å›ä¸»ä»“åº“ cd .. # æäº¤å­æ¨¡å—æ›´æ–° git add path/to/submodule git commit -m \u0026#34;Update submodule\u0026#34; å˜åŸº(Rebase)é«˜çº§ç”¨æ³• äº¤äº’å¼å˜åŸº äº¤äº’å¼å˜åŸºå…è®¸ä½ ç¼–è¾‘ã€åˆ é™¤ã€åˆå¹¶æˆ–é‡æ–°æ’åºæäº¤ã€‚\n1 2 # å¯¹æœ€è¿‘çš„3ä¸ªæäº¤è¿›è¡Œäº¤äº’å¼å˜åŸº git rebase -i HEAD~3 åœ¨æ‰“å¼€çš„ç¼–è¾‘å™¨ä¸­ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„å†…å®¹ï¼š\npick f7f3f6d Commit message 1 pick 310154e Commit message 2 pick a5f4a0d Commit message 3 # Rebase 1234567..a5f4a0d onto 1234567 (3 commands) # # Commands: # p, pick \u0026lt;commit\u0026gt; = use commit # r, reword \u0026lt;commit\u0026gt; = use commit, but edit the commit message # e, edit \u0026lt;commit\u0026gt; = use commit, but stop for amending # s, squash \u0026lt;commit\u0026gt; = use commit, but meld into previous commit # f, fixup \u0026lt;commit\u0026gt; = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message # x, exec \u0026lt;command\u0026gt; = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with \u0026#39;git rebase --continue\u0026#39;) # d, drop \u0026lt;commit\u0026gt; = remove commit # l, label \u0026lt;label\u0026gt; = label current HEAD with a name # t, reset \u0026lt;label\u0026gt; = reset HEAD to a label # m, merge [-C \u0026lt;commit\u0026gt; | -c \u0026lt;commit\u0026gt;] \u0026lt;label\u0026gt; [# \u0026lt;oneline\u0026gt;] # . create a merge commit using the original merge commit\u0026#39;s # . message (or the oneline, if no original merge commit was # . specified). Use -c \u0026lt;commit\u0026gt; to re-use the original merge # . commit\u0026#39;s author and message. # # These lines can be re-ordered; they are executed from top to bottom. ä½ å¯ä»¥é€šè¿‡ä¿®æ”¹å‘½ä»¤å‰çš„å…³é”®å­—æ¥æ”¹å˜æäº¤çš„å¤„ç†æ–¹å¼ã€‚\nå˜åŸº vs åˆå¹¶ å˜åŸºå’Œåˆå¹¶éƒ½æ˜¯æ•´åˆåˆ†æ”¯æ›´æ”¹çš„æ–¹æ³•ï¼Œä½†å®ƒä»¬æœ‰ä¸åŒçš„å·¥ä½œæ–¹å¼ï¼š\nåˆå¹¶(Merge)ï¼š\nåˆ›å»ºä¸€ä¸ªæ–°çš„\u0026quot;åˆå¹¶æäº¤\u0026quot; ä¿ç•™å®Œæ•´çš„åˆ†æ”¯å†å² é€‚åˆå…¬å…±åˆ†æ”¯ å˜åŸº(Rebase)ï¼š\nå°†æäº¤é‡æ–°åº”ç”¨åˆ°ç›®æ ‡åˆ†æ”¯ åˆ›å»ºçº¿æ€§çš„æäº¤å†å² é€‚åˆç§æœ‰åˆ†æ”¯ 1 2 3 4 5 6 7 # åˆå¹¶åˆ†æ”¯ git checkout main git merge feature-branch # å˜åŸºåˆ†æ”¯ git checkout feature-branch git rebase main å‚¨è—(Stash) å‚¨è—å…è®¸ä½ ä¸´æ—¶ä¿å­˜æœªæäº¤çš„ä¿®æ”¹ï¼Œä»¥ä¾¿åˆ‡æ¢åˆ†æ”¯æˆ–æ‰§è¡Œå…¶ä»–æ“ä½œã€‚\nåŸºæœ¬å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # å‚¨è—å½“å‰ä¿®æ”¹ git stash # å‚¨è—å¹¶æ·»åŠ è¯´æ˜ git stash save \u0026#34;Work in progress\u0026#34; # æŸ¥çœ‹å‚¨è—åˆ—è¡¨ git stash list # åº”ç”¨æœ€æ–°å‚¨è—ï¼ˆä¸åˆ é™¤ï¼‰ git stash apply # åº”ç”¨å¹¶åˆ é™¤æœ€æ–°å‚¨è— git stash pop # åº”ç”¨æŒ‡å®šå‚¨è— git stash apply stash@{1} # åˆ é™¤æŒ‡å®šå‚¨è— git stash drop stash@{1} # æ¸…é™¤æ‰€æœ‰å‚¨è— git stash clear é«˜çº§å‚¨è—æ“ä½œ 1 2 3 4 5 6 7 8 # å‚¨è—æœªè·Ÿè¸ªçš„æ–‡ä»¶ git stash -u # å‚¨è—åŒ…æ‹¬å¿½ç•¥çš„æ–‡ä»¶ git stash -a # ä»å‚¨è—åˆ›å»ºåˆ†æ”¯ git stash branch new-branch stash@{1} ç­¾é€‰(Cherry-pick) ç­¾é€‰å…è®¸ä½ é€‰æ‹©ç‰¹å®šçš„æäº¤ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ°å½“å‰åˆ†æ”¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ç­¾é€‰æŒ‡å®šæäº¤ git cherry-pick commit-hash # ç­¾é€‰ä½†ä¸æäº¤ git cherry-pick -n commit-hash # ç­¾é€‰å¹¶ç¼–è¾‘æäº¤ä¿¡æ¯ git cherry-pick -e commit-hash # ç­¾é€‰å¤šä¸ªæäº¤ git cherry-pick commit1 commit2 commit3 # ç­¾é€‰ä¸€ç³»åˆ—æäº¤ git cherry-pick commit1..commit3 # ä¸­æ­¢ç­¾é€‰ git cherry-pick --abort # ç»§ç»­ç­¾é€‰ï¼ˆè§£å†³å†²çªåï¼‰ git cherry-pick --continue å¼•ç”¨æ—¥å¿—(Reflog) å¼•ç”¨æ—¥å¿—è®°å½•äº†Gitä»“åº“ä¸­æ‰€æœ‰å¼•ç”¨çš„æ›´æ–°ï¼ŒåŒ…æ‹¬è¢«åˆ é™¤çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æŸ¥çœ‹å¼•ç”¨æ—¥å¿— git reflog # æŸ¥çœ‹æŒ‡å®šåˆ†æ”¯çš„å¼•ç”¨æ—¥å¿— git reflog show main # æŸ¥çœ‹å¼•ç”¨æ—¥å¿—å¹¶æ˜¾ç¤ºå·®å¼‚ git reflog show --stat # æ¢å¤è¢«åˆ é™¤çš„æäº¤ git reset --hard HEAD@{1} äºŒåˆ†æŸ¥æ‰¾(Bisect) äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºå¿«é€Ÿå®šä½å¼•å…¥é—®é¢˜çš„æäº¤ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # å¼€å§‹äºŒåˆ†æŸ¥æ‰¾ git bisect start # æ ‡è®°å½“å‰æäº¤ä¸ºæœ‰é—®é¢˜ git bisect bad # æ ‡è®°å·²çŸ¥æ­£å¸¸çš„æäº¤ git bisect good commit-hash # Gitä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸€ä¸ªä¸­é—´æäº¤ï¼Œæµ‹è¯•åæ ‡è®°ä¸ºgoodæˆ–bad git bisect good # æˆ– git bisect bad # é‡å¤æµ‹è¯•è¿‡ç¨‹ï¼Œç›´åˆ°æ‰¾åˆ°é—®é¢˜æäº¤ # ç»“æŸäºŒåˆ†æŸ¥æ‰¾ git bisect reset Gitæœ€ä½³å®è·µ æäº¤è§„èŒƒ æäº¤ä¿¡æ¯æ ¼å¼ è‰¯å¥½çš„æäº¤ä¿¡æ¯åº”è¯¥æ¸…æ™°ã€ç®€æ´ï¼Œå¹¶éµå¾ªä¸€å®šçš„æ ¼å¼ï¼š\n\u0026lt;ç±»å‹\u0026gt;(\u0026lt;èŒƒå›´\u0026gt;): \u0026lt;ä¸»é¢˜\u0026gt; \u0026lt;è¯¦ç»†æè¿°\u0026gt; \u0026lt;é¡µè„š\u0026gt; ç±»å‹ï¼š\nfeatï¼šæ–°åŠŸèƒ½ fixï¼šä¿®å¤bug docsï¼šæ–‡æ¡£æ›´æ–° styleï¼šä»£ç æ ¼å¼ï¼ˆä¸å½±å“ä»£ç è¿è¡Œçš„å˜åŠ¨ï¼‰ refactorï¼šé‡æ„ï¼ˆæ—¢ä¸æ˜¯æ–°å¢åŠŸèƒ½ï¼Œä¹Ÿä¸æ˜¯ä¿®æ”¹bugçš„ä»£ç å˜åŠ¨ï¼‰ perfï¼šæ€§èƒ½ä¼˜åŒ– testï¼šå¢åŠ æµ‹è¯• choreï¼šæ„å»ºè¿‡ç¨‹æˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨ èŒƒå›´ï¼šå¯é€‰ï¼Œç”¨äºè¯´æ˜æäº¤å½±å“çš„èŒƒå›´ï¼Œå¦‚docs, api, coreç­‰ã€‚\nä¸»é¢˜ï¼šç®€æ´æè¿°æäº¤å†…å®¹ï¼Œä¸è¶…è¿‡50ä¸ªå­—ç¬¦ã€‚\nè¯¦ç»†æè¿°ï¼šå¯é€‰ï¼Œè¯¦ç»†æè¿°æäº¤å†…å®¹ï¼Œæ¯è¡Œä¸è¶…è¿‡72ä¸ªå­—ç¬¦ã€‚\né¡µè„šï¼šå¯é€‰ï¼Œç”¨äºæ ‡è®°Breaking Changesæˆ–å…³é—­Issueã€‚\nç¤ºä¾‹æäº¤ä¿¡æ¯ feat(api): add user authentication endpoint Add a new endpoint for user authentication using JWT tokens. The endpoint supports both username/password and social login methods. Closes #123 åˆ†æ”¯å‘½åè§„èŒƒ è‰¯å¥½çš„åˆ†æ”¯å‘½åå¯ä»¥æé«˜å›¢é˜Ÿåä½œæ•ˆç‡ï¼š\n\u0026lt;ç±»å‹\u0026gt;/\u0026lt;æè¿°\u0026gt; ä¾‹å¦‚ï¼š feature/user-authentication fix/login-bug docs/api-documentation refactor/user-service ä»£ç å®¡æŸ¥ ä»£ç å®¡æŸ¥æ˜¯ä¿è¯ä»£ç è´¨é‡çš„é‡è¦ç¯èŠ‚ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å»ºè®®ï¼š\nä¿æŒå°çš„æäº¤ï¼šæ¯æ¬¡æäº¤åº”è¯¥åªå…³æ³¨ä¸€ä¸ªåŠŸèƒ½æˆ–ä¿®å¤ï¼Œä¾¿äºå®¡æŸ¥ã€‚ æä¾›æ¸…æ™°çš„æè¿°ï¼šåœ¨Pull Requestä¸­è¯¦ç»†è¯´æ˜ä¿®æ”¹å†…å®¹å’ŒåŸå› ã€‚ è‡ªåŠ¨åŒ–æ£€æŸ¥ï¼šä½¿ç”¨CI/CDå·¥å…·è‡ªåŠ¨è¿è¡Œæµ‹è¯•å’Œä»£ç é£æ ¼æ£€æŸ¥ã€‚ å…³æ³¨ä»£ç é€»è¾‘ï¼šä¸ä»…å…³æ³¨ä»£ç é£æ ¼ï¼Œè¿˜è¦å…³æ³¨é€»è¾‘æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚ æä¾›å»ºè®¾æ€§åé¦ˆï¼šå°Šé‡ä»–äººï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚ å¸¸è§é—®é¢˜è§£å†³ æ’¤é”€å·²æ¨é€çš„æäº¤ 1 2 3 4 5 6 7 # æ–¹æ³•1ï¼šåˆ›å»ºæ–°çš„æäº¤æ¥æ’¤é”€ git revert commit-hash git push origin main # æ–¹æ³•2ï¼šå¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git reset --hard HEAD~1 git push --force origin main åˆå¹¶é”™è¯¯çš„åˆ†æ”¯ 1 2 3 4 5 # æ’¤é”€åˆå¹¶ git reset --hard HEAD~1 # å¦‚æœå·²ç»æ¨é€ git revert -m 1 commit-hash æ¸…ç†å†å²è®°å½• 1 2 3 4 5 # äº¤äº’å¼å˜åŸºæ¸…ç†å†å² git rebase -i HEAD~n # å¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰ git push --force origin main å¤„ç†å¤§æ–‡ä»¶ 1 2 3 4 5 6 7 8 9 10 # æŸ¥æ‰¾å¤§æ–‡ä»¶ git rev-list --objects --all | git cat-file --batch-check=\u0026#39;%(objecttype) %(objectname) %(objectsize) %(rest)\u0026#39; | sed -n \u0026#39;s/^blob //p\u0026#39; | sort -nrk 2 | head -n 10 # ä½¿ç”¨BFG Repo-Cleaneræ¸…ç†å¤§æ–‡ä»¶ java -jar bfg.jar --strip-blobs-bigger-than 100M my-repo.git # æ¸…ç†å¹¶æ¨é€ git reflog expire --expire=now --all git gc --prune=now --aggressive git push --force origin main æ€»ç»“ Gitæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ŒæŒæ¡å…¶å·¥ä½œæµç¨‹å¯¹äºç°ä»£è½¯ä»¶å¼€å‘è‡³å…³é‡è¦ã€‚æœ¬æ–‡ä»Gitçš„åŸºæœ¬æ¦‚å¿µå’Œå‘½ä»¤å¼€å§‹ï¼Œé€æ­¥ä»‹ç»äº†åˆ†æ”¯ç®¡ç†ã€å„ç§å·¥ä½œæµæ¨¡å‹ä»¥åŠé«˜çº§æŠ€å·§ã€‚\né€šè¿‡å­¦ä¹ å’Œå®è·µè¿™äº›å†…å®¹ï¼Œä½ å¯ä»¥ï¼š\né«˜æ•ˆç®¡ç†ä¸ªäººé¡¹ç›®çš„ç‰ˆæœ¬ ä¸å›¢é˜Ÿæˆå‘˜åä½œå¼€å‘ å¤„ç†å¤æ‚çš„åˆå¹¶å’Œå†²çª ä½¿ç”¨é«˜çº§åŠŸèƒ½æé«˜å·¥ä½œæ•ˆç‡ è®°ä½ï¼ŒGitçš„å¼ºå¤§ä¹‹å¤„åœ¨äºå…¶çµæ´»æ€§ï¼Œä½ å¯ä»¥æ ¹æ®é¡¹ç›®éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥ä½œæµç¨‹å’Œå·¥å…·ã€‚åŒæ—¶ï¼Œè‰¯å¥½çš„å®è·µä¹ æƒ¯ï¼ˆå¦‚æ¸…æ™°çš„æäº¤ä¿¡æ¯ã€è§„èŒƒçš„åˆ†æ”¯å‘½åï¼‰å°†ä½¿ä½ çš„å¼€å‘è¿‡ç¨‹æ›´åŠ é¡ºç•…ã€‚\næœ€åï¼ŒGitæ˜¯ä¸€ä¸ªä¸æ–­å‘å±•çš„å·¥å…·ï¼ŒæŒç»­å­¦ä¹ å’Œæ¢ç´¢æ–°åŠŸèƒ½å°†å¸®åŠ©ä½ æ›´å¥½åœ°åˆ©ç”¨è¿™ä¸ªå¼ºå¤§çš„ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ æŒæ¡Gitå·¥ä½œæµç¨‹ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚\n","permalink":"http://localhost:1313/posts/git-workflow/","summary":"\u003ch1 id=\"gitå·¥ä½œæµç¨‹ä»å…¥é—¨åˆ°ç²¾é€š\"\u003eGitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š\u003c/h1\u003e\n\u003cp\u003eGitæ˜¯ç›®å‰æœ€æµè¡Œçš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œå®ƒä¸ä»…èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç®¡ç†ä»£ç ç‰ˆæœ¬ï¼Œè¿˜èƒ½ä¿ƒè¿›å›¢é˜Ÿåä½œã€‚æœ¬æ–‡å°†è¯¦ç»†ä»‹ç»Gitçš„å·¥ä½œæµç¨‹ï¼Œä»åŸºæœ¬å‘½ä»¤åˆ°é«˜çº§æŠ€å·§ï¼Œå¸®åŠ©ä½ å…¨é¢æŒæ¡Gitçš„ä½¿ç”¨æ–¹æ³•ã€‚\u003c/p\u003e","title":"Gitå·¥ä½œæµç¨‹ï¼šä»å…¥é—¨åˆ°ç²¾é€š"},{"content":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\nå›¾åƒåŸºç¡€ å›¾åƒè¡¨ç¤º æ•°å­—å›¾åƒçš„æ¦‚å¿µ æ•°å­—å›¾åƒæ˜¯ç”±æœ‰é™æ•°é‡çš„åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆçš„äºŒç»´çŸ©é˜µã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import numpy as np import matplotlib.pyplot as plt # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç°åº¦å›¾åƒ # 5x5çš„ç°åº¦å›¾åƒï¼Œå€¼èŒƒå›´0-255 gray_image = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ], dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert gray_image is not None, \u0026#34;ç°åº¦å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # æ˜¾ç¤ºå›¾åƒ plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Grayscale Image\u0026#39;) plt.colorbar() plt.show() å½©è‰²å›¾åƒè¡¨ç¤º å½©è‰²å›¾åƒé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“æ¥è¡¨ç¤ºã€‚æ¯ä¸ªåƒç´ ç”±ä¸‰ä¸ªå€¼ç»„æˆï¼Œåˆ†åˆ«ä»£è¡¨çº¢ã€ç»¿ã€è“ä¸‰ä¸ªé¢œè‰²é€šé“çš„å¼ºåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # åˆ›å»ºä¸€ä¸ªç®€å•çš„å½©è‰²å›¾åƒ # 5x5x3çš„RGBå›¾åƒï¼Œå€¼èŒƒå›´0-255 color_image = np.zeros((5, 5, 3), dtype=np.uint8) # åˆ¤ç©ºå¤„ç† assert color_image is not None, \u0026#34;å½©è‰²å›¾åƒåˆ›å»ºå¤±è´¥ï¼\u0026#34; # è®¾ç½®çº¢è‰²é€šé“ color_image[:, :, 0] = np.array([ [255, 200, 150, 100, 50], [230, 180, 130, 80, 30], [210, 160, 110, 60, 10], [190, 140, 90, 40, 0], [170, 120, 70, 20, 0] ]) # è®¾ç½®ç»¿è‰²é€šé“ color_image[:, :, 1] = np.array([ [0, 50, 100, 150, 200], [30, 80, 130, 180, 230], [60, 110, 160, 210, 240], [90, 140, 190, 220, 250], [120, 170, 200, 230, 255] ]) # è®¾ç½®è“è‰²é€šé“ color_image[:, :, 2] = np.array([ [0, 30, 60, 90, 120], [50, 80, 110, 140, 170], [100, 130, 160, 190, 200], [150, 180, 210, 220, 230], [200, 230, 240, 250, 255] ]) # æ˜¾ç¤ºå›¾åƒ plt.imshow(color_image) plt.title(\u0026#39;Color Image\u0026#39;) plt.show() å…¶ä»–é¢œè‰²ç©ºé—´ é™¤äº†RGBï¼Œè¿˜æœ‰å…¶ä»–å¸¸ç”¨çš„é¢œè‰²ç©ºé—´ï¼Œå¦‚HSVï¼ˆè‰²ç›¸ã€é¥±å’Œåº¦ã€æ˜åº¦ï¼‰å’ŒLabï¼ˆäº®åº¦ã€aé€šé“ã€bé€šé“ï¼‰ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import cv2 # å°†RGBå›¾åƒè½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´ hsv_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2HSV) # å°†RGBå›¾åƒè½¬æ¢ä¸ºLabé¢œè‰²ç©ºé—´ lab_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2Lab) # æ˜¾ç¤ºä¸åŒé¢œè‰²ç©ºé—´çš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(color_image) plt.title(\u0026#39;RGB Image\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(hsv_image) plt.title(\u0026#39;HSV Image\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(lab_image) plt.title(\u0026#39;Lab Image\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå±æ€§ åˆ†è¾¨ç‡ å›¾åƒåˆ†è¾¨ç‡æ˜¯æŒ‡å›¾åƒä¸­åƒç´ çš„æ•°é‡ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºå®½åº¦Ã—é«˜åº¦ï¼ˆå¦‚1920Ã—1080ï¼‰ã€‚é«˜åˆ†è¾¨ç‡å›¾åƒåŒ…å«æ›´å¤šç»†èŠ‚ï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šçš„å­˜å‚¨ç©ºé—´å’Œå¤„ç†æ—¶é—´ã€‚\n1 2 3 4 5 6 # è·å–å›¾åƒåˆ†è¾¨ç‡ height, width = gray_image.shape print(f\u0026#34;ç°åº¦å›¾åƒåˆ†è¾¨ç‡: {width}x{height}\u0026#34;) height, width, channels = color_image.shape print(f\u0026#34;å½©è‰²å›¾åƒåˆ†è¾¨ç‡: {width}x{height}, é€šé“æ•°: {channels}\u0026#34;) ä½æ·±åº¦ ä½æ·±åº¦æ˜¯æŒ‡æ¯ä¸ªåƒç´ ä½¿ç”¨çš„ä½æ•°ï¼Œå†³å®šäº†å›¾åƒå¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ã€‚å¸¸è§çš„ä½æ·±åº¦æœ‰8ä½ï¼ˆ256ä¸ªç°åº¦çº§ï¼‰ã€24ä½ï¼ˆRGBå„8ä½ï¼Œçº¦1670ä¸‡ç§é¢œè‰²ï¼‰ç­‰ã€‚\n1 2 3 4 5 6 7 8 9 10 # æ£€æŸ¥å›¾åƒçš„ä½æ·±åº¦ print(f\u0026#34;ç°åº¦å›¾åƒæ•°æ®ç±»å‹: {gray_image.dtype}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ•°æ®ç±»å‹: {color_image.dtype}\u0026#34;) # è®¡ç®—å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²æ•°é‡ gray_levels = 2 ** (gray_image.itemsize * 8) color_levels = 2 ** (color_image.itemsize * 8) print(f\u0026#34;ç°åº¦å›¾åƒå¯ä»¥è¡¨ç¤ºçš„ç°åº¦çº§æ•°: {gray_levels}\u0026#34;) print(f\u0026#34;å½©è‰²å›¾åƒæ¯ä¸ªé€šé“å¯ä»¥è¡¨ç¤ºçš„é¢œè‰²çº§æ•°: {color_levels}\u0026#34;) å›¾åƒåŸºæœ¬å¤„ç† å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨OpenCVè¯»å–å›¾åƒ OpenCVæ˜¯ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„è®¡ç®—æœºè§†è§‰åº“ï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import cv2 # è¯»å–å›¾åƒ # æ³¨æ„ï¼šOpenCVé»˜è®¤ä»¥BGRæ ¼å¼è¯»å–å½©è‰²å›¾åƒ image_bgr = cv2.imread(\u0026#39;example.jpg\u0026#39;) # æ£€æŸ¥å›¾åƒæ˜¯å¦æˆåŠŸè¯»å– if image_bgr is None: print(\u0026#34;æ— æ³•è¯»å–å›¾åƒ\u0026#34;) else: # è½¬æ¢ä¸ºRGBæ ¼å¼ä»¥ä¾¿æ­£ç¡®æ˜¾ç¤º image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.title(\u0026#39;Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() ä½¿ç”¨PIL/Pillowè¯»å–å›¾åƒ Pillowæ˜¯Pythonå›¾åƒå¤„ç†åº“ï¼Œæä¾›äº†ç®€å•æ˜“ç”¨çš„å›¾åƒå¤„ç†åŠŸèƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from PIL import Image # è¯»å–å›¾åƒ image = Image.open(\u0026#39;example.jpg\u0026#39;) # æ˜¾ç¤ºå›¾åƒ image.show() # è½¬æ¢ä¸ºnumpyæ•°ç»„ image_array = np.array(image) # æ˜¾ç¤ºå›¾åƒä¿¡æ¯ print(f\u0026#34;å›¾åƒå¤§å°: {image.size}\u0026#34;) print(f\u0026#34;å›¾åƒæ¨¡å¼: {image.mode}\u0026#34;) print(f\u0026#34;å›¾åƒæ•°ç»„å½¢çŠ¶: {image_array.shape}\u0026#34;) å›¾åƒåŸºæœ¬æ“ä½œ è£å‰ªå›¾åƒ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image_rgb[50:200, 100:300] # æ˜¾ç¤ºè£å‰ªåçš„å›¾åƒ plt.imshow(cropped_image) plt.title(\u0026#39;Cropped Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.show() è°ƒæ•´å›¾åƒå¤§å° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # ä½¿ç”¨OpenCVè°ƒæ•´å›¾åƒå¤§å° resized_cv2 = cv2.resize(image_rgb, (300, 200)) # ä½¿ç”¨PILè°ƒæ•´å›¾åƒå¤§å° resized_pil = Image.fromarray(image_rgb).resize((300, 200)) # æ˜¾ç¤ºè°ƒæ•´å¤§å°åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(resized_cv2) plt.title(\u0026#39;Resized with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(resized_pil) plt.title(\u0026#39;Resized with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() æ—‹è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ä½¿ç”¨OpenCVæ—‹è½¬å›¾åƒ (h, w) = image_rgb.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) rotated_cv2 = cv2.warpAffine(image_rgb, M, (w, h)) # ä½¿ç”¨PILæ—‹è½¬å›¾åƒ rotated_pil = Image.fromarray(image_rgb).rotate(45) # æ˜¾ç¤ºæ—‹è½¬åçš„å›¾åƒ plt.figure(figsize=(10, 5)) plt.subplot(1, 2, 1) plt.imshow(rotated_cv2) plt.title(\u0026#39;Rotated with OpenCV\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(rotated_pil) plt.title(\u0026#39;Rotated with PIL\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç¿»è½¬å›¾åƒ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # æ°´å¹³ç¿»è½¬ flipped_h = cv2.flip(image_rgb, 1) # å‚ç›´ç¿»è½¬ flipped_v = cv2.flip(image_rgb, 0) # æ°´å¹³å’Œå‚ç›´ç¿»è½¬ flipped_hv = cv2.flip(image_rgb, -1) # æ˜¾ç¤ºç¿»è½¬åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(flipped_h) plt.title(\u0026#39;Horizontal Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(flipped_v) plt.title(\u0026#39;Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(flipped_hv) plt.title(\u0026#39;Horizontal and Vertical Flip\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒå¢å¼º äº®åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ äº®åº¦ brightness_increase = cv2.convertScaleAbs(image_rgb, alpha=1.2, beta=50) # å‡å°‘äº®åº¦ brightness_decrease = cv2.convertScaleAbs(image_rgb, alpha=1.0, beta=-50) # æ˜¾ç¤ºäº®åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(brightness_increase) plt.title(\u0026#39;Increased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(brightness_decrease) plt.title(\u0026#39;Decreased Brightness\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # å¢åŠ å¯¹æ¯”åº¦ contrast_increase = cv2.convertScaleAbs(image_rgb, alpha=1.5, beta=0) # å‡å°‘å¯¹æ¯”åº¦ contrast_decrease = cv2.convertScaleAbs(image_rgb, alpha=0.5, beta=0) # æ˜¾ç¤ºå¯¹æ¯”åº¦è°ƒæ•´åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(contrast_increase) plt.title(\u0026#39;Increased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(contrast_decrease) plt.title(\u0026#39;Decreased Contrast\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›´æ–¹å›¾å‡è¡¡åŒ– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # ç›´æ–¹å›¾å‡è¡¡åŒ– equalized_image = cv2.equalizeHist(gray_image) # æ˜¾ç¤ºç›´æ–¹å›¾å‡è¡¡åŒ–å‰åçš„å›¾åƒå’Œç›´æ–¹å›¾ plt.figure(figsize=(15, 10)) # åŸå§‹å›¾åƒ plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Grayscale Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # å‡è¡¡åŒ–åçš„å›¾åƒ plt.subplot(2, 2, 2) plt.imshow(equalized_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Equalized Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) # åŸå§‹ç›´æ–¹å›¾ plt.subplot(2, 2, 3) plt.hist(gray_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Original Histogram\u0026#39;) # å‡è¡¡åŒ–åçš„ç›´æ–¹å›¾ plt.subplot(2, 2, 4) plt.hist(equalized_image.ravel(), 256, [0, 256]) plt.title(\u0026#39;Equalized Histogram\u0026#39;) plt.tight_layout() plt.show() ä¼½é©¬æ ¡æ­£ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def adjust_gamma(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) # åº”ç”¨ä¸åŒçš„ä¼½é©¬å€¼ gamma_1_5 = adjust_gamma(image_rgb, 1.5) gamma_0_5 = adjust_gamma(image_rgb, 0.5) # æ˜¾ç¤ºä¼½é©¬æ ¡æ­£åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image (Î³=1.0)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(gamma_1_5) plt.title(\u0026#39;Gamma=1.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(gamma_0_5) plt.title(\u0026#39;Gamma=0.5\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒæ»¤æ³¢ å‡å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY) # åº”ç”¨ä¸åŒå¤§å°çš„å‡å€¼æ»¤æ³¢ blur_3x3 = cv2.blur(gray_image, (3, 3)) blur_5x5 = cv2.blur(gray_image, (5, 5)) blur_7x7 = cv2.blur(gray_image, (7, 7)) # æ˜¾ç¤ºå‡å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(blur_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(blur_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(blur_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Mean Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() é«˜æ–¯æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°å’Œæ ‡å‡†å·®çš„é«˜æ–¯æ»¤æ³¢ gaussian_3x3 = cv2.GaussianBlur(gray_image, (3, 3), 0) gaussian_5x5 = cv2.GaussianBlur(gray_image, (5, 5), 0) gaussian_7x7 = cv2.GaussianBlur(gray_image, (7, 7), 0) # æ˜¾ç¤ºé«˜æ–¯æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(gaussian_3x3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(gaussian_5x5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(gaussian_7x7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Gaussian Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ä¸­å€¼æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # åº”ç”¨ä¸åŒå¤§å°çš„ä¸­å€¼æ»¤æ³¢ median_3 = cv2.medianBlur(gray_image, 3) median_5 = cv2.medianBlur(gray_image, 5) median_7 = cv2.medianBlur(gray_image, 7) # æ˜¾ç¤ºä¸­å€¼æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(median_3, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;3x3 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(median_5, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;5x5 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(median_7, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;7x7 Median Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åŒè¾¹æ»¤æ³¢ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨åŒè¾¹æ»¤æ³¢ bilateral = cv2.bilateralFilter(gray_image, 9, 75, 75) # æ˜¾ç¤ºåŒè¾¹æ»¤æ³¢åçš„å›¾åƒ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(bilateral, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Bilateral Filter\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è¾¹ç¼˜æ£€æµ‹ Sobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # åº”ç”¨Sobelç®—å­ sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3) sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3) sobel_xy = cv2.Sobel(gray_image, cv2.CV_64F, 1, 1, ksize=3) # è½¬æ¢å›uint8 sobel_x = cv2.convertScaleAbs(sobel_x) sobel_y = cv2.convertScaleAbs(sobel_y) sobel_xy = cv2.convertScaleAbs(sobel_xy) # æ˜¾ç¤ºSobelè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 2) plt.imshow(sobel_x, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel X\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 3) plt.imshow(sobel_y, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel Y\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 2, 4) plt.imshow(sobel_xy, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Sobel XY\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Laplacianç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # åº”ç”¨Laplacianç®—å­ laplacian = cv2.Laplacian(gray_image, cv2.CV_64F) laplacian = cv2.convertScaleAbs(laplacian) # æ˜¾ç¤ºLaplacianè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(laplacian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Laplacian Edge Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Cannyè¾¹ç¼˜æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨Cannyè¾¹ç¼˜æ£€æµ‹ canny_low = cv2.Canny(gray_image, 50, 150) canny_high = cv2.Canny(gray_image, 100, 200) # æ˜¾ç¤ºCannyè¾¹ç¼˜æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(canny_low, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (50, 150)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(canny_high, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Canny (100, 200)\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() å›¾åƒåˆ†å‰² é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # åº”ç”¨ä¸åŒç±»å‹çš„é˜ˆå€¼åˆ†å‰² ret, thresh_binary = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY) ret, thresh_binary_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV) ret, thresh_trunc = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TRUNC) ret, thresh_tozero = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO) ret, thresh_tozero_inv = cv2.threshold(gray_image, 127, 255, cv2.THRESH_TOZERO_INV) # æ˜¾ç¤ºé˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 10)) plt.subplot(2, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 2) plt.imshow(thresh_binary, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 3) plt.imshow(thresh_binary_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 4) plt.imshow(thresh_trunc, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Truncated Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 5) plt.imshow(thresh_tozero, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(2, 3, 6) plt.imshow(thresh_tozero_inv, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;To Zero Inverted Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åº”ç”¨è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_mean = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2) adaptive_gaussian = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) # æ˜¾ç¤ºè‡ªé€‚åº”é˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(adaptive_mean, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Mean Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(adaptive_gaussian, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Adaptive Gaussian Threshold\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Otsué˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # åº”ç”¨Otsué˜ˆå€¼åˆ†å‰² ret, otsu = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # æ˜¾ç¤ºOtsué˜ˆå€¼åˆ†å‰²ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(otsu, cmap=\u0026#39;gray\u0026#39;) plt.title(f\u0026#39;Otsu Threshold (Threshold={ret})\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() åˆ†æ°´å²­ç®—æ³• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # åˆ›å»ºä¸€ä¸ªç®€å•çš„äºŒå€¼å›¾åƒ binary_image = np.zeros((300, 300), dtype=np.uint8) cv2.circle(binary_image, (100, 100), 50, 255, -1) cv2.circle(binary_image, (200, 200), 50, 255, -1) # åº”ç”¨è·ç¦»å˜æ¢ dist_transform = cv2.distanceTransform(binary_image, cv2.DIST_L2, 5) ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0) sure_fg = np.uint8(sure_fg) # æœªçŸ¥åŒºåŸŸ unknown = cv2.subtract(binary_image, sure_fg) # æ ‡è®°æ ‡ç­¾ ret, markers = cv2.connectedComponents(sure_fg) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(cv2.cvtColor(binary_image, cv2.COLOR_GRAY2BGR), markers) # æ˜¾ç¤ºåˆ†æ°´å²­ç®—æ³•ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 3, 1) plt.imshow(binary_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Binary Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 2) plt.imshow(dist_transform, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Distance Transform\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 3, 3) plt.imshow(markers, cmap=\u0026#39;jet\u0026#39;) plt.title(\u0026#39;Watershed Segmentation\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç‰¹å¾æå– Harrisè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # åº”ç”¨Harrisè§’ç‚¹æ£€æµ‹ gray_float = np.float32(gray_image) harris_corners = cv2.cornerHarris(gray_float, 2, 3, 0.04) # æ‰©å¤§è§’ç‚¹æ ‡è®° harris_corners = cv2.dilate(harris_corners, None) # è®¾ç½®é˜ˆå€¼ threshold = 0.01 * harris_corners.max() corner_image = image_rgb.copy() corner_image[harris_corners \u0026gt; threshold] = [255, 0, 0] # æ˜¾ç¤ºHarrisè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(corner_image) plt.title(\u0026#39;Harris Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() Shi-Tomasiè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # åº”ç”¨Shi-Tomasiè§’ç‚¹æ£€æµ‹ corners = cv2.goodFeaturesToTrack(gray_image, 100, 0.01, 10) corners = np.int0(corners) # ç»˜åˆ¶è§’ç‚¹ shi_tomasi_image = image_rgb.copy() for corner in corners: x, y = corner.ravel() cv2.circle(shi_tomasi_image, (x, y), 3, 255, -1) # æ˜¾ç¤ºShi-Tomasiè§’ç‚¹æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(shi_tomasi_image) plt.title(\u0026#39;Shi-Tomasi Corner Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() SIFTç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºSIFTç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(sift_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;SIFT Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ORBç‰¹å¾æå– 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray_image, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray_image, keypoints, None) # æ˜¾ç¤ºORBç‰¹å¾æå–ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(gray_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(orb_image, cmap=\u0026#39;gray\u0026#39;) plt.title(\u0026#39;ORB Feature Extraction\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() ç›®æ ‡æ£€æµ‹ Haarçº§è”åˆ†ç±»å™¨ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # åŠ è½½Haarçº§è”åˆ†ç±»å™¨ face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_frontalface_default.xml\u0026#39;) eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \u0026#39;haarcascade_eye.xml\u0026#39;) # æ£€æµ‹äººè„¸å’Œçœ¼ç› faces = face_cascade.detectMultiScale(gray_image, 1.3, 5) face_eye_image = image_rgb.copy() for (x, y, w, h) in faces: cv2.rectangle(face_eye_image, (x, y), (x+w, y+h), (255, 0, 0), 2) roi_gray = gray_image[y:y+h, x:x+w] roi_color = face_eye_image[y:y+h, x:x+w] eyes = eye_cascade.detectMultiScale(roi_gray) for (ex, ey, ew, eh) in eyes: cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2) # æ˜¾ç¤ºHaarçº§è”åˆ†ç±»å™¨æ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(face_eye_image) plt.title(\u0026#39;Haar Cascade Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() HOGç‰¹å¾ä¸SVM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from skimage.feature import hog from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score # æå–HOGç‰¹å¾ def extract_hog_features(images): features = [] for image in images: # è®¡ç®—HOGç‰¹å¾ fd = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False) features.append(fd) return np.array(features) # å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›æ ‡è®°çš„å›¾åƒæ•°æ® # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦çœŸå®æ•°æ® # X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2) # æå–è®­ç»ƒå’Œæµ‹è¯•é›†çš„HOGç‰¹å¾ # X_train_hog = extract_hog_features(X_train) # X_test_hog = extract_hog_features(X_test) # è®­ç»ƒSVMåˆ†ç±»å™¨ # svm = SVC(kernel=\u0026#39;linear\u0026#39;) # svm.fit(X_train_hog, y_train) # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° # y_pred = svm.predict(X_test_hog) # accuracy = accuracy_score(y_test, y_pred) # print(f\u0026#34;Accuracy: {accuracy}\u0026#34;) æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ä»£ç ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®‰è£…ç›¸åº”çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ # å¦‚TensorFlowæˆ–PyTorchï¼Œä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ # ä½¿ç”¨TensorFlowå’Œé¢„è®­ç»ƒçš„SSDæ¨¡å‹ \u0026#34;\u0026#34;\u0026#34; import tensorflow as tf # åŠ è½½é¢„è®­ç»ƒçš„SSDæ¨¡å‹ model = tf.saved_model.load(\u0026#39;ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model\u0026#39;) # é¢„å¤„ç†å›¾åƒ input_tensor = tf.convert_to_tensor(image_rgb) input_tensor = input_tensor[tf.newaxis, ...] # è¿è¡Œæ¨¡å‹ detections = model(input_tensor) # è§£ææ£€æµ‹ç»“æœ num_detections = int(detections.pop(\u0026#39;num_detections\u0026#39;)) detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()} detections[\u0026#39;num_detections\u0026#39;] = num_detections # è¿‡æ»¤æ£€æµ‹ç»“æœ min_score_thresh = 0.5 detections[\u0026#39;detection_classes\u0026#39;] = detections[\u0026#39;detection_classes\u0026#39;].astype(np.int64) indexes = np.where(detections[\u0026#39;detection_scores\u0026#39;] \u0026gt; min_score_thresh)[0] # ç»˜åˆ¶æ£€æµ‹ç»“æœ result_image = image_rgb.copy() for i in indexes: class_id = detections[\u0026#39;detection_classes\u0026#39;][i] score = detections[\u0026#39;detection_scores\u0026#39;][i] bbox = detections[\u0026#39;detection_boxes\u0026#39;][i] # å°†å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†è½¬æ¢ä¸ºåƒç´ åæ ‡ h, w, _ = image_rgb.shape y1, x1, y2, x2 = bbox y1, x1, y2, x2 = int(y1 * h), int(x1 * w), int(y2 * h), int(x2 * w) # ç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾ cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2) label = f\u0026#34;{class_id}: {score:.2f}\u0026#34; cv2.putText(result_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # æ˜¾ç¤ºæ£€æµ‹ç»“æœ plt.figure(figsize=(15, 5)) plt.subplot(1, 2, 1) plt.imshow(image_rgb) plt.title(\u0026#39;Original Image\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.subplot(1, 2, 2) plt.imshow(result_image) plt.title(\u0026#39;Deep Learning Object Detection\u0026#39;) plt.axis(\u0026#39;off\u0026#39;) plt.tight_layout() plt.show() \u0026#34;\u0026#34;\u0026#34; æ€»ç»“ è®¡ç®—æœºè§†è§‰æ˜¯ä¸€ä¸ªå¹¿æ³›è€Œæ·±å…¥çš„é¢†åŸŸï¼Œæœ¬æ–‡ä»‹ç»äº†ä»åŸºç¡€çš„å›¾åƒè¡¨ç¤ºå’Œå¤„ç†åˆ°é«˜çº§çš„ç‰¹å¾æå–å’Œç›®æ ‡æ£€æµ‹çš„åŸºæœ¬æ¦‚å¿µå’Œæ–¹æ³•ã€‚é€šè¿‡å­¦ä¹ è¿™äº›åŸºç¡€çŸ¥è¯†ï¼Œè¯»è€…å¯ä»¥ä¸ºè¿›ä¸€æ­¥æ¢ç´¢è®¡ç®—æœºè§†è§‰çš„æ›´é«˜çº§ä¸»é¢˜æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸæ­£åœ¨ç»å†å¿«é€Ÿå˜é©ã€‚ä¼ ç»Ÿçš„è®¡ç®—æœºè§†è§‰æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ ç›¸ç»“åˆï¼Œæ­£åœ¨æ¨åŠ¨è®¡ç®—æœºè§†è§‰åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨ä¸æ–­æ‹“å±•ã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºè§†è§‰çš„åŸºæœ¬åŸç†ï¼Œå¹¶æ¿€å‘è¿›ä¸€æ­¥å­¦ä¹ å’Œæ¢ç´¢çš„å…´è¶£ã€‚\nåœ¨æœªæ¥ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å°†ç»§ç»­å‘å±•ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€å¢å¼ºç°å®ã€æœºå™¨äººæŠ€æœ¯ç­‰é¢†åŸŸå‘æŒ¥è¶Šæ¥è¶Šé‡è¦çš„ä½œç”¨ã€‚æŒæ¡è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå°†ä¸ºè¯»è€…åœ¨è¿™ä¸€å……æ»¡æœºé‡çš„é¢†åŸŸä¸­å‘å±•æä¾›æœ‰åŠ›æ”¯æŒã€‚\n","permalink":"http://localhost:1313/posts/computer-vision-basics/","summary":"\u003ch1 id=\"è®¡ç®—æœºè§†è§‰åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eè®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eè®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºè®©è®¡ç®—æœºèƒ½å¤Ÿä»å›¾åƒæˆ–è§†é¢‘ä¸­è·å–ä¿¡æ¯ã€ç†è§£å†…å®¹å¹¶åšå‡ºå†³ç­–ã€‚ä»ç®€å•çš„å›¾åƒå¤„ç†åˆ°å¤æ‚çš„åœºæ™¯ç†è§£ï¼Œè®¡ç®—æœºè§†è§‰æŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ç›‘æ§ã€äººè„¸è¯†åˆ«ç­‰ä¼—å¤šé¢†åŸŸã€‚æœ¬æ–‡å°†å…¨é¢ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€çŸ¥è¯†ï¼Œå¸®åŠ©è¯»è€…ç†è§£è®¡ç®—æœºå¦‚ä½•\u0026quot;çœ‹æ‡‚\u0026quot;å›¾åƒã€‚\u003c/p\u003e","title":"è®¡ç®—æœºè§†è§‰åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£"},{"content":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\næ·±åº¦å­¦ä¹ ä¸å›¾åƒå¤„ç† ä¼ ç»Ÿå›¾åƒå¤„ç†çš„å±€é™æ€§ ä¼ ç»Ÿå›¾åƒå¤„ç†æ–¹æ³•ä¸»è¦ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ç‰¹å¾æå–å™¨å’Œç®—æ³•ï¼Œè¿™äº›æ–¹æ³•è™½ç„¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š\nç‰¹å¾è®¾è®¡å›°éš¾ï¼šéœ€è¦é¢†åŸŸä¸“å®¶è®¾è®¡ç‰¹å¾ï¼Œè€—æ—¶ä¸”éš¾ä»¥æ³›åŒ–ã€‚ é€‚åº”æ€§å·®ï¼šå¯¹å…‰ç…§ã€è§’åº¦ã€å°ºåº¦ç­‰å˜åŒ–æ•æ„Ÿã€‚ å¤æ‚åœºæ™¯å¤„ç†èƒ½åŠ›æœ‰é™ï¼šéš¾ä»¥å¤„ç†å¤æ‚èƒŒæ™¯å’Œå¤šå˜çš„ç¯å¢ƒã€‚ ç«¯åˆ°ç«¯å­¦ä¹ å›°éš¾ï¼šé€šå¸¸éœ€è¦å¤šä¸ªæ­¥éª¤ç»„åˆï¼Œéš¾ä»¥å®ç°ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚ æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿ æ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œï¼Œé€šè¿‡è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„è®¸å¤šå±€é™ï¼š\nè‡ªåŠ¨ç‰¹å¾æå–ï¼šæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾ï¼Œç½‘ç»œè‡ªåŠ¨å­¦ä¹ æœ€ä¼˜è¡¨ç¤ºã€‚ å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ï¼šå¤šå±‚ç½‘ç»œç»“æ„å¯ä»¥å­¦ä¹ å¤æ‚çš„ç‰¹å¾å±‚æ¬¡ã€‚ ç«¯åˆ°ç«¯å­¦ä¹ ï¼šä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºï¼Œæ•´ä¸ªè¿‡ç¨‹å¯ä¼˜åŒ–ã€‚ é€‚åº”æ€§å¼ºï¼šå¯¹å„ç§å˜åŒ–å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ã€‚ å¤§æ•°æ®é©±åŠ¨ï¼šèƒ½å¤Ÿåˆ©ç”¨å¤§é‡æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚ å·ç§¯ç¥ç»ç½‘ç»œ(CNN) å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†é¢†åŸŸæœ€æˆåŠŸçš„åº”ç”¨ä¹‹ä¸€ï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäºç”Ÿç‰©è§†è§‰ç³»ç»Ÿã€‚\nCNNçš„åŸºæœ¬ç»“æ„ å…¸å‹çš„CNNç”±ä»¥ä¸‹å‡ ç§å±‚ç»„æˆï¼š\nå·ç§¯å±‚(Convolutional Layer)ï¼šä½¿ç”¨å·ç§¯æ ¸æå–å±€éƒ¨ç‰¹å¾ã€‚ æ± åŒ–å±‚(Pooling Layer)ï¼šé™ä½ç©ºé—´ç»´åº¦ï¼Œå‡å°‘è®¡ç®—é‡ã€‚ æ¿€æ´»å‡½æ•°å±‚(Activation Layer)ï¼šå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚ å…¨è¿æ¥å±‚(Fully Connected Layer)ï¼šæ•´åˆç‰¹å¾ï¼Œè¿›è¡Œæœ€ç»ˆåˆ†ç±»æˆ–å›å½’ã€‚ å½’ä¸€åŒ–å±‚(Normalization Layer)ï¼šå¦‚æ‰¹å½’ä¸€åŒ–(Batch Normalization)ï¼ŒåŠ é€Ÿè®­ç»ƒã€‚ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # ä½¿ç”¨PyTorchæ„å»ºç®€å•çš„CNN import torch import torch.nn as nn class SimpleCNN(nn.Module): def __init__(self, num_classes=10): super(SimpleCNN, self).__init__() self.features = nn.Sequential( # å·ç§¯å±‚1 nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚2 nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # å·ç§¯å±‚3 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2) ) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(128 * 28 * 28, 512), # è¾“å…¥å°ºå¯¸éœ€ä¸ç‰¹å¾å›¾å°ºå¯¸ä¸€è‡´ nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(512, num_classes) ) def forward(self, x): # x: è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º (batch_size, 3, 224, 224) æˆ–æ ¹æ®å®é™…è¾“å…¥è°ƒæ•´ # è¿”å›åˆ†ç±»ç»“æœ x = self.features(x) x = x.view(x.size(0), -1) x = self.classifier(x) return x ç»å…¸CNNæ¶æ„ LeNet-5 LeNet-5æ˜¯æœ€æ—©çš„å·ç§¯ç¥ç»ç½‘ç»œä¹‹ä¸€ï¼Œç”±Yann LeCunåœ¨1998å¹´æå‡ºï¼Œä¸»è¦ç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class LeNet5(nn.Module): def __init__(self): super(LeNet5, self).__init__() self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2) self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2) self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1) self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = torch.relu(self.conv1(x)) x = self.pool1(x) x = torch.relu(self.conv2(x)) x = self.pool2(x) x = x.view(-1, 16 * 5 * 5) x = torch.relu(self.fc1(x)) x = torch.relu(self.fc2(x)) x = self.fc3(x) return x AlexNet AlexNetåœ¨2012å¹´ImageNetç«èµ›ä¸­å–å¾—äº†çªç ´æ€§æˆç»©ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å´›èµ·ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class AlexNet(nn.Module): def __init__(self, num_classes=1000): super(AlexNet, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(64, 192, kernel_size=5, padding=2), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), nn.Conv2d(192, 384, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=3, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((6, 6)) self.classifier = nn.Sequential( nn.Dropout(), nn.Linear(256 * 6 * 6, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x VGGNet VGGNetä»¥å…¶ç®€æ´çš„ç»“æ„å’Œå‡ºè‰²çš„æ€§èƒ½è‘—ç§°ï¼Œä¸»è¦ç‰¹ç‚¹æ˜¯ä½¿ç”¨å°å°ºå¯¸å·ç§¯æ ¸å’Œæ·±å±‚ç½‘ç»œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class VGG16(nn.Module): def __init__(self, num_classes=1000): super(VGG16, self).__init__() self.features = nn.Sequential( # Block 1 nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 2 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 3 nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 4 nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), # Block 5 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(kernel_size=2, stride=2), ) self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) self.classifier = nn.Sequential( nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(), nn.Linear(4096, num_classes), ) def forward(self, x): x = self.features(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.classifier(x) return x ResNet ResNeté€šè¿‡å¼•å…¥æ®‹å·®è¿æ¥è§£å†³äº†æ·±å±‚ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—æ„å»ºæ•°ç™¾ç”šè‡³ä¸Šåƒå±‚çš„ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class BasicBlock(nn.Module): expansion = 1 def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample self.stride = stride def forward(self, x): identity = x out = self.conv1(x) out = self.bn1(out) out = nn.ReLU(inplace=True)(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = nn.ReLU(inplace=True)(out) return out class ResNet(nn.Module): def __init__(self, block, layers, num_classes=1000): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2) self.layer3 = self._make_layer(block, 256, layers[2], stride=2) self.layer4 = self._make_layer(block, 512, layers[3], stride=2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) def _make_layer(self, block, channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != channels * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.in_channels, channels * block.expansion, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(channels * block.expansion), ) layers = [] layers.append(block(self.in_channels, channels, stride, downsample)) self.in_channels = channels * block.expansion for _ in range(1, blocks): layers.append(block(self.in_channels, channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = nn.ReLU(inplace=True)(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x def resnet18(): return ResNet(BasicBlock, [2, 2, 2, 2]) CNNåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒåˆ†ç±» å›¾åƒåˆ†ç±»æ˜¯CNNæœ€åŸºæœ¬çš„åº”ç”¨ï¼Œé€šè¿‡è®­ç»ƒç½‘ç»œè¯†åˆ«å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNetè¿›è¡Œå›¾åƒåˆ†ç±» import torchvision.models as models import torchvision.transforms as transforms from PIL import Image # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = models.resnet18(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image) input_batch = input_tensor.unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_batch) # è·å–é¢„æµ‹ç»“æœ _, predicted_idx = torch.max(output, 1) ç›®æ ‡æ£€æµ‹ ç›®æ ‡æ£€æµ‹ä¸ä»…è¯†åˆ«å›¾åƒä¸­çš„å¯¹è±¡ï¼Œè¿˜ç¡®å®šå®ƒä»¬çš„ä½ç½®ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # ä½¿ç”¨Faster R-CNNè¿›è¡Œç›®æ ‡æ£€æµ‹ import torchvision from torchvision.models.detection import fasterrcnn_resnet50_fpn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fasterrcnn_resnet50_fpn(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† transform = transforms.Compose([transforms.ToTensor()]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) image_tensor = transform(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): predictions = model(image_tensor) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡ï¼ŒåŒ…æ‹¬è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ä½¿ç”¨FCNè¿›è¡Œè¯­ä¹‰åˆ†å‰² from torchvision.models.segmentation import fcn # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = fcn.fcn_resnet50(pretrained=True) model.eval() # å›¾åƒé¢„å¤„ç† preprocess = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # åŠ è½½å›¾åƒ image = Image.open(\u0026#34;example.jpg\u0026#34;) input_tensor = preprocess(image).unsqueeze(0) # é¢„æµ‹ with torch.no_grad(): output = model(input_tensor)[\u0026#39;out\u0026#39;] ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN) ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ˜¯ç”±Ian Goodfellowåœ¨2014å¹´æå‡ºçš„ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚\nGANçš„åŸºæœ¬åŸç† GANç”±ä¸¤ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼š\nç”Ÿæˆå™¨(Generator)ï¼šè¯•å›¾ç”Ÿæˆé€¼çœŸçš„æ•°æ®ï¼Œä»¥æ¬ºéª—åˆ¤åˆ«å™¨ã€‚ åˆ¤åˆ«å™¨(Discriminator)ï¼šè¯•å›¾åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆå™¨ç”Ÿæˆçš„å‡æ•°æ®ã€‚ è¿™ä¸¤ä¸ªç½‘ç»œé€šè¿‡å¯¹æŠ—è®­ç»ƒä¸æ–­æ”¹è¿›ï¼Œæœ€ç»ˆç”Ÿæˆå™¨èƒ½å¤Ÿç”Ÿæˆä¸çœŸå®æ•°æ®åˆ†å¸ƒç›¸ä¼¼çš„æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€å•çš„GANå®ç° import torch import torch.nn as nn class Generator(nn.Module): def __init__(self, latent_dim, img_shape): super(Generator, self).__init__() self.img_shape = img_shape def block(in_feat, out_feat, normalize=True): layers = [nn.Linear(in_feat, out_feat)] if normalize: layers.append(nn.BatchNorm1d(out_feat, 0.8)) layers.append(nn.LeakyReLU(0.2, inplace=True)) return layers self.model = nn.Sequential( *block(latent_dim, 128, normalize=False), *block(128, 256), *block(256, 512), *block(512, 1024), nn.Linear(1024, int(np.prod(img_shape))), nn.Tanh() ) def forward(self, z): img = self.model(z) img = img.view(img.size(0), *self.img_shape) return img class Discriminator(nn.Module): def __init__(self, img_shape): super(Discriminator, self).__init__() self.model = nn.Sequential( nn.Linear(int(np.prod(img_shape)), 512), nn.LeakyReLU(0.2, inplace=True), nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True), nn.Linear(256, 1), nn.Sigmoid(), ) def forward(self, img): img_flat = img.view(img.size(0), -1) validity = self.model(img_flat) return validity GANçš„è®­ç»ƒè¿‡ç¨‹ GANçš„è®­ç»ƒè¿‡ç¨‹æ˜¯ä¸€ä¸ªæå°æå¤§åšå¼ˆé—®é¢˜ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # GANè®­ç»ƒå¾ªç¯ import torch.optim as optim # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨ latent_dim = 100 img_shape = (1, 28, 28) # MNISTå›¾åƒå¤§å° generator = Generator(latent_dim, img_shape) discriminator = Discriminator(img_shape) # ä¼˜åŒ–å™¨ optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # æŸå¤±å‡½æ•° adversarial_loss = torch.nn.BCELoss() # è®­ç»ƒå‚æ•° n_epochs = 200 batch_size = 64 for epoch in range(n_epochs): for i, (imgs, _) in enumerate(dataloader): # çœŸå®å’Œå‡çš„æ ‡ç­¾ real = torch.ones(imgs.size(0), 1) fake = torch.zeros(imgs.size(0), 1) # è®­ç»ƒç”Ÿæˆå™¨ optimizer_G.zero_grad() z = torch.randn(imgs.size(0), latent_dim) gen_imgs = generator(z) g_loss = adversarial_loss(discriminator(gen_imgs), real) g_loss.backward() optimizer_G.step() # è®­ç»ƒåˆ¤åˆ«å™¨ optimizer_D.zero_grad() real_loss = adversarial_loss(discriminator(imgs), real) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2 d_loss.backward() optimizer_D.step() å¸¸è§çš„GANå˜ä½“ DCGAN (Deep Convolutional GAN) DCGANå°†CNNç»“æ„å¼•å…¥GANï¼Œæé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè®­ç»ƒç¨³å®šæ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class DCGAN_Generator(nn.Module): def __init__(self, latent_dim, channels=1): super(DCGAN_Generator, self).__init__() self.init_size = 7 # åˆå§‹å¤§å° self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2)) self.conv_blocks = nn.Sequential( nn.BatchNorm2d(128), nn.Upsample(scale_factor=2), nn.Conv2d(128, 128, 3, stride=1, padding=1), nn.BatchNorm2d(128, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Upsample(scale_factor=2), nn.Conv2d(128, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64, 0.8), nn.LeakyReLU(0.2, inplace=True), nn.Conv2d(64, channels, 3, stride=1, padding=1), nn.Tanh(), ) def forward(self, z): out = self.l1(z) out = out.view(out.shape[0], 128, self.init_size, self.init_size) img = self.conv_blocks(out) return img CycleGAN CycleGANç”¨äºåœ¨æ²¡æœ‰æˆå¯¹è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class ResidualBlock(nn.Module): def __init__(self, in_features): super(ResidualBlock, self).__init__() self.block = nn.Sequential( nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features), nn.ReLU(inplace=True), nn.ReflectionPad2d(1), nn.Conv2d(in_features, in_features, 3), nn.InstanceNorm2d(in_features) ) def forward(self, x): return x + self.block(x) class GeneratorResNet(nn.Module): def __init__(self, input_shape, num_residual_blocks): super(GeneratorResNet, self).__init__() channels = input_shape[0] # åˆå§‹å·ç§¯å— out_features = 64 model = [ nn.ReflectionPad2d(3), nn.Conv2d(channels, out_features, 7), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # ä¸‹é‡‡æ · for _ in range(2): out_features *= 2 model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # æ®‹å·®å— for _ in range(num_residual_blocks): model += [ResidualBlock(out_features)] # ä¸Šé‡‡æ · for _ in range(2): out_features //= 2 model += [ nn.Upsample(scale_factor=2), nn.Conv2d(in_features, out_features, 3, stride=1, padding=1), nn.InstanceNorm2d(out_features), nn.ReLU(inplace=True) ] in_features = out_features # è¾“å‡ºå±‚ model += [nn.ReflectionPad2d(3), nn.Conv2d(out_features, channels, 7), nn.Tanh()] self.model = nn.Sequential(*model) def forward(self, x): return self.model(x) StyleGAN StyleGANé€šè¿‡é£æ ¼æ§åˆ¶ç”Ÿæˆé«˜è´¨é‡çš„äººè„¸å›¾åƒï¼Œå…·æœ‰å‡ºè‰²çš„å¯æ§æ€§å’Œå¤šæ ·æ€§ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class StyleGAN_Generator(nn.Module): def __init__(self, latent_dim, n_mlp=8): super(StyleGAN_Generator, self).__init__() # æ˜ å°„ç½‘ç»œ layers = [] for i in range(n_mlp): layers.append(nn.Linear(latent_dim, latent_dim)) layers.append(nn.LeakyReLU(0.2)) self.mapping = nn.Sequential(*layers) # åˆæˆç½‘ç»œ self.synthesis = self._build_synthesis_network(latent_dim) def _build_synthesis_network(self, latent_dim): # è¿™é‡Œç®€åŒ–äº†StyleGANçš„åˆæˆç½‘ç»œç»“æ„ # å®é™…çš„StyleGANç»“æ„æ›´ä¸ºå¤æ‚ï¼ŒåŒ…æ‹¬AdaINã€å™ªå£°æ³¨å…¥ç­‰ layers = nn.ModuleList() # åˆå§‹å¸¸æ•° self.constant_input = nn.Parameter(torch.randn(1, 512, 4, 4)) # ç”Ÿæˆå— in_channels = 512 for i in range(8): # 8ä¸ªä¸Šé‡‡æ ·å— out_channels = min(512, 512 // (2 ** (i // 2))) layers.append(StyleGAN_Block(in_channels, out_channels, upsample=(i \u0026gt; 0))) in_channels = out_channels # è¾“å‡ºå±‚ layers.append(nn.Conv2d(in_channels, 3, 1)) layers.append(nn.Tanh()) return nn.Sequential(*layers) def forward(self, z): # é€šè¿‡æ˜ å°„ç½‘ç»œ w = self.mapping(z) # é€šè¿‡åˆæˆç½‘ç»œ x = self.synthesis(w) return x class StyleGAN_Block(nn.Module): def __init__(self, in_channels, out_channels, upsample=False): super(StyleGAN_Block, self).__init__() self.upsample = upsample if upsample: self.up = nn.Upsample(scale_factor=2, mode=\u0026#39;bilinear\u0026#39;, align_corners=False) self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1) self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1) self.activate = nn.LeakyReLU(0.2) def forward(self, x): if self.upsample: x = self.up(x) x = self.conv1(x) x = self.activate(x) x = self.conv2(x) x = self.activate(x) return x GANåœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ å›¾åƒç”Ÿæˆ GANå¯ä»¥ç”Ÿæˆå„ç§ç±»å‹çš„å›¾åƒï¼Œä»ç®€å•çš„äººè„¸åˆ°å¤æ‚çš„åœºæ™¯ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨é¢„è®­ç»ƒçš„StyleGANç”Ÿæˆäººè„¸ import torch from stylegan2_pytorch import Generator # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ model = Generator(256, 512, 8).cuda() # å‡è®¾æœ‰é¢„è®­ç»ƒæƒé‡ model.load_state_dict(torch.load(\u0026#39;stylegan2-ffhq-config-f.pt\u0026#39;)) model.eval() # ç”Ÿæˆéšæœºæ½œåœ¨å‘é‡ z = torch.randn(1, 512).cuda() # ç”Ÿæˆå›¾åƒ with torch.no_grad(): img = model(z) å›¾åƒä¿®å¤ GANå¯ä»¥ç”¨äºä¿®å¤å›¾åƒä¸­çš„ç¼ºå¤±éƒ¨åˆ†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # ç®€åŒ–çš„å›¾åƒä¿®å¤æ¨¡å‹ class ImageInpainting(nn.Module): def __init__(self): super(ImageInpainting, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(4, 64, 7, stride=1, padding=3), # 4é€šé“ï¼šRGB + mask nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 512, 3, stride=2, padding=1), nn.ReLU(inplace=True), ) # ä¸­é—´å±‚ self.middle = nn.Sequential( nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), nn.Conv2d(512, 512, 3, stride=1, padding=1), nn.ReLU(inplace=True), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 7, stride=1, padding=3), nn.Tanh(), ) def forward(self, x, mask): # è¿æ¥å›¾åƒå’Œæ©ç  x_masked = x * (1 - mask) input = torch.cat([x_masked, mask], dim=1) # ç¼–ç  x = self.encoder(input) # ä¸­é—´å¤„ç† x = self.middle(x) # è§£ç  x = self.decoder(x) # ç»„åˆåŸå§‹å›¾åƒå’Œç”Ÿæˆéƒ¨åˆ† output = x * mask + x_masked return output å›¾åƒè¶…åˆ†è¾¨ç‡ GANå¯ä»¥ç”¨äºå°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 # SRGANç”Ÿæˆå™¨ class SRGAN_Generator(nn.Module): def __init__(self, scale_factor=4): super(SRGAN_Generator, self).__init__() # åˆå§‹å·ç§¯ self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4) self.relu = nn.ReLU(inplace=True) # æ®‹å·®å— residual_blocks = [] for _ in range(16): residual_blocks.append(ResidualBlock(64)) self.residual_blocks = nn.Sequential(*residual_blocks) # ä¸Šé‡‡æ · upsampling = [] for _ in range(int(math.log(scale_factor, 2))): upsampling.append(nn.Conv2d(64, 256, 3, stride=1, padding=1)) upsampling.append(nn.PixelShuffle(2)) upsampling.append(nn.ReLU(inplace=True)) self.upsampling = nn.Sequential(*upsampling) # è¾“å‡ºå±‚ self.conv2 = nn.Conv2d(64, 3, 9, stride=1, padding=4) self.tanh = nn.Tanh() def forward(self, x): # åˆå§‹å·ç§¯ x = self.conv1(x) residual = x x = self.relu(x) # æ®‹å·®å— x = self.residual_blocks(x) # æ®‹å·®è¿æ¥ x = x + residual # ä¸Šé‡‡æ · x = self.upsampling(x) # è¾“å‡º x = self.conv2(x) x = self.tanh(x) return x class ResidualBlock(nn.Module): def __init__(self, channels): super(ResidualBlock, self).__init__() self.conv1 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn1 = nn.BatchNorm2d(channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(channels, channels, 3, stride=1, padding=1) self.bn2 = nn.BatchNorm2d(channels) def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = out + residual return out é£æ ¼è¿ç§» GANå¯ä»¥å®ç°ä»ä¸€ç§è‰ºæœ¯é£æ ¼åˆ°å¦ä¸€ç§é£æ ¼çš„å›¾åƒè½¬æ¢ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ç®€åŒ–çš„é£æ ¼è¿ç§»ç½‘ç»œ class StyleTransfer(nn.Module): def __init__(self): super(StyleTransfer, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 9, stride=1, padding=4), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.InstanceNorm2d(128), nn.ReLU(inplace=True), ) # æ®‹å·®å— residual_blocks = [] for _ in range(5): residual_blocks.append(ResidualBlock(128)) self.residual_blocks = nn.Sequential(*residual_blocks) # è§£ç å™¨ self.decoder = nn.Sequential( nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(64), nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.InstanceNorm2d(32), nn.ReLU(inplace=True), nn.Conv2d(32, 3, 9, stride=1, padding=4), nn.Tanh(), ) def forward(self, x): # ç¼–ç  x = self.encoder(x) # æ®‹å·®å¤„ç† x = self.residual_blocks(x) # è§£ç  x = self.decoder(x) return x å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ è‡ªç¼–ç å™¨(Autoencoder) è‡ªç¼–ç å™¨æ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡ç¼–ç å™¨å°†è¾“å…¥å‹ç¼©ä¸ºä½ç»´è¡¨ç¤ºï¼Œå†é€šè¿‡è§£ç å™¨é‡æ„åŸå§‹è¾“å…¥ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class Autoencoder(nn.Module): def __init__(self, latent_dim): super(Autoencoder, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), nn.Linear(128 * 4 * 4, latent_dim), ) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def forward(self, x): z = self.encoder(x) x_reconstructed = self.decoder(z) return x_reconstructed, z å˜åˆ†è‡ªç¼–ç å™¨(VAE) å˜åˆ†è‡ªç¼–ç å™¨æ˜¯è‡ªç¼–ç å™¨çš„æ¦‚ç‡ç‰ˆæœ¬ï¼Œå¯ä»¥ç”Ÿæˆæ–°çš„æ•°æ®æ ·æœ¬ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 class VAE(nn.Module): def __init__(self, latent_dim): super(VAE, self).__init__() # ç¼–ç å™¨ self.encoder = nn.Sequential( nn.Conv2d(3, 32, 3, stride=2, padding=1), # 16x16 nn.ReLU(inplace=True), nn.Conv2d(32, 64, 3, stride=2, padding=1), # 8x8 nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), # 4x4 nn.ReLU(inplace=True), nn.Flatten(), ) # å‡å€¼å’Œæ–¹å·® self.fc_mu = nn.Linear(128 * 4 * 4, latent_dim) self.fc_var = nn.Linear(128 * 4 * 4, latent_dim) # è§£ç å™¨ self.decoder = nn.Sequential( nn.Linear(latent_dim, 128 * 4 * 4), nn.Unflatten(1, (128, 4, 4)), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 8x8 nn.ReLU(inplace=True), nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 16x16 nn.ReLU(inplace=True), nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), # 32x32 nn.Sigmoid(), ) def encode(self, x): h = self.encoder(x) mu = self.fc_mu(h) log_var = self.fc_var(h) return mu, log_var def reparameterize(self, mu, log_var): std = torch.exp(0.5 * log_var) eps = torch.randn_like(std) z = mu + eps * std return z def decode(self, z): return self.decoder(z) def forward(self, x): mu, log_var = self.encode(x) z = self.reparameterize(mu, log_var) x_reconstructed = self.decode(z) return x_reconstructed, mu, log_var æ‰©æ•£æ¨¡å‹(Diffusion Model) æ‰©æ•£æ¨¡å‹æ˜¯è¿‘å¹´æ¥å…´èµ·çš„ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡é€æ­¥æ·»åŠ å’Œå»é™¤å™ªå£°æ¥ç”Ÿæˆå›¾åƒã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class DiffusionModel(nn.Module): def __init__(self, timesteps=1000): super(DiffusionModel, self).__init__() self.timesteps = timesteps # å™ªå£°è°ƒåº¦å™¨ self.beta = torch.linspace(0.0001, 0.02, timesteps) self.alpha = 1. - self.beta self.alpha_hat = torch.cumprod(self.alpha, dim=0) # U-Netç»“æ„ self.unet = self._build_unet() def _build_unet(self): # ç®€åŒ–çš„U-Netç»“æ„ return nn.Sequential( # ä¸‹é‡‡æ · nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU(inplace=True), nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.ReLU(inplace=True), # ä¸­é—´å±‚ nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), nn.Conv2d(256, 256, 3, padding=1), nn.ReLU(inplace=True), # ä¸Šé‡‡æ · nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(inplace=True), nn.Conv2d(64, 3, 3, padding=1), ) def forward(self, x, t): # æ·»åŠ æ—¶é—´åµŒå…¥ t_emb = self._get_time_embedding(t, x.shape[0]) t_emb = t_emb.view(-1, 1, 1, 1).expand(-1, 3, x.shape[2], x.shape[3]) x = torch.cat([x, t_emb], dim=1) # é€šè¿‡U-Neté¢„æµ‹å™ªå£° noise_pred = self.unet(x) return noise_pred def _get_time_embedding(self, t, batch_size): # ç®€åŒ–çš„æ—¶é—´åµŒå…¥ t = t.view(-1, 1) t = t.float() / self.timesteps t = t * 2 * math.pi sin_t = torch.sin(t) cos_t = torch.cos(t) t_emb = torch.cat([sin_t, cos_t], dim=1) t_emb = t_emb.repeat(1, 3) # æ‰©å±•åˆ°3é€šé“ return t_emb def sample(self, x_shape): # ä»çº¯å™ªå£°å¼€å§‹ x = torch.randn(x_shape) # é€æ­¥å»å™ª for t in reversed(range(self.timesteps)): t_batch = torch.full((x_shape[0],), t, dtype=torch.long) noise_pred = self.forward(x, t_batch) # è®¡ç®—å»å™ªåçš„å›¾åƒ alpha_t = self.alpha[t] alpha_hat_t = self.alpha_hat[t] beta_t = self.beta[t] if t \u0026gt; 0: noise = torch.randn_like(x) else: noise = torch.zeros_like(x) x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_hat_t)) * noise_pred) + torch.sqrt(beta_t) * noise return x è§†è§‰Transformer(ViT) è§†è§‰Transformerå°†Transformeræ¶æ„åº”ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸Šå–å¾—äº†ä¸CNNç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 class PatchEmbed(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768): super(PatchEmbed, self).__init__() self.img_size = img_size self.patch_size = patch_size self.n_patches = (img_size // patch_size) ** 2 self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size) def forward(self, x): x = self.proj(x) # (B, embed_dim, n_patches ** 0.5, n_patches ** 0.5) x = x.flatten(2) # (B, embed_dim, n_patches) x = x.transpose(1, 2) # (B, n_patches, embed_dim) return x class Attention(nn.Module): def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.): super(Attention, self).__init__() self.n_heads = n_heads self.dim = dim self.head_dim = dim // n_heads self.scale = self.head_dim ** -0.5 self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias) self.attn_drop = nn.Dropout(attn_p) self.proj = nn.Linear(dim, dim) self.proj_drop = nn.Dropout(proj_p) def forward(self, x): n_samples, n_tokens, dim = x.shape qkv = self.qkv(x) # (n_samples, n_tokens, 3 * dim) qkv = qkv.reshape(n_samples, n_tokens, 3, self.n_heads, self.head_dim) qkv = qkv.permute(2, 0, 3, 1, 4) # (3, n_samples, n_heads, n_tokens, head_dim) q, k, v = qkv[0], qkv[1], qkv[2] k_t = k.transpose(-2, -1) # (n_samples, n_heads, head_dim, n_tokens) dp = (q @ k_t) * self.scale # (n_samples, n_heads, n_tokens, n_tokens) attn = dp.softmax(dim=-1) # (n_samples, n_heads, n_tokens, n_tokens) attn = self.attn_drop(attn) weighted_avg = attn @ v # (n_samples, n_heads, n_tokens, head_dim) weighted_avg = weighted_avg.transpose(1, 2) # (n_samples, n_tokens, n_heads, head_dim) weighted_avg = weighted_avg.flatten(2) # (n_samples, n_tokens, dim) x = self.proj(weighted_avg) x = self.proj_drop(x) return x class MLP(nn.Module): def __init__(self, in_features, hidden_features, out_features, p=0.): super(MLP, self).__init__() self.fc1 = nn.Linear(in_features, hidden_features) self.act = nn.GELU() self.fc2 = nn.Linear(hidden_features, out_features) self.drop = nn.Dropout(p) def forward(self, x): x = self.fc1(x) x = self.act(x) x = self.drop(x) x = self.fc2(x) x = self.drop(x) return x class Block(nn.Module): def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(Block, self).__init__() self.norm1 = nn.LayerNorm(dim, eps=1e-6) self.attn = Attention(dim, n_heads=n_heads, qkv_bias=qkv_bias, attn_p=attn_p, proj_p=p) self.norm2 = nn.LayerNorm(dim, eps=1e-6) hidden_features = int(dim * mlp_ratio) self.mlp = MLP(in_features=dim, hidden_features=hidden_features, out_features=dim, p=p) def forward(self, x): x = x + self.attn(self.norm1(x)) x = x + self.mlp(self.norm2(x)) return x class VisionTransformer(nn.Module): def __init__(self, img_size=224, patch_size=16, in_channels=3, n_classes=1000, embed_dim=768, depth=12, n_heads=12, mlp_ratio=4.0, qkv_bias=True, p=0., attn_p=0.): super(VisionTransformer, self).__init__() self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_channels=in_channels, embed_dim=embed_dim) self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) self.pos_embed = nn.Parameter(torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)) self.pos_drop = nn.Dropout(p=p) self.blocks = nn.ModuleList([ Block(dim=embed_dim, n_heads=n_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, p=p, attn_p=attn_p) for _ in range(depth) ]) self.norm = nn.LayerNorm(embed_dim, eps=1e-6) self.head = nn.Linear(embed_dim, n_classes) def forward(self, x): n_samples = x.shape[0] x = self.patch_embed(x) cls_token = self.cls_token.expand(n_samples, -1, -1) x = torch.cat((cls_token, x), dim=1) x = x + self.pos_embed x = self.pos_drop(x) for block in self.blocks: x = block(x) x = self.norm(x) cls_token_final = x[:, 0] x = self.head(cls_token_final) return x æ·±åº¦å­¦ä¹ å›¾åƒå¤„ç†çš„æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘ å½“å‰æŒ‘æˆ˜ æ•°æ®éœ€æ±‚ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜ã€‚ è®¡ç®—èµ„æºï¼šè®­ç»ƒå¤§å‹æ¨¡å‹éœ€è¦å¼ºå¤§çš„è®¡ç®—èµ„æºï¼Œé™åˆ¶äº†åº”ç”¨èŒƒå›´ã€‚ å¯è§£é‡Šæ€§ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸è¢«è§†ä¸º\u0026quot;é»‘ç›’\u0026quot;ï¼Œéš¾ä»¥è§£é‡Šå…¶å†³ç­–è¿‡ç¨‹ã€‚ æ³›åŒ–èƒ½åŠ›ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®åˆ†å¸ƒå¤–è¡¨ç°ä¸ä½³ï¼Œé²æ£’æ€§æœ‰å¾…æé«˜ã€‚ é¢†åŸŸé€‚åº”ï¼šå°†æ¨¡å‹ä»ä¸€ä¸ªé¢†åŸŸè¿ç§»åˆ°å¦ä¸€ä¸ªé¢†åŸŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ æœªæ¥æ–¹å‘ è‡ªç›‘ç£å­¦ä¹ ï¼šå‡å°‘å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œä»æœªæ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ ã€‚ å°æ ·æœ¬å­¦ä¹ ï¼šä½¿æ¨¡å‹èƒ½å¤Ÿä»å°‘é‡æ ·æœ¬ä¸­å­¦ä¹ ã€‚ å¤šæ¨¡æ€å­¦ä¹ ï¼šç»“åˆå›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€çš„ä¿¡æ¯ã€‚ ç¥ç»æ¶æ„æœç´¢ï¼šè‡ªåŠ¨è®¾è®¡æœ€ä¼˜çš„ç½‘ç»œç»“æ„ã€‚ æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿï¼šä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œã€‚ å¯è§£é‡ŠAIï¼šæé«˜æ¨¡å‹çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚ é²æ£’æ€§å¢å¼ºï¼šæé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ ·æœ¬å’Œåˆ†å¸ƒå¤–æ•°æ®çš„é²æ£’æ€§ã€‚ æ€»ç»“ æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯CNNå’ŒGANï¼Œå·²ç»å½»åº•æ”¹å˜äº†å›¾åƒå¤„ç†é¢†åŸŸã€‚ä»å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹åˆ°å›¾åƒç”Ÿæˆå’Œé£æ ¼è¿ç§»ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­éƒ½å–å¾—äº†ä»¤äººç©ç›®çš„æˆæœã€‚\nCNNé€šè¿‡å…¶å±€éƒ¨è¿æ¥å’Œæƒå€¼å…±äº«çš„ç‰¹æ€§ï¼Œæœ‰æ•ˆåœ°æå–å›¾åƒçš„å±‚æ¬¡ç‰¹å¾ï¼Œæˆä¸ºå›¾åƒå¤„ç†çš„åŸºç¡€æ¶æ„ã€‚GANé€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„å¯¹æŠ—è®­ç»ƒï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä¸ºå›¾åƒç”Ÿæˆå’Œè½¬æ¢ä»»åŠ¡æä¾›äº†å¼ºå¤§çš„å·¥å…·ã€‚\né™¤äº†CNNå’ŒGANï¼Œè‡ªç¼–ç å™¨ã€å˜åˆ†è‡ªç¼–ç å™¨ã€æ‰©æ•£æ¨¡å‹å’Œè§†è§‰Transformerç­‰æ¨¡å‹ä¹Ÿåœ¨å›¾åƒå¤„ç†ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œä¸æ–­æ¨åŠ¨ç€è¯¥é¢†åŸŸçš„å‘å±•ã€‚\nå°½ç®¡æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†ä»é¢ä¸´æ•°æ®éœ€æ±‚ã€è®¡ç®—èµ„æºã€å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ã€‚æœªæ¥ï¼Œè‡ªç›‘ç£å­¦ä¹ ã€å°æ ·æœ¬å­¦ä¹ ã€å¤šæ¨¡æ€å­¦ä¹ ç­‰æ–¹å‘å°†å¼•é¢†å›¾åƒå¤„ç†é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚\nä½œä¸ºå›¾åƒç®—æ³•å·¥ç¨‹å¸ˆï¼Œäº†è§£å’ŒæŒæ¡è¿™äº›æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹äºè§£å†³å®é™…é—®é¢˜è‡³å…³é‡è¦ã€‚é€šè¿‡ä¸æ–­å­¦ä¹ å’Œå®è·µï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°åº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œæ¨åŠ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åˆ›æ–°å’Œå‘å±•ã€‚\n","permalink":"http://localhost:1313/posts/deep-learning-image-processing/","summary":"\u003ch1 id=\"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ä»cnnåˆ°gan\"\u003eæ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ï¼šä»CNNåˆ°GAN\u003c/h1\u003e\n\u003cp\u003eæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¸ºå›¾åƒå¤„ç†é¢†åŸŸå¸¦æ¥äº†é©å‘½æ€§çš„å˜åŒ–ã€‚ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ï¼Œä»å›¾åƒåˆ†å‰²åˆ°å›¾åƒç”Ÿæˆï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å„é¡¹ä»»åŠ¡ä¸­éƒ½å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚æœ¬æ–‡å°†æ¢è®¨æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„ä¸»è¦åº”ç”¨ï¼Œé‡ç‚¹å…³æ³¨å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)ç­‰æ ¸å¿ƒæ¨¡å‹ã€‚\u003c/p\u003e","title":"æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨"},{"content":"ç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ åœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\nç®—æ³•å¤æ‚åº¦åˆ†æ æ—¶é—´å¤æ‚åº¦ æ—¶é—´å¤æ‚åº¦æ˜¯è¡¡é‡ç®—æ³•æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡å¢é•¿è€Œå¢é•¿çš„é€Ÿç‡ã€‚å¸¸è§çš„æ—¶é—´å¤æ‚åº¦ä»ä½åˆ°é«˜ä¾æ¬¡ä¸ºï¼š\nO(1) - å¸¸æ•°æ—¶é—´ å¸¸æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ï¼Œæ˜¯æœ€ç†æƒ³çš„å¤æ‚åº¦ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šè·å–æ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´  def get_first_element(arr): return arr[0] # æ— è®ºæ•°ç»„å¤šå¤§ï¼Œæ‰§è¡Œæ—¶é—´ç›¸åŒ O(log n) - å¯¹æ•°æ—¶é—´ å¯¹æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„å¯¹æ•°å¢é•¿ï¼Œå¸¸è§äºåˆ†æ²»ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šäºŒåˆ†æŸ¥æ‰¾ å‚æ•°ï¼šarr (List[int])ï¼Œtarget (int) è¿”å›ï¼šç›®æ ‡ç´¢å¼•æˆ–-1 \u0026#34;\u0026#34;\u0026#34; def binary_search(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: mid = (left + right) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 O(n) - çº¿æ€§æ—¶é—´ çº¿æ€§æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 4 5 6 7 # ç¤ºä¾‹ï¼šæŸ¥æ‰¾æ•°ç»„ä¸­çš„æœ€å¤§å€¼ def find_max(arr): max_val = arr[0] for val in arr: if val \u0026gt; max_val: max_val = val return max_val O(n log n) - çº¿æ€§å¯¹æ•°æ—¶é—´ çº¿æ€§å¯¹æ•°æ—¶é—´ç®—æ³•å¸¸è§äºé«˜æ•ˆçš„æ’åºç®—æ³•ï¼Œå¦‚å¿«é€Ÿæ’åºã€å½’å¹¶æ’åºã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # ç¤ºä¾‹ï¼šå½’å¹¶æ’åº def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) right = merge_sort(arr[mid:]) return merge(left, right) def merge(left, right): result = [] i = j = 0 while i \u0026lt; len(left) and j \u0026lt; len(right): if left[i] \u0026lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result.extend(left[i:]) result.extend(right[j:]) return result O(nÂ²) - å¹³æ–¹æ—¶é—´ å¹³æ–¹æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ï¼Œå¸¸è§äºç®€å•çš„æ’åºç®—æ³•å’ŒåµŒå¥—å¾ªç¯ã€‚\n1 2 3 4 5 6 7 8 # ç¤ºä¾‹ï¼šå†’æ³¡æ’åº def bubble_sort(arr): n = len(arr) for i in range(n): for j in range(0, n - i - 1): if arr[j] \u0026gt; arr[j + 1]: arr[j], arr[j + 1] = arr[j + 1], arr[j] return arr O(2â¿) - æŒ‡æ•°æ—¶é—´ æŒ‡æ•°æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡æŒ‡æ•°å¢é•¿ï¼Œé€šå¸¸ç”¨äºè§£å†³NPéš¾é—®é¢˜ã€‚\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;\u0026#34;\u0026#34; ç¤ºä¾‹ï¼šé€’å½’è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼ˆä½æ•ˆç‰ˆæœ¬ï¼‰ å‚æ•°ï¼šn (int) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n \u0026lt;= 1: return n return fibonacci(n - 1) + fibonacci(n - 2) O(n!) - é˜¶ä¹˜æ—¶é—´ é˜¶ä¹˜æ—¶é—´ç®—æ³•çš„æ‰§è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡çš„é˜¶ä¹˜å¢é•¿ï¼Œæ˜¯æœ€å·®çš„å¤æ‚åº¦ï¼Œå¸¸è§äºæš´åŠ›æœç´¢æ‰€æœ‰æ’åˆ—ç»„åˆã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ç¤ºä¾‹ï¼šç”Ÿæˆæ‰€æœ‰æ’åˆ— def permutations(arr): if len(arr) \u0026lt;= 1: return [arr] result = [] for i in range(len(arr)): rest = arr[:i] + arr[i+1:] for p in permutations(rest): result.append([arr[i]] + p) return result ç©ºé—´å¤æ‚åº¦ ç©ºé—´å¤æ‚åº¦è¡¡é‡ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­æ‰€éœ€é¢å¤–ç©ºé—´éšè¾“å…¥è§„æ¨¡å¢é•¿çš„é€Ÿç‡ã€‚\nO(1) - å¸¸æ•°ç©ºé—´ å¸¸æ•°ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æ— å…³ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåŸåœ°äº¤æ¢æ•°ç»„å…ƒç´  def swap_elements(arr, i, j): arr[i], arr[j] = arr[j], arr[i] # ä¸éœ€è¦é¢å¤–ç©ºé—´ O(n) - çº¿æ€§ç©ºé—´ çº¿æ€§ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡æˆçº¿æ€§å…³ç³»ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šå¤åˆ¶æ•°ç»„ def copy_array(arr): return arr.copy() # éœ€è¦ä¸åŸæ•°ç»„å¤§å°ç›¸åŒçš„é¢å¤–ç©ºé—´ O(nÂ²) - å¹³æ–¹ç©ºé—´ å¹³æ–¹ç©ºé—´ç®—æ³•ä½¿ç”¨çš„é¢å¤–ç©ºé—´ä¸è¾“å…¥è§„æ¨¡çš„å¹³æ–¹æˆæ­£æ¯”ã€‚\n1 2 3 # ç¤ºä¾‹ï¼šåˆ›å»ºäºŒç»´æ•°ç»„ def create_2d_array(n): return [[0 for _ in range(n)] for _ in range(n)] # éœ€è¦nÂ²çš„é¢å¤–ç©ºé—´ å¤æ‚åº¦åˆ†ææŠ€å·§ å¾ªç¯åˆ†æ å¯¹äºå¾ªç¯ç»“æ„ï¼Œå¤æ‚åº¦é€šå¸¸ç”±å¾ªç¯æ¬¡æ•°å’Œå¾ªç¯ä½“å†…çš„æ“ä½œå†³å®šã€‚\n1 2 3 4 5 6 7 8 9 10 # O(n) - å•å±‚å¾ªç¯ def example1(n): for i in range(n): # å¾ªç¯næ¬¡ print(i) # O(1)æ“ä½œ # O(nÂ²) - åµŒå¥—å¾ªç¯ def example2(n): for i in range(n): # å¤–å±‚å¾ªç¯næ¬¡ for j in range(n): # å†…å±‚å¾ªç¯næ¬¡ print(i, j) # O(1)æ“ä½œ é€’å½’åˆ†æ å¯¹äºé€’å½’ç®—æ³•ï¼Œå¯ä»¥ä½¿ç”¨é€’å½’æ ‘æˆ–ä¸»å®šç†(Master Theorem)æ¥åˆ†æå¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 # é€’å½’æ ‘åˆ†æï¼šå½’å¹¶æ’åº # T(n) = 2T(n/2) + O(n) # æ¯å±‚æ€»å¤æ‚åº¦ä¸ºO(n)ï¼Œå…±æœ‰log nå±‚ï¼Œå› æ­¤æ€»å¤æ‚åº¦ä¸ºO(n log n) def merge_sort(arr): if len(arr) \u0026lt;= 1: return arr mid = len(arr) // 2 left = merge_sort(arr[:mid]) # T(n/2) right = merge_sort(arr[mid:]) # T(n/2) return merge(left, right) # O(n) å‡æ‘Šåˆ†æ å‡æ‘Šåˆ†æç”¨äºè®¡ç®—ä¸€ç³»åˆ—æ“ä½œçš„å¹³å‡å¤æ‚åº¦ï¼Œå³ä½¿æŸäº›æ“ä½œå¯èƒ½å¾ˆè€—æ—¶ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # åŠ¨æ€æ•°ç»„çš„å‡æ‘Šåˆ†æ # è™½ç„¶å¶å°”éœ€è¦O(n)æ—¶é—´æ‰©å®¹ï¼Œä½†næ¬¡appendæ“ä½œçš„æ€»æ—¶é—´ä¸ºO(n) # å› æ­¤æ¯æ¬¡appendçš„å‡æ‘Šæ—¶é—´ä¸ºO(1) class DynamicArray: def __init__(self): self.capacity = 1 self.size = 0 self.array = [None] * self.capacity def append(self, item): if self.size == self.capacity: self._resize(2 * self.capacity) # O(n)æ“ä½œï¼Œä½†ä¸é¢‘ç¹ self.array[self.size] = item self.size += 1 def _resize(self, new_capacity): new_array = [None] * new_capacity for i in range(self.size): new_array[i] = self.array[i] self.array = new_array self.capacity = new_capacity ç®—æ³•ä¼˜åŒ–ç­–ç•¥ æ—¶é—´ä¼˜åŒ–ç­–ç•¥ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„ é€‰æ‹©åˆé€‚çš„ç®—æ³•å’Œæ•°æ®ç»“æ„æ˜¯ä¼˜åŒ–çš„ç¬¬ä¸€æ­¥ã€‚ä¾‹å¦‚ï¼Œå¯¹äºé¢‘ç¹æŸ¥æ‰¾æ“ä½œï¼Œå“ˆå¸Œè¡¨(O(1))æ¯”æ•°ç»„(O(n))æ›´é«˜æ•ˆã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨å“ˆå¸Œè¡¨ä¼˜åŒ–æŸ¥æ‰¾ def find_duplicates(arr): seen = set() duplicates = [] for item in arr: if item in seen: # O(1)æŸ¥æ‰¾ duplicates.append(item) else: seen.add(item) return duplicates é¢„è®¡ç®—å’Œç¼“å­˜ å¯¹äºé‡å¤è®¡ç®—ï¼Œå¯ä»¥ä½¿ç”¨é¢„è®¡ç®—æˆ–ç¼“å­˜æŠ€æœ¯é¿å…é‡å¤å·¥ä½œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— \u0026#34;\u0026#34;\u0026#34; ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ–æ³¢é‚£å¥‘æ•°åˆ—è®¡ç®— å‚æ•°ï¼šn (int), cache (dict) è¿”å›ï¼šç¬¬né¡¹æ–æ³¢é‚£å¥‘æ•° \u0026#34;\u0026#34;\u0026#34; def fibonacci(n, cache={}): if not isinstance(n, int) or n \u0026lt; 0: raise ValueError(\u0026#34;nå¿…é¡»ä¸ºéè´Ÿæ•´æ•°\u0026#34;) if n in cache: return cache[n] if n \u0026lt;= 1: return n result = fibonacci(n - 1, cache) + fibonacci(n - 2, cache) cache[n] = result return result ä½è¿ç®—ä¼˜åŒ– ä½è¿ç®—é€šå¸¸æ¯”ç®—æœ¯è¿ç®—æ›´å¿«ï¼Œå¯ä»¥ç”¨äºæŸäº›ç‰¹å®šåœºæ™¯çš„ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 # ä½¿ç”¨ä½è¿ç®—åˆ¤æ–­å¥‡å¶ def is_even(n): return (n \u0026amp; 1) == 0 # æ¯”n % 2 == 0æ›´å¿« # ä½¿ç”¨ä½è¿ç®—äº¤æ¢å˜é‡ def swap(a, b): a = a ^ b b = a ^ b a = a ^ b return a, b å¹¶è¡Œè®¡ç®— å¯¹äºå¯ä»¥å¹¶è¡Œå¤„ç†çš„é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨å¤šçº¿ç¨‹æˆ–å¤šè¿›ç¨‹åŠ é€Ÿã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† import concurrent.futures def process_data(data): # å¤„ç†æ•°æ®çš„å‡½æ•°ï¼Œè¿”å›å¤„ç†ç»“æœ result = ... # æ ¹æ®å®é™…éœ€æ±‚å¤„ç† return result def parallel_process(data_list, num_workers=4): with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor: results = list(executor.map(process_data, data_list)) return results ç©ºé—´ä¼˜åŒ–ç­–ç•¥ åŸåœ°ç®—æ³• åŸåœ°ç®—æ³•ä¸éœ€è¦é¢å¤–çš„å­˜å‚¨ç©ºé—´æˆ–åªéœ€è¦å¸¸æ•°çº§åˆ«çš„é¢å¤–ç©ºé—´ã€‚\n1 2 3 4 5 6 7 8 # åŸåœ°åè½¬æ•°ç»„ def reverse_array(arr): left, right = 0, len(arr) - 1 while left \u0026lt; right: arr[left], arr[right] = arr[right], arr[left] left += 1 right -= 1 return arr æ•°æ®å‹ç¼© å¯¹äºå¤§è§„æ¨¡æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å‹ç¼©æŠ€æœ¯å‡å°‘å­˜å‚¨éœ€æ±‚ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # ä½¿ç”¨ç¨€ç–çŸ©é˜µè¡¨ç¤ºä¼˜åŒ–å­˜å‚¨ class SparseMatrix: def __init__(self, rows, cols): self.rows = rows self.cols = cols self.data = {} # åªå­˜å‚¨éé›¶å…ƒç´  def set(self, i, j, value): if value != 0: self.data[(i, j)] = value elif (i, j) in self.data: del self.data[(i, j)] def get(self, i, j): return self.data.get((i, j), 0) æƒ°æ€§è®¡ç®— æƒ°æ€§è®¡ç®—åªåœ¨éœ€è¦æ—¶æ‰è®¡ç®—ç»“æœï¼Œå¯ä»¥èŠ‚çœä¸å¿…è¦çš„è®¡ç®—å’Œå­˜å‚¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # æƒ°æ€§è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ— def lazy_fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b # ä½¿ç”¨ç”Ÿæˆå™¨ fib = lazy_fibonacci() for _ in range(10): print(next(fib)) æ—¶ç©ºæƒè¡¡ æœ‰æ—¶å¯ä»¥é€šè¿‡å¢åŠ ç©ºé—´ä½¿ç”¨æ¥å‡å°‘æ—¶é—´å¤æ‚åº¦ï¼Œæˆ–è€…é€šè¿‡å¢åŠ æ—¶é—´å¤æ‚åº¦æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\nç©ºé—´æ¢æ—¶é—´ ä½¿ç”¨é¢å¤–çš„ç©ºé—´æ¥å­˜å‚¨ä¸­é—´ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ä½¿ç”¨åŠ¨æ€è§„åˆ’ä¼˜åŒ–æœ€é•¿å…¬å…±å­åºåˆ— def longest_common_subsequence(text1, text2): m, n = len(text1), len(text2) # åˆ›å»ºäºŒç»´æ•°ç»„å­˜å‚¨ä¸­é—´ç»“æœ dp = [[0] * (n + 1) for _ in range(m + 1)] for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: dp[i][j] = dp[i - 1][j - 1] + 1 else: dp[i][j] = max(dp[i - 1][j], dp[i][j - 1]) return dp[m][n] æ—¶é—´æ¢ç©ºé—´ é€šè¿‡å¢åŠ è®¡ç®—æ—¶é—´æ¥å‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 # ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ def fibonacci_with_rolling_array(n): if n \u0026lt;= 1: return n # åªä¿å­˜æœ€è¿‘çš„ä¸¤ä¸ªå€¼ a, b = 0, 1 for _ in range(2, n + 1): a, b = b, a + b return b å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ æ’åºç®—æ³•ä¼˜åŒ– å¿«é€Ÿæ’åºä¼˜åŒ– å¿«é€Ÿæ’åºçš„å¹³å‡æ—¶é—´å¤æ‚åº¦ä¸ºO(n log n)ï¼Œä½†åœ¨æœ€åæƒ…å†µä¸‹ä¼šé€€åŒ–åˆ°O(nÂ²)ã€‚ä»¥ä¸‹æ˜¯å‡ ç§ä¼˜åŒ–æ–¹æ³•ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def optimized_quick_sort(arr): # ä½¿ç”¨ä¸‰æ•°å–ä¸­æ³•é€‰æ‹©åŸºå‡†ï¼Œé¿å…æœ€åæƒ…å†µ def median_of_three(left, right): mid = (left + right) // 2 if arr[left] \u0026gt; arr[mid]: arr[left], arr[mid] = arr[mid], arr[left] if arr[left] \u0026gt; arr[right]: arr[left], arr[right] = arr[right], arr[left] if arr[mid] \u0026gt; arr[right]: arr[mid], arr[right] = arr[right], arr[mid] return mid def partition(left, right): # é€‰æ‹©åŸºå‡† pivot_idx = median_of_three(left, right) pivot = arr[pivot_idx] # å°†åŸºå‡†ç§»åˆ°æœ€å³è¾¹ arr[pivot_idx], arr[right] = arr[right], arr[pivot_idx] i = left for j in range(left, right): if arr[j] \u0026lt;= pivot: arr[i], arr[j] = arr[j], arr[i] i += 1 # å°†åŸºå‡†ç§»åˆ°æ­£ç¡®ä½ç½® arr[i], arr[right] = arr[right], arr[i] return i def sort(left, right): # å°æ•°ç»„ä½¿ç”¨æ’å…¥æ’åº if right - left + 1 \u0026lt;= 20: insertion_sort(arr, left, right) return if left \u0026lt; right: pivot_idx = partition(left, right) sort(left, pivot_idx - 1) sort(pivot_idx + 1, right) def insertion_sort(arr, left, right): for i in range(left + 1, right + 1): key = arr[i] j = i - 1 while j \u0026gt;= left and arr[j] \u0026gt; key: arr[j + 1] = arr[j] j -= 1 arr[j + 1] = key sort(0, len(arr) - 1) return arr è®¡æ•°æ’åºä¼˜åŒ– è®¡æ•°æ’åºæ˜¯ä¸€ç§éæ¯”è¾ƒæ’åºç®—æ³•ï¼Œé€‚ç”¨äºæ•´æ•°ä¸”èŒƒå›´ä¸å¤§çš„æƒ…å†µã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def counting_sort(arr, max_val=None): if not arr: return arr if max_val is None: max_val = max(arr) # åˆ›å»ºè®¡æ•°æ•°ç»„ count = [0] * (max_val + 1) # ç»Ÿè®¡æ¯ä¸ªå…ƒç´ çš„å‡ºç°æ¬¡æ•° for num in arr: count[num] += 1 # è®¡ç®—ç´¯ç§¯è®¡æ•° for i in range(1, len(count)): count[i] += count[i - 1] # æ„å»ºæ’åºç»“æœ result = [0] * len(arr) for num in reversed(arr): result[count[num] - 1] = num count[num] -= 1 return result æœç´¢ç®—æ³•ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾ä¼˜åŒ– äºŒåˆ†æŸ¥æ‰¾æ˜¯ä¸€ç§é«˜æ•ˆçš„æœç´¢ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸ºO(log n)ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def binary_search_optimized(arr, target): left, right = 0, len(arr) - 1 while left \u0026lt;= right: # é˜²æ­¢æ•´æ•°æº¢å‡º mid = left + (right - left) // 2 if arr[mid] == target: return mid elif arr[mid] \u0026lt; target: left = mid + 1 else: right = mid - 1 return -1 è·³è¡¨æœç´¢ä¼˜åŒ– è·³è¡¨æ˜¯ä¸€ç§æ¦‚ç‡æ•°æ®ç»“æ„ï¼Œå…è®¸å¿«é€Ÿæœç´¢ï¼Œç±»ä¼¼äºå¹³è¡¡æ ‘ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import random class SkipNode: def __init__(self, val=None, level=0): self.val = val self.next = [None] * level class SkipList: def __init__(self, max_level=16, p=0.5): self.max_level = max_level self.p = p self.level = 1 self.head = SkipNode(None, max_level) def random_level(self): level = 1 while random.random() \u0026lt; self.p and level \u0026lt; self.max_level: level += 1 return level def insert(self, val): update = [None] * self.max_level current = self.head # æ‰¾åˆ°æ’å…¥ä½ç½® for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] update[i] = current # åˆ›å»ºæ–°èŠ‚ç‚¹ node_level = self.random_level() if node_level \u0026gt; self.level: for i in range(self.level, node_level): update[i] = self.head self.level = node_level # æ’å…¥æ–°èŠ‚ç‚¹ new_node = SkipNode(val, node_level) for i in range(node_level): new_node.next[i] = update[i].next[i] update[i].next[i] = new_node def search(self, val): current = self.head for i in range(self.level - 1, -1, -1): while current.next[i] and current.next[i].val \u0026lt; val: current = current.next[i] current = current.next[0] if current and current.val == val: return True return False å›¾ç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ä¼˜åŒ– Dijkstraç®—æ³•ç”¨äºå¯»æ‰¾å•æºæœ€çŸ­è·¯å¾„ï¼Œå¯ä»¥ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import heapq def dijkstra_optimized(graph, start): n = len(graph) dist = [float(\u0026#39;inf\u0026#39;)] * n dist[start] = 0 # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ— pq = [(0, start)] while pq: current_dist, u = heapq.heappop(pq) # å¦‚æœå·²ç»æ‰¾åˆ°æ›´çŸ­è·¯å¾„ï¼Œè·³è¿‡ if current_dist \u0026gt; dist[u]: continue for v, weight in graph[u]: distance = current_dist + weight if distance \u0026lt; dist[v]: dist[v] = distance heapq.heappush(pq, (distance, v)) return dist A*ç®—æ³•ä¼˜åŒ– A*ç®—æ³•æ˜¯ä¸€ç§å¯å‘å¼æœç´¢ç®—æ³•ï¼Œå¸¸ç”¨äºè·¯å¾„è§„åˆ’ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import heapq def a_star_search(graph, start, goal, heuristic): # ä¼˜å…ˆé˜Ÿåˆ—ï¼š(f_score, node) open_set = [(0, start)] # ä»èµ·ç‚¹åˆ°æ¯ä¸ªèŠ‚ç‚¹çš„å®é™…ä»£ä»· g_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} g_score[start] = 0 # ä»èµ·ç‚¹ç»è¿‡æ¯ä¸ªèŠ‚ç‚¹åˆ°ç»ˆç‚¹çš„ä¼°è®¡ä»£ä»· f_score = {node: float(\u0026#39;inf\u0026#39;) for node in graph} f_score[start] = heuristic(start, goal) # è®°å½•è·¯å¾„ came_from = {} while open_set: current_f, current = heapq.heappop(open_set) if current == goal: # é‡å»ºè·¯å¾„ path = [current] while current in came_from: current = came_from[current] path.append(current) return path[::-1] for neighbor in graph[current]: # è®¡ç®—ä»èµ·ç‚¹åˆ°é‚»å±…çš„ä¸´æ—¶g_score tentative_g_score = g_score[current] + graph[current][neighbor] if tentative_g_score \u0026lt; g_score[neighbor]: # æ‰¾åˆ°æ›´å¥½çš„è·¯å¾„ came_from[neighbor] = current g_score[neighbor] = tentative_g_score f_score[neighbor] = g_score[neighbor] + heuristic(neighbor, goal) heapq.heappush(open_set, (f_score[neighbor], neighbor)) return None # æ²¡æœ‰æ‰¾åˆ°è·¯å¾„ åŠ¨æ€è§„åˆ’ä¼˜åŒ– çŠ¶æ€å‹ç¼© å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ä½è¿ç®—è¿›è¡ŒçŠ¶æ€å‹ç¼©ï¼Œå‡å°‘ç©ºé—´ä½¿ç”¨ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # æ—…è¡Œå•†é—®é¢˜(TSP)çš„çŠ¶æ€å‹ç¼©ä¼˜åŒ– def tsp_dp(distances): n = len(distances) # dp[mask][i]è¡¨ç¤ºè®¿é—®è¿‡maskä¸­çš„åŸå¸‚ï¼Œæœ€ååœç•™åœ¨åŸå¸‚içš„æœ€çŸ­è·ç¦» dp = [[float(\u0026#39;inf\u0026#39;)] * n for _ in range(1 \u0026lt;\u0026lt; n)] dp[1][0] = 0 # ä»åŸå¸‚0å¼€å§‹ for mask in range(1 \u0026lt;\u0026lt; n): for i in range(n): if mask \u0026amp; (1 \u0026lt;\u0026lt; i): # å¦‚æœåŸå¸‚iåœ¨maskä¸­ for j in range(n): if not mask \u0026amp; (1 \u0026lt;\u0026lt; j): # å¦‚æœåŸå¸‚jä¸åœ¨maskä¸­ new_mask = mask | (1 \u0026lt;\u0026lt; j) dp[new_mask][j] = min(dp[new_mask][j], dp[mask][i] + distances[i][j]) # è®¡ç®—å›åˆ°èµ·ç‚¹çš„æœ€çŸ­è·ç¦» final_mask = (1 \u0026lt;\u0026lt; n) - 1 min_distance = float(\u0026#39;inf\u0026#39;) for i in range(1, n): min_distance = min(min_distance, dp[final_mask][i] + distances[i][0]) return min_distance æ»šåŠ¨æ•°ç»„ä¼˜åŒ– å¯¹äºæŸäº›åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨æ»šåŠ¨æ•°ç»„ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # æœ€é•¿å…¬å…±å­åºåˆ—çš„æ»šåŠ¨æ•°ç»„ä¼˜åŒ– def lcs_rolling_array(text1, text2): m, n = len(text1), len(text2) # ä½¿ç”¨ä¸¤è¡Œæ•°ç»„ä»£æ›¿å®Œæ•´çš„äºŒç»´æ•°ç»„ prev = [0] * (n + 1) curr = [0] * (n + 1) for i in range(1, m + 1): for j in range(1, n + 1): if text1[i - 1] == text2[j - 1]: curr[j] = prev[j - 1] + 1 else: curr[j] = max(prev[j], curr[j - 1]) # æ»šåŠ¨æ•°ç»„ prev, curr = curr, prev curr = [0] * (n + 1) return prev[n] å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æ å›¾åƒå¤„ç†ä¸­çš„ä¼˜åŒ– å·ç§¯è¿ç®—ä¼˜åŒ– å·ç§¯è¿ç®—æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import numpy as np def naive_convolution(image, kernel): # åŸå§‹å·ç§¯å®ç° height, width = image.shape k_height, k_width = kernel.shape output = np.zeros((height - k_height + 1, width - k_width + 1)) for i in range(output.shape[0]): for j in range(output.shape[1]): output[i, j] = np.sum(image[i:i+k_height, j:j+k_width] * kernel) return output def optimized_convolution(image, kernel): # ä½¿ç”¨FFTåŠ é€Ÿå·ç§¯ from scipy.signal import fftconvolve return fftconvolve(image, kernel, mode=\u0026#39;valid\u0026#39;) def separable_convolution(image, kernel): # å¯åˆ†ç¦»å·ç§¯ä¼˜åŒ– # å¦‚æœkernelå¯ä»¥åˆ†ç¦»ä¸ºæ°´å¹³å’Œå‚ç›´ä¸¤ä¸ªä¸€ç»´æ ¸ # ä¾‹å¦‚ï¼škernel = h_kernel * v_kernel^T # å‡è®¾kernelæ˜¯å¯åˆ†ç¦»çš„ u, s, vh = np.linalg.svd(kernel) h_kernel = u[:, 0] * np.sqrt(s[0]) v_kernel = vh[0, :] * np.sqrt(s[0]) # å…ˆè¿›è¡Œæ°´å¹³å·ç§¯ temp = np.zeros_like(image) for i in range(image.shape[0]): temp[i, :] = np.convolve(image[i, :], h_kernel, mode=\u0026#39;valid\u0026#39;) # å†è¿›è¡Œå‚ç›´å·ç§¯ output = np.zeros((temp.shape[0] - len(v_kernel) + 1, temp.shape[1])) for j in range(temp.shape[1]): output[:, j] = np.convolve(temp[:, j], v_kernel, mode=\u0026#39;valid\u0026#39;) return output å›¾åƒé‡‘å­—å¡”ä¼˜åŒ– å›¾åƒé‡‘å­—å¡”æ˜¯ä¸€ç§å¤šå°ºåº¦è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥ç”¨äºåŠ é€Ÿå›¾åƒå¤„ç†ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def build_gaussian_pyramid(image, levels): pyramid = [image] for _ in range(levels - 1): # ä¸‹é‡‡æ · image = cv2.pyrDown(image) pyramid.append(image) return pyramid def process_with_pyramid(image, process_func, levels=4): # æ„å»ºé‡‘å­—å¡” pyramid = build_gaussian_pyramid(image, levels) # ä»æœ€ç²—çº§åˆ«å¼€å§‹å¤„ç† result = process_func(pyramid[-1]) # é€çº§ä¸Šé‡‡æ ·å¹¶ç»†åŒ– for i in range(levels - 2, -1, -1): # ä¸Šé‡‡æ ·ç»“æœ result = cv2.pyrUp(result) # è°ƒæ•´å¤§å°ä»¥åŒ¹é…å½“å‰çº§åˆ« result = cv2.resize(result, (pyramid[i].shape[1], pyramid[i].shape[0])) # ä¸å½“å‰çº§åˆ«ç»“åˆ result = process_func(pyramid[i], result) return result æœºå™¨å­¦ä¹ ä¸­çš„ä¼˜åŒ– æ¢¯åº¦ä¸‹é™ä¼˜åŒ– æ¢¯åº¦ä¸‹é™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ï¼Œæœ‰å¤šç§å˜ä½“ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import numpy as np def gradient_descent(X, y, learning_rate=0.01, epochs=1000): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def stochastic_gradient_descent(X, y, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): for i in range(m): # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬ xi = X[i:i+1] yi = y[i:i+1] # è®¡ç®—é¢„æµ‹å€¼ prediction = xi.dot(theta) # è®¡ç®—è¯¯å·® error = prediction - yi # è®¡ç®—æ¢¯åº¦ gradient = xi.T.dot(error) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def mini_batch_gradient_descent(X, y, batch_size=32, learning_rate=0.01, epochs=100): m, n = X.shape theta = np.zeros(n) for _ in range(epochs): # éšæœºæ‰“ä¹±æ•°æ® indices = np.random.permutation(m) X_shuffled = X[indices] y_shuffled = y[indices] # åˆ†æ‰¹å¤„ç† for i in range(0, m, batch_size): X_batch = X_shuffled[i:i+batch_size] y_batch = y_shuffled[i:i+batch_size] # è®¡ç®—é¢„æµ‹å€¼ predictions = X_batch.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y_batch # è®¡ç®—æ¢¯åº¦ gradient = X_batch.T.dot(error) / len(X_batch) # æ›´æ–°å‚æ•° theta -= learning_rate * gradient return theta def momentum_gradient_descent(X, y, learning_rate=0.01, momentum=0.9, epochs=1000): m, n = X.shape theta = np.zeros(n) velocity = np.zeros(n) for _ in range(epochs): # è®¡ç®—é¢„æµ‹å€¼ predictions = X.dot(theta) # è®¡ç®—è¯¯å·® error = predictions - y # è®¡ç®—æ¢¯åº¦ gradient = X.T.dot(error) / m # æ›´æ–°é€Ÿåº¦ velocity = momentum * velocity - learning_rate * gradient # æ›´æ–°å‚æ•° theta += velocity return theta çŸ©é˜µè¿ç®—ä¼˜åŒ– åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼ŒçŸ©é˜µè¿ç®—æ˜¯æ ¸å¿ƒæ“ä½œï¼Œå¯ä»¥é€šè¿‡å¤šç§æ–¹å¼ä¼˜åŒ–ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 import numpy as np def naive_matrix_multiply(A, B): # åŸå§‹çŸ©é˜µä¹˜æ³•å®ç° m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(m): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] return C def blocked_matrix_multiply(A, B, block_size=32): # åˆ†å—çŸ©é˜µä¹˜æ³•ä¼˜åŒ– m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) for i in range(0, m, block_size): for j in range(0, p, block_size): for k in range(0, n, block_size): # å¤„ç†å½“å‰å— for ii in range(i, min(i + block_size, m)): for jj in range(j, min(j + block_size, p)): for kk in range(k, min(k + block_size, n)): C[ii, jj] += A[ii, kk] * B[kk, jj] return C def vectorized_matrix_multiply(A, B): # å‘é‡åŒ–çŸ©é˜µä¹˜æ³•ï¼ˆä½¿ç”¨NumPyå†…ç½®å‡½æ•°ï¼‰ return np.dot(A, B) def parallel_matrix_multiply(A, B): # å¹¶è¡ŒçŸ©é˜µä¹˜æ³• from concurrent.futures import ThreadPoolExecutor m, n = A.shape n2, p = B.shape assert n == n2, \u0026#34;çŸ©é˜µç»´åº¦ä¸åŒ¹é…\u0026#34; C = np.zeros((m, p)) def compute_row(i): for j in range(p): for k in range(n): C[i, j] += A[i, k] * B[k, j] with ThreadPoolExecutor() as executor: executor.map(compute_row, range(m)) return C æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ– ç´¢å¼•ä¼˜åŒ– ç´¢å¼•æ˜¯æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–çš„å…³é”®ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æŸ¥è¯¢é€Ÿåº¦ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # ç®€å•çš„Bæ ‘ç´¢å¼•å®ç° class BTreeNode: def __init__(self, leaf=False): self.keys = [] self.children = [] self.leaf = leaf class BTree: def __init__(self, t): self.root = BTreeNode(leaf=True) self.t = t # æœ€å°åº¦æ•° def search(self, key, node=None): if node is None: node = self.root i = 0 while i \u0026lt; len(node.keys) and key \u0026gt; node.keys[i]: i += 1 if i \u0026lt; len(node.keys) and key == node.keys[i]: return True # æ‰¾åˆ°é”® if node.leaf: return False # æœªæ‰¾åˆ°é”® return self.search(key, node.children[i]) def insert(self, key): root = self.root if len(root.keys) == (2 * self.t) - 1: # æ ¹èŠ‚ç‚¹å·²æ»¡ï¼Œåˆ›å»ºæ–°æ ¹èŠ‚ç‚¹ new_root = BTreeNode() new_root.children.append(self.root) self.root = new_root self._split_child(new_root, 0) self._insert_nonfull(new_root, key) else: self._insert_nonfull(root, key) def _split_child(self, parent, index): t = self.t y = parent.children[index] z = BTreeNode(leaf=y.leaf) # å°†yçš„ä¸­é—´é”®æå‡åˆ°çˆ¶èŠ‚ç‚¹ parent.keys.insert(index, y.keys[t-1]) # å°†yçš„ååŠéƒ¨åˆ†é”®å¤åˆ¶åˆ°z z.keys = y.keys[t:(2*t-1)] # å¦‚æœyä¸æ˜¯å¶å­èŠ‚ç‚¹ï¼Œå¤åˆ¶å­èŠ‚ç‚¹ if not y.leaf: z.children = y.children[t:(2*t)] # æ›´æ–°yçš„é”®å’Œå­èŠ‚ç‚¹ y.keys = y.keys[0:(t-1)] y.children = y.children[0:t] # å°†zæ’å…¥çˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹åˆ—è¡¨ parent.children.insert(index + 1, z) def _insert_nonfull(self, node, key): i = len(node.keys) - 1 if node.leaf: # åœ¨å¶å­èŠ‚ç‚¹ä¸­æ’å…¥é”® node.keys.append(0) while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: node.keys[i+1] = node.keys[i] i -= 1 node.keys[i+1] = key else: # æ‰¾åˆ°åˆé€‚çš„å­èŠ‚ç‚¹ while i \u0026gt;= 0 and key \u0026lt; node.keys[i]: i -= 1 i += 1 # å¦‚æœå­èŠ‚ç‚¹å·²æ»¡ï¼Œå…ˆåˆ†è£‚ if len(node.children[i].keys) == (2 * self.t) - 1: self._split_child(node, i) if key \u0026gt; node.keys[i]: i += 1 self._insert_nonfull(node.children[i], key) æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ– æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–æ˜¯æ•°æ®åº“ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¯ä»¥é€šè¿‡å¤šç§ç­–ç•¥ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class QueryOptimizer: def __init__(self, database): self.database = database def optimize_query(self, query): # è§£ææŸ¥è¯¢ parsed_query = self._parse_query(query) # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = self._generate_execution_plans(parsed_query) # è¯„ä¼°æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬ plan_costs = [self._estimate_cost(plan) for plan in plans] # é€‰æ‹©æˆæœ¬æœ€ä½çš„è®¡åˆ’ best_plan = plans[plan_costs.index(min(plan_costs))] return best_plan def _parse_query(self, query): # ç®€åŒ–çš„æŸ¥è¯¢è§£æ # å®é™…å®ç°ä¼šæ›´å¤æ‚ return { \u0026#39;tables\u0026#39;: query.get(\u0026#39;tables\u0026#39;, []), \u0026#39;conditions\u0026#39;: query.get(\u0026#39;conditions\u0026#39;, []), \u0026#39;projections\u0026#39;: query.get(\u0026#39;projections\u0026#39;, []), \u0026#39;order_by\u0026#39;: query.get(\u0026#39;order_by\u0026#39;, []), \u0026#39;limit\u0026#39;: query.get(\u0026#39;limit\u0026#39;, None) } def _generate_execution_plans(self, parsed_query): # ç”Ÿæˆå¯èƒ½çš„æ‰§è¡Œè®¡åˆ’ plans = [] # ç®€å•å®ç°ï¼šåªè€ƒè™‘è¡¨è¿æ¥é¡ºåº tables = parsed_query[\u0026#39;tables\u0026#39;] # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è¡¨è¿æ¥é¡ºåº from itertools import permutations for table_order in permutations(tables): plan = { \u0026#39;table_order\u0026#39;: table_order, \u0026#39;join_method\u0026#39;: \u0026#39;nested_loop\u0026#39;, # å¯ä»¥æ˜¯nested_loop, hash_join, merge_join \u0026#39;access_method\u0026#39;: {table: \u0026#39;index_scan\u0026#39; for table in tables}, # å¯ä»¥æ˜¯full_scan, index_scan \u0026#39;conditions\u0026#39;: parsed_query[\u0026#39;conditions\u0026#39;], \u0026#39;projections\u0026#39;: parsed_query[\u0026#39;projections\u0026#39;], \u0026#39;order_by\u0026#39;: parsed_query[\u0026#39;order_by\u0026#39;], \u0026#39;limit\u0026#39;: parsed_query[\u0026#39;limit\u0026#39;] } plans.append(plan) return plans def _estimate_cost(self, plan): # ä¼°è®¡æ‰§è¡Œè®¡åˆ’çš„æˆæœ¬ cost = 0 # ä¼°è®¡è¡¨è®¿é—®æˆæœ¬ for table in plan[\u0026#39;table_order\u0026#39;]: access_method = plan[\u0026#39;access_method\u0026#39;][table] table_stats = self.database.get_table_stats(table) if access_method == \u0026#39;full_scan\u0026#39;: cost += table_stats[\u0026#39;row_count\u0026#39;] elif access_method == \u0026#39;index_scan\u0026#39;: # å‡è®¾ç´¢å¼•å¯ä»¥è¿‡æ»¤æ‰90%çš„æ•°æ® cost += table_stats[\u0026#39;row_count\u0026#39;] * 0.1 # ä¼°è®¡è¿æ¥æˆæœ¬ for i in range(len(plan[\u0026#39;table_order\u0026#39;]) - 1): join_method = plan[\u0026#39;join_method\u0026#39;] if join_method == \u0026#39;nested_loop\u0026#39;: # åµŒå¥—å¾ªç¯è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] * right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;hash_join\u0026#39;: # å“ˆå¸Œè¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] elif join_method == \u0026#39;merge_join\u0026#39;: # åˆå¹¶è¿æ¥çš„æˆæœ¬ left_table = plan[\u0026#39;table_order\u0026#39;][i] right_table = plan[\u0026#39;table_order\u0026#39;][i+1] left_stats = self.database.get_table_stats(left_table) right_stats = self.database.get_table_stats(right_table) cost += left_stats[\u0026#39;row_count\u0026#39;] + right_stats[\u0026#39;row_count\u0026#39;] # ä¼°è®¡æ’åºæˆæœ¬ if plan[\u0026#39;order_by\u0026#39;]: # å‡è®¾æ’åºæˆæœ¬ä¸ºn log n result_size = cost # ç®€åŒ–å‡è®¾ cost += result_size * np.log2(result_size) return cost æ€§èƒ½åˆ†æå·¥å…· æ—¶é—´åˆ†æå·¥å…· Pythonä¸­çš„æ—¶é—´åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import time import timeit import cProfile import pstats def time_function(func, *args, **kwargs): # ç®€å•çš„æ—¶é—´æµ‹é‡ start_time = time.time() result = func(*args, **kwargs) end_time = time.time() print(f\u0026#34;å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: {end_time - start_time:.6f} ç§’\u0026#34;) return result def benchmark_function(func, *args, **kwargs): # ä½¿ç”¨timeitè¿›è¡Œæ›´ç²¾ç¡®çš„åŸºå‡†æµ‹è¯• import functools wrapped = functools.partial(func, *args, **kwargs) time_taken = timeit.timeit(wrapped, number=1000) print(f\u0026#34;å‡½æ•° {func.__name__} å¹³å‡æ‰§è¡Œæ—¶é—´: {time_taken/1000:.6f} ç§’\u0026#34;) return func(*args, **kwargs) def profile_function(func, *args, **kwargs): # ä½¿ç”¨cProfileè¿›è¡Œè¯¦ç»†æ€§èƒ½åˆ†æ profiler = cProfile.Profile() profiler.enable() result = func(*args, **kwargs) profiler.disable() stats = pstats.Stats(profiler).sort_stats(\u0026#39;cumulative\u0026#39;) stats.print_stats() return result å†…å­˜åˆ†æå·¥å…· Pythonä¸­çš„å†…å­˜åˆ†æ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import sys import tracemalloc import objgraph def get_object_size(obj): # è·å–å¯¹è±¡çš„å†…å­˜å¤§å° return sys.getsizeof(obj) def trace_memory(func, *args, **kwargs): # è·Ÿè¸ªå†…å­˜ä½¿ç”¨æƒ…å†µ tracemalloc.start() result = func(*args, **kwargs) snapshot = tracemalloc.take_snapshot() top_stats = snapshot.statistics(\u0026#39;lineno\u0026#39;) print(\u0026#34;[ å†…å­˜ä½¿ç”¨æœ€å¤šçš„ä»£ç è¡Œ ]\u0026#34;) for stat in top_stats[:10]: print(stat) tracemalloc.stop() return result def analyze_object_growth(func, *args, **kwargs): # åˆ†æå¯¹è±¡å¢é•¿æƒ…å†µ objgraph.show_growth() result = func(*args, **kwargs) objgraph.show_growth() return result å¯è§†åŒ–åˆ†æå·¥å…· ä½¿ç”¨matplotlibå¯è§†åŒ–æ€§èƒ½æ•°æ® 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import matplotlib.pyplot as plt import numpy as np def plot_time_complexity(algorithms, input_sizes, title=\u0026#34;æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒ\u0026#34;): # ç»˜åˆ¶ç®—æ³•æ—¶é—´å¤æ‚åº¦æ¯”è¾ƒå›¾ plt.figure(figsize=(10, 6)) for name, func in algorithms.items(): times = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡æ‰§è¡Œæ—¶é—´ start_time = time.time() func(test_data) end_time = time.time() times.append(end_time - start_time) plt.plot(input_sizes, times, label=name, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;æ‰§è¡Œæ—¶é—´ (ç§’)\u0026#39;) plt.title(title) plt.legend() plt.grid(True) plt.show() def generate_test_data(size): # ç”Ÿæˆæµ‹è¯•æ•°æ® return np.random.rand(size) def plot_memory_usage(func, input_sizes, title=\u0026#34;å†…å­˜ä½¿ç”¨æƒ…å†µ\u0026#34;): # ç»˜åˆ¶å‡½æ•°å†…å­˜ä½¿ç”¨æƒ…å†µå›¾ memory_usage = [] for size in input_sizes: # ç”Ÿæˆæµ‹è¯•æ•°æ® test_data = generate_test_data(size) # æµ‹é‡å†…å­˜ä½¿ç”¨ tracemalloc.start() func(test_data) snapshot = tracemalloc.take_snapshot() current, peak = tracemalloc.get_traced_memory() tracemalloc.stop() memory_usage.append(peak / (1024 * 1024)) # è½¬æ¢ä¸ºMB plt.figure(figsize=(10, 6)) plt.plot(input_sizes, memory_usage, marker=\u0026#39;o\u0026#39;) plt.xlabel(\u0026#39;è¾“å…¥å¤§å°\u0026#39;) plt.ylabel(\u0026#39;å†…å­˜ä½¿ç”¨ (MB)\u0026#39;) plt.title(title) plt.grid(True) plt.show() æ€»ç»“ ç®—æ³•ä¼˜åŒ–æ˜¯æå‡è½¯ä»¶æ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚æœ¬æ–‡ä»ç®—æ³•å¤æ‚åº¦åˆ†æå¼€å§‹ï¼Œä»‹ç»äº†æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦çš„æ¦‚å¿µåŠåˆ†ææ–¹æ³•ï¼Œç„¶åè¯¦ç»†æ¢è®¨äº†å„ç§ä¼˜åŒ–ç­–ç•¥ï¼ŒåŒ…æ‹¬æ—¶é—´ä¼˜åŒ–ã€ç©ºé—´ä¼˜åŒ–å’Œæ—¶ç©ºæƒè¡¡ã€‚\né€šè¿‡å¸¸è§ç®—æ³•ä¼˜åŒ–æ¡ˆä¾‹ï¼Œå¦‚æ’åºç®—æ³•ã€æœç´¢ç®—æ³•ã€å›¾ç®—æ³•å’ŒåŠ¨æ€è§„åˆ’çš„ä¼˜åŒ–ï¼Œæˆ‘ä»¬äº†è§£äº†å¦‚ä½•å°†ç†è®ºåº”ç”¨åˆ°å®è·µä¸­ã€‚å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æå±•ç¤ºäº†ç®—æ³•ä¼˜åŒ–åœ¨å›¾åƒå¤„ç†ã€æœºå™¨å­¦ä¹ å’Œæ•°æ®åº“æŸ¥è¯¢ç­‰é¢†åŸŸçš„å…·ä½“åº”ç”¨ã€‚\næœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†å„ç§æ€§èƒ½åˆ†æå·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå¹¶è¿›è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–ã€‚\nç®—æ³•ä¼˜åŒ–æ˜¯ä¸€ä¸ªæŒç»­å­¦ä¹ å’Œå®è·µçš„è¿‡ç¨‹ã€‚éšç€æŠ€æœ¯çš„å‘å±•ï¼Œæ–°çš„ä¼˜åŒ–æ–¹æ³•å’Œå·¥å…·ä¸æ–­æ¶Œç°ã€‚æŒæ¡è¿™äº›ä¼˜åŒ–æŠ€å·§ï¼Œä¸ä»…èƒ½å¤Ÿæé«˜ä»£ç æ€§èƒ½ï¼Œè¿˜èƒ½åŸ¹å…»ç³»ç»Ÿæ€ç»´å’Œé—®é¢˜è§£å†³èƒ½åŠ›ï¼Œä¸ºæˆä¸ºä¸€åä¼˜ç§€çš„è½¯ä»¶å·¥ç¨‹å¸ˆå¥ å®šåŸºç¡€ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©è¯»è€…æ·±å…¥ç†è§£ç®—æ³•ä¼˜åŒ–çš„åŸç†å’Œæ–¹æ³•ï¼Œå¹¶åœ¨å®é™…å¼€å‘ä¸­çµæ´»åº”ç”¨ï¼Œåˆ›é€ å‡ºæ›´é«˜æ•ˆã€æ›´ä¼˜é›…çš„ä»£ç ã€‚\n","permalink":"http://localhost:1313/posts/algorithm-optimization/","summary":"\u003ch1 id=\"ç®—æ³•ä¼˜åŒ–ä»ç†è®ºåˆ°å®è·µ\"\u003eç®—æ³•ä¼˜åŒ–ï¼šä»ç†è®ºåˆ°å®è·µ\u003c/h1\u003e\n\u003cp\u003eåœ¨è½¯ä»¶å¼€å‘ä¸­ï¼Œç®—æ³•ä¼˜åŒ–æ˜¯æå‡ç¨‹åºæ€§èƒ½çš„å…³é”®ç¯èŠ‚ã€‚ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•å¯ä»¥åœ¨ç›¸åŒç¡¬ä»¶æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜ç¨‹åºçš„è¿è¡Œé€Ÿåº¦ï¼Œå‡å°‘èµ„æºæ¶ˆè€—ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ç®—æ³•ä¼˜åŒ–çš„å„ç§æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä»ç†è®ºåˆ†æåˆ°å®é™…åº”ç”¨ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢æå‡ä»£ç æ€§èƒ½ã€‚\u003c/p\u003e","title":"ç®—æ³•ä¼˜åŒ–ï¼šæå‡ä»£ç æ€§èƒ½çš„å®ç”¨æŠ€å·§"},{"content":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\nå›¾åƒçš„åŸºæœ¬è¡¨ç¤º åƒç´ ä¸å›¾åƒçŸ©é˜µ åœ¨æ•°å­—ä¸–ç•Œä¸­ï¼Œå›¾åƒç”±åƒç´ ï¼ˆPicture Elementï¼Œç®€ç§°Pixelï¼‰ç»„æˆã€‚æ¯ä¸ªåƒç´ ä»£è¡¨å›¾åƒä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…·æœ‰ç‰¹å®šçš„ä½ç½®å’Œå€¼ã€‚å¯¹äºç°åº¦å›¾åƒï¼Œæ¯ä¸ªåƒç´ çš„å€¼è¡¨ç¤ºäº®åº¦ï¼Œé€šå¸¸èŒƒå›´æ˜¯0ï¼ˆé»‘è‰²ï¼‰åˆ°255ï¼ˆç™½è‰²ï¼‰ã€‚å¯¹äºå½©è‰²å›¾åƒï¼Œé€šå¸¸ä½¿ç”¨RGBï¼ˆçº¢ã€ç»¿ã€è“ï¼‰ä¸‰ä¸ªé€šé“è¡¨ç¤ºï¼Œæ¯ä¸ªé€šé“çš„å€¼èŒƒå›´ä¹Ÿæ˜¯0åˆ°255ã€‚\nåœ¨è®¡ç®—æœºä¸­ï¼Œå›¾åƒé€šå¸¸è¡¨ç¤ºä¸ºçŸ©é˜µã€‚ç°åº¦å›¾åƒæ˜¯äºŒç»´çŸ©é˜µï¼Œè€Œå½©è‰²å›¾åƒæ˜¯ä¸‰ç»´çŸ©é˜µï¼ˆé«˜åº¦Ã—å®½åº¦Ã—é€šé“æ•°ï¼‰ã€‚\n1 2 3 4 5 6 7 8 # Pythonä¸­ä½¿ç”¨NumPyè¡¨ç¤ºå›¾åƒ import numpy as np # åˆ›å»ºä¸€ä¸ª100x100çš„ç°åº¦å›¾åƒï¼ˆå…¨é»‘ï¼‰ gray_image = np.zeros((100, 100), dtype=np.uint8) # åˆ›å»ºä¸€ä¸ª100x100x3çš„å½©è‰²å›¾åƒï¼ˆå…¨é»‘ï¼‰ color_image = np.zeros((100, 100, 3), dtype=np.uint8) å›¾åƒç±»å‹ äºŒå€¼å›¾åƒï¼šæ¯ä¸ªåƒç´ åªæœ‰ä¸¤ä¸ªå¯èƒ½çš„å€¼ï¼ˆé€šå¸¸æ˜¯0å’Œ1ï¼‰ï¼Œè¡¨ç¤ºé»‘ç™½ä¸¤è‰²ã€‚ ç°åº¦å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰ä¸€ä¸ªå€¼ï¼Œè¡¨ç¤ºä»é»‘åˆ°ç™½çš„ç°åº¦çº§åˆ«ã€‚ å½©è‰²å›¾åƒï¼šæ¯ä¸ªåƒç´ æœ‰å¤šä¸ªå€¼ï¼Œé€šå¸¸ä½¿ç”¨RGBã€HSVæˆ–CMYKç­‰é¢œè‰²æ¨¡å‹è¡¨ç¤ºã€‚ å¤šå…‰è°±å›¾åƒï¼šåŒ…å«å¤šä¸ªå…‰è°±é€šé“çš„å›¾åƒï¼Œå¦‚å«æ˜Ÿå›¾åƒã€‚ 3Då›¾åƒï¼šè¡¨ç¤ºä¸‰ç»´ç©ºé—´æ•°æ®çš„å›¾åƒï¼Œå¦‚åŒ»å­¦CTæ‰«æã€‚ åŸºæœ¬å›¾åƒæ“ä½œ å›¾åƒè¯»å–ä¸æ˜¾ç¤º ä½¿ç”¨Pythonçš„OpenCVåº“å¯ä»¥è½»æ¾è¯»å–å’Œæ˜¾ç¤ºå›¾åƒï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 import cv2 import matplotlib.pyplot as plt # è¯»å–å›¾åƒ image = cv2.imread(\u0026#39;image.jpg\u0026#39;) # è½¬æ¢é¢œè‰²ç©ºé—´ï¼ˆOpenCVé»˜è®¤ä½¿ç”¨BGRï¼Œè€Œmatplotlibä½¿ç”¨RGBï¼‰ image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # æ˜¾ç¤ºå›¾åƒ plt.imshow(image_rgb) plt.axis(\u0026#39;off\u0026#39;) # ä¸æ˜¾ç¤ºåæ ‡è½´ plt.show() å›¾åƒç¼©æ”¾ä¸æ—‹è½¬ 1 2 3 4 5 6 7 8 # ç¼©æ”¾å›¾åƒ resized_image = cv2.resize(image, (width, height)) # æ—‹è½¬å›¾åƒ (h, w) = image.shape[:2] center = (w // 2, h // 2) M = cv2.getRotationMatrix2D(center, 45, 1.0) # æ—‹è½¬45åº¦ï¼Œç¼©æ”¾å› å­ä¸º1.0 rotated_image = cv2.warpAffine(image, M, (w, h)) å›¾åƒè£å‰ªä¸æ‹¼æ¥ 1 2 3 4 5 6 7 8 # è£å‰ªå›¾åƒ (y1:y2, x1:x2) cropped_image = image[100:400, 200:500] # æ‹¼æ¥å›¾åƒ (æ°´å¹³æ‹¼æ¥) horizontal_concat = np.hstack((image1, image2)) # å‚ç›´æ‹¼æ¥ vertical_concat = np.vstack((image1, image2)) å›¾åƒå¢å¼ºæŠ€æœ¯ äº®åº¦ä¸å¯¹æ¯”åº¦è°ƒæ•´ 1 2 3 4 5 # äº®åº¦è°ƒæ•´ (å¢åŠ 50ä¸ªå•ä½) brightness_image = cv2.add(image, np.ones(image.shape, dtype=np.uint8) * 50) # å¯¹æ¯”åº¦è°ƒæ•´ (1.5å€) contrast_image = cv2.multiply(image, 1.5) ç›´æ–¹å›¾å‡è¡¡åŒ– ç›´æ–¹å›¾å‡è¡¡åŒ–æ˜¯ä¸€ç§å¢å¼ºå›¾åƒå¯¹æ¯”åº¦çš„æ–¹æ³•ï¼Œé€šè¿‡é‡æ–°åˆ†å¸ƒå›¾åƒçš„åƒç´ å¼ºåº¦ï¼Œä½¿å…¶ç›´æ–¹å›¾å¹³å¦åŒ–ã€‚\n1 2 3 # ç°åº¦å›¾åƒç›´æ–¹å›¾å‡è¡¡åŒ– gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) equalized_image = cv2.equalizeHist(gray_image) ä¼½é©¬æ ¡æ­£ ä¼½é©¬æ ¡æ­£ç”¨äºè°ƒæ•´å›¾åƒçš„äº®åº¦ï¼Œç‰¹åˆ«é€‚ç”¨äºæ˜¾ç¤ºè®¾å¤‡çš„éçº¿æ€§å“åº”ã€‚\ngamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼\n1 2 3 4 5 6 7 8 9 # ä¼½é©¬æ ¡æ­£å‡½æ•° def gamma_correction(image, gamma=1.0): # æ„å»ºæŸ¥æ‰¾è¡¨ inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\u0026#34;uint8\u0026#34;) # åº”ç”¨ä¼½é©¬æ ¡æ­£ return cv2.LUT(image, table) gamma_image = gamma_correction(image, 2.2) # å…¸å‹çš„ä¼½é©¬å€¼ å›¾åƒæ»¤æ³¢ å›¾åƒæ»¤æ³¢æ˜¯å›¾åƒå¤„ç†ä¸­çš„åŸºæœ¬æ“ä½œï¼Œç”¨äºå»å™ªã€è¾¹ç¼˜æ£€æµ‹å’Œç‰¹å¾æå–ç­‰ä»»åŠ¡ã€‚\nå‡å€¼æ»¤æ³¢ å‡å€¼æ»¤æ³¢æ˜¯æœ€ç®€å•çš„æ»¤æ³¢æ–¹æ³•ä¹‹ä¸€ï¼Œå®ƒç”¨é‚»åŸŸåƒç´ çš„å¹³å‡å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ã€‚\n1 2 # 5x5å‡å€¼æ»¤æ³¢ blurred_image = cv2.blur(image, (5, 5)) é«˜æ–¯æ»¤æ³¢ é«˜æ–¯æ»¤æ³¢ä½¿ç”¨é«˜æ–¯å‡½æ•°ä½œä¸ºæƒé‡ï¼Œå¯¹é‚»åŸŸåƒç´ è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å™ªå£°åŒæ—¶ä¿ç•™è¾¹ç¼˜ä¿¡æ¯ã€‚\n1 2 # 5x5é«˜æ–¯æ»¤æ³¢ gaussian_blurred = cv2.GaussianBlur(image, (5, 5), 0) ä¸­å€¼æ»¤æ³¢ ä¸­å€¼æ»¤æ³¢ç”¨é‚»åŸŸåƒç´ çš„ä¸­å€¼æ›¿æ¢ä¸­å¿ƒåƒç´ ï¼Œå¯¹äºå»é™¤æ¤’ç›å™ªå£°ç‰¹åˆ«æœ‰æ•ˆã€‚\n1 2 # 5x5ä¸­å€¼æ»¤æ³¢ median_blurred = cv2.medianBlur(image, 5) åŒè¾¹æ»¤æ³¢ åŒè¾¹æ»¤æ³¢åœ¨è€ƒè™‘ç©ºé—´é‚»è¿‘åº¦çš„åŒæ—¶ï¼Œä¹Ÿè€ƒè™‘åƒç´ å€¼çš„ç›¸ä¼¼æ€§ï¼Œèƒ½å¤Ÿåœ¨å¹³æ»‘å›¾åƒçš„åŒæ—¶ä¿ç•™è¾¹ç¼˜ã€‚\n1 2 # åŒè¾¹æ»¤æ³¢ bilateral_filtered = cv2.bilateralFilter(image, 9, 75, 75) è¾¹ç¼˜æ£€æµ‹ è¾¹ç¼˜æ£€æµ‹æ˜¯å›¾åƒå¤„ç†ä¸­çš„é‡è¦ä»»åŠ¡ï¼Œç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“è¾¹ç•Œã€‚\nSobelç®—å­ 1 2 3 4 5 6 7 8 9 10 11 12 # è½¬æ¢ä¸ºç°åº¦å›¾åƒ gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Sobelè¾¹ç¼˜æ£€æµ‹ sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3) # æ°´å¹³æ–¹å‘ sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3) # å‚ç›´æ–¹å‘ # è®¡ç®—æ¢¯åº¦å¹…å€¼ gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2) # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´ gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255) Cannyè¾¹ç¼˜æ£€æµ‹ Cannyè¾¹ç¼˜æ£€æµ‹æ˜¯ä¸€ç§å¤šé˜¶æ®µçš„è¾¹ç¼˜æ£€æµ‹ç®—æ³•ï¼Œè¢«è®¤ä¸ºæ˜¯ç›®å‰æœ€ä¼˜çš„è¾¹ç¼˜æ£€æµ‹æ–¹æ³•ä¹‹ä¸€ã€‚\n1 2 # Cannyè¾¹ç¼˜æ£€æµ‹ edges = cv2.Canny(gray, 100, 200) # é˜ˆå€¼1å’Œé˜ˆå€¼2 Laplacianç®—å­ 1 2 3 # Laplacianè¾¹ç¼˜æ£€æµ‹ laplacian = cv2.Laplacian(gray, cv2.CV_64F) laplacian = np.uint8(np.absolute(laplacian)) å½¢æ€å­¦æ“ä½œ å½¢æ€å­¦æ“ä½œåŸºäºå›¾åƒçš„å½¢çŠ¶ï¼Œå¸¸ç”¨äºäºŒå€¼å›¾åƒçš„å¤„ç†ã€‚\nè…èš€ä¸è†¨èƒ€ 1 2 3 4 5 6 7 8 # åˆ›å»ºä¸€ä¸ª5x5çš„æ ¸ kernel = np.ones((5, 5), np.uint8) # è…èš€æ“ä½œ eroded_image = cv2.erode(binary_image, kernel, iterations=1) # è†¨èƒ€æ“ä½œ dilated_image = cv2.dilate(binary_image, kernel, iterations=1) å¼€è¿ç®—ä¸é—­è¿ç®— 1 2 3 4 5 # å¼€è¿ç®—ï¼ˆå…ˆè…èš€åè†¨èƒ€ï¼‰ opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel) # é—­è¿ç®—ï¼ˆå…ˆè†¨èƒ€åè…èš€ï¼‰ closing = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel) å½¢æ€å­¦æ¢¯åº¦ 1 2 # å½¢æ€å­¦æ¢¯åº¦ï¼ˆè†¨èƒ€å‡è…èš€ï¼‰ gradient = cv2.morphologyEx(binary_image, cv2.MORPH_GRADIENT, kernel) å›¾åƒåˆ†å‰² å›¾åƒåˆ†å‰²æ˜¯å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸæˆ–å¯¹è±¡çš„è¿‡ç¨‹ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦ä»»åŠ¡ã€‚\né˜ˆå€¼åˆ†å‰² 1 2 3 4 5 6 # å…¨å±€é˜ˆå€¼åˆ†å‰² _, thresholded = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) # è‡ªé€‚åº”é˜ˆå€¼åˆ†å‰² adaptive_threshold = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2) åˆ†æ°´å²­ç®—æ³• åˆ†æ°´å²­ç®—æ³•æ˜¯ä¸€ç§åŸºäºæ‹“æ‰‘ç†è®ºçš„å›¾åƒåˆ†å‰²æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºå¯¹æ¥è§¦ç‰©ä½“çš„åˆ†å‰²ã€‚\n1 2 3 4 5 6 7 8 # æ ‡è®°èƒŒæ™¯å’Œå‰æ™¯ ret, markers = cv2.connectedComponents(sure_foreground) markers = markers + 1 markers[unknown == 255] = 0 # åº”ç”¨åˆ†æ°´å²­ç®—æ³• markers = cv2.watershed(image, markers) image[markers == -1] = [255, 0, 0] # æ ‡è®°åˆ†æ°´å²­è¾¹ç•Œ K-meansèšç±» 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # å°†å›¾åƒé‡å¡‘ä¸º2Dæ•°ç»„ pixel_values = image.reshape((-1, 3)) pixel_values = np.float32(pixel_values) # å®šä¹‰åœæ­¢æ ‡å‡†å’ŒKå€¼ criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2) k = 3 # åº”ç”¨K-meansèšç±» _, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) # è½¬æ¢å›åŸå§‹å›¾åƒå½¢çŠ¶å¹¶åº”ç”¨èšç±»ç»“æœ centers = np.uint8(centers) segmented_image = centers[labels.flatten()] segmented_image = segmented_image.reshape(image.shape) å›¾åƒç‰¹å¾æå– ç‰¹å¾æå–æ˜¯ä»å›¾åƒä¸­æå–æœ‰æ„ä¹‰ä¿¡æ¯çš„è¿‡ç¨‹ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥ç”¨äºå›¾åƒè¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢ç­‰ä»»åŠ¡ã€‚\nè§’ç‚¹æ£€æµ‹ 1 2 3 4 5 6 7 # Harrisè§’ç‚¹æ£€æµ‹ gray = np.float32(gray) harris_corners = cv2.cornerHarris(gray, 2, 3, 0.04) harris_corners = cv2.dilate(harris_corners, None) # æ ‡è®°è§’ç‚¹ image[harris_corners \u0026gt; 0.01 * harris_corners.max()] = [0, 0, 255] SIFTç‰¹å¾ SIFTï¼ˆScale-Invariant Feature Transformï¼‰æ˜¯ä¸€ç§ç”¨äºæ£€æµ‹å’Œæè¿°å›¾åƒå±€éƒ¨ç‰¹å¾çš„ç®—æ³•ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºSIFTå¯¹è±¡ sift = cv2.SIFT_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = sift.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ sift_image = cv2.drawKeypoints(gray, keypoints, None) ORBç‰¹å¾ ORBæ˜¯ä¸€ç§å¿«é€Ÿçš„ç‰¹å¾æ£€æµ‹å™¨å’Œæè¿°ç¬¦ï¼Œç»“åˆäº†FASTå…³é”®ç‚¹æ£€æµ‹å™¨å’ŒBRIEFæè¿°ç¬¦ã€‚\n1 2 3 4 5 6 7 8 # åˆ›å»ºORBå¯¹è±¡ orb = cv2.ORB_create() # æ£€æµ‹å…³é”®ç‚¹å’Œè®¡ç®—æè¿°ç¬¦ keypoints, descriptors = orb.detectAndCompute(gray, None) # ç»˜åˆ¶å…³é”®ç‚¹ orb_image = cv2.drawKeypoints(gray, keypoints, None) åº”ç”¨åœºæ™¯ å›¾åƒå¤„ç†æŠ€æœ¯å¹¿æ³›åº”ç”¨äºå„ä¸ªé¢†åŸŸï¼š\nåŒ»å­¦å½±åƒï¼šCTã€MRIå›¾åƒçš„åˆ†æå’Œè¯Šæ–­ï¼Œç»†èƒè®¡æ•°ï¼Œç—…å˜æ£€æµ‹ç­‰ã€‚ è‡ªåŠ¨é©¾é©¶ï¼šè½¦é“çº¿æ£€æµ‹ï¼Œéšœç¢ç‰©è¯†åˆ«ï¼Œäº¤é€šæ ‡å¿—è¯†åˆ«ç­‰ã€‚ å®‰é˜²ç›‘æ§ï¼šäººè„¸è¯†åˆ«ï¼Œè¡Œä¸ºåˆ†æï¼Œå¼‚å¸¸æ£€æµ‹ç­‰ã€‚ å·¥ä¸šæ£€æµ‹ï¼šäº§å“ç¼ºé™·æ£€æµ‹ï¼Œå°ºå¯¸æµ‹é‡ï¼Œè´¨é‡æ§åˆ¶ç­‰ã€‚ é¥æ„Ÿå›¾åƒï¼šåœŸåœ°åˆ©ç”¨åˆ†ç±»ï¼Œç¯å¢ƒç›‘æµ‹ï¼Œç¾å®³è¯„ä¼°ç­‰ã€‚ å¢å¼ºç°å®ï¼šå›¾åƒé…å‡†ï¼Œç›®æ ‡è·Ÿè¸ªï¼Œåœºæ™¯ç†è§£ç­‰ã€‚ æ•°å­—å¨±ä¹ï¼šå›¾åƒç¾åŒ–ï¼Œç‰¹æ•ˆå¤„ç†ï¼Œè™šæ‹Ÿç°å®ç­‰ã€‚ æ€»ç»“ å›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰çš„åŸºç¡€ï¼Œæ¶µç›–äº†ä»åŸºæœ¬çš„åƒç´ æ“ä½œåˆ°å¤æ‚çš„ç‰¹å¾æå–å’Œåˆ†æã€‚æœ¬æ–‡ä»‹ç»äº†å›¾åƒçš„åŸºæœ¬è¡¨ç¤ºã€åŸºæœ¬æ“ä½œã€å›¾åƒå¢å¼ºæŠ€æœ¯ã€æ»¤æ³¢æ–¹æ³•ã€è¾¹ç¼˜æ£€æµ‹ã€å½¢æ€å­¦æ“ä½œã€å›¾åƒåˆ†å‰²å’Œç‰¹å¾æå–ç­‰å†…å®¹ã€‚\næŒæ¡è¿™äº›åŸºç¡€çŸ¥è¯†å¯¹äºè¿›ä¸€æ­¥å­¦ä¹ è®¡ç®—æœºè§†è§‰å’Œæ·±åº¦å­¦ä¹ è‡³å…³é‡è¦ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸éœ€è¦æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©åˆé€‚çš„å›¾åƒå¤„ç†æ–¹æ³•ï¼Œå¹¶å¯èƒ½éœ€è¦ç»„åˆå¤šç§æŠ€æœ¯æ¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚\néšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å‘å±•ï¼Œè®¸å¤šä¼ ç»Ÿçš„å›¾åƒå¤„ç†ä»»åŠ¡ç°åœ¨ä¹Ÿå¯ä»¥é€šè¿‡æ·±åº¦å­¦ä¹ æ–¹æ³•å®ç°ï¼Œä½†ç†è§£ä¼ ç»Ÿå›¾åƒå¤„ç†çš„åŸºæœ¬åŸç†ä»ç„¶éå¸¸é‡è¦ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚\nå¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ å…¥é—¨å›¾åƒå¤„ç†é¢†åŸŸï¼Œä¸ºåç»­çš„å­¦ä¹ å’Œç ”ç©¶æ‰“ä¸‹åšå®çš„åŸºç¡€ã€‚\n","permalink":"http://localhost:1313/posts/image-processing-basics/","summary":"\u003ch1 id=\"å›¾åƒå¤„ç†åŸºç¡€ä»åƒç´ åˆ°ç†è§£\"\u003eå›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°ç†è§£\u003c/h1\u003e\n\u003cp\u003eå›¾åƒå¤„ç†æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åŸºç¡€ï¼Œå®ƒæ¶‰åŠå¯¹å›¾åƒè¿›è¡Œå„ç§æ“ä½œä»¥æå–æœ‰ç”¨ä¿¡æ¯ã€å¢å¼ºå›¾åƒè´¨é‡æˆ–å‡†å¤‡å›¾åƒè¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚æœ¬æ–‡å°†ä»‹ç»å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µã€å¸¸ç”¨æŠ€æœ¯å’Œåº”ç”¨åœºæ™¯ã€‚\u003c/p\u003e","title":"å›¾åƒå¤„ç†åŸºç¡€ï¼šä»åƒç´ åˆ°æ»¤æ³¢"},{"content":"404 - é¡µé¢ä¸å­˜åœ¨ æŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\næ‚¨å¯ä»¥å°è¯•ï¼š è¿”å›é¦–é¡µ æŸ¥çœ‹æ–‡ç« åˆ—è¡¨ ä½¿ç”¨æœç´¢åŠŸèƒ½ æŸ¥çœ‹ç½‘ç«™åœ°å›¾ å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡å…³äºé¡µé¢ä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\n","permalink":"http://localhost:1313/404/","summary":"\u003ch1 id=\"404---é¡µé¢ä¸å­˜åœ¨\"\u003e404 - é¡µé¢ä¸å­˜åœ¨\u003c/h1\u003e\n\u003cp\u003eæŠ±æ­‰ï¼Œæ‚¨è®¿é—®çš„é¡µé¢ä¸å­˜åœ¨ã€‚\u003c/p\u003e\n\u003ch2 id=\"æ‚¨å¯ä»¥å°è¯•\"\u003eæ‚¨å¯ä»¥å°è¯•ï¼š\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/\"\u003eè¿”å›é¦–é¡µ\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/posts/\"\u003eæŸ¥çœ‹æ–‡ç« åˆ—è¡¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/search/\"\u003eä½¿ç”¨æœç´¢åŠŸèƒ½\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/sitemap.xml\"\u003eæŸ¥çœ‹ç½‘ç«™åœ°å›¾\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eå¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·é€šè¿‡\u003ca href=\"/about/\"\u003eå…³äºé¡µé¢\u003c/a\u003eä¸­çš„è”ç³»æ–¹å¼ä¸æˆ‘è”ç³»ã€‚\u003c/p\u003e","title":"404 é¡µé¢ä¸å­˜åœ¨"}]